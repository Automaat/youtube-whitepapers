{"text": " Witajcie. Dzisiaj we\u017amiemy na warsztat jeden z tych problem\u00f3w w \u015bwiecie AI, kt\u00f3ry na pierwszy rzut oka wydaje si\u0119 prosty, ale tak naprawd\u0119 jest niesamowicie z\u0142o\u017cony. Wyobra\u017amy sobie takiego no cyfrowego eksperta. Rozwi\u0105\u017ce ka\u017cde zadanie, ale jest jeden haczyk. Musimy mu pokaza\u0107 par\u0119 przyk\u0142ad\u00f3w. Czyli takie uczenie na wzorach? Dok\u0142adnie. Dajesz mu trzy rozwi\u0105zane zadania z fizyki, on bez problemu robi czwarte. Ale jak dasz mu co\u015b z chemii, bez \u017cadnego przyk\u0142adu i powiesz tylko, zr\u00f3b to, to nagle klapa. I to jest w\u0142a\u015bnie ten dylemat Fuse Shot kontra Zero Shot, prawda? W\u0142a\u015bnie. Modele takie jak GPT-3 s\u0105 niesamowite w trybie Fuse Shot z podpowiedziami, ale w Zero Shot na zimno ich skupeczno\u015b\u0107 no leci na \u0142eb na szyj\u0119. Pytanie brzmi. Jak nauczy\u0107 model, \u017ceby naprawd\u0119 rozumia\u0142 polecenia, a nie tylko kopiowa\u0142 wzorce? A odpowiedzi poszukamy dzisiaj w moim zdaniem prze\u0142omowym artykule z Google Research. Tytu\u0142 to Find Tuned Language Models or Zero Shot Learners. Dok\u0142adnie. A celem jest zrozumienie jednej w sumie prostej, ale genialnej koncepcji. Instruction Tuning. To jest metoda, kt\u00f3ra stworzy\u0142a model Flan i kt\u00f3ra no w pewnym sensie uczy model, jak si\u0119 uczy\u0107. Dobrze, rozpakujmy to. Instruction Tuning. Jaka jest g\u0142\u00f3wna idea? Bo wiesz, jak o tym my\u015bl\u0119, to od razu mam w g\u0142owie tak\u0105 analogi\u0119. O, ciekawe. Wyobra\u017amy sobie studenta. Zamiast wk\u00f3\u0142ko pokazywa\u0107 mu te same rozwi\u0105zane zadania z algebry, dajemy mu taki gruby podr\u0119cznik. Z instrukcjami, przyk\u0142adami, ale z r\u00f3\u017cnych dziedzin. Algebra, geometria, analiza, logika. Czyli poszerzamy mu horyzonty? Tak, a potem na egzaminie rzucamy mu zadanie z trygonometrii, kt\u00f3rej nigdy nie widzia\u0142. I liczymy, \u017ce on nauczy\u0142 si\u0119 nie schemat\u00f3w, tylko og\u00f3lnej metodyki rozwi\u0105zywania problem\u00f3w z instrukcji. To jest idealne por\u00f3wnanie. Naprawd\u0119, bo \u015bwietnie oddaj\u0119 filozofi\u0119 tego podej\u015bcia. M\u00f3wi\u0105c ju\u017c tak bardziej technicznie, badacze wzi\u0119li pot\u0119\u017cny model Lambda PT 137 miliard\u00f3w parametr\u00f3w. Czyli ju\u017c wytrenowan\u0105 besti\u0119. Dok\u0142adnie. I zamiast go specjalizowa\u0107, zrobili co\u015b odwrotnego. Wystawili go na ponad 60 r\u00f3\u017cnych zbior\u00f3w danych z NLP, ale kluczowa by\u0142a nie ilo\u015b\u0107, a forma. Forma. Co masz na my\u015bli? Ka\u017cdy, nawet taki najbardziej suchy przyk\u0142ad, zosta\u0142 przeformu\u0142owany w naturalne ludzkie polecenie. Czyli zamiast dawa\u0107 mu po prostu par\u0119 tekst A, tekst B i kaza\u0107 zgadn\u0105\u0107 relacje, zadawali mu pytanie, kt\u00f3re my by\u015bmy zadali. Na przyk\u0142ad w zadaniu wnioskowania zamiast suchego przes\u0142anka hipoteza model dostawa\u0142 pytanie na podstawie tego akapitu, czy mo\u017cemy wnioskowa\u0107, \u017ce tu tre\u015b\u0107 hipotezy odpowied\u017a tak lub nie. To nie by ma\u0142a zmiana, ale wydaje si\u0119 fundamentalna. Bo jest model zaczyna kojarzy\u0107 j\u0119zyk naturalny, w kt\u00f3rym my ludzie wydajemy polecenia z konkretnym zadaniem, kt\u00f3re ma wykona\u0107. Czyli to nie jest ani taki klasyczny Fine Tuning, gdzie rze\u017abimy model pod jedno zadanie? Nie. Ani nie jest to podej\u015bcie w stylu GPT-3, gdzie liczymy, \u017ce on sam za\u0142apie schemat spalu przyk\u0142ad\u00f3w. To jest jaka\u015b no trzecia droga. W\u0142a\u015bnie tak. To podej\u015bcie hybrydowy. U\u017cywa mechanizmu Fine Tuning, ale nie \u017ceby specjalizowa\u0107, tylko \u017ceby generalizowa\u0107. Celem nie jest stworzenie mistrza w jednej dziedzinie. Tylko wszechstronnego ucznia. Dok\u0142adnie. Ucznia, kt\u00f3ry potrafi pod\u0105\u017ca\u0107 za instrukcjami. Chodzi o to, \u017ceby model nauczy\u0142 si\u0119, jak si\u0119 uczy\u0107, kiedy dostaje nowe polecenie. Brzmi \u015bwietnie w teorii. Stworzy\u0107 uniwersalnego ucznia. Ale teoria w AI to jedno, a praktyka, no, bywa r\u00f3\u017cnie. Jak to wypad\u0142o w rzeczywisto\u015bci? Zadzia\u0142a\u0142o? Trenowali go na wszystkim, opr\u00f3cz NLI. A potem rzucili go na g\u0142\u0119bok\u0105 wod\u0119. I co si\u0119 sta\u0142o? Wyniki by\u0142y, no, spektakularne. Flan, maj\u0105cy 137 miliard\u00f3w parametr\u00f3w w trybie Zero Shot, czyli bez \u017cadnych przyk\u0142ad\u00f3w, pokona\u0142 wi\u0119kszy od siebie model GPT-3, 175 miliard\u00f3w parametr\u00f3w na przyt\u0142aczaj\u0105cej wi\u0119kszo\u015bci test\u00f3w. M\u00f3wimy tu o zwyci\u0119stwie na 20 z 25 zada\u0144. Wow. A poprawa w stosunku do jego w\u0142asnej wersji bazowej, bez tego Instruction Tuning, by\u0142a wr\u0119cz astronomiczna. W zadaniach wymagaj\u0105cych rozumowania bazowy model mia\u0142 powiedzmy 10-20% poprawno\u015bci. Czyli w zasadzie strzela\u0142? Praktycznie tak. A po treningu instrukcjami ten sam model nagle wskakiwa\u0142 na 60-70, czasem nawet 80%. To jest niewiarygodne, ale czyta\u0142em, \u017ce by\u0142o tam co\u015b jeszcze, co\u015b jeszcze bardziej zaskakuj\u0105cego. Pono\u0107 Flan w niekt\u00f3rych zadaniach pobi\u0142 GPT-3, dzia\u0142aj\u0105cy w trybie Fuse Shot. Tak, czyli z dost\u0119pem do \u015bci\u0105gi. Jak to jest w og\u00f3le mo\u017cliwe? Model bez \u017cadnych przyk\u0142ad\u00f3w jest lepszy od wi\u0119kszego modelu, kt\u00f3ry je dosta\u0142, szczeg\u00f3lnie w tych zadaniach NLI, o kt\u00f3rych wspomnia\u0142e\u015b. No i to jest jeden z najciekawszych wniosk\u00f3w. NLI to s\u0105 zadania typu prawda, fa\u0142sz, niewiadomo dla maszyn. Ok. Okazuje si\u0119, \u017ce dla modeli jak GPT-3 te zadania cz\u0119sto formu\u0142owano w bardzo sztuczny spos\u00f3b, jako doka\u0144czanie zdania. A Flan dzi\u0119ki treningowi oczekiwa\u0142 po prostu naturalnego pytania. Jego spos\u00f3b my\u015blenia by\u0142 lepiej dopasowany do problemu. Sama instrukcja pozwoli\u0142a mu lepiej wykorzysta\u0107 wiedz\u0119, kt\u00f3r\u0105 ju\u017c mia\u0142. To brzmi logicznie, ale czy to jest jaki\u015b z\u0142oty \u015brodek? Czy by\u0142y zadania, gdzie Instruction Tuning w og\u00f3le nie pom\u00f3g\u0142? Albo co gorsza zaszkodzi\u0142? Tak i to jest bardzo wa\u017cne spostrze\u017cenie. Pokazuje, \u017ce nie ma darmowych lanczy. Ta technika nie przynios\u0142a poprawy w zadaniach, kt\u00f3re same w sobie s\u0105 bardzo podobne do tego, co modele j\u0119zykowe robi\u0105 od pocz\u0105tku. Czyli do przewidywania nast\u0119pnego s\u0142owa. Dok\u0142adnie. Chodzi na przyk\u0142ad o uzupe\u0142nianie brakuj\u0105cych fragment\u00f3w w zdaniach, co testuje tak zwane Commonsense Reasoning. Ach, czyli je\u015bli zadanie z natury polega na zgadni co b\u0119dzie dalej, to dodawanie instrukcji w stylu prosz\u0119 zgadni co b\u0119dzie dalej jest po prostu zb\u0119dne. Dok\u0142adnie tak. Autorzy sami napisali, \u017ce w takich przypadkach instrukcje s\u0105 w du\u017cej mierze redundantne. I to pi\u0119knie pokazuje, gdzie le\u017cy si\u0142a tej metody. OK, czyli wiemy, \u017ce to dzia\u0142a i gdzie dzia\u0142a najlepiej. Ale dla mnie najciekawsze pytanie brzmi, dlaczego? Co by\u0142o tym kluczowym sk\u0142adnikiem sukcesu? Czy chodzi\u0142o po prostu o to, \u017ceby wrzuci\u0107 do treningu jak najwi\u0119cej r\u00f3\u017cnych zada\u0144? To by\u0142o jedno z pierwszych pyta\u0144, kt\u00f3re sobie zadali i odpowied\u017a jest jednoznacznie tak. Pokazali to na bardzo wymownym wykresie, wygl\u0105da\u0142 troch\u0119 jak schody pn\u0105ce si\u0119 w g\u00f3r\u0119. Co to znaczy? Za ka\u017cdym razem, gdy do programu nauczania dodawali now\u0105 grup\u0119 zada\u0144, np. t\u0142umaczenia, potem odpowiadanie na pytania, potem analiz\u0119 sentymentu, \u015brednia wydajno\u015b\u0107 na zupe\u0142nie nowych testach ros\u0142a. Czyli ka\u017cdy nowy przedmiot szkolny czyni\u0142 go lepszym uczniem. Dok\u0142adnie i co ciekawe. Ale chwila tu jest troch\u0119 wbrew intuicji. Zwykle w uczeniu maszynowym w pewnym momencie jest \u015bciana. Zyski z dodawania danych malej\u0105. A ty m\u00f3wisz, \u017ce im wi\u0119cej r\u00f3\u017cnorodno\u015bci tym lepiej i to bez widocznego sufitu? Dok\u0142adnie tak. Autorzy podkre\u015blaj\u0105, \u017ce ta krzywa wzrostu w stale si\u0119 mnie wyp\u0142aszcza\u0142a. To sugeruje, \u017ce potencja\u0142 na dalsz\u0105 poprawie jest ogromny. R\u00f3\u017cnorodno\u015b\u0107 do\u015bwiadcze\u0144 jest kluczowa. Ale to prowadzi do kolejnego pytania. A co z wielko\u015bci\u0105 m\u00f3zgu tego ucznia? Czy rozmiar modelu mia\u0142 znaczenie? Wi\u0119kszy zawsze znaczy\u0142 lepszy? I tu dochodzimy do najbardziej chyba szokuj\u0105cego odkrycia w ca\u0142ym artykule. Okazuje si\u0119, \u017ce nie tylko wi\u0119kszy znaczy lepszy, ale tylko wi\u0119kszy ma sens. Jak to? W przypadku naprawd\u0119 du\u017cych modeli 68 i 137 miliard\u00f3w parametr\u00f3w Instruction Tuning dzia\u0142a\u0142 fantastycznie. Ale dla mniejszych modeli 8 miliard\u00f3w i mniej ta sama technika pogarsza\u0142a ich wyniki na niewidzianych zadaniach. Pogarsza\u0142a, to jak to jest w og\u00f3le mo\u017cliwe. Uczymy go wi\u0119cej, a on staje si\u0119 gorszy. To jest kompletnie bez sensu. Wiem, na pierwszy rzut oka to paradoks, ale hipoteza autor\u00f3w jest bardzo elegancka. Uwa\u017caj\u0105, \u017ce mniejsze modele maj\u0105 powiedzmy ograniczon\u0105 pojemno\u015b\u0107. Ok. Kiedy uczymy je tych kilkudziesi\u0119ciu zada\u0144, one zu\u017cywaj\u0105 ca\u0142\u0105 swoj\u0105 moc na zapami\u0119tanie jak rozwi\u0105zywa\u0107 te konkretne zadania. Brakuje im ju\u017c miejsca w sieci neuronowej, \u017ceby nauczy\u0107 si\u0119 tej nadrz\u0119dnej metaumiej\u0119tno\u015bci. Czyli generalizacji, pod\u0105\u017cania za nowymi instrukcjami. Dok\u0142adnie. Dopiero te naprawd\u0119 wielkie modele maj\u0105 wystarczaj\u0105co du\u017co pojemno\u015bci, by nauczy\u0107 si\u0119 obu rzeczy naraz. Rozwi\u0105zywania zada\u0144 z treningu i og\u00f3lnej zasady post\u0119powania z nowymi poleczeniami. To jest fascynuj\u0105ce, bo to obala mit, \u017ce ka\u017cda technika treningu to jaka\u015b magiczna r\u00f3\u017cczka. To troch\u0119 jak w sporcie. Zaawansowane techniki dla olimpijczyka mog\u0105 zaszkodzi\u0107 amatorowi. Po prostu go przeci\u0105\u017c\u0105. Idealna analogia. To jest technika, kt\u00f3ra wymaga odpowiedniej skali, \u017ceby w og\u00f3le zadzia\u0142a\u0107. Czyli Instruction Tuning to luksus dla wagi super ci\u0119\u017ckiej. W\u0142a\u015bnie, a to doprowadzi\u0142o badaczy do ostatniego testu. Co by\u0142o wa\u017cniejsze? Samar\u00f3\u017cnorodno\u015b\u0107 zada\u0144? Czy jednak te instrukcje w naturalnym j\u0119zyku? No w\u0142a\u015bnie, mo\u017ce wystarczy\u0142o po prostu uczy\u0107 go wielu rzeczy naraz. Bez tych wszystkich polece\u0144. Sprawdzili to. Odpowied\u017a by\u0142a jednoznaczna. Instrukcje s\u0105 absolutnie kluczowe. Zrobili eksperyment, w kt\u00f3rym trenowali model na tej samej mieszance, ale bez naturalnych polece\u0144. Podawali mu na przyk\u0142ad tylko nazwy zbioru danych. I co? Wyniki dramatycznie spad\u0142y. Okaza\u0142o si\u0119, \u017ce model musi si\u0119 nauczy\u0107 budowa\u0107 ten most. Mi\u0119dzy konkretnym sformu\u0142owaniem w j\u0119zyku naturalnym, a typem zadania, kt\u00f3rego si\u0119 od niego oczekuje. Bez tego j\u0119zykowego pomostu ca\u0142a metoda traci moc. Podsumujmy. Instruction tuning to w gruncie rzeczy prosta, ale pot\u0119\u017cna koncepcja. Bierzemy bardzo du\u017cy model. I zamiast go specjalizowa\u0107, uczymy go og\u00f3lnej umiej\u0119tno\u015bci wykonywania polece\u0144. Poprzez trening na ogromnej, zr\u00f3\u017cnicowanej mieszance zada\u0144, gdzie ka\u017cdy jest sformu\u0142owany jak naturalna ludzka instrukcja. I w rezultacie dostajemy model, kt\u00f3ry potrafi robi\u0107 zupe\u0142nie nowe rzeczy w trybie zero shot. Cz\u0119sto lepiej ni\u017c wi\u0119ksze modele. Ale s\u0105 dwa warunki brzegowe. Model musi by\u0107 du\u017cy, a instrukcje musz\u0105 by\u0107 jasne. Dok\u0142adnie. Wiesz patrz\u0105c na to z szerszej perspektywy, to nie jest tylko kolejna techniczna sztuczka. To wygl\u0105da na fundamentaln\u0105 zmian\u0119 w podej\u015bciu do uczenia modeli. Zdecydowanie. Ta metoda zaciera granice mi\u0119dzy, powiedzmy, wyspecjalizowanymi rzemie\u015blnikami, a modelami og\u00f3lnego przeznaczenia. Pokazuje, \u017ce te same dane, kt\u00f3re do tej pory s\u0142u\u017cy\u0142y do zamykania modelu w jednej specjalizacji, mo\u017cna wykorzysta\u0107, \u017ceby go otworzy\u0107. Tak, \u017ceby go uczyni\u0107 bardziej elastycznym, zwinnym, gotowym na nowe wyzwania. Zamiast tworzy\u0107 eksperta, tworzymy po prostu lepszego ucznia. I to prowadzi do ostatniej my\u015bli. W artykule by\u0142 jeszcze jeden ciekawy detal. Taki wyeducowany model staje si\u0119 te\u017c lepszy w innych technikach, jak prompt tuning. To sugeruje, \u017ce on nie tylko uczy si\u0119 reagowa\u0107 na komendy, on staje si\u0119 fundamentalnie bardziej podatny nastrojenie, \u0142atwiejszy w dalszej edukacji. To nie jest tylko nowa umiej\u0119tno\u015b\u0107. Wygl\u0105da, jakby\u015bmy zmieniali jego podstawow\u0105 zdolno\u015b\u0107 do nauki. Dok\u0142adnie. I tu dochodzimy do sedna. Do tej pory uczyli\u015bmy modele g\u0142\u00f3wnie, co maj\u0105 my\u015ble\u0107 o problemie, a ta metoda uczy je, jak my\u015ble\u0107 o ka\u017cdym nowym problemie. To jest przej\u015bcie od uczenia si\u0119 na pami\u0119\u0107 do uczenia z rozumieniem. Tak, to jest r\u00f3\u017cnica mi\u0119dzy zapami\u0119taniem rozm\u00f3wek na wyjazd, a faktycznym nauczeniem si\u0119 gramatyki. Jedno pozwala zam\u00f3wi\u0107 kaw\u0119, drugie napisa\u0107 powie\u015b\u0107. I ta zdolno\u015b\u0107 do generalizacji, no, to jest ten \u015bwi\u0119ty gral AI. Co zostawia nas z intryguj\u0105cym pytaniem na przysz\u0142o\u015b\u0107? Skoro mo\u017cemy uczy\u0107 modele generalizowania na podstawie instrukcji, to czy nasza rola powoli zmienia si\u0119 z roli in\u017cynier\u00f3w AI w rol\u0119 nauczycieli? Projektant\u00f3w program\u00f3w nauczania dla sztucznych umys\u0142\u00f3w. I co to w\u0142a\u015bciwie b\u0119dzie znaczy\u0107, \u017ce model rozumie polecenie, kiedy jego program nauczania stanie si\u0119 tak bogaty jak nasz w\u0142asny? To pytanie, kt\u00f3re na razie pozostaje otwarte.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.78, "text": " Witajcie. Dzisiaj we\u017amiemy na warsztat jeden z tych problem\u00f3w w \u015bwiecie AI,", "tokens": [50364, 42299, 47276, 13, 39448, 22356, 321, 10659, 25210, 2226, 1667, 13718, 2682, 267, 12906, 710, 15180, 1154, 3901, 261, 40078, 4260, 7318, 11, 50653], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 1, "seek": 0, "start": 6.18, "end": 11.9, "text": " kt\u00f3ry na pierwszy rzut oka wydaje si\u0119 prosty, ale tak naprawd\u0119 jest niesamowicie z\u0142o\u017cony.", "tokens": [50673, 9913, 1667, 34016, 367, 89, 325, 277, 2330, 49165, 3244, 10293, 88, 11, 6775, 991, 20970, 3492, 48100, 335, 305, 28434, 710, 5249, 1427, 2526, 13, 50959], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 2, "seek": 0, "start": 12.58, "end": 15.860000000000001, "text": " Wyobra\u017amy sobie takiego no cyfrowego eksperta.", "tokens": [50993, 14458, 24393, 10659, 2226, 13652, 32296, 572, 3185, 69, 1892, 6308, 30724, 610, 1328, 13, 51157], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 3, "seek": 0, "start": 16.18, "end": 19.3, "text": " Rozwi\u0105\u017ce ka\u017cde zadanie, ale jest jeden haczyk.", "tokens": [51173, 43313, 18234, 2875, 21912, 1479, 42788, 7155, 11, 6775, 3492, 12906, 324, 6522, 74, 13, 51329], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 4, "seek": 0, "start": 19.7, "end": 21.7, "text": " Musimy mu pokaza\u0107 par\u0119 przyk\u0142ad\u00f3w.", "tokens": [51349, 3569, 13189, 2992, 13010, 12257, 2162, 971, 1274, 23144, 3901, 13, 51449], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 5, "seek": 0, "start": 21.86, "end": 23.66, "text": " Czyli takie uczenie na wzorach?", "tokens": [51457, 37099, 15963, 344, 39043, 1667, 24809, 284, 608, 30, 51547], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 6, "seek": 0, "start": 23.82, "end": 24.62, "text": " Dok\u0142adnie.", "tokens": [51555, 29768, 10358, 2766, 13, 51595], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 7, "seek": 0, "start": 24.86, "end": 29.26, "text": " Dajesz mu trzy rozwi\u0105zane zadania z fizyki, on bez problemu robi czwarte.", "tokens": [51607, 413, 1805, 10430, 2992, 34573, 9544, 22620, 1929, 42788, 5609, 710, 21000, 88, 2984, 11, 322, 10782, 1154, 84, 47380, 6472, 86, 11026, 13, 51827], "temperature": 0.0, "avg_logprob": -0.234075954042632, "compression_ratio": 1.4493243243243243, "no_speech_prob": 0.010714209638535976}, {"id": 8, "seek": 2926, "start": 29.82, "end": 36.260000000000005, "text": " Ale jak dasz mu co\u015b z chemii, bez \u017cadnego przyk\u0142adu i powiesz tylko, zr\u00f3b to, to nagle klapa.", "tokens": [50392, 9366, 4207, 1482, 89, 2992, 19241, 710, 4771, 5597, 11, 10782, 39628, 11858, 23144, 84, 741, 3388, 15347, 13219, 11, 710, 11721, 65, 281, 11, 281, 297, 15088, 9671, 7961, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 9, "seek": 2926, "start": 36.58, "end": 40.660000000000004, "text": " I to jest w\u0142a\u015bnie ten dylemat Fuse Shot kontra Zero Shot, prawda?", "tokens": [50730, 286, 281, 3492, 14234, 2064, 274, 2072, 15677, 479, 438, 28845, 14373, 424, 17182, 28845, 11, 43607, 30, 50934], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 10, "seek": 2926, "start": 40.94, "end": 41.46, "text": " W\u0142a\u015bnie.", "tokens": [50948, 343, 5024, 12221, 13, 50974], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 11, "seek": 2926, "start": 41.660000000000004, "end": 46.620000000000005, "text": " Modele takie jak GPT-3 s\u0105 niesamowite w trybie Fuse Shot z podpowiedziami,", "tokens": [50984, 20500, 306, 15963, 4207, 26039, 51, 12, 18, 9015, 48100, 335, 305, 642, 261, 853, 7392, 479, 438, 28845, 710, 2497, 14701, 15338, 15568, 11, 51232], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 12, "seek": 2926, "start": 47.02, "end": 51.34, "text": " ale w Zero Shot na zimno ich skupeczno\u015b\u0107 no leci na \u0142eb na szyj\u0119.", "tokens": [51252, 6775, 261, 17182, 28845, 1667, 710, 332, 1771, 1893, 1110, 84, 494, 3689, 23293, 572, 476, 537, 1667, 220, 19827, 65, 1667, 30526, 11115, 13, 51468], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 13, "seek": 2926, "start": 51.82, "end": 52.7, "text": " Pytanie brzmi.", "tokens": [51492, 430, 4328, 7155, 738, 89, 3057, 13, 51536], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 14, "seek": 2926, "start": 53.14, "end": 58.7, "text": " Jak nauczy\u0107 model, \u017ceby naprawd\u0119 rozumia\u0142 polecenia, a nie tylko kopiowa\u0142 wzorce?", "tokens": [51558, 15029, 49103, 27150, 2316, 11, 11316, 20970, 48797, 8908, 13208, 13037, 654, 11, 257, 2838, 13219, 28920, 72, 30105, 24809, 284, 384, 30, 51836], "temperature": 0.0, "avg_logprob": -0.23354823477316222, "compression_ratio": 1.4180602006688963, "no_speech_prob": 0.0034238751977682114}, {"id": 15, "seek": 5870, "start": 59.14, "end": 64.42, "text": " A odpowiedzi poszukamy dzisiaj w moim zdaniem prze\u0142omowym artykule z Google Research.", "tokens": [50386, 316, 36574, 3992, 1366, 43994, 7804, 25772, 261, 48569, 710, 10312, 4907, 8325, 1221, 298, 31691, 594, 874, 74, 2271, 710, 3329, 10303, 13, 50650], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 16, "seek": 5870, "start": 64.62, "end": 69.5, "text": " Tytu\u0142 to Find Tuned Language Models or Zero Shot Learners.", "tokens": [50660, 314, 4328, 84, 1221, 281, 11809, 21363, 292, 24445, 6583, 1625, 420, 17182, 28845, 17216, 433, 13, 50904], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 17, "seek": 5870, "start": 69.86, "end": 70.38, "text": " Dok\u0142adnie.", "tokens": [50922, 29768, 10358, 2766, 13, 50948], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 18, "seek": 5870, "start": 70.78, "end": 75.34, "text": " A celem jest zrozumienie jednej w sumie prostej, ale genialnej koncepcji.", "tokens": [50968, 316, 1769, 10386, 3492, 710, 27857, 449, 27385, 5232, 11794, 261, 2408, 414, 10293, 40779, 11, 6775, 48228, 11794, 5897, 27493, 19649, 13, 51196], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 19, "seek": 5870, "start": 75.58, "end": 76.94, "text": " Instruction Tuning.", "tokens": [51208, 2730, 3826, 21363, 278, 13, 51276], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 20, "seek": 5870, "start": 77.54, "end": 84.14, "text": " To jest metoda, kt\u00f3ra stworzy\u0142a model Flan i kt\u00f3ra no w pewnym sensie uczy model, jak si\u0119 uczy\u0107.", "tokens": [51306, 1407, 3492, 1131, 13449, 11, 19456, 342, 28321, 1229, 5024, 2316, 3235, 282, 741, 19456, 572, 261, 47160, 4199, 2923, 414, 344, 6522, 2316, 11, 4207, 3244, 344, 33967, 13, 51636], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 21, "seek": 5870, "start": 84.58, "end": 85.82000000000001, "text": " Dobrze, rozpakujmy to.", "tokens": [51658, 29679, 13503, 11, 9544, 45944, 4579, 2226, 281, 13, 51720], "temperature": 0.0, "avg_logprob": -0.20039218664169312, "compression_ratio": 1.3860294117647058, "no_speech_prob": 0.0009133163257502019}, {"id": 22, "seek": 8582, "start": 86.46, "end": 87.58, "text": " Instruction Tuning.", "tokens": [50396, 2730, 3826, 21363, 278, 13, 50452], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 23, "seek": 8582, "start": 87.77999999999999, "end": 89.41999999999999, "text": " Jaka jest g\u0142\u00f3wna idea?", "tokens": [50462, 508, 7849, 3492, 18117, 3901, 629, 1558, 30, 50544], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 24, "seek": 8582, "start": 89.94, "end": 93.46, "text": " Bo wiesz, jak o tym my\u015bl\u0119, to od razu mam w g\u0142owie tak\u0105 analogi\u0119.", "tokens": [50570, 3286, 261, 15347, 11, 4207, 277, 8107, 37730, 11, 281, 3611, 367, 8813, 13524, 261, 18117, 13998, 31069, 16660, 5034, 13, 50746], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 25, "seek": 8582, "start": 93.61999999999999, "end": 94.5, "text": " O, ciekawe.", "tokens": [50754, 422, 11, 30596, 2330, 826, 13, 50798], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 26, "seek": 8582, "start": 94.61999999999999, "end": 95.97999999999999, "text": " Wyobra\u017amy sobie studenta.", "tokens": [50804, 14458, 24393, 10659, 2226, 13652, 3107, 64, 13, 50872], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 27, "seek": 8582, "start": 96.17999999999999, "end": 101.97999999999999, "text": " Zamiast wk\u00f3\u0142ko pokazywa\u0107 mu te same rozwi\u0105zane zadania z algebry, dajemy mu taki gruby podr\u0119cznik.", "tokens": [50882, 1176, 4526, 525, 261, 74, 16181, 4093, 13010, 33235, 25234, 2992, 535, 912, 9544, 22620, 1929, 42788, 5609, 710, 419, 432, 65, 627, 11, 1120, 73, 3633, 2992, 20065, 677, 836, 88, 2497, 81, 1274, 3689, 13123, 13, 51172], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 28, "seek": 8582, "start": 102.22, "end": 105.41999999999999, "text": " Z instrukcjami, przyk\u0142adami, ale z r\u00f3\u017cnych dziedzin.", "tokens": [51184, 1176, 1058, 25126, 66, 73, 4526, 11, 23144, 4526, 11, 6775, 710, 42602, 9758, 15338, 259, 13, 51344], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 29, "seek": 8582, "start": 105.61999999999999, "end": 107.74, "text": " Algebra, geometria, analiza, logika.", "tokens": [51354, 967, 432, 6198, 11, 12956, 4668, 11, 2624, 13427, 11, 3565, 5439, 13, 51460], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 30, "seek": 8582, "start": 108.25999999999999, "end": 109.85999999999999, "text": " Czyli poszerzamy mu horyzonty?", "tokens": [51486, 37099, 1366, 4527, 89, 7804, 2992, 276, 827, 35296, 874, 30, 51566], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 31, "seek": 8582, "start": 110.02, "end": 114.17999999999999, "text": " Tak, a potem na egzaminie rzucamy mu zadanie z trygonometrii, kt\u00f3rej nigdy nie widzia\u0142.", "tokens": [51574, 9118, 11, 257, 36513, 1667, 24263, 89, 7428, 414, 367, 89, 1311, 7804, 2992, 42788, 7155, 710, 853, 10660, 649, 470, 72, 11, 36023, 26996, 3173, 2838, 27486, 8908, 13, 51782], "temperature": 0.0, "avg_logprob": -0.16738236283456814, "compression_ratio": 1.4259818731117824, "no_speech_prob": 0.017823288217186928}, {"id": 32, "seek": 11418, "start": 114.62, "end": 120.78, "text": " I liczymy, \u017ce on nauczy\u0142 si\u0119 nie schemat\u00f3w, tylko og\u00f3lnej metodyki rozwi\u0105zywania problem\u00f3w z instrukcji.", "tokens": [50386, 286, 6169, 1229, 2226, 11, 3561, 322, 49103, 1229, 1221, 3244, 2838, 956, 8615, 3901, 11, 13219, 5360, 15741, 11794, 1131, 843, 2984, 9544, 18234, 1229, 86, 5609, 1154, 3901, 710, 1058, 25126, 19649, 13, 50694], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 33, "seek": 11418, "start": 120.9, "end": 122.42, "text": " To jest idealne por\u00f3wnanie.", "tokens": [50700, 1407, 3492, 7157, 716, 1515, 812, 895, 7155, 13, 50776], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 34, "seek": 11418, "start": 122.7, "end": 125.94000000000001, "text": " Naprawd\u0119, bo \u015bwietnie oddaj\u0119 filozofi\u0119 tego podej\u015bcia.", "tokens": [50790, 18287, 20098, 11, 748, 8299, 39083, 2766, 7401, 1805, 1274, 1387, 15151, 2670, 5034, 8627, 7468, 73, 1788, 2755, 13, 50952], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 35, "seek": 11418, "start": 126.22000000000001, "end": 134.26000000000002, "text": " M\u00f3wi\u0105c ju\u017c tak bardziej technicznie, badacze wzi\u0119li pot\u0119\u017cny model Lambda PT 137 miliard\u00f3w parametr\u00f3w.", "tokens": [50966, 376, 3901, 11404, 66, 10678, 991, 27209, 1537, 17946, 2766, 11, 1578, 326, 1381, 261, 16706, 2081, 1847, 1274, 1427, 1634, 2316, 45691, 35460, 3705, 22, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51368], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 36, "seek": 11418, "start": 134.3, "end": 135.78, "text": " Czyli ju\u017c wytrenowan\u0105 besti\u0119.", "tokens": [51370, 37099, 10678, 261, 4328, 1095, 37345, 1611, 1151, 5034, 13, 51444], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 37, "seek": 11418, "start": 135.9, "end": 136.66, "text": " Dok\u0142adnie.", "tokens": [51450, 29768, 10358, 2766, 13, 51488], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 38, "seek": 11418, "start": 136.70000000000002, "end": 139.94, "text": " I zamiast go specjalizowa\u0107, zrobili co\u015b odwrotnego.", "tokens": [51490, 286, 710, 4526, 525, 352, 46433, 590, 11445, 11, 44399, 2312, 19241, 3611, 7449, 310, 11858, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13792729871026402, "compression_ratio": 1.3588039867109634, "no_speech_prob": 0.008494580164551735}, {"id": 39, "seek": 13994, "start": 140.06, "end": 147.46, "text": " Wystawili go na ponad 60 r\u00f3\u017cnych zbior\u00f3w danych z NLP, ale kluczowa by\u0142a nie ilo\u015b\u0107, a forma.", "tokens": [50370, 14458, 22580, 2312, 352, 1667, 9224, 345, 4060, 42602, 710, 33362, 3901, 274, 34644, 710, 426, 45196, 11, 6775, 9671, 1311, 89, 5528, 23936, 2838, 1930, 78, 7753, 11, 257, 8366, 13, 50740], "temperature": 0.0, "avg_logprob": -0.15529669484784525, "compression_ratio": 1.3650190114068441, "no_speech_prob": 0.026575734838843346}, {"id": 40, "seek": 13994, "start": 147.5, "end": 148.18, "text": " Forma.", "tokens": [50742, 10126, 64, 13, 50776], "temperature": 0.0, "avg_logprob": -0.15529669484784525, "compression_ratio": 1.3650190114068441, "no_speech_prob": 0.026575734838843346}, {"id": 41, "seek": 13994, "start": 148.82, "end": 149.62, "text": " Co masz na my\u015bli?", "tokens": [50808, 3066, 2300, 89, 1667, 452, 15350, 30, 50848], "temperature": 0.0, "avg_logprob": -0.15529669484784525, "compression_ratio": 1.3650190114068441, "no_speech_prob": 0.026575734838843346}, {"id": 42, "seek": 13994, "start": 149.78, "end": 155.98, "text": " Ka\u017cdy, nawet taki najbardziej suchy przyk\u0142ad, zosta\u0142 przeformu\u0142owany w naturalne ludzkie polecenie.", "tokens": [50856, 10988, 1427, 3173, 11, 22696, 20065, 41857, 1270, 88, 23144, 11, 23154, 1221, 8325, 837, 84, 1221, 23341, 261, 3303, 716, 15946, 89, 22872, 13208, 13037, 414, 13, 51166], "temperature": 0.0, "avg_logprob": -0.15529669484784525, "compression_ratio": 1.3650190114068441, "no_speech_prob": 0.026575734838843346}, {"id": 43, "seek": 13994, "start": 156.62, "end": 164.86, "text": " Czyli zamiast dawa\u0107 mu po prostu par\u0119 tekst A, tekst B i kaza\u0107 zgadn\u0105\u0107 relacje, zadawali mu pytanie, kt\u00f3re my by\u015bmy zadali.", "tokens": [51198, 37099, 710, 4526, 525, 1120, 25234, 2992, 714, 19518, 971, 1274, 16624, 372, 316, 11, 16624, 372, 363, 741, 350, 12257, 2162, 40948, 345, 13113, 2162, 1039, 29293, 11, 710, 1538, 40054, 2992, 36610, 11, 8864, 452, 538, 10513, 42788, 5103, 13, 51610], "temperature": 0.0, "avg_logprob": -0.15529669484784525, "compression_ratio": 1.3650190114068441, "no_speech_prob": 0.026575734838843346}, {"id": 44, "seek": 16486, "start": 165.46, "end": 179.06, "text": " Na przyk\u0142ad w zadaniu wnioskowania zamiast suchego przes\u0142anka hipoteza model dostawa\u0142 pytanie na podstawie tego akapitu, czy mo\u017cemy wnioskowa\u0107, \u017ce tu tre\u015b\u0107 hipotezy odpowied\u017a tak lub nie.", "tokens": [50394, 6056, 23144, 261, 42788, 25849, 45368, 2717, 74, 21308, 710, 4526, 525, 1270, 6308, 6541, 279, 1221, 21729, 8103, 1370, 2394, 2316, 20568, 10449, 1221, 36610, 1667, 43443, 414, 8627, 9308, 569, 6380, 11, 6430, 26500, 45368, 2717, 74, 11445, 11, 3561, 2604, 2192, 7753, 8103, 1370, 1229, 36574, 10659, 991, 15980, 2838, 13, 51074], "temperature": 0.0, "avg_logprob": -0.14364877768925258, "compression_ratio": 1.4674329501915708, "no_speech_prob": 0.023860575631260872}, {"id": 45, "seek": 16486, "start": 179.58, "end": 182.26000000000002, "text": " To nie by ma\u0142a zmiana, ale wydaje si\u0119 fundamentalna.", "tokens": [51100, 1407, 2838, 538, 463, 5024, 17020, 8497, 11, 6775, 49165, 3244, 8088, 629, 13, 51234], "temperature": 0.0, "avg_logprob": -0.14364877768925258, "compression_ratio": 1.4674329501915708, "no_speech_prob": 0.023860575631260872}, {"id": 46, "seek": 16486, "start": 182.62, "end": 192.02, "text": " Bo jest model zaczyna kojarzy\u0107 j\u0119zyk naturalny, w kt\u00f3rym my ludzie wydajemy polecenia z konkretnym zadaniem, kt\u00f3re ma wykona\u0107.", "tokens": [51252, 3286, 3492, 2316, 43811, 629, 8384, 10150, 27150, 49055, 74, 3303, 1634, 11, 261, 30120, 452, 37025, 25984, 1805, 3633, 13208, 13037, 654, 710, 36500, 12996, 710, 11338, 4907, 11, 8864, 463, 39287, 4037, 2162, 13, 51722], "temperature": 0.0, "avg_logprob": -0.14364877768925258, "compression_ratio": 1.4674329501915708, "no_speech_prob": 0.023860575631260872}, {"id": 47, "seek": 19202, "start": 192.22, "end": 196.98000000000002, "text": " Czyli to nie jest ani taki klasyczny Fine Tuning, gdzie rze\u017abimy model pod jedno zadanie?", "tokens": [50374, 37099, 281, 2838, 3492, 40477, 20065, 9671, 5871, 3689, 1634, 12024, 21363, 278, 11, 18922, 16081, 10659, 65, 13189, 2316, 2497, 5232, 1771, 42788, 7155, 30, 50612], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 48, "seek": 19202, "start": 197.02, "end": 197.66, "text": " Nie.", "tokens": [50614, 12016, 13, 50646], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 49, "seek": 19202, "start": 197.70000000000002, "end": 203.10000000000002, "text": " Ani nie jest to podej\u015bcie w stylu GPT-3, gdzie liczymy, \u017ce on sam za\u0142apie schemat spalu przyk\u0142ad\u00f3w.", "tokens": [50648, 1107, 72, 2838, 3492, 281, 7468, 73, 9815, 261, 7952, 2781, 26039, 51, 12, 18, 11, 18922, 6169, 1229, 2226, 11, 3561, 322, 3247, 7949, 1221, 569, 414, 956, 8615, 637, 4929, 23144, 3901, 13, 50918], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 50, "seek": 19202, "start": 203.62, "end": 205.94, "text": " To jest jaka\u015b no trzecia droga.", "tokens": [50944, 1407, 3492, 4207, 64, 1788, 572, 22266, 2755, 3789, 3680, 13, 51060], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 51, "seek": 19202, "start": 206.10000000000002, "end": 208.82000000000002, "text": " W\u0142a\u015bnie tak. To podej\u015bcie hybrydowy.", "tokens": [51068, 343, 5024, 12221, 991, 13, 1407, 7468, 73, 9815, 2477, 65, 627, 67, 10089, 13, 51204], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 52, "seek": 19202, "start": 209.3, "end": 215.94, "text": " U\u017cywa mechanizmu Fine Tuning, ale nie \u017ceby specjalizowa\u0107, tylko \u017ceby generalizowa\u0107.", "tokens": [51228, 624, 7735, 4151, 4236, 590, 20140, 12024, 21363, 278, 11, 6775, 2838, 11316, 46433, 590, 11445, 11, 13219, 11316, 2674, 590, 11445, 13, 51560], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 53, "seek": 19202, "start": 216.3, "end": 219.66000000000003, "text": " Celem nie jest stworzenie mistrza w jednej dziedzinie.", "tokens": [51578, 8257, 10386, 2838, 3492, 342, 28321, 16778, 3544, 81, 2394, 261, 5232, 11794, 9758, 15338, 259, 414, 13, 51746], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 54, "seek": 19202, "start": 219.74, "end": 221.42000000000002, "text": " Tylko wszechstronnego ucznia.", "tokens": [51750, 49286, 4093, 37647, 19439, 372, 2044, 11858, 35403, 12679, 13, 51834], "temperature": 0.0, "avg_logprob": -0.14401625379731384, "compression_ratio": 1.510135135135135, "no_speech_prob": 0.026267601177096367}, {"id": 55, "seek": 22142, "start": 221.42, "end": 225.89999999999998, "text": " Dok\u0142adnie. Ucznia, kt\u00f3ry potrafi pod\u0105\u017ca\u0107 za instrukcjami.", "tokens": [50364, 29768, 10358, 2766, 13, 624, 3689, 12679, 11, 9913, 1847, 10437, 72, 2497, 27242, 43379, 7949, 1058, 25126, 66, 73, 4526, 13, 50588], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 56, "seek": 22142, "start": 226.14, "end": 231.94, "text": " Chodzi o to, \u017ceby model nauczy\u0142 si\u0119, jak si\u0119 uczy\u0107, kiedy dostaje nowe polecenie.", "tokens": [50600, 761, 14543, 277, 281, 11, 11316, 2316, 49103, 1229, 1221, 3244, 11, 4207, 3244, 344, 33967, 11, 18777, 20568, 11153, 586, 68, 13208, 13037, 414, 13, 50890], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 57, "seek": 22142, "start": 231.98, "end": 235.26, "text": " Brzmi \u015bwietnie w teorii. Stworzy\u0107 uniwersalnego ucznia.", "tokens": [50892, 1603, 89, 3057, 8299, 39083, 2766, 261, 40238, 5597, 13, 745, 28321, 27150, 36435, 5364, 304, 11858, 35403, 12679, 13, 51056], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 58, "seek": 22142, "start": 235.77999999999997, "end": 239.54, "text": " Ale teoria w AI to jedno, a praktyka, no, bywa r\u00f3\u017cnie.", "tokens": [51082, 9366, 535, 8172, 261, 7318, 281, 5232, 1771, 11, 257, 3206, 74, 874, 2330, 11, 572, 11, 538, 4151, 19637, 2766, 13, 51270], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 59, "seek": 22142, "start": 240.14, "end": 242.26, "text": " Jak to wypad\u0142o w rzeczywisto\u015bci? Zadzia\u0142a\u0142o?", "tokens": [51300, 15029, 281, 4628, 13647, 5249, 261, 26297, 86, 9334, 6199, 30, 1176, 345, 89, 25605, 5249, 30, 51406], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 60, "seek": 22142, "start": 242.57999999999998, "end": 245.73999999999998, "text": " Trenowali go na wszystkim, opr\u00f3cz NLI.", "tokens": [51422, 314, 1095, 305, 5103, 352, 1667, 30481, 11, 999, 11721, 3689, 426, 48718, 13, 51580], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 61, "seek": 22142, "start": 246.06, "end": 248.06, "text": " A potem rzucili go na g\u0142\u0119bok\u0105 wod\u0119.", "tokens": [51596, 316, 36513, 367, 89, 1311, 2312, 352, 1667, 18117, 1274, 21666, 1611, 47751, 1274, 13, 51696], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 62, "seek": 22142, "start": 248.66, "end": 249.42, "text": " I co si\u0119 sta\u0142o?", "tokens": [51726, 286, 598, 3244, 11135, 5249, 30, 51764], "temperature": 0.0, "avg_logprob": -0.15165672302246094, "compression_ratio": 1.37, "no_speech_prob": 0.010999765247106552}, {"id": 63, "seek": 24942, "start": 250.05999999999997, "end": 252.85999999999999, "text": " Wyniki by\u0142y, no, spektakularne.", "tokens": [50396, 343, 2534, 9850, 26366, 11, 572, 11, 768, 2320, 514, 1040, 716, 13, 50536], "temperature": 0.0, "avg_logprob": -0.18635912502513213, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.03352322056889534}, {"id": 64, "seek": 24942, "start": 253.5, "end": 259.53999999999996, "text": " Flan, maj\u0105cy 137 miliard\u00f3w parametr\u00f3w w trybie Zero Shot, czyli bez \u017cadnych przyk\u0142ad\u00f3w,", "tokens": [50568, 3235, 282, 11, 26064, 1344, 3705, 22, 1962, 72, 515, 3901, 6220, 27965, 3901, 261, 853, 7392, 17182, 28845, 11, 16591, 10782, 39628, 9399, 23144, 3901, 11, 50870], "temperature": 0.0, "avg_logprob": -0.18635912502513213, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.03352322056889534}, {"id": 65, "seek": 24942, "start": 260.14, "end": 267.62, "text": " pokona\u0142 wi\u0119kszy od siebie model GPT-3, 175 miliard\u00f3w parametr\u00f3w na przyt\u0142aczaj\u0105cej wi\u0119kszo\u015bci test\u00f3w.", "tokens": [50900, 13010, 4037, 1221, 29968, 1229, 3611, 39137, 2316, 26039, 51, 12, 18, 11, 41165, 1962, 72, 515, 3901, 6220, 27965, 3901, 1667, 6501, 83, 1221, 14875, 11133, 20811, 29968, 4765, 6199, 1500, 3901, 13, 51274], "temperature": 0.0, "avg_logprob": -0.18635912502513213, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.03352322056889534}, {"id": 66, "seek": 24942, "start": 268.09999999999997, "end": 271.9, "text": " M\u00f3wimy tu o zwyci\u0119stwie na 20 z 25 zada\u0144.", "tokens": [51298, 376, 3901, 13189, 2604, 277, 43436, 537, 1274, 372, 8699, 1667, 945, 710, 3552, 710, 1538, 5248, 13, 51488], "temperature": 0.0, "avg_logprob": -0.18635912502513213, "compression_ratio": 1.3055555555555556, "no_speech_prob": 0.03352322056889534}, {"id": 67, "seek": 27190, "start": 271.9, "end": 279.73999999999995, "text": " Wow. A poprawa w stosunku do jego w\u0142asnej wersji bazowej, bez tego Instruction Tuning, by\u0142a wr\u0119cz astronomiczna.", "tokens": [50364, 3153, 13, 316, 1665, 424, 4151, 261, 43581, 49910, 360, 26542, 43572, 11794, 261, 433, 4013, 27147, 21091, 11, 10782, 8627, 2730, 3826, 21363, 278, 11, 23936, 928, 1274, 3689, 26302, 17946, 629, 13, 50756], "temperature": 0.0, "avg_logprob": -0.1769261019570487, "compression_ratio": 1.346774193548387, "no_speech_prob": 0.0530853196978569}, {"id": 68, "seek": 27190, "start": 280.34, "end": 286.34, "text": " W zadaniach wymagaj\u0105cych rozumowania bazowy model mia\u0142 powiedzmy 10-20% poprawno\u015bci.", "tokens": [50786, 343, 42788, 3782, 608, 29764, 559, 11133, 31306, 48797, 21308, 27147, 10089, 2316, 27989, 27617, 2226, 1266, 12, 2009, 4, 1665, 424, 20944, 6199, 13, 51086], "temperature": 0.0, "avg_logprob": -0.1769261019570487, "compression_ratio": 1.346774193548387, "no_speech_prob": 0.0530853196978569}, {"id": 69, "seek": 27190, "start": 286.62, "end": 287.97999999999996, "text": " Czyli w zasadzie strzela\u0142?", "tokens": [51100, 37099, 261, 44585, 3283, 1056, 89, 4053, 1221, 30, 51168], "temperature": 0.0, "avg_logprob": -0.1769261019570487, "compression_ratio": 1.346774193548387, "no_speech_prob": 0.0530853196978569}, {"id": 70, "seek": 27190, "start": 288.17999999999995, "end": 297.53999999999996, "text": " Praktycznie tak. A po treningu instrukcjami ten sam model nagle wskakiwa\u0142 na 60-70, czasem nawet 80%.", "tokens": [51178, 430, 11272, 45586, 991, 13, 316, 714, 2192, 773, 84, 1058, 25126, 66, 73, 4526, 2064, 3247, 2316, 297, 15088, 261, 5161, 7421, 44603, 1667, 4060, 12, 5867, 11, 13190, 443, 22696, 4688, 6856, 51646], "temperature": 0.0, "avg_logprob": -0.1769261019570487, "compression_ratio": 1.346774193548387, "no_speech_prob": 0.0530853196978569}, {"id": 71, "seek": 29754, "start": 297.70000000000005, "end": 304.22, "text": " To jest niewiarygodne, ale czyta\u0142em, \u017ce by\u0142o tam co\u015b jeszcze, co\u015b jeszcze bardziej zaskakuj\u0105cego.", "tokens": [50372, 1407, 3492, 43622, 29104, 21787, 716, 11, 6775, 6430, 1328, 11126, 11, 3561, 14811, 7677, 19241, 14168, 11, 19241, 14168, 27209, 710, 3863, 514, 13263, 384, 1571, 13, 50698], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 72, "seek": 29754, "start": 304.86, "end": 309.86, "text": " Pono\u0107 Flan w niekt\u00f3rych zadaniach pobi\u0142 GPT-3, dzia\u0142aj\u0105cy w trybie Fuse Shot.", "tokens": [50730, 430, 8957, 2162, 3235, 282, 261, 2838, 43073, 627, 339, 42788, 3782, 608, 714, 5614, 1221, 26039, 51, 12, 18, 11, 27121, 11133, 1344, 261, 853, 7392, 479, 438, 28845, 13, 50980], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 73, "seek": 29754, "start": 310.1, "end": 312.74, "text": " Tak, czyli z dost\u0119pem do \u015bci\u0105gi.", "tokens": [50992, 9118, 11, 16591, 710, 48209, 443, 360, 220, 50227, 7834, 13, 51124], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 74, "seek": 29754, "start": 313.02000000000004, "end": 314.34000000000003, "text": " Jak to jest w og\u00f3le mo\u017cliwe?", "tokens": [51138, 15029, 281, 3492, 261, 29229, 30854, 826, 30, 51204], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 75, "seek": 29754, "start": 314.62, "end": 322.1, "text": " Model bez \u017cadnych przyk\u0142ad\u00f3w jest lepszy od wi\u0119kszego modelu, kt\u00f3ry je dosta\u0142, szczeg\u00f3lnie w tych zadaniach NLI, o kt\u00f3rych wspomnia\u0142e\u015b.", "tokens": [51218, 17105, 10782, 39628, 9399, 23144, 3901, 3492, 476, 1878, 1229, 3611, 29968, 27725, 2316, 84, 11, 9913, 1506, 274, 8638, 1221, 11, 49624, 2766, 261, 15180, 42788, 3782, 608, 426, 48718, 11, 277, 30382, 17757, 38131, 8908, 68, 1788, 13, 51592], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 76, "seek": 29754, "start": 322.18, "end": 325.02000000000004, "text": " No i to jest jeden z najciekawszych wniosk\u00f3w.", "tokens": [51596, 883, 741, 281, 3492, 12906, 710, 11212, 4260, 74, 1607, 45021, 45368, 2717, 23849, 13, 51738], "temperature": 0.0, "avg_logprob": -0.14109230041503906, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.032990679144859314}, {"id": 77, "seek": 32502, "start": 325.14, "end": 329.65999999999997, "text": " NLI to s\u0105 zadania typu prawda, fa\u0142sz, niewiadomo dla maszyn.", "tokens": [50370, 426, 48718, 281, 9015, 42788, 5609, 2125, 84, 43607, 11, 2050, 1221, 15453, 11, 43622, 38069, 13395, 12285, 2300, 1229, 77, 13, 50596], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 78, "seek": 32502, "start": 329.94, "end": 330.34, "text": " Ok.", "tokens": [50610, 3477, 13, 50630], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 79, "seek": 32502, "start": 330.38, "end": 338.74, "text": " Okazuje si\u0119, \u017ce dla modeli jak GPT-3 te zadania cz\u0119sto formu\u0142owano w bardzo sztuczny spos\u00f3b, jako doka\u0144czanie zdania.", "tokens": [50632, 3477, 43317, 3244, 11, 3561, 12285, 2316, 72, 4207, 26039, 51, 12, 18, 535, 42788, 5609, 34369, 1254, 84, 1221, 305, 3730, 261, 9034, 262, 2682, 1311, 89, 1634, 22904, 11, 17123, 360, 2330, 5248, 3689, 7155, 16221, 5609, 13, 51050], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 80, "seek": 32502, "start": 339.21999999999997, "end": 344.06, "text": " A Flan dzi\u0119ki treningowi oczekiwa\u0142 po prostu naturalnego pytania.", "tokens": [51074, 316, 3235, 282, 45003, 2192, 773, 24503, 277, 3689, 14753, 44603, 714, 19518, 3303, 11858, 25878, 5609, 13, 51316], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 81, "seek": 32502, "start": 344.21999999999997, "end": 347.62, "text": " Jego spos\u00f3b my\u015blenia by\u0142 lepiej dopasowany do problemu.", "tokens": [51324, 508, 6308, 22904, 48633, 6698, 654, 16673, 476, 39699, 360, 20990, 23341, 360, 1154, 84, 13, 51494], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 82, "seek": 32502, "start": 348.14, "end": 352.85999999999996, "text": " Sama instrukcja pozwoli\u0142a mu lepiej wykorzysta\u0107 wiedz\u0119, kt\u00f3r\u0105 ju\u017c mia\u0142.", "tokens": [51520, 318, 2404, 1058, 25126, 34056, 40557, 9384, 5024, 2992, 476, 39699, 43606, 49590, 2162, 46894, 11052, 11, 37415, 10678, 27989, 13, 51756], "temperature": 0.0, "avg_logprob": -0.12924727819916002, "compression_ratio": 1.375, "no_speech_prob": 0.05411342531442642}, {"id": 83, "seek": 35286, "start": 353.22, "end": 356.98, "text": " To brzmi logicznie, ale czy to jest jaki\u015b z\u0142oty \u015brodek?", "tokens": [50382, 1407, 738, 89, 3057, 9952, 89, 2766, 11, 6775, 6430, 281, 3492, 34721, 31614, 6737, 28580, 916, 30, 50570], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 84, "seek": 35286, "start": 357.7, "end": 361.5, "text": " Czy by\u0142y zadania, gdzie Instruction Tuning w og\u00f3le nie pom\u00f3g\u0142?", "tokens": [50606, 19832, 26366, 42788, 5609, 11, 18922, 2730, 3826, 21363, 278, 261, 29229, 2838, 12991, 14047, 1221, 30, 50796], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 85, "seek": 35286, "start": 361.82, "end": 363.82, "text": " Albo co gorsza zaszkodzi\u0142?", "tokens": [50812, 967, 1763, 598, 290, 830, 2394, 710, 19601, 74, 14543, 1221, 30, 50912], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 86, "seek": 35286, "start": 364.14, "end": 367.38, "text": " Tak i to jest bardzo wa\u017cne spostrze\u017cenie.", "tokens": [50928, 9118, 741, 281, 3492, 9034, 46110, 637, 555, 13503, 41118, 13, 51090], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 87, "seek": 35286, "start": 367.62, "end": 369.94, "text": " Pokazuje, \u017ce nie ma darmowych lanczy.", "tokens": [51102, 14958, 43317, 11, 3561, 2838, 463, 4072, 76, 19605, 287, 4463, 1229, 13, 51218], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 88, "seek": 35286, "start": 370.5, "end": 378.78000000000003, "text": " Ta technika nie przynios\u0142a poprawy w zadaniach, kt\u00f3re same w sobie s\u0105 bardzo podobne do tego, co modele j\u0119zykowe robi\u0105 od pocz\u0105tku.", "tokens": [51246, 6551, 1537, 5439, 2838, 6501, 77, 2717, 5024, 1665, 5131, 88, 261, 42788, 3782, 608, 11, 8864, 912, 261, 13652, 9015, 9034, 43024, 716, 360, 8627, 11, 598, 4391, 306, 49055, 74, 6880, 3870, 11404, 3611, 43959, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 89, "seek": 35286, "start": 378.98, "end": 381.38, "text": " Czyli do przewidywania nast\u0119pnego s\u0142owa.", "tokens": [51670, 37099, 360, 39758, 327, 27112, 5609, 39662, 11858, 15116, 5528, 13, 51790], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 90, "seek": 35286, "start": 381.62, "end": 382.38, "text": " Dok\u0142adnie.", "tokens": [51802, 29768, 10358, 2766, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1517290733229946, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.00248371041379869}, {"id": 91, "seek": 38238, "start": 382.62, "end": 389.65999999999997, "text": " Chodzi na przyk\u0142ad o uzupe\u0142nianie brakuj\u0105cych fragment\u00f3w w zdaniach, co testuje tak zwane Commonsense Reasoning.", "tokens": [50376, 761, 14543, 1667, 23144, 277, 344, 11728, 31457, 77, 952, 414, 1548, 74, 13263, 31306, 26424, 3901, 261, 16221, 3782, 608, 11, 598, 1500, 13008, 991, 11873, 1929, 3046, 13039, 39693, 278, 13, 50728], "temperature": 0.0, "avg_logprob": -0.16476212377133576, "compression_ratio": 1.5034482758620689, "no_speech_prob": 0.005900450050830841}, {"id": 92, "seek": 38238, "start": 389.9, "end": 401.58, "text": " Ach, czyli je\u015bli zadanie z natury polega na zgadni co b\u0119dzie dalej, to dodawanie instrukcji w stylu prosz\u0119 zgadni co b\u0119dzie dalej jest po prostu zb\u0119dne.", "tokens": [50740, 15847, 11, 16591, 25630, 42788, 7155, 710, 2249, 2598, 13208, 3680, 1667, 710, 70, 345, 3722, 598, 10562, 34257, 11, 281, 13886, 1607, 7155, 1058, 25126, 19649, 261, 7952, 2781, 39677, 710, 70, 345, 3722, 598, 10562, 34257, 3492, 714, 19518, 710, 65, 6298, 716, 13, 51324], "temperature": 0.0, "avg_logprob": -0.16476212377133576, "compression_ratio": 1.5034482758620689, "no_speech_prob": 0.005900450050830841}, {"id": 93, "seek": 38238, "start": 401.78, "end": 402.7, "text": " Dok\u0142adnie tak.", "tokens": [51334, 29768, 10358, 2766, 991, 13, 51380], "temperature": 0.0, "avg_logprob": -0.16476212377133576, "compression_ratio": 1.5034482758620689, "no_speech_prob": 0.005900450050830841}, {"id": 94, "seek": 38238, "start": 402.9, "end": 408.58, "text": " Autorzy sami napisali, \u017ce w takich przypadkach instrukcje s\u0105 w du\u017cej mierze redundantne.", "tokens": [51390, 6049, 284, 1229, 3247, 72, 9296, 271, 5103, 11, 3561, 261, 29607, 33100, 41326, 1058, 25126, 44261, 9015, 261, 1581, 38493, 47448, 1381, 40997, 716, 13, 51674], "temperature": 0.0, "avg_logprob": -0.16476212377133576, "compression_ratio": 1.5034482758620689, "no_speech_prob": 0.005900450050830841}, {"id": 95, "seek": 38238, "start": 408.94, "end": 411.65999999999997, "text": " I to pi\u0119knie pokazuje, gdzie le\u017cy si\u0142a tej metody.", "tokens": [51692, 286, 281, 48085, 2766, 13010, 43317, 11, 18922, 476, 7735, 1511, 5024, 12573, 1131, 843, 13, 51828], "temperature": 0.0, "avg_logprob": -0.16476212377133576, "compression_ratio": 1.5034482758620689, "no_speech_prob": 0.005900450050830841}, {"id": 96, "seek": 41166, "start": 411.98, "end": 415.06, "text": " OK, czyli wiemy, \u017ce to dzia\u0142a i gdzie dzia\u0142a najlepiej.", "tokens": [50380, 2264, 11, 16591, 3355, 2226, 11, 3561, 281, 37903, 741, 18922, 37903, 41903, 39699, 13, 50534], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 97, "seek": 41166, "start": 415.42, "end": 418.58000000000004, "text": " Ale dla mnie najciekawsze pytanie brzmi, dlaczego?", "tokens": [50552, 9366, 12285, 17661, 11212, 4260, 74, 28354, 36610, 738, 89, 3057, 11, 37873, 39329, 30, 50710], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 98, "seek": 41166, "start": 419.14000000000004, "end": 421.46000000000004, "text": " Co by\u0142o tym kluczowym sk\u0142adnikiem sukcesu?", "tokens": [50738, 3066, 14811, 8107, 9671, 1311, 89, 31691, 1110, 10358, 13123, 4907, 46432, 887, 84, 30, 50854], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 99, "seek": 41166, "start": 421.78000000000003, "end": 425.94000000000005, "text": " Czy chodzi\u0142o po prostu o to, \u017ceby wrzuci\u0107 do treningu jak najwi\u0119cej r\u00f3\u017cnych zada\u0144?", "tokens": [50870, 19832, 23998, 5249, 714, 19518, 277, 281, 11, 11316, 928, 11728, 39162, 360, 2192, 773, 84, 4207, 48636, 20811, 42602, 710, 1538, 5248, 30, 51078], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 100, "seek": 41166, "start": 426.38000000000005, "end": 431.98, "text": " To by\u0142o jedno z pierwszych pyta\u0144, kt\u00f3re sobie zadali i odpowied\u017a jest jednoznacznie tak.", "tokens": [51100, 1407, 14811, 5232, 1771, 710, 34016, 339, 10664, 1328, 5248, 11, 8864, 13652, 42788, 5103, 741, 36574, 10659, 3492, 5232, 1771, 22672, 14875, 2766, 991, 13, 51380], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 101, "seek": 41166, "start": 432.34000000000003, "end": 436.86, "text": " Pokazali to na bardzo wymownym wykresie, wygl\u0105da\u0142 troch\u0119 jak schody pn\u0105ce si\u0119 w g\u00f3r\u0119.", "tokens": [51398, 14958, 921, 5103, 281, 1667, 9034, 29764, 648, 4199, 39287, 495, 414, 11, 32015, 1221, 24926, 4207, 956, 843, 280, 13113, 384, 3244, 261, 290, 15614, 1274, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 102, "seek": 41166, "start": 437.5, "end": 438.34000000000003, "text": " Co to znaczy?", "tokens": [51656, 3066, 281, 36584, 30, 51698], "temperature": 0.0, "avg_logprob": -0.1174401770104895, "compression_ratio": 1.4322580645161291, "no_speech_prob": 0.003461072687059641}, {"id": 103, "seek": 43834, "start": 438.65999999999997, "end": 444.06, "text": " Za ka\u017cdym razem, gdy do programu nauczania dodawali now\u0105 grup\u0119 zada\u0144, np. t\u0142umaczenia,", "tokens": [50380, 31440, 31615, 76, 40225, 11, 28405, 360, 1461, 84, 49103, 89, 5609, 13886, 1607, 5103, 586, 1611, 12740, 1274, 710, 1538, 5248, 11, 33808, 13, 256, 49166, 326, 14320, 11, 50650], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 104, "seek": 43834, "start": 444.34, "end": 450.82, "text": " potem odpowiadanie na pytania, potem analiz\u0119 sentymentu, \u015brednia wydajno\u015b\u0107 na zupe\u0142nie nowych testach ros\u0142a.", "tokens": [50664, 36513, 24314, 38069, 7155, 1667, 25878, 5609, 11, 36513, 2624, 590, 1274, 2279, 88, 518, 84, 11, 8299, 986, 12679, 25984, 1805, 23293, 1667, 49922, 586, 16384, 1500, 608, 18953, 5024, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 105, "seek": 43834, "start": 451.46, "end": 454.58, "text": " Czyli ka\u017cdy nowy przedmiot szkolny czyni\u0142 go lepszym uczniem.", "tokens": [51020, 37099, 31615, 586, 88, 18334, 3057, 310, 7870, 36620, 1634, 6430, 3722, 1221, 352, 476, 1878, 26681, 35403, 2766, 76, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 106, "seek": 43834, "start": 454.78, "end": 456.41999999999996, "text": " Dok\u0142adnie i co ciekawe.", "tokens": [51186, 29768, 10358, 2766, 741, 598, 30596, 2330, 826, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 107, "seek": 43834, "start": 456.62, "end": 459.34, "text": " Ale chwila tu jest troch\u0119 wbrew intuicji.", "tokens": [51278, 9366, 26237, 7371, 2604, 3492, 24926, 261, 65, 2236, 560, 84, 299, 4013, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 108, "seek": 43834, "start": 459.82, "end": 463.38, "text": " Zwykle w uczeniu maszynowym w pewnym momencie jest \u015bciana.", "tokens": [51438, 1176, 9726, 14677, 261, 344, 66, 39651, 2300, 1229, 3785, 4199, 261, 47160, 4199, 40883, 3492, 220, 6199, 2095, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 109, "seek": 43834, "start": 463.82, "end": 466.21999999999997, "text": " Zyski z dodawania danych malej\u0105.", "tokens": [51638, 1176, 749, 2984, 710, 13886, 1607, 5609, 274, 34644, 7133, 8555, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1265272908396535, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.017087619751691818}, {"id": 110, "seek": 46622, "start": 466.78000000000003, "end": 471.5, "text": " A ty m\u00f3wisz, \u017ce im wi\u0119cej r\u00f3\u017cnorodno\u015bci tym lepiej i to bez widocznego sufitu?", "tokens": [50392, 316, 1104, 13489, 23848, 11, 3561, 566, 26004, 19637, 19048, 378, 16438, 8107, 476, 39699, 741, 281, 10782, 5274, 905, 89, 11858, 46282, 6380, 30, 50628], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 111, "seek": 46622, "start": 471.74, "end": 476.90000000000003, "text": " Dok\u0142adnie tak. Autorzy podkre\u015blaj\u0105, \u017ce ta krzywa wzrostu w stale si\u0119 mnie wyp\u0142aszcza\u0142a.", "tokens": [50640, 29768, 10358, 2766, 991, 13, 6049, 284, 1229, 2497, 27885, 1788, 875, 8555, 11, 3561, 1846, 350, 13047, 4151, 24809, 27494, 84, 261, 342, 1220, 3244, 17661, 46392, 1221, 19601, 41524, 5024, 13, 50898], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 112, "seek": 46622, "start": 477.42, "end": 480.70000000000005, "text": " To sugeruje, \u017ce potencja\u0142 na dalsz\u0105 poprawie jest ogromny.", "tokens": [50924, 1407, 459, 1321, 13008, 11, 3561, 1847, 22660, 2938, 1221, 1667, 274, 1124, 8925, 1665, 5131, 414, 3492, 34416, 298, 1634, 13, 51088], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 113, "seek": 46622, "start": 481.22, "end": 483.46000000000004, "text": " R\u00f3\u017cnorodno\u015b\u0107 do\u015bwiadcze\u0144 jest kluczowa.", "tokens": [51114, 497, 812, 1427, 19048, 378, 23293, 46661, 9680, 5248, 3492, 9671, 1311, 89, 5528, 13, 51226], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 114, "seek": 46622, "start": 484.02000000000004, "end": 485.86, "text": " Ale to prowadzi do kolejnego pytania.", "tokens": [51254, 9366, 281, 36590, 3992, 360, 23749, 11858, 25878, 5609, 13, 51346], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 115, "seek": 46622, "start": 486.18, "end": 488.18, "text": " A co z wielko\u015bci\u0105 m\u00f3zgu tego ucznia?", "tokens": [51362, 316, 598, 710, 20570, 4093, 50227, 32515, 89, 2794, 8627, 35403, 12679, 30, 51462], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 116, "seek": 46622, "start": 488.70000000000005, "end": 490.22, "text": " Czy rozmiar modelu mia\u0142 znaczenie?", "tokens": [51488, 19832, 9544, 3057, 289, 2316, 84, 27989, 15397, 326, 16778, 30, 51564], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 117, "seek": 46622, "start": 490.46000000000004, "end": 492.18, "text": " Wi\u0119kszy zawsze znaczy\u0142 lepszy?", "tokens": [51576, 30127, 1694, 1229, 30964, 15397, 14691, 1221, 476, 1878, 1229, 30, 51662], "temperature": 0.0, "avg_logprob": -0.12653443783144408, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.05647128075361252}, {"id": 118, "seek": 49218, "start": 492.62, "end": 497.5, "text": " I tu dochodzimy do najbardziej chyba szokuj\u0105cego odkrycia w ca\u0142ym artykule.", "tokens": [50386, 286, 2604, 9243, 378, 89, 13189, 360, 41857, 31532, 7870, 453, 13263, 384, 1571, 3611, 43298, 2755, 261, 35224, 4199, 594, 874, 74, 2271, 13, 50630], "temperature": 0.0, "avg_logprob": -0.1525286397626323, "compression_ratio": 1.4343065693430657, "no_speech_prob": 0.03592263534665108}, {"id": 119, "seek": 49218, "start": 498.1, "end": 503.46, "text": " Okazuje si\u0119, \u017ce nie tylko wi\u0119kszy znaczy lepszy, ale tylko wi\u0119kszy ma sens.", "tokens": [50660, 3477, 43317, 3244, 11, 3561, 2838, 13219, 29968, 1229, 36584, 476, 1878, 1229, 11, 6775, 13219, 29968, 1229, 463, 2923, 13, 50928], "temperature": 0.0, "avg_logprob": -0.1525286397626323, "compression_ratio": 1.4343065693430657, "no_speech_prob": 0.03592263534665108}, {"id": 120, "seek": 49218, "start": 503.58, "end": 504.1, "text": " Jak to?", "tokens": [50934, 15029, 281, 30, 50960], "temperature": 0.0, "avg_logprob": -0.1525286397626323, "compression_ratio": 1.4343065693430657, "no_speech_prob": 0.03592263534665108}, {"id": 121, "seek": 49218, "start": 504.38, "end": 512.82, "text": " W przypadku naprawd\u0119 du\u017cych modeli 68 i 137 miliard\u00f3w parametr\u00f3w Instruction Tuning dzia\u0142a\u0142 fantastycznie.", "tokens": [50974, 343, 41955, 20970, 1581, 7735, 339, 2316, 72, 23317, 741, 3705, 22, 1962, 72, 515, 3901, 6220, 27965, 3901, 2730, 3826, 21363, 278, 37903, 1221, 4115, 9820, 19923, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1525286397626323, "compression_ratio": 1.4343065693430657, "no_speech_prob": 0.03592263534665108}, {"id": 122, "seek": 49218, "start": 513.46, "end": 521.14, "text": " Ale dla mniejszych modeli 8 miliard\u00f3w i mniej ta sama technika pogarsza\u0142a ich wyniki na niewidzianych zadaniach.", "tokens": [51428, 9366, 12285, 39513, 45021, 2316, 72, 1649, 1962, 72, 515, 3901, 741, 39513, 1846, 17768, 1537, 5439, 32037, 685, 2394, 5024, 1893, 31936, 9850, 1667, 43622, 327, 89, 952, 16384, 42788, 3782, 608, 13, 51812], "temperature": 0.0, "avg_logprob": -0.1525286397626323, "compression_ratio": 1.4343065693430657, "no_speech_prob": 0.03592263534665108}, {"id": 123, "seek": 52114, "start": 521.26, "end": 523.06, "text": " Pogarsza\u0142a, to jak to jest w og\u00f3le mo\u017cliwe.", "tokens": [50370, 430, 664, 685, 2394, 5024, 11, 281, 4207, 281, 3492, 261, 29229, 30854, 826, 13, 50460], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 124, "seek": 52114, "start": 523.3, "end": 525.8199999999999, "text": " Uczymy go wi\u0119cej, a on staje si\u0119 gorszy.", "tokens": [50472, 624, 6522, 2226, 352, 26004, 11, 257, 322, 342, 11153, 3244, 290, 830, 1229, 13, 50598], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 125, "seek": 52114, "start": 526.3, "end": 527.66, "text": " To jest kompletnie bez sensu.", "tokens": [50622, 1407, 3492, 5207, 14657, 2766, 10782, 2923, 84, 13, 50690], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 126, "seek": 52114, "start": 527.9, "end": 532.78, "text": " Wiem, na pierwszy rzut oka to paradoks, ale hipoteza autor\u00f3w jest bardzo elegancka.", "tokens": [50702, 343, 4907, 11, 1667, 34016, 367, 89, 325, 277, 2330, 281, 13480, 25500, 11, 6775, 8103, 1370, 2394, 19510, 3901, 3492, 9034, 1118, 1275, 39342, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 127, "seek": 52114, "start": 533.14, "end": 537.74, "text": " Uwa\u017caj\u0105, \u017ce mniejsze modele maj\u0105 powiedzmy ograniczon\u0105 pojemno\u015b\u0107.", "tokens": [50964, 624, 27111, 11133, 11, 3561, 275, 44258, 4391, 306, 26064, 27617, 2226, 34416, 282, 17946, 266, 1611, 714, 30833, 23293, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 128, "seek": 52114, "start": 537.8199999999999, "end": 538.34, "text": " Ok.", "tokens": [51198, 3477, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 129, "seek": 52114, "start": 538.78, "end": 546.42, "text": " Kiedy uczymy je tych kilkudziesi\u0119ciu zada\u0144, one zu\u017cywaj\u0105 ca\u0142\u0105 swoj\u0105 moc na zapami\u0119tanie jak rozwi\u0105zywa\u0107 te konkretne zadania.", "tokens": [51246, 591, 16446, 344, 6522, 2226, 1506, 15180, 5128, 74, 532, 89, 530, 5034, 30795, 710, 1538, 5248, 11, 472, 2164, 7735, 86, 11133, 1335, 15926, 49194, 34962, 1667, 14223, 23806, 83, 7155, 4207, 9544, 18234, 1229, 25234, 535, 36500, 716, 42788, 5609, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1628601178020036, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0016819905722513795}, {"id": 130, "seek": 54642, "start": 546.54, "end": 552.2199999999999, "text": " Brakuje im ju\u017c miejsca w sieci neuronowej, \u017ceby nauczy\u0107 si\u0119 tej nadrz\u0119dnej metaumiej\u0119tno\u015bci.", "tokens": [50370, 4991, 5279, 2884, 566, 10678, 18522, 44239, 261, 2804, 537, 34090, 21091, 11, 11316, 49103, 27150, 3244, 12573, 12617, 19390, 6298, 11794, 19616, 449, 7764, 46788, 16438, 13, 50654], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 131, "seek": 54642, "start": 552.3399999999999, "end": 556.42, "text": " Czyli generalizacji, pod\u0105\u017cania za nowymi instrukcjami.", "tokens": [50660, 37099, 2674, 590, 13152, 11, 2497, 27242, 5609, 7949, 586, 88, 3057, 1058, 25126, 66, 73, 4526, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 132, "seek": 54642, "start": 556.5799999999999, "end": 557.2199999999999, "text": " Dok\u0142adnie.", "tokens": [50872, 29768, 10358, 2766, 13, 50904], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 133, "seek": 54642, "start": 557.66, "end": 563.4599999999999, "text": " Dopiero te naprawd\u0119 wielkie modele maj\u0105 wystarczaj\u0105co du\u017co pojemno\u015bci, by nauczy\u0107 si\u0119 obu rzeczy naraz.", "tokens": [50926, 42657, 12030, 535, 20970, 20570, 22872, 4391, 306, 26064, 4628, 9710, 3689, 11133, 1291, 26673, 714, 30833, 16438, 11, 538, 49103, 27150, 3244, 1111, 84, 26297, 6714, 921, 13, 51216], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 134, "seek": 54642, "start": 563.54, "end": 568.2199999999999, "text": " Rozwi\u0105zywania zada\u0144 z treningu i og\u00f3lnej zasady post\u0119powania z nowymi poleczeniami.", "tokens": [51220, 43313, 18234, 1229, 86, 5609, 710, 1538, 5248, 710, 2192, 773, 84, 741, 5360, 15741, 11794, 26530, 880, 2183, 1274, 14701, 5609, 710, 586, 88, 3057, 13208, 66, 2904, 15568, 13, 51454], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 135, "seek": 54642, "start": 568.74, "end": 574.54, "text": " To jest fascynuj\u0105ce, bo to obala mit, \u017ce ka\u017cda technika treningu to jaka\u015b magiczna r\u00f3\u017cczka.", "tokens": [51480, 1407, 3492, 30632, 1344, 77, 13263, 384, 11, 748, 281, 1111, 5159, 2194, 11, 3561, 21912, 2675, 1537, 5439, 2192, 773, 84, 281, 4207, 64, 1788, 5585, 35458, 19637, 3689, 2330, 13, 51770], "temperature": 0.0, "avg_logprob": -0.13489534916021886, "compression_ratio": 1.4903846153846154, "no_speech_prob": 0.03833339363336563}, {"id": 136, "seek": 57454, "start": 574.9399999999999, "end": 576.2199999999999, "text": " To troch\u0119 jak w sporcie.", "tokens": [50384, 1407, 24926, 4207, 261, 43729, 4260, 13, 50448], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 137, "seek": 57454, "start": 576.4599999999999, "end": 580.0999999999999, "text": " Zaawansowane techniki dla olimpijczyka mog\u0105 zaszkodzi\u0107 amatorowi.", "tokens": [50460, 31440, 1607, 599, 23066, 1537, 9850, 12285, 2545, 8814, 1718, 6522, 2330, 34123, 710, 19601, 74, 14543, 2162, 669, 1639, 24503, 13, 50642], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 138, "seek": 57454, "start": 580.42, "end": 581.5799999999999, "text": " Po prostu go przeci\u0105\u017c\u0105.", "tokens": [50658, 6165, 19518, 352, 8325, 34381, 1427, 1611, 13, 50716], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 139, "seek": 57454, "start": 581.86, "end": 583.02, "text": " Idealna analogia.", "tokens": [50730, 13090, 304, 629, 16660, 654, 13, 50788], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 140, "seek": 57454, "start": 583.3399999999999, "end": 587.3, "text": " To jest technika, kt\u00f3ra wymaga odpowiedniej skali, \u017ceby w og\u00f3le zadzia\u0142a\u0107.", "tokens": [50804, 1407, 3492, 1537, 5439, 11, 19456, 29764, 9286, 36574, 10402, 1110, 5103, 11, 11316, 261, 29229, 42788, 89, 25605, 2162, 13, 51002], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 141, "seek": 57454, "start": 587.5799999999999, "end": 591.4599999999999, "text": " Czyli Instruction Tuning to luksus dla wagi super ci\u0119\u017ckiej.", "tokens": [51016, 37099, 2730, 3826, 21363, 278, 281, 10438, 1694, 301, 12285, 261, 20291, 1687, 35484, 1427, 45145, 13, 51210], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 142, "seek": 57454, "start": 592.14, "end": 594.86, "text": " W\u0142a\u015bnie, a to doprowadzi\u0142o badaczy do ostatniego testu.", "tokens": [51244, 343, 5024, 12221, 11, 257, 281, 360, 35019, 3992, 5249, 1578, 14691, 360, 32686, 2766, 1571, 1500, 84, 13, 51380], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 143, "seek": 57454, "start": 595.06, "end": 596.14, "text": " Co by\u0142o wa\u017cniejsze?", "tokens": [51390, 3066, 14811, 27777, 44258, 30, 51444], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 144, "seek": 57454, "start": 596.4599999999999, "end": 597.9, "text": " Samar\u00f3\u017cnorodno\u015b\u0107 zada\u0144?", "tokens": [51460, 4832, 289, 812, 1427, 19048, 378, 23293, 710, 1538, 5248, 30, 51532], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 145, "seek": 57454, "start": 598.14, "end": 600.54, "text": " Czy jednak te instrukcje w naturalnym j\u0119zyku?", "tokens": [51544, 19832, 25897, 535, 1058, 25126, 44261, 261, 3303, 12996, 49055, 5279, 30, 51664], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 146, "seek": 57454, "start": 600.98, "end": 604.14, "text": " No w\u0142a\u015bnie, mo\u017ce wystarczy\u0142o po prostu uczy\u0107 go wielu rzeczy naraz.", "tokens": [51686, 883, 14234, 11, 12034, 4628, 9710, 6522, 5249, 714, 19518, 344, 33967, 352, 40437, 26297, 6714, 921, 13, 51844], "temperature": 0.0, "avg_logprob": -0.16212868409998277, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.002132406458258629}, {"id": 147, "seek": 60414, "start": 604.34, "end": 605.62, "text": " Bez tych wszystkich polece\u0144.", "tokens": [50374, 879, 89, 15180, 34234, 13208, 384, 5248, 13, 50438], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 148, "seek": 60414, "start": 605.9399999999999, "end": 606.6999999999999, "text": " Sprawdzili to.", "tokens": [50454, 1738, 15889, 89, 2312, 281, 13, 50492], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 149, "seek": 60414, "start": 607.02, "end": 608.3, "text": " Odpowied\u017a by\u0142a jednoznaczna.", "tokens": [50508, 12210, 14701, 1091, 10659, 23936, 5232, 1771, 22672, 14875, 629, 13, 50572], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 150, "seek": 60414, "start": 608.58, "end": 610.9, "text": " Instrukcje s\u0105 absolutnie kluczowe.", "tokens": [50586, 2730, 25126, 44261, 9015, 18757, 2766, 9671, 1311, 89, 6880, 13, 50702], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 151, "seek": 60414, "start": 611.5, "end": 616.34, "text": " Zrobili eksperyment, w kt\u00f3rym trenowali model na tej samej mieszance, ale bez naturalnych polece\u0144.", "tokens": [50732, 1176, 16614, 2312, 30724, 610, 88, 518, 11, 261, 30120, 23136, 305, 5103, 2316, 1667, 12573, 912, 73, 33039, 719, 11, 6775, 10782, 3303, 9399, 13208, 384, 5248, 13, 50974], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 152, "seek": 60414, "start": 616.66, "end": 619.14, "text": " Podawali mu na przyk\u0142ad tylko nazwy zbioru danych.", "tokens": [50990, 12646, 1607, 5103, 2992, 1667, 23144, 13219, 20151, 9726, 710, 33362, 84, 274, 34644, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 153, "seek": 60414, "start": 619.5, "end": 619.9, "text": " I co?", "tokens": [51132, 286, 598, 30, 51152], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 154, "seek": 60414, "start": 620.8199999999999, "end": 622.5, "text": " Wyniki dramatycznie spad\u0142y.", "tokens": [51198, 343, 2534, 9850, 42749, 17466, 2766, 637, 345, 6825, 13, 51282], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 155, "seek": 60414, "start": 623.02, "end": 626.54, "text": " Okaza\u0142o si\u0119, \u017ce model musi si\u0119 nauczy\u0107 budowa\u0107 ten most.", "tokens": [51308, 3477, 12257, 5249, 3244, 11, 3561, 2316, 37587, 3244, 49103, 27150, 3265, 11445, 2064, 881, 13, 51484], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 156, "seek": 60414, "start": 626.86, "end": 632.38, "text": " Mi\u0119dzy konkretnym sformu\u0142owaniem w j\u0119zyku naturalnym, a typem zadania, kt\u00f3rego si\u0119 od niego oczekuje.", "tokens": [51500, 376, 49485, 36500, 12996, 262, 837, 84, 1221, 37345, 4907, 261, 49055, 5279, 3303, 12996, 11, 257, 2125, 443, 42788, 5609, 11, 46951, 3244, 3611, 49615, 277, 3689, 916, 13008, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13382690335497444, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.010375362820923328}, {"id": 157, "seek": 63238, "start": 632.86, "end": 636.22, "text": " Bez tego j\u0119zykowego pomostu ca\u0142a metoda traci moc.", "tokens": [50388, 879, 89, 8627, 49055, 74, 26576, 12991, 555, 84, 1335, 5024, 1131, 13449, 504, 22086, 34962, 13, 50556], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 158, "seek": 63238, "start": 636.46, "end": 637.22, "text": " Podsumujmy.", "tokens": [50568, 12646, 82, 449, 4579, 2226, 13, 50606], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 159, "seek": 63238, "start": 637.98, "end": 642.54, "text": " Instruction tuning to w gruncie rzeczy prosta, ale pot\u0119\u017cna koncepcja.", "tokens": [50644, 2730, 3826, 15164, 281, 261, 677, 409, 4260, 26297, 582, 8638, 11, 6775, 1847, 1274, 1427, 629, 5897, 27493, 34056, 13, 50872], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 160, "seek": 63238, "start": 642.9, "end": 644.38, "text": " Bierzemy bardzo du\u017cy model.", "tokens": [50890, 363, 34602, 3633, 9034, 1581, 7735, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 161, "seek": 63238, "start": 644.9, "end": 649.9, "text": " I zamiast go specjalizowa\u0107, uczymy go og\u00f3lnej umiej\u0119tno\u015bci wykonywania polece\u0144.", "tokens": [50990, 286, 710, 4526, 525, 352, 46433, 590, 11445, 11, 344, 6522, 2226, 352, 5360, 15741, 11794, 1105, 7764, 46788, 16438, 39287, 2526, 86, 5609, 13208, 384, 5248, 13, 51240], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 162, "seek": 63238, "start": 650.22, "end": 657.78, "text": " Poprzez trening na ogromnej, zr\u00f3\u017cnicowanej mieszance zada\u0144, gdzie ka\u017cdy jest sformu\u0142owany jak naturalna ludzka instrukcja.", "tokens": [51256, 10215, 13503, 89, 2192, 773, 1667, 34416, 298, 11794, 11, 710, 11721, 1427, 7692, 23066, 73, 33039, 719, 710, 1538, 5248, 11, 18922, 31615, 3492, 262, 837, 84, 1221, 23341, 4207, 3303, 629, 15946, 89, 2330, 1058, 25126, 34056, 13, 51634], "temperature": 0.0, "avg_logprob": -0.12490269675183652, "compression_ratio": 1.3948339483394834, "no_speech_prob": 0.01349682454019785}, {"id": 163, "seek": 65778, "start": 658.14, "end": 663.66, "text": " I w rezultacie dostajemy model, kt\u00f3ry potrafi robi\u0107 zupe\u0142nie nowe rzeczy w trybie zero shot.", "tokens": [50382, 286, 261, 48060, 723, 30805, 20568, 1805, 3633, 2316, 11, 9913, 1847, 10437, 72, 46900, 49922, 586, 68, 26297, 261, 853, 7392, 4018, 3347, 13, 50658], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 164, "seek": 65778, "start": 664.14, "end": 666.18, "text": " Cz\u0119sto lepiej ni\u017c wi\u0119ksze modele.", "tokens": [50682, 383, 11052, 20875, 476, 39699, 28502, 29968, 1381, 4391, 306, 13, 50784], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 165, "seek": 65778, "start": 666.78, "end": 668.4599999999999, "text": " Ale s\u0105 dwa warunki brzegowe.", "tokens": [50814, 9366, 9015, 35045, 1516, 409, 2984, 738, 89, 1146, 6880, 13, 50898], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 166, "seek": 65778, "start": 668.9399999999999, "end": 672.06, "text": " Model musi by\u0107 du\u017cy, a instrukcje musz\u0105 by\u0107 jasne.", "tokens": [50922, 17105, 37587, 15069, 1581, 7735, 11, 257, 1058, 25126, 44261, 1038, 8925, 15069, 361, 296, 716, 13, 51078], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 167, "seek": 65778, "start": 672.3, "end": 673.02, "text": " Dok\u0142adnie.", "tokens": [51090, 29768, 10358, 2766, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 168, "seek": 65778, "start": 673.86, "end": 678.18, "text": " Wiesz patrz\u0105c na to z szerszej perspektywy, to nie jest tylko kolejna techniczna sztuczka.", "tokens": [51168, 343, 15347, 1947, 81, 8925, 66, 1667, 281, 710, 7870, 433, 16920, 868, 32659, 874, 9726, 11, 281, 2838, 3492, 13219, 23749, 629, 1537, 17946, 629, 262, 2682, 1311, 89, 2330, 13, 51384], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 169, "seek": 65778, "start": 678.62, "end": 682.22, "text": " To wygl\u0105da na fundamentaln\u0105 zmian\u0119 w podej\u015bciu do uczenia modeli.", "tokens": [51406, 1407, 32015, 1667, 8088, 13113, 43591, 1274, 261, 7468, 73, 6199, 84, 360, 344, 38517, 2316, 72, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1153436916977612, "compression_ratio": 1.3767605633802817, "no_speech_prob": 0.03610076755285263}, {"id": 170, "seek": 68222, "start": 682.5, "end": 683.34, "text": " Zdecydowanie.", "tokens": [50378, 1176, 1479, 1344, 67, 22028, 13, 50420], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 171, "seek": 68222, "start": 683.5400000000001, "end": 691.26, "text": " Ta metoda zaciera granice mi\u0119dzy, powiedzmy, wyspecjalizowanymi rzemie\u015blnikami, a modelami og\u00f3lnego przeznaczenia.", "tokens": [50430, 6551, 1131, 13449, 34430, 10609, 9370, 573, 33964, 11, 27617, 2226, 11, 27062, 494, 66, 22600, 590, 23341, 3057, 367, 24313, 414, 19212, 13123, 4526, 11, 257, 2316, 4526, 5360, 15741, 11858, 14064, 77, 326, 14320, 13, 50816], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 172, "seek": 68222, "start": 691.58, "end": 697.94, "text": " Pokazuje, \u017ce te same dane, kt\u00f3re do tej pory s\u0142u\u017cy\u0142y do zamykania modelu w jednej specjalizacji,", "tokens": [50832, 14958, 43317, 11, 3561, 535, 912, 49206, 11, 8864, 360, 12573, 280, 827, 48459, 7735, 6825, 360, 710, 7804, 5225, 654, 2316, 84, 261, 5232, 11794, 46433, 590, 13152, 11, 51150], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 173, "seek": 68222, "start": 697.98, "end": 700.22, "text": " mo\u017cna wykorzysta\u0107, \u017ceby go otworzy\u0107.", "tokens": [51152, 17790, 43606, 49590, 2162, 11, 11316, 352, 4337, 28321, 27150, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 174, "seek": 68222, "start": 700.6600000000001, "end": 705.9, "text": " Tak, \u017ceby go uczyni\u0107 bardziej elastycznym, zwinnym, gotowym na nowe wyzwania.", "tokens": [51286, 9118, 11, 11316, 352, 344, 6522, 3722, 2162, 27209, 806, 9820, 3689, 12996, 11, 11873, 259, 12996, 11, 658, 31691, 1667, 586, 68, 4628, 14406, 5609, 13, 51548], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 175, "seek": 68222, "start": 706.5400000000001, "end": 710.58, "text": " Zamiast tworzy\u0107 eksperta, tworzymy po prostu lepszego ucznia.", "tokens": [51580, 1176, 4526, 525, 46288, 27150, 30724, 610, 1328, 11, 46288, 1229, 2226, 714, 19518, 476, 1878, 27725, 35403, 12679, 13, 51782], "temperature": 0.0, "avg_logprob": -0.12481969636062096, "compression_ratio": 1.5, "no_speech_prob": 0.2049759328365326}, {"id": 176, "seek": 71058, "start": 710.86, "end": 712.9000000000001, "text": " I to prowadzi do ostatniej my\u015bli.", "tokens": [50378, 286, 281, 36590, 3992, 360, 32686, 10402, 452, 15350, 13, 50480], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 177, "seek": 71058, "start": 713.38, "end": 716.4200000000001, "text": " W artykule by\u0142 jeszcze jeden ciekawy detal.", "tokens": [50504, 343, 594, 874, 74, 2271, 16673, 14168, 12906, 46419, 41961, 33185, 13, 50656], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 178, "seek": 71058, "start": 716.74, "end": 722.4200000000001, "text": " Taki wyeducowany model staje si\u0119 te\u017c lepszy w innych technikach, jak prompt tuning.", "tokens": [50672, 314, 7421, 4628, 32604, 23341, 2316, 342, 11153, 3244, 9516, 476, 1878, 1229, 261, 36286, 1537, 1035, 608, 11, 4207, 12391, 15164, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 179, "seek": 71058, "start": 723.5, "end": 731.0600000000001, "text": " To sugeruje, \u017ce on nie tylko uczy si\u0119 reagowa\u0107 na komendy, on staje si\u0119 fundamentalnie bardziej podatny nastrojenie,", "tokens": [51010, 1407, 459, 1321, 13008, 11, 3561, 322, 2838, 13219, 344, 6522, 3244, 26949, 11445, 1667, 5207, 18642, 11, 322, 342, 11153, 3244, 8088, 2766, 27209, 2497, 267, 1634, 26088, 340, 15378, 414, 11, 51388], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 180, "seek": 71058, "start": 731.3000000000001, "end": 733.34, "text": " \u0142atwiejszy w dalszej edukacji.", "tokens": [51400, 47759, 86, 7764, 7706, 261, 274, 1124, 16920, 1257, 2034, 13152, 13, 51502], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 181, "seek": 71058, "start": 733.82, "end": 735.82, "text": " To nie jest tylko nowa umiej\u0119tno\u015b\u0107.", "tokens": [51526, 1407, 2838, 3492, 13219, 586, 64, 1105, 7764, 46788, 23293, 13, 51626], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 182, "seek": 71058, "start": 736.0600000000001, "end": 739.98, "text": " Wygl\u0105da, jakby\u015bmy zmieniali jego podstawow\u0105 zdolno\u015b\u0107 do nauki.", "tokens": [51638, 14458, 7191, 26398, 11, 28976, 10513, 17020, 1053, 831, 72, 26542, 43443, 30297, 16221, 401, 23293, 360, 35616, 2984, 13, 51834], "temperature": 0.0, "avg_logprob": -0.1405453090250057, "compression_ratio": 1.4655172413793103, "no_speech_prob": 0.008364776149392128}, {"id": 183, "seek": 73998, "start": 740.0600000000001, "end": 740.86, "text": " Dok\u0142adnie.", "tokens": [50368, 29768, 10358, 2766, 13, 50408], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 184, "seek": 73998, "start": 741.5, "end": 742.82, "text": " I tu dochodzimy do sedna.", "tokens": [50440, 286, 2604, 9243, 378, 89, 13189, 360, 9643, 629, 13, 50506], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 185, "seek": 73998, "start": 743.22, "end": 747.0600000000001, "text": " Do tej pory uczyli\u015bmy modele g\u0142\u00f3wnie, co maj\u0105 my\u015ble\u0107 o problemie,", "tokens": [50526, 1144, 12573, 280, 827, 344, 6522, 38452, 4391, 306, 18117, 812, 14215, 11, 598, 26064, 48633, 306, 2162, 277, 1154, 414, 11, 50718], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 186, "seek": 73998, "start": 747.46, "end": 751.34, "text": " a ta metoda uczy je, jak my\u015ble\u0107 o ka\u017cdym nowym problemie.", "tokens": [50738, 257, 1846, 1131, 13449, 344, 6522, 1506, 11, 4207, 48633, 306, 2162, 277, 31615, 76, 586, 4199, 1154, 414, 13, 50932], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 187, "seek": 73998, "start": 751.54, "end": 755.98, "text": " To jest przej\u015bcie od uczenia si\u0119 na pami\u0119\u0107 do uczenia z rozumieniem.", "tokens": [50942, 1407, 3492, 8325, 73, 9815, 3611, 344, 38517, 3244, 1667, 31088, 2162, 360, 344, 38517, 710, 48797, 1053, 4907, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 188, "seek": 73998, "start": 756.1800000000001, "end": 763.14, "text": " Tak, to jest r\u00f3\u017cnica mi\u0119dzy zapami\u0119taniem rozm\u00f3wek na wyjazd, a faktycznym nauczeniem si\u0119 gramatyki.", "tokens": [51174, 9118, 11, 281, 3492, 19637, 32687, 33964, 14223, 23806, 20356, 4907, 35234, 812, 826, 74, 1667, 4628, 34820, 67, 11, 257, 33647, 874, 3689, 12996, 49103, 2904, 4907, 3244, 21353, 21398, 2984, 13, 51522], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 189, "seek": 73998, "start": 763.7, "end": 766.9, "text": " Jedno pozwala zam\u00f3wi\u0107 kaw\u0119, drugie napisa\u0107 powie\u015b\u0107.", "tokens": [51550, 27076, 1771, 40557, 5159, 19876, 3901, 12757, 350, 1607, 1274, 11, 4110, 414, 9296, 3837, 2162, 3388, 414, 7753, 13, 51710], "temperature": 0.0, "avg_logprob": -0.13937943557213092, "compression_ratio": 1.4836363636363636, "no_speech_prob": 0.003964376635849476}, {"id": 190, "seek": 76690, "start": 767.4599999999999, "end": 772.9399999999999, "text": " I ta zdolno\u015b\u0107 do generalizacji, no, to jest ten \u015bwi\u0119ty gral AI.", "tokens": [50392, 286, 1846, 16221, 401, 23293, 360, 2674, 590, 13152, 11, 572, 11, 281, 3492, 2064, 8299, 22423, 874, 677, 304, 7318, 13, 50666], "temperature": 0.0, "avg_logprob": -0.18119752934548708, "compression_ratio": 1.4083333333333334, "no_speech_prob": 0.06894319504499435}, {"id": 191, "seek": 76690, "start": 773.14, "end": 776.98, "text": " Co zostawia nas z intryguj\u0105cym pytaniem na przysz\u0142o\u015b\u0107?", "tokens": [50676, 3066, 31873, 34953, 5382, 710, 560, 627, 2794, 8555, 1344, 76, 25878, 282, 4907, 1667, 44018, 44742, 30, 50868], "temperature": 0.0, "avg_logprob": -0.18119752934548708, "compression_ratio": 1.4083333333333334, "no_speech_prob": 0.06894319504499435}, {"id": 192, "seek": 76690, "start": 777.18, "end": 788.5799999999999, "text": " Skoro mo\u017cemy uczy\u0107 modele generalizowania na podstawie instrukcji, to czy nasza rola powoli zmienia si\u0119 z roli in\u017cynier\u00f3w AI w rol\u0119 nauczycieli?", "tokens": [50878, 7324, 10780, 26500, 344, 33967, 4391, 306, 2674, 590, 21308, 1667, 43443, 414, 1058, 25126, 19649, 11, 281, 6430, 5382, 2394, 744, 875, 3388, 9384, 17020, 18811, 3244, 710, 744, 2081, 294, 1427, 2534, 811, 3901, 7318, 261, 34109, 1274, 49103, 1229, 537, 10148, 30, 51448], "temperature": 0.0, "avg_logprob": -0.18119752934548708, "compression_ratio": 1.4083333333333334, "no_speech_prob": 0.06894319504499435}, {"id": 193, "seek": 76690, "start": 789.34, "end": 792.78, "text": " Projektant\u00f3w program\u00f3w nauczania dla sztucznych umys\u0142\u00f3w.", "tokens": [51486, 34804, 394, 3901, 1461, 3901, 49103, 89, 5609, 12285, 262, 2682, 1311, 89, 9399, 1105, 39508, 3901, 13, 51658], "temperature": 0.0, "avg_logprob": -0.18119752934548708, "compression_ratio": 1.4083333333333334, "no_speech_prob": 0.06894319504499435}, {"id": 194, "seek": 79278, "start": 793.5799999999999, "end": 801.26, "text": " I co to w\u0142a\u015bciwie b\u0119dzie znaczy\u0107, \u017ce model rozumie polecenie, kiedy jego program nauczania stanie si\u0119 tak bogaty jak nasz w\u0142asny?", "tokens": [50404, 286, 598, 281, 50108, 10562, 36584, 2162, 11, 3561, 2316, 48797, 414, 13208, 13037, 414, 11, 18777, 26542, 1461, 49103, 89, 5609, 40013, 3244, 991, 26132, 21398, 4207, 5382, 89, 43572, 1634, 30, 50788], "temperature": 0.0, "avg_logprob": -0.15642831875727728, "compression_ratio": 1.2039473684210527, "no_speech_prob": 0.08993493765592575}, {"id": 195, "seek": 79278, "start": 802.06, "end": 804.62, "text": " To pytanie, kt\u00f3re na razie pozostaje otwarte.", "tokens": [50828, 1407, 36610, 11, 8864, 1667, 9639, 414, 21281, 555, 11153, 4337, 86, 11026, 13, 50956], "temperature": 0.0, "avg_logprob": -0.15642831875727728, "compression_ratio": 1.2039473684210527, "no_speech_prob": 0.08993493765592575}], "language": "pl"}