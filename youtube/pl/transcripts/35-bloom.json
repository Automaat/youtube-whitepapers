{"text": " co by by\u0142o, gdyby najwi\u0119ksze umys\u0142y z ca\u0142ego \u015bwiata zebra\u0142y si\u0119, \u017ceby zbudowa\u0107 jeden z najpot\u0119\u017cniejszych modeli j\u0119zykowych, a potem udost\u0119pnili go wszystkim za darmu. Brzmi jak science fiction. Prawda. Ale to dok\u0142adnie historia powstania modelu Bloom, kt\u00f3rej dzisiaj si\u0119 przyjrzymy. Dok\u0142adnie. Mamy przed sob\u0105 prac\u0119 naukow\u0105, kt\u00f3ra opisuje Bloom, to jest kolos, 176 miliard\u00f3w parametr\u00f3w. Ale wiesz, kluczowe jest to, \u017ce nie stworzy\u0142a go jedna korporacja za zamkni\u0119tymi drzwiami. Tylko kto? To by\u0142 efekt otwartej wsp\u00f3\u0142pracy, ponad 1000 badaczy z projektu Big Science. Wi\u0119c to nie jest tylko opowie\u015b\u0107 o technologii, ale o zupe\u0142nie nowym sposobie jej tworzenia, radykalnie otwartym. Czyli naszym celem jest zrozumie\u0107, co sprawia, \u017ce Bloom jest tak wyj\u0105tkowy, jak go zbudowano i co to wszystko oznacza dla przysz\u0142o\u015bci AI. OK, to zanurzmy si\u0119 w temat. Mo\u017ce zacznijmy od kontekstu, bo on jest tu, wydaje mi si\u0119, absolutnie kluczowy. Zdecydowanie. Zanim pojawi\u0142 si\u0119 Bloom, \u015bwiat wielkich modeli j\u0119zykowych tych LLM\u00f3w, by\u0142 bardzo ekskluzywny. Pot\u0119\u017cne modele powstawa\u0142y za zamkni\u0119tymi drzwiami w naprawd\u0119 bogatych organizacjach. To tworzy\u0142o ogromn\u0105 barier\u0119 dla naukowc\u00f3w z zewn\u0105trz. I co r\u00f3wnie wa\u017cne, prowadzi\u0142o do niemal ca\u0142kowitego skupienia si\u0119 na j\u0119zyku angielskim. W\u0142a\u015bnie. I to jest dok\u0142adnie punkt wyj\u015bcia dla ca\u0142ej tej pracy. Autorzy wprost pisz\u0105 o, cytuj\u0119, spo\u0142ecznych ograniczeniach rozwoju LLM. Czyli nie chodzi\u0142o im tylko o technologie? Nie, celem nie by\u0142o po prostu stworzenie kolejnego wielkiego modelu, kt\u00f3ry pobije jaki\u015b benchmark. Chodzi\u0142o o co\u015b znacznie wi\u0119kszego, o demokratyzacj\u0119 tej technologii. Co to znaczy w praktyce? To znaczy, \u017ce od samego pocz\u0105tku za\u0142o\u017cyli, \u017ce model musi by\u0107 Open Access, czyli w pe\u0142ni dost\u0119pny. I co najwa\u017cniejsze, prawdziwie wieloj\u0119zyczny. No dobrze, ale s\u0142owo demokratyzacja bywa nadu\u017cywane. M\u00f3wimy tu o projekcie Big Science. To by\u0142o ponad 1200 uczestnik\u00f3w z 38 kraj\u00f3w. Tak. Ale to, co mnie naprawd\u0119 uderzy\u0142o, to nie tylko skala, ale r\u00f3\u017cnorodno\u015b\u0107. To nie byli, wiesz, sami specjali\u015bci od Machine Learning. No w\u0142a\u015bnie. Byli tam linkwi\u015bci, prawnicy, filozofowie, socjolodzy. I to jest sedno sprawy. Co wi\u0119cej, ca\u0142y ten ogromny, rozproszony zesp\u00f3\u0142 kierowa\u0142 si\u0119 od samego pocz\u0105tku czym\u015b, co nazwali kart\u0105 etyczn\u0105. Ethical Charter. Dok\u0142adnie. Wiesz, \u0142atwo by\u0107 cynicznym, jak si\u0119 s\u0142ysz\u0119 o czym\u015b takim jak karta etyczna. W \u015bwiecie korpo to cz\u0119sto jest po prostu PDF na stronie internetowej, kt\u00f3ry nic nie znaczy. Rozumiem sceptyzm. Jakie mamy do wody, \u017ce ta karta by\u0142a czym\u015b wi\u0119cej ni\u017c tylko dobrym pijarem? To jest \u015bwietne i bardzo zasadne pytanie. A ta praca naukowa dostarcza konkretnych odpowiedzi. Najlepszy przyk\u0142ad to proces zbierania danych. OK. Zamiast i\u015b\u0107 na \u0142atwizn\u0119 i wiesz po prostu zasa\u0107 p\u00f3\u0142 internetu, co jest standardem. Bo tak si\u0119 zwykle robi. Dok\u0142adnie. Oni podj\u0119li \u015bwiadom\u0105 decyzj\u0119 o r\u0119cznym i celowym kuratorowaniu \u017ar\u00f3de\u0142. Wsp\u00f3\u0142pracowali z grupami takimi jak masakane, \u017ceby \u015bwiadomie w\u0142\u0105czy\u0107 j\u0119zyki afryka\u0144skie, albo z Latinx in AI. Czyli to by\u0142a bezpo\u015brednia konsekwencja zapis\u00f3w tej karty o inkluzywno\u015bci. Tak. I to kosztowa\u0142o ich mn\u00f3stwo czasu i pieni\u0119dzy, ale trzymali si\u0119 tej zasady. Czyli decyzje techniczne by\u0142y podyktowane warto\u015bciami. To faktycznie robi r\u00f3\u017cnic\u0105. Dobrze, to zejd\u017amy g\u0142\u0119biej. Jasne. \u017beby wytrenowa\u0107 model o 176 miliardach parametr\u00f3w, potrzeba niewyobra\u017calnej ilo\u015bci danych. M\u00f3wisz, \u017ce to nie by\u0142 zwyk\u0142y zrzut z sieci. Zgadza si\u0119. Blum by\u0142 trenowany na korpusie Roots. To by\u0142o jeden przycinek 61 terabajta tekstu. Gigantyczna ilo\u015b\u0107. A decodaj wa\u017cniejsze, ten korpus sk\u0142ada\u0142 si\u0119 z danych z 46 j\u0119zyk\u00f3w naturalnych i 13 j\u0119zyk\u00f3w programowania. A sam proces jego tworzenia by\u0142 nadzorowany przez ludzi. Co to zmienia? To stoi w ostrym kontra\u015bcie z typowym automatycznym filtrowaniem. Inne badania, kt\u00f3re oni cytuj\u0105, pokazuj\u0105, \u017ce takie filtry potrafi\u0105 przypadkowo wycina\u0107 ca\u0142e po\u0142acie internetu. Na przyk\u0142ad? Na przyk\u0142ad tre\u015bci tworone przez spo\u0142eczno\u015bci LGBTQ+, albo teksty pisane w dialekcie Afrikan American English. Tutaj tego unikni\u0119to. I to jest fascynuj\u0105ce. Czyta\u0142am, \u017ce poszli nawet okrok dalej i zdobyli oficjalne zgody na wykorzystanie danych od niekt\u00f3rych wydawc\u00f3w. Tak, na przyk\u0142ad od francuskiej gazety Lemon. To jest zupe\u0142nie inny poziom dba\u0142o\u015bci o \u017ar\u00f3d\u0142a ni\u017c jeste\u015bmy przyzwyczajeni. Niesamowite. Ale dane to jedno. Przejd\u017amy do samej maszyny. Jak zbudowany jest ten gigant? Podstawowa archipektura to Decoder Only Transformer, czyli bardzo podobna do tej, kt\u00f3r\u0105 znamy z modeli serii GPT. Wyb\u00f3r by\u0142 raczej pragmatyczny? Tak. Ich w\u0142asne eksperymenty pokaza\u0142y, \u017ce modele Causal Decoder Only osi\u0105ga\u0142y najlepsze wyniki w generalizacji Zero Shot zaraz po treningu. Ale, jak zawsze, diabe\u0142 tkwi w szczeg\u00f3\u0142ach. I co to za szczeg\u00f3\u0142y? Wprowadzili dwa kluczowe ulepszenia w stosunku do standardowej architektury. Pierwsze to Alibi Positional Emberings. To jest odpowied\u017a na to fundamentalne pytanie. Sk\u0105d model wie, w jakiej kolejno\u015bci s\u0105 s\u0142owa w zdaniu? Dok\u0142adnie. Wyobra\u017a sobie, \u017ce tradycyjne metody nadaj\u0105 ka\u017cdemu s\u0142owu w zdaniu konkretny adres, jak numer domu na ulicy, s\u0142owo numer jeden, s\u0142owo numer dwa i tak dalej. Okej. Alibi dzia\u0142a inaczej, bardziej intuicyjnie. Nie u\u017cywa adres\u00f3w. Po prostu m\u00f3wi modelowi. Hej, s\u0142owo, na kt\u00f3re teraz patrzysz, jest tu\u017c obok, ale bardzo daleko od tamtego na ko\u0144cu, czyli im bli\u017cej tym wa\u017cniej. W\u0142a\u015bnie. Ta prosta zasada okaza\u0142a si\u0119 znacznie bardziej elastyczna. Bezpo\u015brednio os\u0142abia si\u0142\u0119 uwagi, czyli attention scores, w zale\u017cno\u015bci od odleb\u0142o\u015bci. I badania, na kt\u00f3re si\u0119 powo\u0142uj\u0105, pokaza\u0142y, \u017ce to prowadzi do stabilniejszego treningu i lepszych wynik\u00f3w. To ma sens. Bardziej elastyczne podej\u015bcie, a to drugie ulepszenie. Drugie to embedding layer norm. To jest dodatkowa warstwa normalizacyjna, czyli layer normalization, dodana zaraz po warstwie wej\u015bciowej embedding layer. I tu jest co\u015b fascynuj\u0105cego, prawda? O i tak. Zosta\u0142a dodana, by poprawi\u0107 stabilno\u015b\u0107 treningu przy tej ogromnej skali. Czekaj, ale co w tym fascynuj\u0105cego? Dodanie czego\u015b dla stabilno\u015bci brzmi jak standardowa procedura in\u017cynierska. Ale w\u0142a\u015bnie nie do ko\u0144ca, bo w ich w\u0142asnych testach na mniejszych modelach ta dodatkowa warstwa nieznacznie pogarsza\u0142a wyniki zero shot. Fila chwila, czyli \u015bwiadomie dodali co\u015b, co obni\u017ca\u0142o wydajno\u015b\u0107? Tak. To brzmi kompletnie wbrew intuicji, zw\u0142aszcza w projekcie za miliony dolar\u00f3w. Dok\u0142adnie. I to jest kluczowy wgl\u0105d w realia in\u017cynierii na tej skali. Przy tak gigantycznym modelu samo utrzymanie treningu przy \u017cyciu, bez jego za\u0142amania, jest monumentalnym wyzlaniem. Rozumiem. Ta decyzja nie mia\u0142a na ce\u0142u wyci\u015bni\u0119cia dodatkowego u\u0142amka procenta na jakim\u015b benchmarku. To by\u0142 pragmatyczny wyb\u00f3r, kt\u00f3ry mia\u0142 zagwarantowa\u0107, \u017ce ca\u0142y proces w og\u00f3le dobiegnie ko\u0144ca. To jest niesamowite. Czyli priorytetem by\u0142o nie zepsu\u0107, zamiast maksymalizowa\u0107. To idealny przyk\u0142ad, jak teoria zderza si\u0119 z in\u017cynierijn\u0105 rzeczywisto\u015bci\u0105. Brzmi jakby ka\u017cda nawet najmniejsza decyzja musia\u0142a by\u0107 przemy\u015blana na nowo dla tej skali. Domy\u015blam si\u0119, \u017ce podobnie by\u0142o z najbardziej fundamentalnym krokiem. Czyli? I jak w og\u00f3le podzieli\u0107 tekst z 46 r\u00f3\u017cnych j\u0119zyk\u00f3w na kawa\u0142ki, zanim wrzuci si\u0119 go do modelu? To musia\u0142o by\u0107 piekielne wyzwanie. By\u0142o ogromne. I tu te\u017c podj\u0119li bardzo ciekawe decyzje. U\u017cyto algorytmu Byte Level BPE na s\u0142owniku o wielko\u015bci prawie 251 tysi\u0119cy token\u00f3w. A co oznacza to Byte Level? To oznacza, \u017ce tokalizacja nigdy nie napotka nieznanego znaku. Bo operuje na poziomie byt\u00f3w, a nie znak\u00f3w unicode. To kluczowe dla modelu, kt\u00f3ry ma radzi\u0107 sobie z tak\u0105 r\u00f3\u017cnorodno\u015bci\u0105 j\u0119zyk\u00f3w i symboli. Co wi\u0119cej, \u015bwiadomie zrezygnowano z jakiejkolwiek normalizacji tekstu, jak np. NFKC, \u017ceby model uczy\u0142 si\u0119 na surowych, nieoczyszczonych danych. Odrzucili te\u017c te typowo anglo-centryczne regu\u0142y np. wok\u00f3\u0142 ko\u0144c\u00f3wek end czy ill. Dok\u0142adnie. Wszystko po to, by by\u0107 jak najbardziej neutralnym j\u0119zykowo. Mamy wi\u0119c gigantyczny, wieloj\u0119zyczny model zbudowany na unikalnym, r\u0119cznie kuratorowanym zbiorze danych. Z kilkoma bardzo sprytnymi modyfikacjami w architekturze, podyktowanymi pragmatyzmem. Pytanie za 100 punkt\u00f3w. Jak to wszystko dzia\u0142a w praktyce? Czy ta ca\u0142a filozofia i ten wysi\u0142ek prze\u0142o\u017cy\u0142o si\u0119 na wyniki? Wyniki s\u0105 z\u0142o\u017cone, ale w\u0142a\u015bnie przez to tak ciekawe. Zacznijmy od czego\u015b, co mo\u017ce wydawa\u0107 si\u0119 testem wbrew za\u0142o\u017ceniam benchmark superglue. Kt\u00f3ry jest w 100% po angielsku? Tak. I bloom wypada tu por\u00f3wnywalnie do innych modeli tej skali jak np. OPT. Czyli nie jest gorszy. Co ju\u017c samo w sobie jest sukcesem. Bo mo\u017cna by si\u0119 obawia\u0107, \u017ce model, kt\u00f3ry uczy\u0142 si\u0119 45 innych j\u0119zyk\u00f3w, b\u0119dzie s\u0142abszy w angielskim. Taki jack of all trades, master of none. Dok\u0142adnie. A tak nie jest. Ale jest co\u015b jeszcze ciekawszego. Co takiego? Przy przej\u015bciu z trybu zero shot do one shot. Czyli gdy model dostaje jeden przyk\u0142ad zadania? W\u0142a\u015bnie. Jego wydajno\u015b\u0107 ro\u015bnie bardziej ni\u017c u konkurencji. Autorzy spekuluj\u0105, \u017ce ten jeden przyk\u0142ad, ten dodatkowy kontekst, pomaga wieloj\u0119zycznemu m\u00f3zgowi bluma skupi\u0107 si\u0119 na angielskim i lepiej zrozumie\u0107 zadanie. Czyli trening wieloj\u0119zyczny nie tylko nie zaszkodzi\u0142, ale mo\u017ce nawet da\u0142 mu pewn\u0105 elastyczno\u015b\u0107. To mocny dow\u00f3d na to. OK, czyli na angielskim terytorium daje rad\u0119. Ale przecie\u017c ca\u0142y sen z tego projektu to by\u0142a radykalna wieloj\u0119zyczno\u015b\u0107. Jak sobie poradzi\u0142 na przyk\u0142ad z t\u0142umaczeniem? I to zaczyna si\u0119 prawdziwa magia. Na zestawie flores 101, kt\u00f3ry obejmuje mn\u00f3stwo par j\u0119zykowych, blum cz\u0119sto rywalizowa\u0142, a czasem nawet wygrywa\u0142 z wyspecjalizowanymi nadzorowanymi modelami. Chwileczk\u0119. Chcesz powiedzie\u0107, \u017ce konkurowa\u0142 z modelami, kt\u00f3re zosta\u0142y stworzone tylko i wy\u0142\u0105cznie do t\u0142umaczenia? W\u0142a\u015bnie tak. A wisienka na torcie jest taka, \u017ce potrafi\u0142 nawet t\u0142umaczy\u0107 z j\u0119zyka galicyjskiego. Kt\u00f3rego oficjalnie w og\u00f3le nie widzia\u0142 podczas treningu? Nie widzia\u0142. Prawdopodobnie wykorzysta\u0142 jego ogromne podobie\u0144stwo do innych j\u0119zyk\u00f3w roma\u0144skich, jak hiszpa\u0144ski czy portugalski, kt\u00f3re by\u0142y w danych. To pokazuje niesamowit\u0105 zdolno\u015b\u0107 do transferu wiedzy mi\u0119dzy j\u0119zykami. Ale czuj\u0119, \u017ce musi by\u0107 jakie\u015b ale. Gdzie s\u0105 jego s\u0142absze strony? Oczywi\u015bcie, \u017ce s\u0105. Model bardzo s\u0142abo radzi sobie z j\u0119zykami, kt\u00f3re mia\u0142y ma\u0142\u0105 reprezentacj\u0119 w danych treningowych, jak s\u0142ahili czy joruba. I to jest brutalne zderzenie z rzeczywisto\u015bci\u0105. Zdecydowanie. Pokazuje, \u017ce pomimo ca\u0142ej innowacyjnej architektury i filozofii ilo\u015b\u0107 danych dla danego j\u0119zyka wci\u0105\u017c jest absolutnie kluczowym czynnikiem. Nie da si\u0119 tego przyskoczy\u0107 sam\u0105 m\u0105dro\u015bci\u0105 modelu. Niestety nie. Rozumiem. Dane to wci\u0105\u017c paliwo. A co z kodem? W korpusie by\u0142o 13 j\u0119zyk\u00f3w programowania. Tutaj wyniki s\u0105 zgodne z oczekiwaniami. Na benchmarku Human Evil wydajno\u015b\u0107 jest podobna do modeli GPT trenowanych na korpusie Depile, kt\u00f3ry te\u017c miesza tekst i kod. Ale jest znacznie ni\u017csze ni\u017c w przypadku modeli wyspecjalizowanych w kodzie, jak kodeks. No tak. To logiczne, bo kod stanowi\u0142 tylko oko\u0142o 11% danych treningowych bloom. Po prostu nie by\u0142 to jego priorytet. Praca du\u017co miejsca po\u015bwi\u0119ca te\u017c czemu\u015b, co nazywa si\u0119 bloom Z. Co to jest i co da\u0142 ten ca\u0142y proces multitask find tuning? To jest kluczowy i ostatni etap ewolucji tego modelu. Multitask prompted find tuning to proces, w kt\u00f3rym gotowy, wytrenowany model jest dodatkowo dostrajany na zbiorze bardzo r\u00f3\u017cnorodnych zada\u0144. A te zadania s\u0105 opisane w j\u0119zyku naturalnym za pomoc\u0105 tak zwanych prompt\u00f3w. Dok\u0142adnie. U\u017cyto do tego specjalnie przygotowanego wieloj\u0119zycznego zbioru XP3. I jaki by\u0142 efekt? Drastyczna poprawa zdolno\u015bci zero shot w zadaniach, kt\u00f3rych model wcze\u015bniej nie widzia\u0142. Bloom Z, czyli model po tym procesie, znacznie przewy\u017csza bazowy model bloom, na przyk\u0142ad w zadaniach wnioskowania w j\u0119zyku naturalnym. Czyli to przej\u015bcie od wiedzy do dzia\u0142ania. Idealne podsumowanie. Samo przeczytanie internetu to jedno, a nauczenie si\u0119 wykonywania konkretnych polece\u0144 to zupe\u0142nie inna, ale niezwykle wa\u017cna umiej\u0119tno\u015b\u0107. Dobrze. To spr\u00f3bujmy zebra\u0107 to wszystko w ca\u0142o\u015b\u0107. Gdyby trzeba by\u0142o wskaza\u0107 najwa\u017cniejszy wniosek z ca\u0142ego ogromnego projektu bloom, co by to by\u0142o? My\u015bl\u0119, \u017ce s\u0105 trzy kluczowe lekcje. Po pierwsze, i to mo\u017ce by\u0107 najwa\u017cniejsze. Proces jest r\u00f3wnie wa\u017cny jak produkt. Hmm. Historia Big Science to gotowy przepis na to, jak w przysz\u0142o\u015bci mo\u017cna prowadzi\u0107 otwarte i co wa\u017cne etycznie \u015bwiadome projekty w AI. Pokazali, \u017ce da si\u0119 to zrobi\u0107 inaczej. Zgadzam si\u0119. Sama organizacja pracy, zaanga\u017cowanie spo\u0142eczno\u015bci i ta karta etyczna, kt\u00f3ra faktycznie dzia\u0142a\u0142a, s\u0105 osi\u0105gni\u0119ciem na miar\u0119 samego modelu. Jak jest drugi punkt? Drugi to twardy dow\u00f3d na to, \u017ce prawdziwa wieloj\u0119zyczno\u015b\u0107 jest mo\u017cliwa, ale ma swoje granice. To znaczy? Bloom udowodnia, \u017ce mo\u017cna stworzy\u0107 pot\u0119\u017cny model wieloj\u0119zyczny, kt\u00f3ry nie traci na wydajno\u015bci w j\u0119zykach z du\u017c\u0105 ilo\u015bci\u0105 danych jak angielski. Jednocze\u015bnie jego problemy z j\u0119zykami o niskich zasobach to zimny prysznic. Pokazuj\u0105, jak krytycznie wa\u017cna jest reprezentacja danych. W\u0142a\u015bnie. Je wystarczy wrzuci\u0107 kilkuset zda\u0144 w danym j\u0119zyku i oczekiwa\u0107 cud\u00f3w. A trzeci wniosek? Otwarto\u015b\u0107. Otwarto\u015b\u0107 ma fundamentalne znaczenie. Udost\u0119pnienie modelu, kodu i ca\u0142ej dokumentacji na licencj\u0119, kt\u00f3r\u0105 nazwali Responsible AI License w skr\u00f3cie RAIL, to ogromny krok naprz\u00f3d. Ta licencja zawiera klauzule ograniczaj\u0105ce u\u017cycie modelu do szkodliwych cel\u00f3w, prawda? Tak. To pozwala ca\u0142ej spo\u0142eczno\u015bci naukowej korzysta\u0107 z tej technologii, ale robi\u0107 to w spos\u00f3b bardziej odpowiedzialny. A to by\u0142o przecie\u017c celem ca\u0142ego projektu. Jest jeszcze jedna rzecz w tej pracy, kt\u00f3ra mnie absolutnie zafascynowa\u0142a i dotyczy kosztu \u015brodowiskowego. A tak. Transparentno\u015b\u0107 w tym zakresie. Niezwyk\u0142a. Ci\u0105gle s\u0142yszymy, jak energoch\u0142onne s\u0105 te modele. Zesp\u00f3\u0142 Bloom obliczy\u0142, \u017ce ich trening wygenerowa\u0142 oko\u0142o 25 ton ekwiwalentu CO2. Co samo w sobie wci\u0105\u017c jest spor\u0105 warto\u015bci\u0105? Oczywi\u015bcie. Ale potem patrzymy na szatunki dla GPT-3, kt\u00f3re m\u00f3wi\u0105 o ponad 500 tonach. Tu jest 20-krotna r\u00f3\u017cnica. Jak to w og\u00f3le mo\u017cliwe przy podobnej skali modelu? Odpowied\u017a le\u017cy w tym, gdzie pod\u0142\u0105czysz wtyczk\u0119 Superkomputera. Bloom by\u0142 trenowany na Superkomputerze Jean-Zal\u00e9, we Francji. Kt\u00f3ry jest zasilany g\u0142\u00f3wnie niskoemisyjn\u0105 energi\u0105 j\u0105drow\u0105. Dok\u0142adnie. To pokazuje, \u017ce nie tylko optymalizacja algorytm\u00f3w, ale te\u017c strategiczny wyb\u00f3r centrum danych ma kolosalne znaczenie dla ekologicznego kosztu AI. Ta praca stawia mn\u00f3stwo otwartych pyta\u0144. Ale jest jedno, kt\u00f3re wydaje si\u0119 szczeg\u00f3lnie niepokoj\u0105ce i intryguj\u0105ce. Pochodzi z sekcji o badaniu w\u0142a\u015bciwo\u015bci lingwistycznych modelu. Tak, ten multilingual probing. To jedno z tych odkry\u0107, kt\u00f3re naprawd\u0119 zmuszaj\u0105 do my\u015blenia i kwestionowania wszystkiego, co wydaje nam si\u0119 oczywiste. No w\u0142a\u015bnie. Okaza\u0142o si\u0119, \u017ce mniejszy 1,7 miliardowy wariant Bloom radzi\u0142 sobie z niekt\u00f3rymi zadaniami morfosyntaktycznymi, czyli dotycz\u0105cymi wewn\u0119trznej budowy s\u0142\u00f3w i zda\u0144. Lepiej ni\u017c jego gigantyczny 17,6 miliardowy odpowiednik. Co jest kompletnie wbrew intuicji? Totalnie. Przecie\u017c zawsze my\u015blimy. Wi\u0119kszy znaczy lepszy. No w\u0142a\u015bnie. Nie zawsze i nie we wszystkim. Autorzy sugeruj\u0105, \u017ce ten ogromny model ma lepszy zdolno\u015bci og\u00f3lnej generalizacji. Czyli radzi sobie lepiej z szerszym zakresem zada\u0144. Ale to odkrycie rodzi fundamentalne pytanie. Czy bezrefleksyjne powi\u0119kszanie modeli, ta pogo\u0144za skal\u0105 zawsze czyni je m\u0105drzejszymi pod ka\u017cdym wzgl\u0119dem? To jest autentycznie niepokoj\u0105ca my\u015bl, \u017ce \u015bcie\u017cka, kt\u00f3r\u0105 wszyscy pod\u0105\u017caj\u0105, ta mantra bigger is better, mo\u017ce nas wcale nie prowadzi w stron\u0119 prawdziwego zrozumienia j\u0119zyka. A mo\u017ce nawet od niej oddala\u0107 w pewnych aspektach. Dok\u0142adnie. A mo\u017ce w tej pogoni za coraz wi\u0119ksz\u0105 liczb\u0119 parametr\u00f3w gubimy po drodze pewne subtelne, bardziej fundamentalne zdolno\u015bci j\u0119zykowe. I co to oznacza dla przysz\u0142o\u015bci AI, kt\u00f3ra ma nie tylko generowa\u0107 zgrabny tekst, ale naprawd\u0119 rozumie\u0107, czym jest j\u0119zyk? To pytanie, z kt\u00f3rym ta praca nas zostawia. I na razie nikt nie ma na nie dobrej odpowiedzi.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.16, "text": " co by by\u0142o, gdyby najwi\u0119ksze umys\u0142y z ca\u0142ego \u015bwiata zebra\u0142y si\u0119,", "tokens": [50364, 598, 538, 14811, 11, 28405, 2322, 48636, 1694, 1381, 1105, 749, 6825, 710, 35224, 6308, 21485, 3274, 47060, 6825, 3244, 11, 50572], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 1, "seek": 0, "start": 4.2, "end": 7.8, "text": " \u017ceby zbudowa\u0107 jeden z najpot\u0119\u017cniejszych modeli j\u0119zykowych,", "tokens": [50574, 11316, 710, 18281, 11445, 12906, 710, 11212, 17698, 1274, 1427, 10402, 45021, 2316, 72, 49055, 74, 19605, 11, 50754], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 2, "seek": 0, "start": 7.84, "end": 11.0, "text": " a potem udost\u0119pnili go wszystkim za darmu.", "tokens": [50756, 257, 36513, 11727, 555, 18085, 77, 2312, 352, 30481, 7949, 4072, 20140, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 3, "seek": 0, "start": 11.040000000000001, "end": 12.76, "text": " Brzmi jak science fiction.", "tokens": [50916, 1603, 89, 3057, 4207, 3497, 13266, 13, 51002], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 4, "seek": 0, "start": 12.8, "end": 17.04, "text": " Prawda. Ale to dok\u0142adnie historia powstania modelu Bloom,", "tokens": [51004, 430, 5131, 2675, 13, 9366, 281, 45864, 2766, 18385, 3388, 372, 5609, 2316, 84, 25927, 11, 51216], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 5, "seek": 0, "start": 17.080000000000002, "end": 18.72, "text": " kt\u00f3rej dzisiaj si\u0119 przyjrzymy.", "tokens": [51218, 36023, 25772, 3244, 6501, 73, 13047, 2226, 13, 51300], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 6, "seek": 0, "start": 18.76, "end": 23.240000000000002, "text": " Dok\u0142adnie. Mamy przed sob\u0105 prac\u0119 naukow\u0105, kt\u00f3ra opisuje Bloom,", "tokens": [51302, 29768, 10358, 2766, 13, 376, 7804, 18334, 18253, 1611, 22404, 1274, 35616, 74, 30297, 11, 19456, 45477, 13008, 25927, 11, 51526], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 7, "seek": 0, "start": 23.28, "end": 28.04, "text": " to jest kolos, 176 miliard\u00f3w parametr\u00f3w.", "tokens": [51528, 281, 3492, 17818, 329, 11, 3282, 21, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51766], "temperature": 0.0, "avg_logprob": -0.17806131699505975, "compression_ratio": 1.410344827586207, "no_speech_prob": 0.003054830012843013}, {"id": 8, "seek": 2804, "start": 28.04, "end": 32.879999999999995, "text": " Ale wiesz, kluczowe jest to, \u017ce nie stworzy\u0142a go jedna korporacja", "tokens": [50364, 9366, 261, 15347, 11, 9671, 1311, 89, 6880, 3492, 281, 11, 3561, 2838, 342, 28321, 1229, 5024, 352, 5232, 629, 14784, 2816, 23395, 50606], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 9, "seek": 2804, "start": 32.92, "end": 34.4, "text": " za zamkni\u0119tymi drzwiami.", "tokens": [50608, 7949, 19876, 74, 35938, 874, 3057, 1224, 14406, 15568, 13, 50682], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 10, "seek": 2804, "start": 34.44, "end": 35.32, "text": " Tylko kto?", "tokens": [50684, 49286, 4093, 23780, 30, 50728], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 11, "seek": 2804, "start": 35.36, "end": 37.519999999999996, "text": " To by\u0142 efekt otwartej wsp\u00f3\u0142pracy,", "tokens": [50730, 1407, 16673, 31482, 8192, 4337, 86, 11026, 73, 39069, 1424, 2551, 11, 50838], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 12, "seek": 2804, "start": 37.56, "end": 41.16, "text": " ponad 1000 badaczy z projektu Big Science.", "tokens": [50840, 9224, 345, 9714, 1578, 14691, 710, 26261, 84, 5429, 8976, 13, 51020], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 13, "seek": 2804, "start": 41.2, "end": 44.44, "text": " Wi\u0119c to nie jest tylko opowie\u015b\u0107 o technologii,", "tokens": [51022, 32508, 281, 2838, 3492, 13219, 999, 13998, 7753, 277, 1537, 1132, 5597, 11, 51184], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 14, "seek": 2804, "start": 44.480000000000004, "end": 48.68, "text": " ale o zupe\u0142nie nowym sposobie jej tworzenia, radykalnie otwartym.", "tokens": [51186, 6775, 277, 49922, 586, 4199, 20443, 996, 414, 28924, 46288, 14320, 11, 367, 880, 19990, 2766, 4337, 29587, 4199, 13, 51396], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 15, "seek": 2804, "start": 48.72, "end": 51.599999999999994, "text": " Czyli naszym celem jest zrozumie\u0107, co sprawia,", "tokens": [51398, 37099, 48094, 1769, 10386, 3492, 710, 27857, 449, 414, 2162, 11, 598, 22734, 654, 11, 51542], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 16, "seek": 2804, "start": 51.64, "end": 55.36, "text": " \u017ce Bloom jest tak wyj\u0105tkowy, jak go zbudowano", "tokens": [51544, 3561, 25927, 3492, 991, 4628, 8555, 83, 74, 10089, 11, 4207, 352, 710, 18281, 305, 3730, 51730], "temperature": 0.0, "avg_logprob": -0.13284789191351998, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.006387169472873211}, {"id": 17, "seek": 5536, "start": 55.36, "end": 58.16, "text": " i co to wszystko oznacza dla przysz\u0142o\u015bci AI.", "tokens": [50364, 741, 598, 281, 22607, 277, 22672, 326, 2394, 12285, 44018, 35059, 7318, 13, 50504], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 18, "seek": 5536, "start": 58.2, "end": 60.08, "text": " OK, to zanurzmy si\u0119 w temat.", "tokens": [50506, 2264, 11, 281, 710, 282, 374, 89, 2226, 3244, 261, 32954, 13, 50600], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 19, "seek": 5536, "start": 60.12, "end": 61.96, "text": " Mo\u017ce zacznijmy od kontekstu,", "tokens": [50602, 43774, 710, 14875, 77, 1718, 2226, 3611, 14373, 916, 372, 84, 11, 50694], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 20, "seek": 5536, "start": 62.0, "end": 65.16, "text": " bo on jest tu, wydaje mi si\u0119, absolutnie kluczowy.", "tokens": [50696, 748, 322, 3492, 2604, 11, 49165, 2752, 3244, 11, 18757, 2766, 9671, 1311, 89, 10089, 13, 50854], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 21, "seek": 5536, "start": 65.2, "end": 66.84, "text": " Zdecydowanie.", "tokens": [50856, 1176, 1479, 1344, 67, 22028, 13, 50938], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 22, "seek": 5536, "start": 66.88, "end": 68.56, "text": " Zanim pojawi\u0142 si\u0119 Bloom,", "tokens": [50940, 1176, 17869, 30655, 40622, 3244, 25927, 11, 51024], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 23, "seek": 5536, "start": 68.6, "end": 72.68, "text": " \u015bwiat wielkich modeli j\u0119zykowych tych LLM\u00f3w,", "tokens": [51026, 36425, 20570, 48349, 2316, 72, 49055, 74, 19605, 15180, 441, 43, 44, 3901, 11, 51230], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 24, "seek": 5536, "start": 72.72, "end": 76.76, "text": " by\u0142 bardzo ekskluzywny.", "tokens": [51232, 16673, 9034, 30724, 74, 2781, 1229, 43682, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 25, "seek": 5536, "start": 76.8, "end": 79.96000000000001, "text": " Pot\u0119\u017cne modele powstawa\u0142y za zamkni\u0119tymi drzwiami", "tokens": [51436, 9145, 1274, 1427, 716, 4391, 306, 3388, 372, 10449, 6825, 7949, 19876, 74, 35938, 874, 3057, 1224, 14406, 15568, 51594], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 26, "seek": 5536, "start": 80.0, "end": 82.52, "text": " w naprawd\u0119 bogatych organizacjach.", "tokens": [51596, 261, 20970, 26132, 267, 16384, 4645, 326, 45059, 13, 51722], "temperature": 0.0, "avg_logprob": -0.1432145989459494, "compression_ratio": 1.371212121212121, "no_speech_prob": 0.004966323729604483}, {"id": 27, "seek": 8252, "start": 82.64, "end": 86.64, "text": " To tworzy\u0142o ogromn\u0105 barier\u0119 dla naukowc\u00f3w z zewn\u0105trz.", "tokens": [50370, 1407, 46288, 1229, 5249, 34416, 298, 13113, 2159, 811, 1274, 12285, 35616, 74, 305, 29268, 710, 5277, 895, 1611, 6903, 89, 13, 50570], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 28, "seek": 8252, "start": 86.67999999999999, "end": 89.8, "text": " I co r\u00f3wnie wa\u017cne, prowadzi\u0142o do niemal ca\u0142kowitego skupienia si\u0119", "tokens": [50572, 286, 598, 11416, 14215, 46110, 11, 36590, 3992, 5249, 360, 2838, 5579, 35224, 74, 305, 642, 1571, 1110, 1010, 18811, 3244, 50728], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 29, "seek": 8252, "start": 89.84, "end": 91.08, "text": " na j\u0119zyku angielskim.", "tokens": [50730, 1667, 49055, 5279, 2562, 1187, 5161, 332, 13, 50792], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 30, "seek": 8252, "start": 91.11999999999999, "end": 92.03999999999999, "text": " W\u0142a\u015bnie.", "tokens": [50794, 343, 5024, 12221, 13, 50840], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 31, "seek": 8252, "start": 92.08, "end": 95.19999999999999, "text": " I to jest dok\u0142adnie punkt wyj\u015bcia dla ca\u0142ej tej pracy.", "tokens": [50842, 286, 281, 3492, 45864, 2766, 39561, 4628, 73, 1788, 2755, 12285, 47631, 73, 12573, 35591, 13, 50998], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 32, "seek": 8252, "start": 95.24, "end": 98.08, "text": " Autorzy wprost pisz\u0105 o, cytuj\u0119,", "tokens": [51000, 6049, 284, 1229, 261, 1424, 555, 26584, 8925, 277, 11, 40248, 18258, 11, 51142], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 33, "seek": 8252, "start": 98.11999999999999, "end": 100.88, "text": " spo\u0142ecznych ograniczeniach rozwoju LLM.", "tokens": [51144, 36851, 89, 9399, 34416, 30732, 42124, 608, 9544, 6120, 8954, 441, 43, 44, 13, 51282], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 34, "seek": 8252, "start": 100.92, "end": 103.03999999999999, "text": " Czyli nie chodzi\u0142o im tylko o technologie?", "tokens": [51284, 37099, 2838, 23998, 5249, 566, 13219, 277, 1537, 20121, 30, 51390], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 35, "seek": 8252, "start": 103.08, "end": 105.19999999999999, "text": " Nie, celem nie by\u0142o po prostu stworzenie", "tokens": [51392, 12016, 11, 1769, 10386, 2838, 14811, 714, 19518, 342, 28321, 16778, 51498], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 36, "seek": 8252, "start": 105.24, "end": 108.6, "text": " kolejnego wielkiego modelu, kt\u00f3ry pobije jaki\u015b benchmark.", "tokens": [51500, 23749, 11858, 20570, 42349, 2316, 84, 11, 9913, 714, 30418, 68, 34721, 18927, 13, 51668], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 37, "seek": 8252, "start": 108.64, "end": 110.39999999999999, "text": " Chodzi\u0142o o co\u015b znacznie wi\u0119kszego,", "tokens": [51670, 761, 14543, 5249, 277, 19241, 15397, 14875, 2766, 29968, 27725, 11, 51758], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 38, "seek": 8252, "start": 110.44, "end": 112.44, "text": " o demokratyzacj\u0119 tej technologii.", "tokens": [51760, 277, 49432, 37433, 29924, 12573, 1537, 1132, 5597, 13, 51860], "temperature": 0.0, "avg_logprob": -0.12389967295044628, "compression_ratio": 1.484149855907781, "no_speech_prob": 0.015109865926206112}, {"id": 39, "seek": 11244, "start": 112.44, "end": 113.88, "text": " Co to znaczy w praktyce?", "tokens": [50364, 3066, 281, 36584, 261, 3206, 74, 874, 384, 30, 50436], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 40, "seek": 11244, "start": 113.92, "end": 116.39999999999999, "text": " To znaczy, \u017ce od samego pocz\u0105tku za\u0142o\u017cyli,", "tokens": [50438, 1407, 36584, 11, 3561, 3611, 912, 1571, 43959, 7949, 5249, 7735, 2081, 11, 50562], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 41, "seek": 11244, "start": 116.44, "end": 120.36, "text": " \u017ce model musi by\u0107 Open Access, czyli w pe\u0142ni dost\u0119pny.", "tokens": [50564, 3561, 2316, 37587, 15069, 7238, 17166, 11, 16591, 261, 43205, 3722, 48209, 1634, 13, 50760], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 42, "seek": 11244, "start": 120.39999999999999, "end": 123.4, "text": " I co najwa\u017cniejsze, prawdziwie wieloj\u0119zyczny.", "tokens": [50762, 286, 598, 11212, 27111, 44258, 11, 41175, 3992, 8699, 20570, 78, 11115, 1229, 3689, 1634, 13, 50912], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 43, "seek": 11244, "start": 123.44, "end": 127.08, "text": " No dobrze, ale s\u0142owo demokratyzacja bywa nadu\u017cywane.", "tokens": [50914, 883, 28335, 11, 6775, 15116, 19941, 49432, 37433, 23395, 538, 4151, 12617, 84, 7735, 86, 1929, 13, 51096], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 44, "seek": 11244, "start": 127.12, "end": 129.4, "text": " M\u00f3wimy tu o projekcie Big Science.", "tokens": [51098, 376, 3901, 13189, 2604, 277, 447, 27023, 4260, 5429, 8976, 13, 51212], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 45, "seek": 11244, "start": 129.44, "end": 133.44, "text": " To by\u0142o ponad 1200 uczestnik\u00f3w z 38 kraj\u00f3w.", "tokens": [51214, 1407, 14811, 9224, 345, 29139, 35403, 377, 47447, 710, 12843, 28248, 73, 3901, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 46, "seek": 11244, "start": 133.48, "end": 134.0, "text": " Tak.", "tokens": [51416, 9118, 13, 51442], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 47, "seek": 11244, "start": 134.04, "end": 137.24, "text": " Ale to, co mnie naprawd\u0119 uderzy\u0142o, to nie tylko skala,", "tokens": [51444, 9366, 281, 11, 598, 17661, 20970, 344, 1068, 1229, 5249, 11, 281, 2838, 13219, 1110, 5159, 11, 51604], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 48, "seek": 11244, "start": 137.28, "end": 138.72, "text": " ale r\u00f3\u017cnorodno\u015b\u0107.", "tokens": [51606, 6775, 19637, 19048, 378, 23293, 13, 51678], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 49, "seek": 11244, "start": 138.76, "end": 141.48, "text": " To nie byli, wiesz, sami specjali\u015bci od Machine Learning.", "tokens": [51680, 1407, 2838, 538, 2081, 11, 261, 15347, 11, 3247, 72, 1608, 73, 5103, 6199, 3611, 22155, 15205, 13, 51816], "temperature": 0.0, "avg_logprob": -0.13230243232679664, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.004590495023876429}, {"id": 50, "seek": 14148, "start": 141.51999999999998, "end": 142.72, "text": " No w\u0142a\u015bnie.", "tokens": [50366, 883, 14234, 13, 50426], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 51, "seek": 14148, "start": 142.76, "end": 146.79999999999998, "text": " Byli tam linkwi\u015bci, prawnicy, filozofowie, socjolodzy.", "tokens": [50428, 3146, 2081, 7677, 2113, 6253, 6199, 11, 37047, 2632, 11, 1387, 15151, 2670, 13998, 11, 13598, 73, 401, 378, 1229, 13, 50630], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 52, "seek": 14148, "start": 146.84, "end": 148.44, "text": " I to jest sedno sprawy.", "tokens": [50632, 286, 281, 3492, 9643, 1771, 22734, 88, 13, 50712], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 53, "seek": 14148, "start": 148.48, "end": 151.83999999999997, "text": " Co wi\u0119cej, ca\u0142y ten ogromny, rozproszony zesp\u00f3\u0142", "tokens": [50714, 3066, 26004, 11, 35226, 2064, 34416, 298, 1634, 11, 9544, 1424, 329, 44479, 710, 13361, 16181, 50882], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 54, "seek": 14148, "start": 151.88, "end": 156.67999999999998, "text": " kierowa\u0142 si\u0119 od samego pocz\u0105tku czym\u015b, co nazwali kart\u0105 etyczn\u0105.", "tokens": [50884, 38767, 30105, 3244, 3611, 912, 1571, 43959, 31466, 1788, 11, 598, 20151, 40054, 29120, 1611, 1030, 17466, 13113, 13, 51124], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 55, "seek": 14148, "start": 156.72, "end": 157.95999999999998, "text": " Ethical Charter.", "tokens": [51126, 10540, 804, 4327, 391, 13, 51188], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 56, "seek": 14148, "start": 158.0, "end": 158.92, "text": " Dok\u0142adnie.", "tokens": [51190, 29768, 10358, 2766, 13, 51236], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 57, "seek": 14148, "start": 158.95999999999998, "end": 160.76, "text": " Wiesz, \u0142atwo by\u0107 cynicznym,", "tokens": [51238, 343, 15347, 11, 47759, 6120, 15069, 28365, 17946, 12996, 11, 51328], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 58, "seek": 14148, "start": 160.79999999999998, "end": 163.64, "text": " jak si\u0119 s\u0142ysz\u0119 o czym\u015b takim jak karta etyczna.", "tokens": [51330, 4207, 3244, 15116, 749, 11052, 277, 31466, 1788, 31732, 4207, 350, 19061, 1030, 17466, 629, 13, 51472], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 59, "seek": 14148, "start": 163.67999999999998, "end": 167.64, "text": " W \u015bwiecie korpo to cz\u0119sto jest po prostu PDF na stronie internetowej,", "tokens": [51474, 343, 40078, 4260, 14784, 2259, 281, 34369, 3492, 714, 19518, 17752, 1667, 1056, 32242, 4705, 21091, 11, 51672], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 60, "seek": 14148, "start": 167.67999999999998, "end": 168.83999999999997, "text": " kt\u00f3ry nic nie znaczy.", "tokens": [51674, 9913, 6201, 2838, 36584, 13, 51732], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 61, "seek": 14148, "start": 168.88, "end": 170.16, "text": " Rozumiem sceptyzm.", "tokens": [51734, 43313, 449, 4907, 262, 1336, 37433, 76, 13, 51798], "temperature": 0.0, "avg_logprob": -0.14601393590999556, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.011458644643425941}, {"id": 62, "seek": 17016, "start": 170.16, "end": 174.56, "text": " Jakie mamy do wody, \u017ce ta karta by\u0142a czym\u015b wi\u0119cej ni\u017c tylko dobrym pijarem?", "tokens": [50364, 15029, 414, 17335, 360, 261, 843, 11, 3561, 1846, 350, 19061, 23936, 31466, 1788, 26004, 28502, 13219, 35884, 76, 280, 1718, 19183, 30, 50584], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 63, "seek": 17016, "start": 174.6, "end": 177.72, "text": " To jest \u015bwietne i bardzo zasadne pytanie.", "tokens": [50586, 1407, 3492, 8299, 39083, 716, 741, 9034, 44585, 716, 36610, 13, 50742], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 64, "seek": 17016, "start": 177.76, "end": 181.44, "text": " A ta praca naukowa dostarcza konkretnych odpowiedzi.", "tokens": [50744, 316, 1846, 582, 6628, 35616, 74, 5528, 20568, 40088, 2394, 36500, 9399, 36574, 3992, 13, 50928], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 65, "seek": 17016, "start": 181.48, "end": 184.0, "text": " Najlepszy przyk\u0142ad to proces zbierania danych.", "tokens": [50930, 31576, 306, 1878, 1229, 23144, 281, 17565, 710, 65, 811, 5609, 274, 34644, 13, 51056], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 66, "seek": 17016, "start": 184.04, "end": 184.56, "text": " OK.", "tokens": [51058, 2264, 13, 51084], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 67, "seek": 17016, "start": 184.6, "end": 189.76, "text": " Zamiast i\u015b\u0107 na \u0142atwizn\u0119 i wiesz po prostu zasa\u0107 p\u00f3\u0142 internetu, co jest standardem.", "tokens": [51086, 1176, 4526, 525, 741, 7753, 1667, 47759, 86, 590, 77, 1274, 741, 261, 15347, 714, 19518, 710, 9994, 2162, 47907, 4705, 84, 11, 598, 3492, 3832, 443, 13, 51344], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 68, "seek": 17016, "start": 189.8, "end": 191.04, "text": " Bo tak si\u0119 zwykle robi.", "tokens": [51346, 3286, 991, 3244, 43436, 14677, 47380, 13, 51408], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 69, "seek": 17016, "start": 191.07999999999998, "end": 192.2, "text": " Dok\u0142adnie.", "tokens": [51410, 29768, 10358, 2766, 13, 51466], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 70, "seek": 17016, "start": 192.24, "end": 197.4, "text": " Oni podj\u0119li \u015bwiadom\u0105 decyzj\u0119 o r\u0119cznym i celowym kuratorowaniu \u017ar\u00f3de\u0142.", "tokens": [51468, 1282, 72, 2497, 11115, 2081, 21485, 345, 298, 1611, 979, 37433, 11115, 277, 41197, 3689, 12996, 741, 9277, 31691, 10072, 1639, 305, 25849, 50212, 11721, 1479, 1221, 13, 51726], "temperature": 0.0, "avg_logprob": -0.13445716155202767, "compression_ratio": 1.4, "no_speech_prob": 0.0030123579781502485}, {"id": 71, "seek": 19740, "start": 197.48000000000002, "end": 200.0, "text": " Wsp\u00f3\u0142pracowali z grupami takimi jak masakane,", "tokens": [50368, 343, 4952, 16181, 1424, 326, 305, 5103, 710, 12740, 4526, 991, 10121, 4207, 2300, 514, 1929, 11, 50494], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 72, "seek": 19740, "start": 200.04, "end": 202.52, "text": " \u017ceby \u015bwiadomie w\u0142\u0105czy\u0107 j\u0119zyki afryka\u0144skie,", "tokens": [50496, 11316, 21485, 345, 40120, 261, 15926, 33967, 49055, 2984, 3238, 627, 2330, 27125, 414, 11, 50620], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 73, "seek": 19740, "start": 202.56, "end": 204.48000000000002, "text": " albo z Latinx in AI.", "tokens": [50622, 22622, 710, 10803, 87, 294, 7318, 13, 50718], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 74, "seek": 19740, "start": 204.52, "end": 208.8, "text": " Czyli to by\u0142a bezpo\u015brednia konsekwencja zapis\u00f3w tej karty o inkluzywno\u015bci.", "tokens": [50720, 37099, 281, 23936, 10782, 2259, 1788, 986, 12679, 47020, 74, 15615, 34056, 14223, 271, 3901, 12573, 29120, 88, 277, 11276, 2781, 1229, 20944, 6199, 13, 50934], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 75, "seek": 19740, "start": 208.84, "end": 209.4, "text": " Tak.", "tokens": [50936, 9118, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 76, "seek": 19740, "start": 209.44, "end": 213.44, "text": " I to kosztowa\u0142o ich mn\u00f3stwo czasu i pieni\u0119dzy, ale trzymali si\u0119 tej zasady.", "tokens": [50966, 286, 281, 19532, 2682, 5528, 5249, 1893, 275, 77, 45052, 6120, 40860, 741, 26274, 49485, 11, 6775, 34573, 76, 5103, 3244, 12573, 26530, 880, 13, 51166], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 77, "seek": 19740, "start": 213.48000000000002, "end": 216.68, "text": " Czyli decyzje techniczne by\u0142y podyktowane warto\u015bciami.", "tokens": [51168, 37099, 979, 37433, 2884, 1537, 17946, 716, 26366, 280, 843, 2320, 23066, 31830, 6199, 4526, 13, 51328], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 78, "seek": 19740, "start": 216.72, "end": 218.24, "text": " To faktycznie robi r\u00f3\u017cnic\u0105.", "tokens": [51330, 1407, 33647, 45586, 47380, 19637, 7692, 1611, 13, 51406], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 79, "seek": 19740, "start": 218.28, "end": 220.16, "text": " Dobrze, to zejd\u017amy g\u0142\u0119biej.", "tokens": [51408, 29679, 13503, 11, 281, 5277, 37109, 10659, 2226, 18117, 1274, 7392, 73, 13, 51502], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 80, "seek": 19740, "start": 220.20000000000002, "end": 220.84, "text": " Jasne.", "tokens": [51504, 34023, 716, 13, 51536], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 81, "seek": 19740, "start": 220.88, "end": 224.92000000000002, "text": " \u017beby wytrenowa\u0107 model o 176 miliardach parametr\u00f3w,", "tokens": [51538, 46864, 2322, 261, 4328, 1095, 11445, 2316, 277, 3282, 21, 1962, 72, 515, 608, 6220, 27965, 3901, 11, 51740], "temperature": 0.0, "avg_logprob": -0.13082971738253027, "compression_ratio": 1.375, "no_speech_prob": 0.008579329587519169}, {"id": 82, "seek": 22492, "start": 224.95999999999998, "end": 228.0, "text": " potrzeba niewyobra\u017calnej ilo\u015bci danych.", "tokens": [50366, 28577, 4231, 43622, 88, 24393, 1427, 304, 11794, 1930, 44468, 274, 34644, 13, 50518], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 83, "seek": 22492, "start": 228.04, "end": 231.16, "text": " M\u00f3wisz, \u017ce to nie by\u0142 zwyk\u0142y zrzut z sieci.", "tokens": [50520, 376, 3901, 23848, 11, 3561, 281, 2838, 16673, 43436, 74, 6825, 710, 19390, 325, 710, 2804, 537, 13, 50676], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 84, "seek": 22492, "start": 231.2, "end": 232.48, "text": " Zgadza si\u0119.", "tokens": [50678, 1176, 70, 345, 2394, 3244, 13, 50742], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 85, "seek": 22492, "start": 232.51999999999998, "end": 235.0, "text": " Blum by\u0142 trenowany na korpusie Roots.", "tokens": [50744, 2177, 449, 16673, 23136, 23341, 1667, 14784, 31624, 414, 3101, 1971, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 86, "seek": 22492, "start": 235.04, "end": 237.92, "text": " To by\u0142o jeden przycinek 61 terabajta tekstu.", "tokens": [50870, 1407, 14811, 12906, 6501, 66, 48421, 28294, 1796, 455, 1805, 1328, 16624, 372, 84, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 87, "seek": 22492, "start": 237.95999999999998, "end": 239.51999999999998, "text": " Gigantyczna ilo\u015b\u0107.", "tokens": [51016, 40489, 394, 17466, 629, 1930, 78, 7753, 13, 51094], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 88, "seek": 22492, "start": 239.56, "end": 242.76, "text": " A decodaj wa\u017cniejsze, ten korpus sk\u0142ada\u0142 si\u0119 z danych", "tokens": [51096, 316, 979, 378, 1805, 27777, 44258, 11, 2064, 14784, 31624, 1110, 46217, 1221, 3244, 710, 274, 34644, 51256], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 89, "seek": 22492, "start": 242.79999999999998, "end": 248.16, "text": " z 46 j\u0119zyk\u00f3w naturalnych i 13 j\u0119zyk\u00f3w programowania.", "tokens": [51258, 710, 17835, 49055, 23849, 3303, 9399, 741, 3705, 49055, 23849, 1461, 21308, 13, 51526], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 90, "seek": 22492, "start": 248.2, "end": 251.83999999999997, "text": " A sam proces jego tworzenia by\u0142 nadzorowany przez ludzi.", "tokens": [51528, 316, 3247, 17565, 26542, 46288, 14320, 16673, 12617, 89, 284, 23341, 14064, 29586, 13, 51710], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 91, "seek": 22492, "start": 251.88, "end": 252.95999999999998, "text": " Co to zmienia?", "tokens": [51712, 3066, 281, 17020, 18811, 30, 51766], "temperature": 0.0, "avg_logprob": -0.1477832794189453, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.10869603604078293}, {"id": 92, "seek": 25296, "start": 252.96, "end": 257.12, "text": " To stoi w ostrym kontra\u015bcie z typowym automatycznym filtrowaniem.", "tokens": [50364, 1407, 342, 4869, 261, 32946, 627, 76, 14373, 424, 9815, 710, 2125, 31691, 28034, 17466, 12996, 29148, 1892, 282, 4907, 13, 50572], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 93, "seek": 25296, "start": 257.16, "end": 259.48, "text": " Inne badania, kt\u00f3re oni cytuj\u0105, pokazuj\u0105,", "tokens": [50574, 682, 716, 1578, 5609, 11, 8864, 36317, 40248, 13263, 11, 13010, 921, 13263, 11, 50690], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 94, "seek": 25296, "start": 259.52, "end": 264.0, "text": " \u017ce takie filtry potrafi\u0105 przypadkowo wycina\u0107 ca\u0142e po\u0142acie internetu.", "tokens": [50692, 3561, 15963, 29148, 627, 1847, 10437, 11404, 33100, 74, 19941, 4628, 66, 1426, 2162, 47631, 714, 1221, 30805, 4705, 84, 13, 50916], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 95, "seek": 25296, "start": 264.04, "end": 265.12, "text": " Na przyk\u0142ad?", "tokens": [50918, 6056, 23144, 30, 50972], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 96, "seek": 25296, "start": 265.16, "end": 268.68, "text": " Na przyk\u0142ad tre\u015bci tworone przez spo\u0142eczno\u015bci LGBTQ+,", "tokens": [50974, 6056, 23144, 2192, 6199, 46288, 546, 14064, 36851, 89, 16438, 26862, 46797, 51150], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 97, "seek": 25296, "start": 268.72, "end": 271.8, "text": " albo teksty pisane w dialekcie Afrikan American English.", "tokens": [51152, 22622, 16624, 25134, 26584, 1929, 261, 5502, 916, 4260, 3325, 470, 5225, 2665, 3669, 13, 51306], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 98, "seek": 25296, "start": 271.84000000000003, "end": 273.24, "text": " Tutaj tego unikni\u0119to.", "tokens": [51308, 41819, 8627, 517, 1035, 35938, 1353, 13, 51378], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 99, "seek": 25296, "start": 273.28000000000003, "end": 274.88, "text": " I to jest fascynuj\u0105ce.", "tokens": [51380, 286, 281, 3492, 30632, 1344, 77, 13263, 384, 13, 51460], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 100, "seek": 25296, "start": 274.92, "end": 277.04, "text": " Czyta\u0142am, \u017ce poszli nawet okrok dalej", "tokens": [51462, 19832, 1328, 20177, 11, 3561, 1366, 89, 2081, 22696, 3133, 31621, 34257, 51568], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 101, "seek": 25296, "start": 277.08, "end": 280.96000000000004, "text": " i zdobyli oficjalne zgody na wykorzystanie danych od niekt\u00f3rych wydawc\u00f3w.", "tokens": [51570, 741, 16221, 13944, 2081, 295, 299, 22600, 716, 40948, 843, 1667, 43606, 36049, 7155, 274, 34644, 3611, 2838, 43073, 627, 339, 25984, 1607, 29268, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13250788102238814, "compression_ratio": 1.4454545454545455, "no_speech_prob": 0.03767305985093117}, {"id": 102, "seek": 28096, "start": 280.96, "end": 283.35999999999996, "text": " Tak, na przyk\u0142ad od francuskiej gazety Lemon.", "tokens": [50364, 9118, 11, 1667, 23144, 3611, 431, 282, 1149, 45145, 26232, 2210, 35404, 13, 50484], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 103, "seek": 28096, "start": 283.4, "end": 287.79999999999995, "text": " To jest zupe\u0142nie inny poziom dba\u0142o\u015bci o \u017ar\u00f3d\u0142a ni\u017c jeste\u015bmy przyzwyczajeni.", "tokens": [50486, 1407, 3492, 49922, 294, 1634, 38503, 298, 274, 4231, 35059, 277, 50212, 43678, 5024, 28502, 35928, 6501, 89, 9726, 3689, 1805, 15711, 13, 50706], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 104, "seek": 28096, "start": 287.84, "end": 289.56, "text": " Niesamowite.", "tokens": [50708, 426, 530, 335, 305, 642, 13, 50794], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 105, "seek": 28096, "start": 289.59999999999997, "end": 291.12, "text": " Ale dane to jedno.", "tokens": [50796, 9366, 49206, 281, 5232, 1771, 13, 50872], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 106, "seek": 28096, "start": 291.15999999999997, "end": 292.84, "text": " Przejd\u017amy do samej maszyny.", "tokens": [50874, 2114, 16920, 67, 10659, 2226, 360, 912, 73, 2300, 1229, 1634, 13, 50958], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 107, "seek": 28096, "start": 292.88, "end": 294.68, "text": " Jak zbudowany jest ten gigant?", "tokens": [50960, 15029, 710, 18281, 23341, 3492, 2064, 8741, 394, 30, 51050], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 108, "seek": 28096, "start": 294.71999999999997, "end": 298.64, "text": " Podstawowa archipektura to Decoder Only Transformer,", "tokens": [51052, 12646, 22580, 5528, 3912, 647, 8192, 2991, 281, 12427, 19866, 5686, 27938, 260, 11, 51248], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 109, "seek": 28096, "start": 298.67999999999995, "end": 302.96, "text": " czyli bardzo podobna do tej, kt\u00f3r\u0105 znamy z modeli serii GPT.", "tokens": [51250, 16591, 9034, 43024, 629, 360, 12573, 11, 37415, 710, 5378, 88, 710, 2316, 72, 816, 5597, 26039, 51, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 110, "seek": 28096, "start": 303.0, "end": 304.96, "text": " Wyb\u00f3r by\u0142 raczej pragmatyczny?", "tokens": [51466, 14458, 65, 15614, 16673, 4129, 16920, 33394, 15677, 17466, 1634, 30, 51564], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 111, "seek": 28096, "start": 305.0, "end": 305.84, "text": " Tak.", "tokens": [51566, 9118, 13, 51608], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 112, "seek": 28096, "start": 305.88, "end": 307.84, "text": " Ich w\u0142asne eksperymenty pokaza\u0142y,", "tokens": [51610, 3141, 43572, 716, 30724, 610, 88, 518, 88, 13010, 12257, 6825, 11, 51708], "temperature": 0.0, "avg_logprob": -0.13735422551237195, "compression_ratio": 1.355263157894737, "no_speech_prob": 0.00696978997439146}, {"id": 113, "seek": 30784, "start": 307.88, "end": 310.4, "text": " \u017ce modele Causal Decoder Only", "tokens": [50366, 3561, 4391, 306, 7544, 11765, 12427, 19866, 5686, 50492], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 114, "seek": 30784, "start": 310.44, "end": 314.79999999999995, "text": " osi\u0105ga\u0142y najlepsze wyniki w generalizacji Zero Shot zaraz po treningu.", "tokens": [50494, 3003, 11404, 3680, 6825, 41903, 1878, 1381, 31936, 9850, 261, 2674, 590, 13152, 17182, 28845, 22675, 921, 714, 2192, 773, 84, 13, 50712], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 115, "seek": 30784, "start": 314.84, "end": 317.96, "text": " Ale, jak zawsze, diabe\u0142 tkwi w szczeg\u00f3\u0142ach.", "tokens": [50714, 9366, 11, 4207, 30964, 11, 1026, 4488, 1221, 256, 74, 6253, 261, 22090, 1146, 16181, 608, 13, 50870], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 116, "seek": 30784, "start": 318.0, "end": 319.44, "text": " I co to za szczeg\u00f3\u0142y?", "tokens": [50872, 286, 598, 281, 7949, 22090, 1146, 812, 6825, 30, 50944], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 117, "seek": 30784, "start": 319.47999999999996, "end": 323.79999999999995, "text": " Wprowadzili dwa kluczowe ulepszenia w stosunku do standardowej architektury.", "tokens": [50946, 343, 35019, 89, 2312, 35045, 9671, 1311, 89, 6880, 344, 306, 1878, 14320, 261, 43581, 49910, 360, 3832, 21091, 3912, 642, 2320, 2598, 13, 51162], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 118, "seek": 30784, "start": 323.84, "end": 326.55999999999995, "text": " Pierwsze to Alibi Positional Emberings.", "tokens": [51164, 16676, 14358, 1381, 281, 967, 25515, 25906, 2628, 3968, 607, 1109, 13, 51300], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 119, "seek": 30784, "start": 326.59999999999997, "end": 329.35999999999996, "text": " To jest odpowied\u017a na to fundamentalne pytanie.", "tokens": [51302, 1407, 3492, 36574, 10659, 1667, 281, 8088, 716, 36610, 13, 51440], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 120, "seek": 30784, "start": 329.4, "end": 333.12, "text": " Sk\u0105d model wie, w jakiej kolejno\u015bci s\u0105 s\u0142owa w zdaniu?", "tokens": [51442, 7324, 18962, 2316, 3355, 11, 261, 4207, 7764, 23749, 16438, 9015, 15116, 5528, 261, 16221, 25849, 30, 51628], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 121, "seek": 30784, "start": 333.15999999999997, "end": 334.2, "text": " Dok\u0142adnie.", "tokens": [51630, 29768, 10358, 2766, 13, 51682], "temperature": 0.0, "avg_logprob": -0.16817026204996174, "compression_ratio": 1.3898305084745763, "no_speech_prob": 0.01856010966002941}, {"id": 122, "seek": 33420, "start": 334.2, "end": 338.0, "text": " Wyobra\u017a sobie, \u017ce tradycyjne metody nadaj\u0105 ka\u017cdemu s\u0142owu", "tokens": [50364, 14458, 24393, 10659, 13652, 11, 3561, 504, 880, 42949, 716, 1131, 843, 8096, 8555, 21912, 10730, 84, 15116, 305, 84, 50554], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 123, "seek": 33420, "start": 338.03999999999996, "end": 341.24, "text": " w zdaniu konkretny adres, jak numer domu na ulicy,", "tokens": [50556, 261, 16221, 25849, 36500, 1634, 614, 495, 11, 4207, 7866, 48465, 1667, 344, 1050, 88, 11, 50716], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 124, "seek": 33420, "start": 341.28, "end": 344.2, "text": " s\u0142owo numer jeden, s\u0142owo numer dwa i tak dalej.", "tokens": [50718, 15116, 19941, 7866, 12906, 11, 15116, 19941, 7866, 35045, 741, 991, 34257, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 125, "seek": 33420, "start": 344.24, "end": 345.08, "text": " Okej.", "tokens": [50866, 29094, 73, 13, 50908], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 126, "seek": 33420, "start": 345.12, "end": 347.96, "text": " Alibi dzia\u0142a inaczej, bardziej intuicyjnie.", "tokens": [50910, 967, 25515, 37903, 33230, 16920, 11, 27209, 560, 84, 2632, 73, 2766, 13, 51052], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 127, "seek": 33420, "start": 348.0, "end": 349.44, "text": " Nie u\u017cywa adres\u00f3w.", "tokens": [51054, 12016, 34097, 4151, 614, 495, 3901, 13, 51126], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 128, "seek": 33420, "start": 349.48, "end": 351.0, "text": " Po prostu m\u00f3wi modelowi.", "tokens": [51128, 6165, 19518, 24592, 2316, 24503, 13, 51204], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 129, "seek": 33420, "start": 351.03999999999996, "end": 354.24, "text": " Hej, s\u0142owo, na kt\u00f3re teraz patrzysz, jest tu\u017c obok,", "tokens": [51206, 44567, 11, 15116, 19941, 11, 1667, 8864, 16854, 1947, 19390, 20589, 11, 3492, 2604, 1427, 1111, 453, 11, 51366], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 130, "seek": 33420, "start": 354.28, "end": 358.44, "text": " ale bardzo daleko od tamtego na ko\u0144cu, czyli im bli\u017cej tym wa\u017cniej.", "tokens": [51368, 6775, 9034, 11702, 34241, 3611, 7677, 975, 1571, 1667, 26470, 12032, 11, 16591, 566, 27182, 38493, 8107, 27777, 10402, 13, 51576], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 131, "seek": 33420, "start": 358.48, "end": 363.64, "text": " W\u0142a\u015bnie. Ta prosta zasada okaza\u0142a si\u0119 znacznie bardziej elastyczna.", "tokens": [51578, 343, 5024, 12221, 13, 6551, 582, 8638, 26530, 1538, 3133, 12257, 5024, 3244, 15397, 14875, 2766, 27209, 806, 9820, 3689, 629, 13, 51836], "temperature": 0.0, "avg_logprob": -0.15417306423187255, "compression_ratio": 1.501639344262295, "no_speech_prob": 0.0339132696390152}, {"id": 132, "seek": 36364, "start": 363.76, "end": 367.88, "text": " Bezpo\u015brednio os\u0142abia si\u0142\u0119 uwagi, czyli attention scores,", "tokens": [50370, 879, 89, 2259, 1788, 986, 41084, 3003, 1221, 455, 654, 1511, 46564, 23147, 20291, 11, 16591, 3202, 13444, 11, 50576], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 133, "seek": 36364, "start": 367.91999999999996, "end": 370.08, "text": " w zale\u017cno\u015bci od odleb\u0142o\u015bci.", "tokens": [50578, 261, 710, 45494, 16438, 3611, 277, 2285, 65, 35059, 13, 50686], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 134, "seek": 36364, "start": 370.12, "end": 372.28, "text": " I badania, na kt\u00f3re si\u0119 powo\u0142uj\u0105,", "tokens": [50688, 286, 1578, 5609, 11, 1667, 8864, 3244, 3388, 78, 1221, 13263, 11, 50796], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 135, "seek": 36364, "start": 372.32, "end": 377.44, "text": " pokaza\u0142y, \u017ce to prowadzi do stabilniejszego treningu i lepszych wynik\u00f3w.", "tokens": [50798, 13010, 12257, 6825, 11, 3561, 281, 36590, 3992, 360, 11652, 10402, 15453, 6308, 2192, 773, 84, 741, 476, 1878, 28051, 31936, 1035, 3901, 13, 51054], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 136, "seek": 36364, "start": 377.47999999999996, "end": 378.52, "text": " To ma sens.", "tokens": [51056, 1407, 463, 2923, 13, 51108], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 137, "seek": 36364, "start": 378.56, "end": 382.15999999999997, "text": " Bardziej elastyczne podej\u015bcie, a to drugie ulepszenie.", "tokens": [51110, 26841, 19554, 806, 9820, 38491, 7468, 73, 9815, 11, 257, 281, 4110, 414, 344, 306, 1878, 16778, 13, 51290], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 138, "seek": 36364, "start": 382.2, "end": 384.64, "text": " Drugie to embedding layer norm.", "tokens": [51292, 35806, 414, 281, 12240, 3584, 4583, 2026, 13, 51414], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 139, "seek": 36364, "start": 384.68, "end": 390.03999999999996, "text": " To jest dodatkowa warstwa normalizacyjna, czyli layer normalization,", "tokens": [51416, 1407, 3492, 13886, 33525, 5528, 1516, 372, 4151, 2710, 590, 31285, 629, 11, 16591, 4583, 2710, 2144, 11, 51684], "temperature": 0.0, "avg_logprob": -0.14420296763645785, "compression_ratio": 1.4258555133079849, "no_speech_prob": 0.0010578033979982138}, {"id": 140, "seek": 39004, "start": 390.12, "end": 393.72, "text": " dodana zaraz po warstwie wej\u015bciowej embedding layer.", "tokens": [50368, 13886, 2095, 22675, 921, 714, 1516, 372, 8699, 321, 73, 6199, 21091, 12240, 3584, 4583, 13, 50548], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 141, "seek": 39004, "start": 393.76000000000005, "end": 396.08000000000004, "text": " I tu jest co\u015b fascynuj\u0105cego, prawda?", "tokens": [50550, 286, 2604, 3492, 19241, 30632, 1344, 77, 13263, 384, 1571, 11, 43607, 30, 50666], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 142, "seek": 39004, "start": 396.12, "end": 401.6, "text": " O i tak. Zosta\u0142a dodana, by poprawi\u0107 stabilno\u015b\u0107 treningu przy tej ogromnej skali.", "tokens": [50668, 422, 741, 991, 13, 1176, 8638, 5024, 13886, 2095, 11, 538, 1665, 5131, 12757, 11652, 23293, 2192, 773, 84, 6501, 12573, 34416, 298, 11794, 1110, 5103, 13, 50942], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 143, "seek": 39004, "start": 401.64000000000004, "end": 403.88, "text": " Czekaj, ale co w tym fascynuj\u0105cego?", "tokens": [50944, 383, 19878, 1805, 11, 6775, 598, 261, 8107, 30632, 1344, 77, 13263, 384, 1571, 30, 51056], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 144, "seek": 39004, "start": 403.92, "end": 407.68, "text": " Dodanie czego\u015b dla stabilno\u015bci brzmi jak standardowa procedura in\u017cynierska.", "tokens": [51058, 26904, 7155, 36559, 1788, 12285, 11652, 16438, 738, 89, 3057, 4207, 3832, 5528, 6682, 2991, 294, 1427, 2534, 4890, 2330, 13, 51246], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 145, "seek": 39004, "start": 407.72, "end": 409.88, "text": " Ale w\u0142a\u015bnie nie do ko\u0144ca,", "tokens": [51248, 9366, 14234, 2838, 360, 26470, 496, 11, 51356], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 146, "seek": 39004, "start": 409.92, "end": 413.6, "text": " bo w ich w\u0142asnych testach na mniejszych modelach", "tokens": [51358, 748, 261, 1893, 43572, 9399, 1500, 608, 1667, 39513, 45021, 2316, 608, 51542], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 147, "seek": 39004, "start": 413.64000000000004, "end": 418.40000000000003, "text": " ta dodatkowa warstwa nieznacznie pogarsza\u0142a wyniki zero shot.", "tokens": [51544, 1846, 13886, 33525, 5528, 1516, 372, 4151, 2838, 22672, 14875, 2766, 32037, 685, 2394, 5024, 31936, 9850, 4018, 3347, 13, 51782], "temperature": 0.0, "avg_logprob": -0.12737919340197673, "compression_ratio": 1.5138888888888888, "no_speech_prob": 0.005153011530637741}, {"id": 148, "seek": 41840, "start": 418.47999999999996, "end": 423.0, "text": " Fila chwila, czyli \u015bwiadomie dodali co\u015b, co obni\u017ca\u0142o wydajno\u015b\u0107?", "tokens": [50368, 479, 7371, 26237, 7371, 11, 16591, 21485, 345, 40120, 13886, 5103, 19241, 11, 598, 1111, 3722, 35075, 5249, 25984, 1805, 23293, 30, 50594], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 149, "seek": 41840, "start": 423.03999999999996, "end": 423.64, "text": " Tak.", "tokens": [50596, 9118, 13, 50626], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 150, "seek": 41840, "start": 423.67999999999995, "end": 427.56, "text": " To brzmi kompletnie wbrew intuicji, zw\u0142aszcza w projekcie za miliony dolar\u00f3w.", "tokens": [50628, 1407, 738, 89, 3057, 5207, 14657, 2766, 261, 65, 2236, 560, 84, 299, 4013, 11, 11873, 1221, 19601, 41524, 261, 447, 27023, 4260, 7949, 1962, 46184, 360, 2200, 3901, 13, 50822], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 151, "seek": 41840, "start": 427.59999999999997, "end": 428.67999999999995, "text": " Dok\u0142adnie.", "tokens": [50824, 29768, 10358, 2766, 13, 50878], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 152, "seek": 41840, "start": 428.71999999999997, "end": 432.84, "text": " I to jest kluczowy wgl\u0105d w realia in\u017cynierii na tej skali.", "tokens": [50880, 286, 281, 3492, 9671, 1311, 89, 10089, 261, 7191, 18962, 261, 957, 654, 294, 1427, 2534, 811, 5597, 1667, 12573, 1110, 5103, 13, 51086], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 153, "seek": 41840, "start": 432.88, "end": 437.28, "text": " Przy tak gigantycznym modelu samo utrzymanie treningu przy \u017cyciu,", "tokens": [51088, 39590, 991, 8741, 394, 17466, 12996, 2316, 84, 36422, 2839, 13047, 1601, 414, 2192, 773, 84, 6501, 16136, 30795, 11, 51308], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 154, "seek": 41840, "start": 437.32, "end": 440.32, "text": " bez jego za\u0142amania, jest monumentalnym wyzlaniem.", "tokens": [51310, 10782, 26542, 7949, 20177, 5609, 11, 3492, 43105, 12996, 4628, 89, 8658, 4907, 13, 51460], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 155, "seek": 41840, "start": 440.35999999999996, "end": 441.23999999999995, "text": " Rozumiem.", "tokens": [51462, 43313, 449, 4907, 13, 51506], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 156, "seek": 41840, "start": 441.28, "end": 447.08, "text": " Ta decyzja nie mia\u0142a na ce\u0142u wyci\u015bni\u0119cia dodatkowego u\u0142amka procenta na jakim\u015b benchmarku.", "tokens": [51508, 6551, 979, 37433, 2938, 2838, 21290, 5024, 1667, 1769, 1221, 84, 4628, 537, 1788, 35938, 2755, 13886, 33525, 26576, 344, 20177, 2330, 38826, 64, 1667, 49410, 1788, 18927, 84, 13, 51798], "temperature": 0.0, "avg_logprob": -0.11959860310752012, "compression_ratio": 1.4303797468354431, "no_speech_prob": 0.0031109994743019342}, {"id": 157, "seek": 44708, "start": 447.15999999999997, "end": 450.03999999999996, "text": " To by\u0142 pragmatyczny wyb\u00f3r, kt\u00f3ry mia\u0142 zagwarantowa\u0107,", "tokens": [50368, 1407, 16673, 33394, 15677, 17466, 1634, 45780, 15614, 11, 9913, 27989, 27001, 6925, 394, 11445, 11, 50512], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 158, "seek": 44708, "start": 450.08, "end": 452.15999999999997, "text": " \u017ce ca\u0142y proces w og\u00f3le dobiegnie ko\u0144ca.", "tokens": [50514, 3561, 35226, 17565, 261, 29229, 360, 7392, 70, 2766, 26470, 496, 13, 50618], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 159, "seek": 44708, "start": 452.2, "end": 453.47999999999996, "text": " To jest niesamowite.", "tokens": [50620, 1407, 3492, 48100, 335, 305, 642, 13, 50684], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 160, "seek": 44708, "start": 453.52, "end": 458.28, "text": " Czyli priorytetem by\u0142o nie zepsu\u0107, zamiast maksymalizowa\u0107.", "tokens": [50686, 37099, 1790, 827, 83, 302, 443, 14811, 2838, 710, 10653, 84, 2162, 11, 710, 4526, 525, 963, 3187, 5579, 590, 11445, 13, 50924], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 161, "seek": 44708, "start": 458.32, "end": 462.12, "text": " To idealny przyk\u0142ad, jak teoria zderza si\u0119 z in\u017cynierijn\u0105 rzeczywisto\u015bci\u0105.", "tokens": [50926, 1407, 7157, 1634, 23144, 11, 4207, 535, 8172, 710, 1068, 2394, 3244, 710, 294, 1427, 2534, 811, 6041, 1611, 26297, 86, 9334, 50227, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 162, "seek": 44708, "start": 462.15999999999997, "end": 467.4, "text": " Brzmi jakby ka\u017cda nawet najmniejsza decyzja musia\u0142a by\u0107 przemy\u015blana na nowo dla tej skali.", "tokens": [51118, 1603, 89, 3057, 28976, 21912, 2675, 22696, 11212, 76, 30295, 2394, 979, 37433, 2938, 1038, 25605, 15069, 6541, 3633, 19212, 2095, 1667, 586, 78, 12285, 12573, 1110, 5103, 13, 51380], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 163, "seek": 44708, "start": 467.44, "end": 470.52, "text": " Domy\u015blam si\u0119, \u017ce podobnie by\u0142o z najbardziej fundamentalnym krokiem.", "tokens": [51382, 413, 8488, 1788, 4326, 3244, 11, 3561, 43024, 2766, 14811, 710, 41857, 8088, 12996, 45909, 26116, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 164, "seek": 44708, "start": 470.56, "end": 471.08, "text": " Czyli?", "tokens": [51538, 37099, 30, 51564], "temperature": 0.0, "avg_logprob": -0.1194062395160701, "compression_ratio": 1.4521452145214522, "no_speech_prob": 0.002058739075437188}, {"id": 165, "seek": 47108, "start": 471.08, "end": 476.64, "text": " I jak w og\u00f3le podzieli\u0107 tekst z 46 r\u00f3\u017cnych j\u0119zyk\u00f3w na kawa\u0142ki,", "tokens": [50364, 286, 4207, 261, 29229, 2497, 42280, 12757, 16624, 372, 710, 17835, 42602, 49055, 23849, 1667, 350, 10449, 1221, 2984, 11, 50642], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 166, "seek": 47108, "start": 476.68, "end": 479.08, "text": " zanim wrzuci si\u0119 go do modelu?", "tokens": [50644, 710, 17869, 928, 11728, 537, 3244, 352, 360, 2316, 84, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 167, "seek": 47108, "start": 479.12, "end": 481.28, "text": " To musia\u0142o by\u0107 piekielne wyzwanie.", "tokens": [50766, 1407, 1038, 654, 5249, 15069, 1730, 74, 1187, 716, 4628, 14406, 7155, 13, 50874], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 168, "seek": 47108, "start": 481.32, "end": 483.08, "text": " By\u0142o ogromne.", "tokens": [50876, 3146, 5249, 34416, 298, 716, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 169, "seek": 47108, "start": 483.12, "end": 485.88, "text": " I tu te\u017c podj\u0119li bardzo ciekawe decyzje.", "tokens": [50966, 286, 2604, 9516, 2497, 11115, 2081, 9034, 30596, 2330, 826, 979, 37433, 2884, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 170, "seek": 47108, "start": 485.91999999999996, "end": 488.68, "text": " U\u017cyto algorytmu Byte Level BPE", "tokens": [51106, 624, 7735, 1353, 3501, 827, 83, 20140, 3146, 975, 16872, 363, 5208, 51244], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 171, "seek": 47108, "start": 488.71999999999997, "end": 492.4, "text": " na s\u0142owniku o wielko\u015bci prawie 251 tysi\u0119cy token\u00f3w.", "tokens": [51246, 1667, 15116, 648, 24320, 277, 20570, 4093, 6199, 3206, 8699, 3552, 16, 38156, 47303, 14862, 3901, 13, 51430], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 172, "seek": 47108, "start": 492.44, "end": 494.64, "text": " A co oznacza to Byte Level?", "tokens": [51432, 316, 598, 277, 22672, 326, 2394, 281, 3146, 975, 16872, 30, 51542], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 173, "seek": 47108, "start": 494.68, "end": 498.88, "text": " To oznacza, \u017ce tokalizacja nigdy nie napotka nieznanego znaku.", "tokens": [51544, 1407, 277, 22672, 326, 2394, 11, 3561, 281, 19990, 590, 23395, 26996, 3173, 2838, 9296, 310, 2330, 2838, 22672, 282, 6308, 15397, 15803, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1311398970114218, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.10826709121465683}, {"id": 174, "seek": 49888, "start": 498.96, "end": 502.71999999999997, "text": " Bo operuje na poziomie byt\u00f3w, a nie znak\u00f3w unicode.", "tokens": [50368, 3286, 2208, 13008, 1667, 38503, 40120, 538, 83, 3901, 11, 257, 2838, 15397, 514, 3901, 517, 299, 1429, 13, 50556], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 175, "seek": 49888, "start": 502.76, "end": 507.04, "text": " To kluczowe dla modelu, kt\u00f3ry ma radzi\u0107 sobie z tak\u0105 r\u00f3\u017cnorodno\u015bci\u0105 j\u0119zyk\u00f3w i symboli.", "tokens": [50558, 1407, 9671, 1311, 89, 6880, 12285, 2316, 84, 11, 9913, 463, 2843, 28496, 13652, 710, 31069, 19637, 19048, 378, 16438, 1611, 49055, 23849, 741, 5986, 72, 13, 50772], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 176, "seek": 49888, "start": 507.08, "end": 511.71999999999997, "text": " Co wi\u0119cej, \u015bwiadomie zrezygnowano z jakiejkolwiek normalizacji tekstu,", "tokens": [50774, 3066, 26004, 11, 21485, 345, 40120, 710, 265, 1229, 70, 3785, 3730, 710, 4207, 7764, 36620, 44674, 2710, 590, 13152, 16624, 372, 84, 11, 51006], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 177, "seek": 49888, "start": 511.76, "end": 517.64, "text": " jak np. NFKC, \u017ceby model uczy\u0142 si\u0119 na surowych, nieoczyszczonych danych.", "tokens": [51008, 4207, 33808, 13, 13576, 42, 34, 11, 11316, 2316, 344, 6522, 1221, 3244, 1667, 1022, 19605, 11, 2838, 905, 89, 20589, 3689, 2526, 339, 274, 34644, 13, 51302], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 178, "seek": 49888, "start": 517.68, "end": 523.04, "text": " Odrzucili te\u017c te typowo anglo-centryczne regu\u0142y np. wok\u00f3\u0142 ko\u0144c\u00f3wek end czy ill.", "tokens": [51304, 12210, 19390, 1311, 2312, 9516, 535, 2125, 19941, 2562, 752, 12, 2207, 627, 38491, 1121, 84, 6825, 33808, 13, 40022, 16181, 26470, 66, 812, 826, 74, 917, 6430, 3171, 13, 51572], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 179, "seek": 49888, "start": 523.08, "end": 527.48, "text": " Dok\u0142adnie. Wszystko po to, by by\u0107 jak najbardziej neutralnym j\u0119zykowo.", "tokens": [51574, 29768, 10358, 2766, 13, 343, 10424, 4093, 714, 281, 11, 538, 15069, 4207, 41857, 10598, 12996, 49055, 74, 19941, 13, 51794], "temperature": 0.0, "avg_logprob": -0.13835417706033457, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.08816081285476685}, {"id": 180, "seek": 52748, "start": 527.48, "end": 532.28, "text": " Mamy wi\u0119c gigantyczny, wieloj\u0119zyczny model zbudowany na unikalnym,", "tokens": [50364, 376, 7804, 16677, 8741, 394, 17466, 1634, 11, 20570, 78, 11115, 1229, 3689, 1634, 2316, 710, 18281, 23341, 1667, 517, 41216, 12996, 11, 50604], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 181, "seek": 52748, "start": 532.32, "end": 534.6, "text": " r\u0119cznie kuratorowanym zbiorze danych.", "tokens": [50606, 41197, 19923, 10072, 1639, 23341, 76, 710, 33362, 1381, 274, 34644, 13, 50720], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 182, "seek": 52748, "start": 534.64, "end": 538.2, "text": " Z kilkoma bardzo sprytnymi modyfikacjami w architekturze,", "tokens": [50722, 1176, 5128, 74, 6440, 9034, 637, 627, 83, 31813, 275, 843, 31230, 326, 73, 4526, 261, 3912, 642, 2320, 374, 1381, 11, 50900], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 183, "seek": 52748, "start": 538.24, "end": 540.52, "text": " podyktowanymi pragmatyzmem.", "tokens": [50902, 280, 843, 2320, 23341, 3057, 33394, 15677, 37433, 17886, 13, 51016], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 184, "seek": 52748, "start": 540.5600000000001, "end": 542.2, "text": " Pytanie za 100 punkt\u00f3w.", "tokens": [51018, 430, 4328, 7155, 7949, 2319, 39561, 3901, 13, 51100], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 185, "seek": 52748, "start": 542.24, "end": 544.64, "text": " Jak to wszystko dzia\u0142a w praktyce?", "tokens": [51102, 15029, 281, 22607, 37903, 261, 3206, 74, 874, 384, 30, 51222], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 186, "seek": 52748, "start": 544.6800000000001, "end": 548.6, "text": " Czy ta ca\u0142a filozofia i ten wysi\u0142ek prze\u0142o\u017cy\u0142o si\u0119 na wyniki?", "tokens": [51224, 19832, 1846, 1335, 5024, 1387, 15151, 2670, 654, 741, 2064, 27062, 40622, 916, 8325, 5249, 7735, 5249, 3244, 1667, 31936, 9850, 30, 51420], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 187, "seek": 52748, "start": 548.64, "end": 552.2, "text": " Wyniki s\u0105 z\u0142o\u017cone, ale w\u0142a\u015bnie przez to tak ciekawe.", "tokens": [51422, 343, 2534, 9850, 9015, 710, 5249, 1427, 546, 11, 6775, 14234, 14064, 281, 991, 30596, 2330, 826, 13, 51600], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 188, "seek": 52748, "start": 552.24, "end": 554.9200000000001, "text": " Zacznijmy od czego\u015b, co mo\u017ce wydawa\u0107 si\u0119 testem", "tokens": [51602, 1176, 14875, 77, 1718, 2226, 3611, 36559, 1788, 11, 598, 12034, 25984, 10449, 2162, 3244, 1500, 443, 51736], "temperature": 0.0, "avg_logprob": -0.12263606507101177, "compression_ratio": 1.4071661237785016, "no_speech_prob": 0.004427027888596058}, {"id": 189, "seek": 55492, "start": 554.92, "end": 557.8, "text": " wbrew za\u0142o\u017ceniam benchmark superglue.", "tokens": [50364, 261, 65, 2236, 7949, 5249, 24930, 2918, 18927, 1687, 7191, 622, 13, 50508], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 190, "seek": 55492, "start": 557.8399999999999, "end": 559.7199999999999, "text": " Kt\u00f3ry jest w 100% po angielsku?", "tokens": [50510, 591, 4547, 627, 3492, 261, 2319, 4, 714, 2562, 1187, 5161, 84, 30, 50604], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 191, "seek": 55492, "start": 559.76, "end": 565.3199999999999, "text": " Tak. I bloom wypada tu por\u00f3wnywalnie do innych modeli tej skali jak np. OPT.", "tokens": [50606, 9118, 13, 286, 26899, 46392, 1538, 2604, 1515, 812, 895, 27112, 304, 2766, 360, 36286, 2316, 72, 12573, 1110, 5103, 4207, 33808, 13, 23324, 51, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 192, "seek": 55492, "start": 565.36, "end": 566.9599999999999, "text": " Czyli nie jest gorszy.", "tokens": [50886, 37099, 2838, 3492, 290, 830, 1229, 13, 50966], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 193, "seek": 55492, "start": 567.0, "end": 569.3199999999999, "text": " Co ju\u017c samo w sobie jest sukcesem.", "tokens": [50968, 3066, 10678, 36422, 261, 13652, 3492, 46432, 887, 443, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 194, "seek": 55492, "start": 569.36, "end": 574.16, "text": " Bo mo\u017cna by si\u0119 obawia\u0107, \u017ce model, kt\u00f3ry uczy\u0142 si\u0119 45 innych j\u0119zyk\u00f3w,", "tokens": [51086, 3286, 17790, 538, 3244, 1111, 34953, 2162, 11, 3561, 2316, 11, 9913, 344, 6522, 1221, 3244, 6905, 36286, 49055, 23849, 11, 51326], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 195, "seek": 55492, "start": 574.1999999999999, "end": 576.12, "text": " b\u0119dzie s\u0142abszy w angielskim.", "tokens": [51328, 10562, 15116, 455, 7706, 261, 2562, 1187, 5161, 332, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 196, "seek": 55492, "start": 576.16, "end": 578.5999999999999, "text": " Taki jack of all trades, master of none.", "tokens": [51426, 314, 7421, 7109, 295, 439, 21287, 11, 4505, 295, 6022, 13, 51548], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 197, "seek": 55492, "start": 578.64, "end": 580.4399999999999, "text": " Dok\u0142adnie. A tak nie jest.", "tokens": [51550, 29768, 10358, 2766, 13, 316, 991, 2838, 3492, 13, 51640], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 198, "seek": 55492, "start": 580.48, "end": 582.04, "text": " Ale jest co\u015b jeszcze ciekawszego.", "tokens": [51642, 9366, 3492, 19241, 14168, 46419, 1607, 15453, 6308, 13, 51720], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 199, "seek": 55492, "start": 582.0799999999999, "end": 582.9599999999999, "text": " Co takiego?", "tokens": [51722, 3066, 32296, 30, 51766], "temperature": 0.0, "avg_logprob": -0.1923182579778856, "compression_ratio": 1.4215686274509804, "no_speech_prob": 0.0971192941069603}, {"id": 200, "seek": 58296, "start": 583.08, "end": 586.2800000000001, "text": " Przy przej\u015bciu z trybu zero shot do one shot.", "tokens": [50370, 39590, 8325, 73, 6199, 84, 710, 853, 6021, 4018, 3347, 360, 472, 3347, 13, 50530], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 201, "seek": 58296, "start": 586.32, "end": 588.8000000000001, "text": " Czyli gdy model dostaje jeden przyk\u0142ad zadania?", "tokens": [50532, 37099, 28405, 2316, 20568, 11153, 12906, 23144, 42788, 5609, 30, 50656], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 202, "seek": 58296, "start": 588.84, "end": 592.88, "text": " W\u0142a\u015bnie. Jego wydajno\u015b\u0107 ro\u015bnie bardziej ni\u017c u konkurencji.", "tokens": [50658, 343, 5024, 12221, 13, 508, 6308, 25984, 1805, 23293, 744, 12221, 27209, 28502, 344, 21428, 9873, 19649, 13, 50860], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 203, "seek": 58296, "start": 592.9200000000001, "end": 597.2800000000001, "text": " Autorzy spekuluj\u0105, \u017ce ten jeden przyk\u0142ad, ten dodatkowy kontekst,", "tokens": [50862, 6049, 284, 1229, 768, 74, 425, 13263, 11, 3561, 2064, 12906, 23144, 11, 2064, 13886, 33525, 10089, 14373, 916, 372, 11, 51080], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 204, "seek": 58296, "start": 597.32, "end": 601.52, "text": " pomaga wieloj\u0119zycznemu m\u00f3zgowi bluma skupi\u0107 si\u0119 na angielskim", "tokens": [51082, 12991, 9286, 20570, 78, 11115, 1229, 3689, 25989, 84, 32515, 89, 70, 24503, 888, 5544, 1110, 1010, 12757, 3244, 1667, 2562, 1187, 5161, 332, 51292], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 205, "seek": 58296, "start": 601.5600000000001, "end": 603.1600000000001, "text": " i lepiej zrozumie\u0107 zadanie.", "tokens": [51294, 741, 476, 39699, 710, 27857, 449, 414, 2162, 42788, 7155, 13, 51374], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 206, "seek": 58296, "start": 603.2, "end": 606.36, "text": " Czyli trening wieloj\u0119zyczny nie tylko nie zaszkodzi\u0142,", "tokens": [51376, 37099, 2192, 773, 20570, 78, 11115, 1229, 3689, 1634, 2838, 13219, 2838, 710, 19601, 74, 14543, 1221, 11, 51534], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 207, "seek": 58296, "start": 606.4000000000001, "end": 608.72, "text": " ale mo\u017ce nawet da\u0142 mu pewn\u0105 elastyczno\u015b\u0107.", "tokens": [51536, 6775, 12034, 22696, 1120, 1221, 2992, 47160, 1611, 806, 9820, 3689, 23293, 13, 51652], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 208, "seek": 58296, "start": 608.76, "end": 610.12, "text": " To mocny dow\u00f3d na to.", "tokens": [51654, 1407, 34962, 1634, 9459, 17081, 1667, 281, 13, 51722], "temperature": 0.0, "avg_logprob": -0.12344459971045232, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.015715083107352257}, {"id": 209, "seek": 61012, "start": 610.16, "end": 613.12, "text": " OK, czyli na angielskim terytorium daje rad\u0119.", "tokens": [50366, 2264, 11, 16591, 1667, 2562, 1187, 5161, 332, 1796, 4328, 284, 2197, 1120, 2884, 2843, 1274, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 210, "seek": 61012, "start": 613.16, "end": 617.52, "text": " Ale przecie\u017c ca\u0142y sen z tego projektu to by\u0142a radykalna wieloj\u0119zyczno\u015b\u0107.", "tokens": [50516, 9366, 8325, 40082, 35226, 3151, 710, 8627, 26261, 84, 281, 23936, 367, 880, 19990, 629, 20570, 78, 11115, 1229, 3689, 23293, 13, 50734], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 211, "seek": 61012, "start": 617.5600000000001, "end": 620.16, "text": " Jak sobie poradzi\u0142 na przyk\u0142ad z t\u0142umaczeniem?", "tokens": [50736, 15029, 13652, 1515, 345, 3992, 1221, 1667, 23144, 710, 256, 49166, 326, 2904, 4907, 30, 50866], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 212, "seek": 61012, "start": 620.2, "end": 622.36, "text": " I to zaczyna si\u0119 prawdziwa magia.", "tokens": [50868, 286, 281, 43811, 629, 3244, 41175, 3992, 4151, 2258, 654, 13, 50976], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 213, "seek": 61012, "start": 622.4, "end": 627.0, "text": " Na zestawie flores 101, kt\u00f3ry obejmuje mn\u00f3stwo par j\u0119zykowych,", "tokens": [50978, 6056, 37889, 1607, 414, 932, 2706, 21055, 11, 9913, 36346, 35195, 13008, 275, 77, 45052, 6120, 971, 49055, 74, 19605, 11, 51208], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 214, "seek": 61012, "start": 627.04, "end": 629.0, "text": " blum cz\u0119sto rywalizowa\u0142,", "tokens": [51210, 888, 449, 34369, 20791, 29530, 590, 30105, 11, 51308], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 215, "seek": 61012, "start": 629.04, "end": 633.44, "text": " a czasem nawet wygrywa\u0142 z wyspecjalizowanymi nadzorowanymi modelami.", "tokens": [51310, 257, 13190, 443, 22696, 4628, 70, 627, 44603, 710, 27062, 494, 66, 22600, 590, 23341, 3057, 12617, 89, 284, 23341, 3057, 2316, 4526, 13, 51530], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 216, "seek": 61012, "start": 633.48, "end": 636.8, "text": " Chwileczk\u0119. Chcesz powiedzie\u0107, \u017ce konkurowa\u0142 z modelami,", "tokens": [51532, 761, 86, 794, 3689, 15724, 13, 761, 887, 89, 27886, 11, 3561, 21428, 374, 30105, 710, 2316, 4526, 11, 51698], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 217, "seek": 61012, "start": 636.84, "end": 639.84, "text": " kt\u00f3re zosta\u0142y stworzone tylko i wy\u0142\u0105cznie do t\u0142umaczenia?", "tokens": [51700, 8864, 23154, 6825, 342, 28321, 16896, 13219, 741, 4628, 15926, 19923, 360, 256, 49166, 326, 14320, 30, 51850], "temperature": 0.0, "avg_logprob": -0.11800467830964889, "compression_ratio": 1.470414201183432, "no_speech_prob": 0.0010026204399764538}, {"id": 218, "seek": 63984, "start": 639.88, "end": 640.9200000000001, "text": " W\u0142a\u015bnie tak.", "tokens": [50366, 343, 5024, 12221, 991, 13, 50418], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 219, "seek": 63984, "start": 640.96, "end": 645.9200000000001, "text": " A wisienka na torcie jest taka, \u017ce potrafi\u0142 nawet t\u0142umaczy\u0107 z j\u0119zyka galicyjskiego.", "tokens": [50420, 316, 9074, 1053, 2330, 1667, 3930, 4260, 3492, 28017, 11, 3561, 1847, 10437, 40622, 22696, 256, 49166, 14691, 2162, 710, 42309, 40940, 7660, 2632, 32625, 12200, 13, 50668], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 220, "seek": 63984, "start": 645.96, "end": 649.6800000000001, "text": " Kt\u00f3rego oficjalnie w og\u00f3le nie widzia\u0142 podczas treningu?", "tokens": [50670, 591, 4547, 265, 1571, 295, 299, 22600, 2766, 261, 29229, 2838, 27486, 8908, 2497, 30989, 2192, 773, 84, 30, 50856], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 221, "seek": 63984, "start": 649.72, "end": 650.9200000000001, "text": " Nie widzia\u0142.", "tokens": [50858, 12016, 27486, 8908, 13, 50918], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 222, "seek": 63984, "start": 650.96, "end": 654.24, "text": " Prawdopodobnie wykorzysta\u0142 jego ogromne podobie\u0144stwo", "tokens": [50920, 430, 15889, 46684, 996, 2766, 43606, 49590, 1221, 26542, 34416, 298, 716, 43024, 414, 12229, 6120, 51084], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 223, "seek": 63984, "start": 654.2800000000001, "end": 659.2800000000001, "text": " do innych j\u0119zyk\u00f3w roma\u0144skich, jak hiszpa\u0144ski czy portugalski, kt\u00f3re by\u0142y w danych.", "tokens": [51086, 360, 36286, 49055, 23849, 367, 6440, 27125, 480, 11, 4207, 702, 89, 4306, 5248, 18020, 6430, 2436, 697, 1124, 2984, 11, 8864, 26366, 261, 274, 34644, 13, 51336], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 224, "seek": 63984, "start": 659.32, "end": 663.84, "text": " To pokazuje niesamowit\u0105 zdolno\u015b\u0107 do transferu wiedzy mi\u0119dzy j\u0119zykami.", "tokens": [51338, 1407, 13010, 43317, 48100, 335, 305, 270, 1611, 16221, 401, 23293, 360, 5003, 84, 46894, 1229, 33964, 49055, 48737, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 225, "seek": 63984, "start": 663.88, "end": 667.96, "text": " Ale czuj\u0119, \u017ce musi by\u0107 jakie\u015b ale.", "tokens": [51566, 9366, 6472, 18258, 11, 3561, 37587, 15069, 31163, 6775, 13, 51770], "temperature": 0.0, "avg_logprob": -0.15143419291875135, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.002205417025834322}, {"id": 226, "seek": 66796, "start": 668.0400000000001, "end": 669.88, "text": " Gdzie s\u0105 jego s\u0142absze strony?", "tokens": [50368, 460, 13096, 9015, 26542, 15116, 455, 82, 1381, 32406, 30, 50460], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 227, "seek": 66796, "start": 669.9200000000001, "end": 671.8000000000001, "text": " Oczywi\u015bcie, \u017ce s\u0105.", "tokens": [50462, 42980, 11, 3561, 9015, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 228, "seek": 66796, "start": 671.84, "end": 674.2, "text": " Model bardzo s\u0142abo radzi sobie z j\u0119zykami,", "tokens": [50558, 17105, 9034, 15116, 41265, 2843, 3992, 13652, 710, 49055, 48737, 11, 50676], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 229, "seek": 66796, "start": 674.24, "end": 679.12, "text": " kt\u00f3re mia\u0142y ma\u0142\u0105 reprezentacj\u0119 w danych treningowych, jak s\u0142ahili czy joruba.", "tokens": [50678, 8864, 21290, 6825, 463, 15926, 1085, 265, 14185, 29924, 261, 274, 34644, 2192, 773, 19605, 11, 4207, 15116, 545, 2312, 6430, 361, 284, 12584, 13, 50922], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 230, "seek": 66796, "start": 679.1600000000001, "end": 682.0, "text": " I to jest brutalne zderzenie z rzeczywisto\u015bci\u0105.", "tokens": [50924, 286, 281, 3492, 17878, 716, 710, 1068, 16778, 710, 26297, 86, 9334, 50227, 13, 51066], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 231, "seek": 66796, "start": 682.0400000000001, "end": 683.44, "text": " Zdecydowanie.", "tokens": [51068, 1176, 1479, 1344, 67, 22028, 13, 51138], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 232, "seek": 66796, "start": 683.48, "end": 687.72, "text": " Pokazuje, \u017ce pomimo ca\u0142ej innowacyjnej architektury i filozofii", "tokens": [51140, 14958, 43317, 11, 3561, 12991, 6934, 47631, 73, 294, 3785, 31285, 11794, 3912, 642, 2320, 2598, 741, 1387, 15151, 2670, 5597, 51352], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 233, "seek": 66796, "start": 687.76, "end": 690.36, "text": " ilo\u015b\u0107 danych dla danego j\u0119zyka", "tokens": [51354, 1930, 78, 7753, 274, 34644, 12285, 3277, 6308, 42309, 40940, 51484], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 234, "seek": 66796, "start": 690.4000000000001, "end": 693.2, "text": " wci\u0105\u017c jest absolutnie kluczowym czynnikiem.", "tokens": [51486, 261, 537, 27242, 3492, 18757, 2766, 9671, 1311, 89, 31691, 6430, 77, 13123, 4907, 13, 51626], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 235, "seek": 66796, "start": 693.24, "end": 696.6800000000001, "text": " Nie da si\u0119 tego przyskoczy\u0107 sam\u0105 m\u0105dro\u015bci\u0105 modelu.", "tokens": [51628, 12016, 1120, 3244, 8627, 6541, 749, 74, 905, 27150, 3247, 1611, 275, 18962, 340, 50227, 2316, 84, 13, 51800], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 236, "seek": 66796, "start": 696.72, "end": 697.6800000000001, "text": " Niestety nie.", "tokens": [51802, 426, 6495, 2210, 2838, 13, 51850], "temperature": 0.0, "avg_logprob": -0.1321972288736483, "compression_ratio": 1.4935483870967743, "no_speech_prob": 0.03177415952086449}, {"id": 237, "seek": 69768, "start": 697.76, "end": 698.68, "text": " Rozumiem.", "tokens": [50368, 43313, 449, 4907, 13, 50414], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 238, "seek": 69768, "start": 698.7199999999999, "end": 700.7199999999999, "text": " Dane to wci\u0105\u017c paliwo.", "tokens": [50416, 413, 1929, 281, 261, 537, 27242, 3984, 72, 6120, 13, 50516], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 239, "seek": 69768, "start": 700.76, "end": 701.8399999999999, "text": " A co z kodem?", "tokens": [50518, 316, 598, 710, 350, 378, 443, 30, 50572], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 240, "seek": 69768, "start": 701.88, "end": 704.3599999999999, "text": " W korpusie by\u0142o 13 j\u0119zyk\u00f3w programowania.", "tokens": [50574, 343, 14784, 31624, 414, 14811, 3705, 49055, 23849, 1461, 21308, 13, 50698], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 241, "seek": 69768, "start": 704.4, "end": 706.9599999999999, "text": " Tutaj wyniki s\u0105 zgodne z oczekiwaniami.", "tokens": [50700, 41819, 31936, 9850, 9015, 710, 21787, 716, 710, 277, 3689, 14753, 7916, 15568, 13, 50828], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 242, "seek": 69768, "start": 707.0, "end": 708.8399999999999, "text": " Na benchmarku Human Evil", "tokens": [50830, 6056, 18927, 84, 10294, 20528, 50922], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 243, "seek": 69768, "start": 708.88, "end": 713.4399999999999, "text": " wydajno\u015b\u0107 jest podobna do modeli GPT trenowanych na korpusie Depile,", "tokens": [50924, 25984, 1805, 23293, 3492, 43024, 629, 360, 2316, 72, 26039, 51, 23136, 23341, 339, 1667, 14784, 31624, 414, 4056, 794, 11, 51152], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 244, "seek": 69768, "start": 713.4799999999999, "end": 715.76, "text": " kt\u00f3ry te\u017c miesza tekst i kod.", "tokens": [51154, 9913, 9516, 41543, 2394, 16624, 372, 741, 350, 378, 13, 51268], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 245, "seek": 69768, "start": 715.8, "end": 718.5999999999999, "text": " Ale jest znacznie ni\u017csze ni\u017c w przypadku modeli", "tokens": [51270, 9366, 3492, 15397, 14875, 2766, 28502, 82, 1381, 28502, 261, 41955, 2316, 72, 51410], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 246, "seek": 69768, "start": 718.64, "end": 721.28, "text": " wyspecjalizowanych w kodzie, jak kodeks.", "tokens": [51412, 27062, 494, 66, 22600, 590, 23341, 339, 261, 350, 378, 3283, 11, 4207, 350, 378, 24785, 13, 51544], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 247, "seek": 69768, "start": 721.3199999999999, "end": 722.1999999999999, "text": " No tak.", "tokens": [51546, 883, 991, 13, 51590], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 248, "seek": 69768, "start": 722.24, "end": 727.64, "text": " To logiczne, bo kod stanowi\u0142 tylko oko\u0142o 11% danych treningowych bloom.", "tokens": [51592, 1407, 9952, 43077, 11, 748, 350, 378, 27984, 24503, 1221, 13219, 45730, 5249, 2975, 4, 274, 34644, 2192, 773, 19605, 26899, 13, 51862], "temperature": 0.0, "avg_logprob": -0.17553621456946855, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.0016608282458037138}, {"id": 249, "seek": 72768, "start": 727.68, "end": 729.92, "text": " Po prostu nie by\u0142 to jego priorytet.", "tokens": [50364, 6165, 19518, 2838, 16673, 281, 26542, 1790, 827, 83, 302, 13, 50476], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 250, "seek": 72768, "start": 729.9599999999999, "end": 733.9599999999999, "text": " Praca du\u017co miejsca po\u015bwi\u0119ca te\u017c czemu\u015b, co nazywa si\u0119 bloom Z.", "tokens": [50478, 2114, 6628, 26673, 18522, 44239, 714, 1788, 22423, 496, 9516, 6472, 37552, 1788, 11, 598, 20151, 88, 4151, 3244, 26899, 1176, 13, 50678], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 251, "seek": 72768, "start": 734.0, "end": 738.4799999999999, "text": " Co to jest i co da\u0142 ten ca\u0142y proces multitask find tuning?", "tokens": [50680, 3066, 281, 3492, 741, 598, 1120, 1221, 2064, 35226, 17565, 42338, 3863, 915, 15164, 30, 50904], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 252, "seek": 72768, "start": 738.52, "end": 742.8, "text": " To jest kluczowy i ostatni etap ewolucji tego modelu.", "tokens": [50906, 1407, 3492, 9671, 1311, 89, 10089, 741, 32686, 3722, 47634, 43364, 401, 1311, 4013, 8627, 2316, 84, 13, 51120], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 253, "seek": 72768, "start": 742.8399999999999, "end": 745.8, "text": " Multitask prompted find tuning to proces,", "tokens": [51122, 14665, 270, 3863, 31042, 915, 15164, 281, 17565, 11, 51270], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 254, "seek": 72768, "start": 745.8399999999999, "end": 749.52, "text": " w kt\u00f3rym gotowy, wytrenowany model jest dodatkowo dostrajany", "tokens": [51272, 261, 30120, 658, 10089, 11, 261, 4328, 1095, 23341, 2316, 3492, 13886, 33525, 19941, 20568, 48690, 1325, 51456], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 255, "seek": 72768, "start": 749.56, "end": 751.64, "text": " na zbiorze bardzo r\u00f3\u017cnorodnych zada\u0144.", "tokens": [51458, 1667, 710, 33362, 1381, 9034, 19637, 19048, 378, 9399, 710, 1538, 5248, 13, 51562], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 256, "seek": 72768, "start": 751.68, "end": 754.5999999999999, "text": " A te zadania s\u0105 opisane w j\u0119zyku naturalnym", "tokens": [51564, 316, 535, 42788, 5609, 9015, 45477, 1929, 261, 49055, 5279, 3303, 12996, 51710], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 257, "seek": 72768, "start": 754.64, "end": 756.56, "text": " za pomoc\u0105 tak zwanych prompt\u00f3w.", "tokens": [51712, 7949, 48962, 1611, 991, 11873, 34644, 12391, 3901, 13, 51808], "temperature": 0.0, "avg_logprob": -0.17157762344569377, "compression_ratio": 1.4817275747508305, "no_speech_prob": 0.00046769637265242636}, {"id": 258, "seek": 75656, "start": 756.56, "end": 757.56, "text": " Dok\u0142adnie.", "tokens": [50364, 29768, 10358, 2766, 13, 50414], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 259, "seek": 75656, "start": 757.5999999999999, "end": 759.56, "text": " U\u017cyto do tego specjalnie przygotowanego", "tokens": [50416, 624, 7735, 1353, 360, 8627, 46433, 2766, 35914, 37345, 6308, 50514], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 260, "seek": 75656, "start": 759.5999999999999, "end": 761.9599999999999, "text": " wieloj\u0119zycznego zbioru XP3.", "tokens": [50516, 20570, 78, 11115, 1229, 3689, 11858, 710, 33362, 84, 33984, 18, 13, 50634], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 261, "seek": 75656, "start": 762.0, "end": 763.3599999999999, "text": " I jaki by\u0142 efekt?", "tokens": [50636, 286, 24492, 16673, 31482, 8192, 30, 50704], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 262, "seek": 75656, "start": 763.4, "end": 767.52, "text": " Drastyczna poprawa zdolno\u015bci zero shot w zadaniach,", "tokens": [50706, 2491, 9820, 3689, 629, 1665, 424, 4151, 16221, 401, 16438, 4018, 3347, 261, 42788, 3782, 608, 11, 50912], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 263, "seek": 75656, "start": 767.56, "end": 769.7199999999999, "text": " kt\u00f3rych model wcze\u015bniej nie widzia\u0142.", "tokens": [50914, 30382, 2316, 40785, 2838, 27486, 8908, 13, 51022], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 264, "seek": 75656, "start": 769.76, "end": 772.88, "text": " Bloom Z, czyli model po tym procesie,", "tokens": [51024, 25927, 1176, 11, 16591, 2316, 714, 8107, 17565, 414, 11, 51180], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 265, "seek": 75656, "start": 772.92, "end": 775.76, "text": " znacznie przewy\u017csza bazowy model bloom,", "tokens": [51182, 15397, 14875, 2766, 39758, 88, 1427, 82, 2394, 27147, 10089, 2316, 26899, 11, 51324], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 266, "seek": 75656, "start": 775.8, "end": 779.04, "text": " na przyk\u0142ad w zadaniach wnioskowania w j\u0119zyku naturalnym.", "tokens": [51326, 1667, 23144, 261, 42788, 3782, 608, 45368, 2717, 74, 21308, 261, 49055, 5279, 3303, 12996, 13, 51488], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 267, "seek": 75656, "start": 779.0799999999999, "end": 782.0, "text": " Czyli to przej\u015bcie od wiedzy do dzia\u0142ania.", "tokens": [51490, 37099, 281, 8325, 73, 9815, 3611, 46894, 1229, 360, 27121, 5609, 13, 51636], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 268, "seek": 75656, "start": 782.04, "end": 783.76, "text": " Idealne podsumowanie.", "tokens": [51638, 13090, 304, 716, 31925, 449, 22028, 13, 51724], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 269, "seek": 75656, "start": 783.8, "end": 786.3599999999999, "text": " Samo przeczytanie internetu to jedno,", "tokens": [51726, 4832, 78, 8325, 6522, 83, 7155, 4705, 84, 281, 5232, 1771, 11, 51854], "temperature": 0.0, "avg_logprob": -0.15693840227629008, "compression_ratio": 1.4713804713804715, "no_speech_prob": 0.01302797719836235}, {"id": 270, "seek": 78636, "start": 786.36, "end": 789.52, "text": " a nauczenie si\u0119 wykonywania konkretnych polece\u0144", "tokens": [50364, 257, 49103, 16778, 3244, 39287, 2526, 86, 5609, 36500, 9399, 13208, 384, 5248, 50522], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 271, "seek": 78636, "start": 789.5600000000001, "end": 793.64, "text": " to zupe\u0142nie inna, ale niezwykle wa\u017cna umiej\u0119tno\u015b\u0107.", "tokens": [50524, 281, 49922, 294, 629, 11, 6775, 33511, 9726, 14677, 27777, 629, 1105, 7764, 46788, 23293, 13, 50728], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 272, "seek": 78636, "start": 793.6800000000001, "end": 794.6800000000001, "text": " Dobrze.", "tokens": [50730, 29679, 13503, 13, 50780], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 273, "seek": 78636, "start": 794.72, "end": 797.48, "text": " To spr\u00f3bujmy zebra\u0107 to wszystko w ca\u0142o\u015b\u0107.", "tokens": [50782, 1407, 6103, 14216, 4579, 2226, 47060, 2162, 281, 22607, 261, 1335, 44742, 13, 50920], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 274, "seek": 78636, "start": 797.52, "end": 800.32, "text": " Gdyby trzeba by\u0142o wskaza\u0107 najwa\u017cniejszy wniosek", "tokens": [50922, 460, 3173, 2322, 25860, 14811, 261, 5161, 12257, 2162, 11212, 27111, 10402, 7706, 261, 3722, 541, 74, 51062], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 275, "seek": 78636, "start": 800.36, "end": 804.0, "text": " z ca\u0142ego ogromnego projektu bloom, co by to by\u0142o?", "tokens": [51064, 710, 35224, 6308, 34416, 298, 11858, 26261, 84, 26899, 11, 598, 538, 281, 14811, 30, 51246], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 276, "seek": 78636, "start": 804.04, "end": 806.6, "text": " My\u015bl\u0119, \u017ce s\u0105 trzy kluczowe lekcje.", "tokens": [51248, 1222, 28749, 11, 3561, 9015, 34573, 9671, 1311, 89, 6880, 30863, 44261, 13, 51376], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 277, "seek": 78636, "start": 806.64, "end": 809.64, "text": " Po pierwsze, i to mo\u017ce by\u0107 najwa\u017cniejsze.", "tokens": [51378, 6165, 45994, 11, 741, 281, 12034, 15069, 11212, 27111, 44258, 13, 51528], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 278, "seek": 78636, "start": 809.6800000000001, "end": 812.44, "text": " Proces jest r\u00f3wnie wa\u017cny jak produkt.", "tokens": [51530, 1705, 887, 3492, 11416, 14215, 27777, 1634, 4207, 42816, 13, 51668], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 279, "seek": 78636, "start": 812.48, "end": 813.48, "text": " Hmm.", "tokens": [51670, 8239, 13, 51720], "temperature": 0.0, "avg_logprob": -0.16263208742494936, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.000838235835544765}, {"id": 280, "seek": 81348, "start": 813.6, "end": 816.72, "text": " Historia Big Science to gotowy przepis na to,", "tokens": [50370, 9038, 8172, 5429, 8976, 281, 658, 10089, 30829, 271, 1667, 281, 11, 50526], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 281, "seek": 81348, "start": 816.76, "end": 819.96, "text": " jak w przysz\u0142o\u015bci mo\u017cna prowadzi\u0107 otwarte", "tokens": [50528, 4207, 261, 44018, 35059, 17790, 36590, 28496, 4337, 86, 11026, 50688], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 282, "seek": 81348, "start": 820.0, "end": 823.88, "text": " i co wa\u017cne etycznie \u015bwiadome projekty w AI.", "tokens": [50690, 741, 598, 46110, 1030, 17466, 2766, 21485, 345, 423, 447, 27023, 874, 261, 7318, 13, 50884], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 283, "seek": 81348, "start": 823.9200000000001, "end": 826.04, "text": " Pokazali, \u017ce da si\u0119 to zrobi\u0107 inaczej.", "tokens": [50886, 14958, 921, 5103, 11, 3561, 1120, 3244, 281, 31785, 33230, 16920, 13, 50992], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 284, "seek": 81348, "start": 826.08, "end": 827.28, "text": " Zgadzam si\u0119.", "tokens": [50994, 1176, 70, 345, 28915, 3244, 13, 51054], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 285, "seek": 81348, "start": 827.32, "end": 831.4, "text": " Sama organizacja pracy, zaanga\u017cowanie spo\u0142eczno\u015bci", "tokens": [51056, 318, 2404, 4645, 23395, 35591, 11, 7949, 656, 18264, 22028, 36851, 89, 16438, 51260], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 286, "seek": 81348, "start": 831.44, "end": 835.04, "text": " i ta karta etyczna, kt\u00f3ra faktycznie dzia\u0142a\u0142a,", "tokens": [51262, 741, 1846, 350, 19061, 1030, 17466, 629, 11, 19456, 33647, 45586, 37903, 5024, 11, 51442], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 287, "seek": 81348, "start": 835.08, "end": 837.88, "text": " s\u0105 osi\u0105gni\u0119ciem na miar\u0119 samego modelu.", "tokens": [51444, 9015, 3003, 11404, 70, 35938, 4260, 76, 1667, 2752, 289, 1274, 912, 1571, 2316, 84, 13, 51584], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 288, "seek": 81348, "start": 837.9200000000001, "end": 839.32, "text": " Jak jest drugi punkt?", "tokens": [51586, 15029, 3492, 4110, 72, 39561, 30, 51656], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 289, "seek": 81348, "start": 839.36, "end": 841.08, "text": " Drugi to twardy dow\u00f3d na to,", "tokens": [51658, 2491, 24780, 281, 683, 515, 88, 9459, 17081, 1667, 281, 11, 51744], "temperature": 0.0, "avg_logprob": -0.12461499402122776, "compression_ratio": 1.4035714285714285, "no_speech_prob": 0.003672602353617549}, {"id": 290, "seek": 84108, "start": 841.08, "end": 843.48, "text": " \u017ce prawdziwa wieloj\u0119zyczno\u015b\u0107 jest mo\u017cliwa,", "tokens": [50364, 3561, 41175, 3992, 4151, 20570, 78, 11115, 1229, 3689, 23293, 3492, 30854, 4151, 11, 50484], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 291, "seek": 84108, "start": 843.5200000000001, "end": 846.2800000000001, "text": " ale ma swoje granice.", "tokens": [50486, 6775, 463, 29489, 9370, 573, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 292, "seek": 84108, "start": 846.32, "end": 847.32, "text": " To znaczy?", "tokens": [50626, 1407, 36584, 30, 50676], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 293, "seek": 84108, "start": 847.36, "end": 851.12, "text": " Bloom udowodnia, \u017ce mo\u017cna stworzy\u0107 pot\u0119\u017cny model wieloj\u0119zyczny,", "tokens": [50678, 25927, 11727, 305, 378, 12679, 11, 3561, 17790, 342, 28321, 27150, 1847, 1274, 1427, 1634, 2316, 20570, 78, 11115, 1229, 3689, 1634, 11, 50866], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 294, "seek": 84108, "start": 851.1600000000001, "end": 853.32, "text": " kt\u00f3ry nie traci na wydajno\u015bci w j\u0119zykach", "tokens": [50868, 9913, 2838, 504, 22086, 1667, 25984, 1805, 16438, 261, 49055, 41326, 50976], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 295, "seek": 84108, "start": 853.36, "end": 855.72, "text": " z du\u017c\u0105 ilo\u015bci\u0105 danych jak angielski.", "tokens": [50978, 710, 21783, 1611, 1930, 44468, 1611, 274, 34644, 4207, 2562, 1187, 18020, 13, 51096], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 296, "seek": 84108, "start": 855.76, "end": 857.84, "text": " Jednocze\u015bnie jego problemy z j\u0119zykami", "tokens": [51098, 27076, 26694, 1381, 12221, 26542, 1154, 88, 710, 49055, 48737, 51202], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 297, "seek": 84108, "start": 857.88, "end": 860.6, "text": " o niskich zasobach to zimny prysznic.", "tokens": [51204, 277, 297, 7797, 480, 26530, 996, 608, 281, 710, 332, 1634, 582, 20589, 7692, 13, 51340], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 298, "seek": 84108, "start": 860.64, "end": 864.36, "text": " Pokazuj\u0105, jak krytycznie wa\u017cna jest reprezentacja danych.", "tokens": [51342, 14958, 921, 13263, 11, 4207, 34847, 45586, 27777, 629, 3492, 1085, 265, 14185, 23395, 274, 34644, 13, 51528], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 299, "seek": 84108, "start": 864.4000000000001, "end": 865.32, "text": " W\u0142a\u015bnie.", "tokens": [51530, 343, 5024, 12221, 13, 51576], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 300, "seek": 84108, "start": 865.36, "end": 867.9200000000001, "text": " Je wystarczy wrzuci\u0107 kilkuset zda\u0144 w danym j\u0119zyku", "tokens": [51578, 2588, 4628, 9710, 6522, 928, 11728, 39162, 5128, 35080, 302, 710, 2675, 5248, 261, 274, 1325, 76, 49055, 5279, 51706], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 301, "seek": 84108, "start": 867.96, "end": 869.36, "text": " i oczekiwa\u0107 cud\u00f3w.", "tokens": [51708, 741, 277, 3689, 14753, 25234, 40287, 3901, 13, 51778], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 302, "seek": 84108, "start": 869.4000000000001, "end": 870.8000000000001, "text": " A trzeci wniosek?", "tokens": [51780, 316, 22266, 537, 261, 3722, 541, 74, 30, 51850], "temperature": 0.0, "avg_logprob": -0.13333546515949612, "compression_ratio": 1.501577287066246, "no_speech_prob": 0.1923477202653885}, {"id": 303, "seek": 87080, "start": 870.8399999999999, "end": 872.0799999999999, "text": " Otwarto\u015b\u0107.", "tokens": [50366, 12936, 86, 15864, 7753, 13, 50428], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 304, "seek": 87080, "start": 872.12, "end": 874.4399999999999, "text": " Otwarto\u015b\u0107 ma fundamentalne znaczenie.", "tokens": [50430, 12936, 86, 15864, 7753, 463, 8088, 716, 15397, 326, 16778, 13, 50546], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 305, "seek": 87080, "start": 874.4799999999999, "end": 877.9599999999999, "text": " Udost\u0119pnienie modelu, kodu i ca\u0142ej dokumentacji na licencj\u0119,", "tokens": [50548, 624, 67, 555, 18085, 77, 27385, 2316, 84, 11, 350, 34873, 741, 47631, 73, 40858, 13152, 1667, 6169, 22660, 11115, 11, 50722], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 306, "seek": 87080, "start": 878.0, "end": 882.16, "text": " kt\u00f3r\u0105 nazwali Responsible AI License w skr\u00f3cie RAIL,", "tokens": [50724, 37415, 20151, 40054, 46003, 964, 7318, 40627, 1288, 261, 1110, 11721, 4260, 14626, 4620, 11, 50932], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 307, "seek": 87080, "start": 882.1999999999999, "end": 884.0799999999999, "text": " to ogromny krok naprz\u00f3d.", "tokens": [50934, 281, 34416, 298, 1634, 350, 31621, 9296, 19390, 17081, 13, 51028], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 308, "seek": 87080, "start": 884.12, "end": 887.56, "text": " Ta licencja zawiera klauzule ograniczaj\u0105ce u\u017cycie modelu", "tokens": [51030, 6551, 6169, 22660, 2938, 28165, 10609, 33337, 3334, 2271, 34416, 282, 17946, 11133, 384, 34097, 4260, 2316, 84, 51202], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 309, "seek": 87080, "start": 887.5999999999999, "end": 889.52, "text": " do szkodliwych cel\u00f3w, prawda?", "tokens": [51204, 360, 7870, 74, 378, 2081, 9726, 339, 9277, 3901, 11, 43607, 30, 51300], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 310, "seek": 87080, "start": 889.56, "end": 890.4799999999999, "text": " Tak.", "tokens": [51302, 9118, 13, 51348], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 311, "seek": 87080, "start": 890.52, "end": 894.7199999999999, "text": " To pozwala ca\u0142ej spo\u0142eczno\u015bci naukowej korzysta\u0107 z tej technologii,", "tokens": [51350, 1407, 40557, 5159, 47631, 73, 36851, 89, 16438, 35616, 74, 21091, 14784, 49590, 2162, 710, 12573, 1537, 1132, 5597, 11, 51560], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 312, "seek": 87080, "start": 894.76, "end": 897.4399999999999, "text": " ale robi\u0107 to w spos\u00f3b bardziej odpowiedzialny.", "tokens": [51562, 6775, 46900, 281, 261, 22904, 27209, 24314, 15338, 831, 1634, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 313, "seek": 87080, "start": 897.4799999999999, "end": 899.5999999999999, "text": " A to by\u0142o przecie\u017c celem ca\u0142ego projektu.", "tokens": [51698, 316, 281, 14811, 8325, 40082, 1769, 10386, 35224, 6308, 26261, 84, 13, 51804], "temperature": 0.0, "avg_logprob": -0.12324801142911733, "compression_ratio": 1.4433962264150944, "no_speech_prob": 0.0011400578077882528}, {"id": 314, "seek": 89960, "start": 899.64, "end": 901.84, "text": " Jest jeszcze jedna rzecz w tej pracy,", "tokens": [50366, 24918, 14168, 5232, 629, 36833, 261, 12573, 35591, 11, 50476], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 315, "seek": 89960, "start": 901.88, "end": 904.44, "text": " kt\u00f3ra mnie absolutnie zafascynowa\u0142a", "tokens": [50478, 19456, 17661, 18757, 2766, 710, 2792, 296, 1344, 3785, 64, 5024, 50606], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 316, "seek": 89960, "start": 904.48, "end": 906.72, "text": " i dotyczy kosztu \u015brodowiskowego.", "tokens": [50608, 741, 5893, 88, 6522, 19532, 2682, 84, 28580, 305, 7797, 26576, 13, 50720], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 317, "seek": 89960, "start": 906.76, "end": 907.9200000000001, "text": " A tak.", "tokens": [50722, 316, 991, 13, 50780], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 318, "seek": 89960, "start": 907.96, "end": 909.84, "text": " Transparentno\u015b\u0107 w tym zakresie.", "tokens": [50782, 6531, 38321, 23293, 261, 8107, 23810, 495, 414, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 319, "seek": 89960, "start": 909.88, "end": 911.2, "text": " Niezwyk\u0142a.", "tokens": [50878, 12016, 89, 9726, 74, 5024, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 320, "seek": 89960, "start": 911.24, "end": 914.6, "text": " Ci\u0105gle s\u0142yszymy, jak energoch\u0142onne s\u0105 te modele.", "tokens": [50946, 383, 11404, 22631, 15116, 749, 1229, 2226, 11, 4207, 2043, 1571, 339, 1221, 22419, 9015, 535, 4391, 306, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 321, "seek": 89960, "start": 914.64, "end": 917.64, "text": " Zesp\u00f3\u0142 Bloom obliczy\u0142, \u017ce ich trening wygenerowa\u0142", "tokens": [51116, 1176, 13361, 16181, 25927, 1111, 1050, 1229, 1221, 11, 3561, 1893, 2192, 773, 4628, 21848, 30105, 51266], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 322, "seek": 89960, "start": 917.6800000000001, "end": 920.88, "text": " oko\u0142o 25 ton ekwiwalentu CO2.", "tokens": [51268, 45730, 5249, 3552, 2952, 13359, 6253, 29530, 317, 84, 3002, 17, 13, 51428], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 323, "seek": 89960, "start": 920.9200000000001, "end": 923.4, "text": " Co samo w sobie wci\u0105\u017c jest spor\u0105 warto\u015bci\u0105?", "tokens": [51430, 3066, 36422, 261, 13652, 261, 537, 27242, 3492, 43729, 1611, 31830, 50227, 30, 51554], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 324, "seek": 89960, "start": 923.44, "end": 924.52, "text": " Oczywi\u015bcie.", "tokens": [51556, 42980, 13, 51610], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 325, "seek": 89960, "start": 924.5600000000001, "end": 927.6, "text": " Ale potem patrzymy na szatunki dla GPT-3,", "tokens": [51612, 9366, 36513, 1947, 13047, 2226, 1667, 7870, 267, 409, 2984, 12285, 26039, 51, 12, 18, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1374047143118722, "compression_ratio": 1.3366336633663367, "no_speech_prob": 0.0045583113096654415}, {"id": 326, "seek": 92760, "start": 927.6, "end": 930.36, "text": " kt\u00f3re m\u00f3wi\u0105 o ponad 500 tonach.", "tokens": [50364, 8864, 46591, 277, 9224, 345, 5923, 2952, 608, 13, 50502], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 327, "seek": 92760, "start": 930.4, "end": 932.32, "text": " Tu jest 20-krotna r\u00f3\u017cnica.", "tokens": [50504, 7836, 3492, 945, 12, 74, 10536, 629, 19637, 32687, 13, 50600], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 328, "seek": 92760, "start": 932.36, "end": 935.28, "text": " Jak to w og\u00f3le mo\u017cliwe przy podobnej skali modelu?", "tokens": [50602, 15029, 281, 261, 29229, 30854, 826, 6501, 43024, 11794, 1110, 5103, 2316, 84, 30, 50748], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 329, "seek": 92760, "start": 935.32, "end": 939.2, "text": " Odpowied\u017a le\u017cy w tym, gdzie pod\u0142\u0105czysz wtyczk\u0119 Superkomputera.", "tokens": [50750, 12210, 14701, 1091, 10659, 476, 7735, 261, 8107, 11, 18922, 2497, 15926, 3689, 20589, 261, 874, 3689, 15724, 4548, 20557, 2582, 1663, 13, 50944], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 330, "seek": 92760, "start": 939.24, "end": 942.84, "text": " Bloom by\u0142 trenowany na Superkomputerze Jean-Zal\u00e9, we Francji.", "tokens": [50946, 25927, 16673, 23136, 23341, 1667, 4548, 20557, 13849, 1381, 13854, 12, 57, 304, 526, 11, 321, 8686, 4013, 13, 51126], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 331, "seek": 92760, "start": 942.88, "end": 947.0, "text": " Kt\u00f3ry jest zasilany g\u0142\u00f3wnie niskoemisyjn\u0105 energi\u0105 j\u0105drow\u0105.", "tokens": [51128, 591, 4547, 627, 3492, 710, 13353, 1325, 18117, 812, 14215, 297, 43442, 443, 14169, 73, 13113, 10575, 11404, 361, 18962, 1892, 1611, 13, 51334], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 332, "seek": 92760, "start": 947.0400000000001, "end": 948.24, "text": " Dok\u0142adnie.", "tokens": [51336, 29768, 10358, 2766, 13, 51396], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 333, "seek": 92760, "start": 948.28, "end": 951.12, "text": " To pokazuje, \u017ce nie tylko optymalizacja algorytm\u00f3w,", "tokens": [51398, 1407, 13010, 43317, 11, 3561, 2838, 13219, 2427, 4199, 304, 590, 23395, 3501, 827, 83, 76, 3901, 11, 51540], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 334, "seek": 92760, "start": 951.16, "end": 953.8000000000001, "text": " ale te\u017c strategiczny wyb\u00f3r centrum danych", "tokens": [51542, 6775, 9516, 10924, 89, 1634, 45780, 15614, 1489, 6247, 274, 34644, 51674], "temperature": 0.0, "avg_logprob": -0.15366062896930618, "compression_ratio": 1.3460317460317461, "no_speech_prob": 0.05423881858587265}, {"id": 335, "seek": 95380, "start": 953.8, "end": 957.7199999999999, "text": " ma kolosalne znaczenie dla ekologicznego kosztu AI.", "tokens": [50364, 463, 17818, 329, 304, 716, 15397, 326, 16778, 12285, 13359, 1132, 17946, 11858, 19532, 2682, 84, 7318, 13, 50560], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 336, "seek": 95380, "start": 957.76, "end": 960.1999999999999, "text": " Ta praca stawia mn\u00f3stwo otwartych pyta\u0144.", "tokens": [50562, 6551, 582, 6628, 342, 34953, 275, 77, 45052, 6120, 4337, 29587, 16384, 10664, 1328, 5248, 13, 50684], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 337, "seek": 95380, "start": 960.24, "end": 965.0799999999999, "text": " Ale jest jedno, kt\u00f3re wydaje si\u0119 szczeg\u00f3lnie niepokoj\u0105ce i intryguj\u0105ce.", "tokens": [50686, 9366, 3492, 5232, 1771, 11, 8864, 49165, 3244, 49624, 2766, 2838, 79, 13704, 8555, 384, 741, 560, 627, 2794, 8555, 384, 13, 50928], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 338, "seek": 95380, "start": 965.12, "end": 968.8399999999999, "text": " Pochodzi z sekcji o badaniu w\u0142a\u015bciwo\u015bci lingwistycznych modelu.", "tokens": [50930, 6165, 34616, 710, 17215, 19649, 277, 1578, 25849, 40112, 36476, 22949, 86, 468, 17466, 9399, 2316, 84, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 339, "seek": 95380, "start": 968.88, "end": 970.92, "text": " Tak, ten multilingual probing.", "tokens": [51118, 9118, 11, 2064, 2120, 38219, 1239, 278, 13, 51220], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 340, "seek": 95380, "start": 970.9599999999999, "end": 974.12, "text": " To jedno z tych odkry\u0107, kt\u00f3re naprawd\u0119 zmuszaj\u0105 do my\u015blenia", "tokens": [51222, 1407, 5232, 1771, 710, 15180, 3611, 43298, 2162, 11, 8864, 20970, 17020, 22378, 11133, 360, 48633, 6698, 654, 51380], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 341, "seek": 95380, "start": 974.16, "end": 978.16, "text": " i kwestionowania wszystkiego, co wydaje nam si\u0119 oczywiste.", "tokens": [51382, 741, 42035, 313, 21308, 14615, 12200, 11, 598, 49165, 8835, 3244, 277, 6522, 86, 8375, 13, 51582], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 342, "seek": 95380, "start": 978.1999999999999, "end": 979.28, "text": " No w\u0142a\u015bnie.", "tokens": [51584, 883, 14234, 13, 51638], "temperature": 0.0, "avg_logprob": -0.1299142907135678, "compression_ratio": 1.4519572953736655, "no_speech_prob": 0.052229031920433044}, {"id": 343, "seek": 97928, "start": 979.36, "end": 984.4, "text": " Okaza\u0142o si\u0119, \u017ce mniejszy 1,7 miliardowy wariant Bloom", "tokens": [50368, 3477, 12257, 5249, 3244, 11, 3561, 275, 10402, 7706, 502, 11, 22, 1962, 72, 515, 10089, 1516, 5798, 25927, 50620], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 344, "seek": 97928, "start": 984.4399999999999, "end": 987.8399999999999, "text": " radzi\u0142 sobie z niekt\u00f3rymi zadaniami morfosyntaktycznymi,", "tokens": [50622, 2843, 3992, 1221, 13652, 710, 2838, 43073, 627, 3057, 710, 11338, 15568, 1896, 69, 329, 88, 580, 514, 874, 3689, 31813, 11, 50792], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 345, "seek": 97928, "start": 987.88, "end": 990.52, "text": " czyli dotycz\u0105cymi wewn\u0119trznej budowy s\u0142\u00f3w i zda\u0144.", "tokens": [50794, 16591, 5893, 17466, 1611, 1344, 3057, 321, 895, 1274, 6903, 89, 11794, 3265, 10089, 15116, 3901, 741, 710, 2675, 5248, 13, 50926], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 346, "seek": 97928, "start": 990.56, "end": 995.36, "text": " Lepiej ni\u017c jego gigantyczny 17,6 miliardowy odpowiednik.", "tokens": [50928, 441, 595, 7764, 28502, 26542, 8741, 394, 17466, 1634, 3282, 11, 21, 1962, 72, 515, 10089, 36574, 13123, 13, 51168], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 347, "seek": 97928, "start": 995.4, "end": 997.52, "text": " Co jest kompletnie wbrew intuicji?", "tokens": [51170, 3066, 3492, 5207, 14657, 2766, 261, 65, 2236, 560, 84, 299, 4013, 30, 51276], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 348, "seek": 97928, "start": 997.56, "end": 999.52, "text": " Totalnie. Przecie\u017c zawsze my\u015blimy.", "tokens": [51278, 23170, 2766, 13, 2114, 1381, 40082, 30964, 48633, 4197, 88, 13, 51376], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 349, "seek": 97928, "start": 999.56, "end": 1001.16, "text": " Wi\u0119kszy znaczy lepszy.", "tokens": [51378, 30127, 1694, 1229, 36584, 476, 1878, 1229, 13, 51458], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 350, "seek": 97928, "start": 1001.1999999999999, "end": 1004.36, "text": " No w\u0142a\u015bnie. Nie zawsze i nie we wszystkim.", "tokens": [51460, 883, 14234, 13, 12016, 30964, 741, 2838, 321, 30481, 13, 51618], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 351, "seek": 97928, "start": 1004.4, "end": 1009.24, "text": " Autorzy sugeruj\u0105, \u017ce ten ogromny model ma lepszy zdolno\u015bci og\u00f3lnej generalizacji.", "tokens": [51620, 6049, 284, 1229, 459, 1321, 13263, 11, 3561, 2064, 34416, 298, 1634, 2316, 463, 476, 1878, 1229, 16221, 401, 16438, 5360, 15741, 11794, 2674, 590, 13152, 13, 51862], "temperature": 0.0, "avg_logprob": -0.15406122151211168, "compression_ratio": 1.3957055214723926, "no_speech_prob": 0.33972954750061035}, {"id": 352, "seek": 100928, "start": 1009.28, "end": 1012.6, "text": " Czyli radzi sobie lepiej z szerszym zakresem zada\u0144.", "tokens": [50364, 37099, 2843, 3992, 13652, 476, 39699, 710, 7870, 433, 26681, 23810, 265, 19872, 710, 1538, 5248, 13, 50530], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 353, "seek": 100928, "start": 1012.64, "end": 1016.0, "text": " Ale to odkrycie rodzi fundamentalne pytanie.", "tokens": [50532, 9366, 281, 3611, 43298, 4260, 8685, 3992, 8088, 716, 36610, 13, 50700], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 354, "seek": 100928, "start": 1016.04, "end": 1018.4399999999999, "text": " Czy bezrefleksyjne powi\u0119kszanie modeli,", "tokens": [50702, 19832, 10782, 33115, 306, 1694, 88, 73, 716, 3388, 5034, 1694, 89, 7155, 2316, 72, 11, 50822], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 355, "seek": 100928, "start": 1018.48, "end": 1022.8399999999999, "text": " ta pogo\u0144za skal\u0105 zawsze czyni je m\u0105drzejszymi pod ka\u017cdym wzgl\u0119dem?", "tokens": [50824, 1846, 32037, 78, 5248, 2394, 16890, 1611, 30964, 6430, 3722, 1506, 275, 18962, 13503, 73, 7706, 3057, 2497, 31615, 76, 48538, 6298, 443, 30, 51042], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 356, "seek": 100928, "start": 1022.88, "end": 1026.04, "text": " To jest autentycznie niepokoj\u0105ca my\u015bl,", "tokens": [51044, 1407, 3492, 1476, 4179, 19923, 2838, 79, 13704, 8555, 496, 452, 19212, 11, 51202], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 357, "seek": 100928, "start": 1026.08, "end": 1030.92, "text": " \u017ce \u015bcie\u017cka, kt\u00f3r\u0105 wszyscy pod\u0105\u017caj\u0105, ta mantra bigger is better,", "tokens": [51204, 3561, 8299, 40082, 2330, 11, 37415, 44232, 2497, 27242, 11133, 11, 1846, 32094, 3801, 307, 1101, 11, 51446], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 358, "seek": 100928, "start": 1030.96, "end": 1034.92, "text": " mo\u017ce nas wcale nie prowadzi w stron\u0119 prawdziwego zrozumienia j\u0119zyka.", "tokens": [51448, 12034, 5382, 261, 37088, 2838, 36590, 3992, 261, 45766, 1274, 41175, 3992, 826, 1571, 710, 27857, 449, 18811, 42309, 40940, 13, 51646], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 359, "seek": 100928, "start": 1034.96, "end": 1037.76, "text": " A mo\u017ce nawet od niej oddala\u0107 w pewnych aspektach.", "tokens": [51648, 316, 12034, 22696, 3611, 2838, 73, 7401, 5159, 2162, 261, 47160, 16384, 382, 23533, 608, 13, 51788], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 360, "seek": 100928, "start": 1037.8, "end": 1038.76, "text": " Dok\u0142adnie.", "tokens": [51790, 29768, 10358, 2766, 13, 51838], "temperature": 0.0, "avg_logprob": -0.1328997222132653, "compression_ratio": 1.4254658385093169, "no_speech_prob": 0.0016908753896132112}, {"id": 361, "seek": 103876, "start": 1038.76, "end": 1042.56, "text": " A mo\u017ce w tej pogoni za coraz wi\u0119ksz\u0105 liczb\u0119 parametr\u00f3w", "tokens": [50364, 316, 12034, 261, 12573, 32037, 17049, 7949, 25899, 29968, 8925, 6169, 89, 65, 1274, 6220, 27965, 3901, 50554], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 362, "seek": 103876, "start": 1042.6, "end": 1047.24, "text": " gubimy po drodze pewne subtelne, bardziej fundamentalne zdolno\u015bci j\u0119zykowe.", "tokens": [50556, 695, 65, 13189, 714, 3789, 67, 1381, 25889, 716, 7257, 338, 716, 11, 27209, 8088, 716, 16221, 401, 16438, 49055, 74, 6880, 13, 50788], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 363, "seek": 103876, "start": 1047.28, "end": 1049.52, "text": " I co to oznacza dla przysz\u0142o\u015bci AI,", "tokens": [50790, 286, 598, 281, 277, 22672, 326, 2394, 12285, 44018, 35059, 7318, 11, 50902], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 364, "seek": 103876, "start": 1049.56, "end": 1052.08, "text": " kt\u00f3ra ma nie tylko generowa\u0107 zgrabny tekst,", "tokens": [50904, 19456, 463, 2838, 13219, 1337, 11445, 710, 20735, 65, 1634, 16624, 372, 11, 51030], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 365, "seek": 103876, "start": 1052.12, "end": 1054.68, "text": " ale naprawd\u0119 rozumie\u0107, czym jest j\u0119zyk?", "tokens": [51032, 6775, 20970, 48797, 414, 2162, 11, 31466, 3492, 49055, 74, 30, 51160], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 366, "seek": 103876, "start": 1054.72, "end": 1057.36, "text": " To pytanie, z kt\u00f3rym ta praca nas zostawia.", "tokens": [51162, 1407, 36610, 11, 710, 30120, 1846, 582, 6628, 5382, 31873, 34953, 13, 51294], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}, {"id": 367, "seek": 103876, "start": 1057.4, "end": 1060.28, "text": " I na razie nikt nie ma na nie dobrej odpowiedzi.", "tokens": [51296, 286, 1667, 9639, 414, 297, 9874, 2838, 463, 1667, 2838, 41959, 73, 36574, 3992, 13, 51440], "temperature": 0.0, "avg_logprob": -0.12491567256086963, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.0007524119573645294}], "language": "pl"}