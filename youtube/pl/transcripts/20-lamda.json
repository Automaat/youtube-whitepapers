{"text": " Wszyscy chyba jeste\u015bmy pod wra\u017ceniem tego, co potrafi\u0105 wsp\u00f3\u0142czesne modele j\u0119zykowe. Pisz\u0105, wiersze, koduj\u0105, no tworz\u0105 ca\u0142e eseje. Wydaj\u0105 si\u0119 wr\u0119cz genialne, a jednak jak tylko poprosimy o co\u015b, no wiesz, konkretnego, o jaki\u015b fakt, to nagle potrafi\u0105 zmy\u015bli\u0107 co\u015b, co brzmi super wiarygodnie, ale jest kompletn\u0105 bzdur\u0105. Sk\u0105d ten rozdzi\u0119k? I to jest szczerze m\u00f3wi\u0105c pytanie za milion dolar\u00f3w dla ka\u017cdego, kto dzi\u015b pracuje nad tymi modelami. Jak sprawi\u0107, by chatbot by\u0142 nie tylko, powiedzmy, elokw\u0119tnym rozm\u00f3wc\u0105, ale te\u017c wiarygodnym \u017ar\u00f3d\u0142em informacji? W\u0142a\u015bnie tego problemu dotyka praca badawcza od Google, kt\u00f3r\u0105 dzi\u015b analizujemy. Nazywa si\u0119 Lambda, Language Models for Dialogue Applications. Lambda, tak ta nazwa przewija\u0142a si\u0119 w mediach, czyli naszym celem jest zrozumienie, co jest w niej tak prze\u0142omowego. Z tego, co widz\u0119 w materiale, skupimy si\u0119 na dw\u00f3ch kluczowych wyzwaniach. Safety, czyli bezpiecze\u0144stwie i Factual Grounding, czyli ugruntowaniu w faktach. Dok\u0142adnie. Wygl\u0105da na to, \u017ce autorzy proponuj\u0105 co\u015b wi\u0119cej, ni\u017c tylko zbudujmy wi\u0119kszy model. Chc\u0105 go uczyni\u0107 m\u0105drzejszym. W\u0142a\u015bnie. Chodzi o to, by nauczy\u0107 go, kiedy ma si\u0119 zatrzyma\u0107 i pomy\u015ble\u0107, a nawet no wiesz sprawdzi\u0107 fakty zanim co\u015b powie. To jest fundamentalna zmiana w podej\u015bciu. Ok, czyli samo powi\u0119kszanie m\u00f3zgu AI nie dzia\u0142a? To intuicyjnie ma sens, kto\u015b mo\u017ce zna\u0107 na pami\u0119\u0107 ca\u0142\u0105 bibliotek\u0119, a i tak nie by\u0107 m\u0105dry. Jaki by\u0142 wi\u0119c dotychczasowy problem z tym podej\u015bciem opartym na czystej skali? Wi\u0119c problem le\u017cy w samej naturze tych modeli. One s\u0105 trenowane, by przewidywa\u0107 nast\u0119pne s\u0142ow\u00f3w sekwencji. Aha. To sprawia, \u017ce s\u0105 absolutnymi mistrzami w tworzeniu tekstu, kt\u00f3ry jest statystycznie prawdopodobny. Ich celem jest p\u0142ynno\u015b\u0107, sp\u00f3jno\u015b\u0107, a nie prawdziwo\u015b\u0107. Czyli odpowied\u017a mo\u017ce by\u0107 gramatycznie idealna, logicznie pasowa\u0107? Tak, tak. A jednocze\u015bnie by\u0107 kompletnym wymis\u0142em? Dok\u0142adnie. Jak improwizator, kt\u00f3ry za wszelk\u0105 cen\u0119 chce kontynuowa\u0107 scen\u0119, nawet je\u015bli musi zmy\u015bla\u0107 na poczekaniu. \u015awietna analogia. A praca nad Lambda pokazuje to wprost na danych. Por\u00f3wnuj\u0105 modele o r\u00f3\u017cne wielko\u015bci od dw\u00f3ch miliard\u00f3w parametr\u00f3w a\u017c do 137 miliard\u00f3w. I owszem wi\u0119kszy model staje si\u0119 lepszy w og\u00f3lnej jako\u015bci konwersacji. M\u00f3wi p\u0142ynniej, jest bardziej elokw\u0119tny. Ale. Ale. Kiedy spojrzymy na te k\u0142uczowe dla nas metryki, czyli safety i groundedness, post\u0119p jest minimalny. Pami\u0119tam te wykresy z artyku\u0142u figure one i four. Te niebieskie s\u0142upki, kt\u00f3re pokazuj\u0105 model zaraz po tym podstawowym treningu, czyli pre-training. One ledwo drgn\u0119\u0142y w g\u00f3r\u0119 w tych dw\u00f3ch kategoriach, nawet przy gigantycznym skoku liczby parametr\u00f3w. No w\u0142a\u015bnie. Czyli dorzucaniem mocy obliczeniowej nie ucz\u0119 modelu etyki ani weryfikacji fakt\u00f3w. W\u0142a\u015bnie. Model staje si\u0119 powiedzmy lepszym gadu\u0142\u0105, ale niekoniecznie m\u0105drzejszym czy bardziej odpowiedzialnym partnerem do rozmowy. I to jest \u015bciana, o kt\u00f3r\u0105 rozbi\u0142o si\u0119 podej\u015bcie oparte wy\u0142\u0105cznie na skalowaniu. Rozumiem. Badacze z Google zdali sobie spraw\u0119, \u017ce trzeba czego\u015b wi\u0119cej. No dobrze, to je\u015bli nie wi\u0119cej danych i wi\u0119kszy model to co? Lepsze dane? Jaki zupe\u0142nie inny rodzaj treningu? Dok\u0142adnie. Inny rodzaj treningu. Zastosowali technik\u0119, kt\u00f3r\u0105 znamy jako fine tuning. Okej. Ale zrobili to w bardzo przemy\u015blany dwutorowy spos\u00f3b. Wsieli ten ogromny wst\u0119pnie wytrenowany model i zapisali go na swego rodzaju specjalistyczne korepetycje prowadzone przez ludzi. Korepetycje. Z czego? Z bycia dobrym chatbotem. Mo\u017cna tak powiedzie\u0107. Pierwszy tor korepetycji dotyczy\u0142 og\u00f3lnej jako\u015bci i bezpiecze\u0144stwa rozmowy. Zamiast pozwoli\u0107 modelowi po prostu generowa\u0107 tekst, zacz\u0119li go uczy\u0107 jak ocenia\u0107 w\u0142asn\u0105 odpowiedzi. Aha. Zdefiniowali jako\u015b\u0107 za pomoc\u0105 trzech metryk, kt\u00f3re nazwali w skr\u00f3cie SSI. SSI. Widz\u0119 tutaj sensibilness, specificity i interestingness. Dobra. Sensibilness, czyli sensowno\u015b\u0107. To jest jasne. Odpowied\u017a musi pasowa\u0107 do rozmowy. Tak. Specificity, czyli konkretno\u015b\u0107. Te\u017c koniec z odpowiedziami w sty\u0142u. To ciekawe na wszystko. Dok\u0142adnie. Ale interestingness. Jak w og\u00f3le mo\u017cna nauczy\u0107 maszyn\u0119 bycia interesuj\u0105c\u0105? To jest \u015bwietne pytanie. Zrobili to w bardzo prosty, ale skuteczny spos\u00f3b. Zatrudni\u0107 tysi\u0105ce ludzi, tak zwanych crowd workers, kt\u00f3rzy prowadzili rozmowy z modelem i oceniali jego odpowiedzi w tych trzech kategoriach. Czyli czy odpowied\u017a by\u0142a wnikliwa, a mo\u017ce do wcipna? Tak. Czy wnios\u0142a co\u015b nowego? Te oceny stworzy\u0142y ogromny zbi\u00f3r danych, na kt\u00f3rym model uczy\u0142 si\u0119, co ludzie uwa\u017caj\u0105 zainteresuj\u0105ce. Czyli na podstawie tych ludzkich ocen model nauczy\u0142 si\u0119 sam siebie recenzowa\u0107. Dok\u0142adnie. Wytrenowali go by dzia\u0142a\u0142 jako sw\u00f3j w\u0142asny dyskryminator. A to w praktyce co oznacza? W praktyce oznacza to, \u017ce zanim lambda udzieli ostatecznej odpowiedzi, wewn\u0119trznie generuje kilka potencjalnych wariant\u00f3w. Nast\u0119pnie ten wewn\u0119trzny krytyk ocenia je pod k\u0105tem SSI i odrzuca te, kt\u00f3re s\u0105 bezsensowne, zbyt og\u00f3lne albo po prostu nudne. I wybiera najlepsz\u0105? I wybiera najlepsz\u0105. To ju\u017c jest du\u017cy krok na prz\u00f3d. Ale co z bezpiecze\u0144stwem? Ten sam mechanizm? Ten sam mechanizm zdefiniowali jasne cele bezpiecze\u0144stwa. Unikanie generowania szkodliwych tre\u015bci, mowy nienawi\u015bci, uprzedze\u0144, niebezpiecznych porad. I znowu, na podstawie ludzkich adnotacji model nauczy\u0142 si\u0119 rozpoznawa\u0107 i odfiltrowywa\u0107 takie odpowiedzi. I to wida\u0107 na wykresach. Jak najbardziej. Kiedy wr\u00f3cimy do tych wykres\u00f3w zobaczymy, \u017ce r\u00f3\u017cowe s\u0142upki reprezentuj\u0105ce model po finalne tuning wystrzeluj\u0105 w g\u00f3r\u0119 w por\u00f3wnaniu do niebieskich. Post\u0119p jest gigantyczny. Ok, to by\u0142 pierwszy tor ataku. Jako\u015b\u0107 i bezpiecze\u0144stwo przez samokrytyk\u0119. Ale to wci\u0105\u017c nie rozwi\u0105zuje problemu ze zmy\u015blania fakt\u00f3w. Jaki by\u0142 drugi tor? I tu dochodzimy do, moim zdaniem, najbardziej rewolucyjnej cz\u0119\u015bci tej pracy. A mianowicie? Zamiast pr\u00f3bowa\u0107 wypchn\u0105\u0107 ca\u0142\u0105 wiedz\u0119 \u015bwiata do g\u0142owy modelu, postanowili da\u0107 mu narz\u0119dzia. Narz\u0119dzia? Jakie narz\u0119dzia? Stworzyli co\u015b, co nazywaj\u0105 toolset, w skr\u00f3cie TS. To jest zestaw zewn\u0119trznych aplikacji, z kt\u00f3rych model mo\u017ce korzysta\u0107 w czasie rzeczywistym. W jego sk\u0142ad wchodzi system wyszukiwania informacji, dzia\u0142aj\u0105cy jak wewn\u0119trzna wyszukiwarka, a tak\u017ce kalkulator i translator. Chwila, chwila. Czyli model mo\u017ce sam co\u015b wygooglowa\u0107, je\u015bli nie jest czego\u015b pewien? W\u0142a\u015bnie tak. To brzmi jak proste rozwi\u0105zanie, ale musi by\u0107 w tym jaki\u015b haczyk. Sk\u0105d model wie, kiedy ma szuka\u0107 i co wa\u017cniejsze, jak odr\u00f3\u017cnia wiarygodne \u017ar\u00f3d\u0142o od niewiarygodnego? Przecie\u017c internet jest pe\u0142en \u015bmieci. Doskona\u0142e pytania, kt\u00f3re pokazuj\u0105 z\u0142o\u017cono\u015b\u0107 problemu. Odpowiedzi\u0105 znowu jest fine tuning. Nauczyli model rozpoznawa\u0107 sytuacj\u0119, w kt\u00f3rych jego wewn\u0119trzna wiedza mo\u017ce by\u0107 niewystarczaj\u0105ca. A \u017ar\u00f3d\u0142a? A co do \u017ar\u00f3dy? Na tym etapie bada\u0144 korzystali z zamkni\u0119tej wewn\u0119trznej bazy wiedzy, co upraszcza\u0142o problem weryfikacji. Kluczowo jest jednak to, \u017ce model nauczy\u0142 si\u0119 iteracyjnego procesu dochodzenia do prawdy. Ok. Zobaczmy to na przyk\u0142adzie z artyku\u0142u tym o artystce Rosali Gascon. Tak, ten przyk\u0142ad by\u0142 fascynuj\u0105cy. U\u017cytkownik pyta o jej rze\u017aby, a model Lambda Base robi to, co potrafi najlepiej. Improwizuje, generuje bardzo wiarygodnie brzmi\u0105ce zdanie. Czy wiesz, \u017ce by\u0142a jedn\u0105 z artystek, kt\u00f3re inspirowa\u0142y Miro? Brzmi dobrze, prawda? Dw\u00f3ch artyst\u00f3w, podobny okres, brzmi prawdopodobnie. Pewnie, ale tu w\u0142\u0105cza si\u0119 nowa umiej\u0119tno\u015b\u0107. Dostrojony model rozpoznaje, \u017ce to jest stwierdzenie faktu, kt\u00f3rego nie jest w 100% pewien. I wtedy odpala ten sw\u00f3j toolset. Dok\u0142adnie. Wewn\u0119trznie generuje zapytanie do wyszukiwarki. Co\u015b w stylu Miro and Ein Gascoin. System przeszukuje baz\u0119 wiedzy i nie znajduje \u017cadnego potwierdzenia dla tej tezy. Aha. I teraz dzieje si\u0119 magia, model widz\u0105c brak dowod\u00f3w odrzuca swoj\u0105 w\u0142asn\u0105, pierwotn\u0105 odpowied\u017a. Czyli sam siebie poprawia, zanim cokolwiek powie na g\u0142os. Co wi\u0119c zrobi\u0107 zamian? W zamian przeszukuje dalej informacje o Gascoin i znajduje inny, potwierdzony fakt. Finalna odpowied\u017a, kt\u00f3r\u0105 widzi u\u017cytkownik, brzmi. Czy wiesz, \u017ce zajmowa\u0142a si\u0119 japo\u0144sk\u0105 sztuk\u0105 uk\u0142adania kwiat\u00f3w i keban\u0105, zanim zaj\u0119\u0142a si\u0119 rze\u017ab\u0105? Niesamowite. I co wi\u0119cej, dodaj\u0119 odno\u015bnik do \u017ar\u00f3d\u0142a tej informacji. To jest fundamentalna zmiana. Od pewnego siebie k\u0142amcy do ostro\u017cnego researchera. To jest niesamowite, bo to nie jest prosta weryfikacja. Tak, nie. To jest aktywny proces edycji w\u0142asnej my\u015bli w oparciu o zewn\u0119trzne dane. Tak. A przyk\u0142ad zwierz\u0105 Eifla, pokazany na figur\u0119 3, idzie nawet okrok dalej. Tak, bo pokazuje, \u017ce ten proces mo\u017ce by\u0107 wieloetapowy. U\u017cytkownik pyta, kiedy zbudowano wierz\u0119. Model najpierw generuje niepe\u0142n\u0105 odpowied\u017a w 1887. Ale modu\u0142 researchu wysy\u0142a za pytanie. Eiffel Tower Construction Date. I dostaje odpowied\u017a. Budowa rozpocz\u0119\u0142a si\u0119 28 stycznia 1887. Czyli on nie tylko zada\u0142 jedno pytanie i przyj\u0105\u0142 odpowied\u017a. Ale sam zorientowa\u0142 si\u0119, \u017ce pierwsza informacja by\u0142a niekompletna. To ju\u017c jest my\u015blenie okrok do przodu. W\u0142a\u015bnie. Model wie, \u017ce data rozpocz\u0119cia to nie to samo, co data uko\u0144czenia. Dlatego generuje drugie, bardziej precyzyjne zapytanie. Eiffel Tower Completed When. I dostaje drug\u0105 dat\u0119. Otrzymuje drug\u0105 informacj\u0119. Otwarcie 31 marca 1889. Dopiero maj\u0105c te dwa zweryfikowane fakty, komponuje ostateczn\u0105, pe\u0142n\u0105 i poprawn\u0105 odpowied\u017a dla u\u017cytkownika. Prace nad ni\u0105 rozpocz\u0119\u0142y si\u0119 w styczniu 1887, a zosta\u0142a otwarta w marcu 1889. Dok\u0142adnie tak. To wszystko brzmi rewelacyjnie, w teorii i na tych wybranych przyk\u0142adach. Ale czy to faktycznie zadzia\u0142a\u0142o na du\u017c\u0105 skal\u0119? Jakie by\u0142y wymierne efekty? Kiedy spojrzymy na te wykresy, co nam m\u00f3wi\u0105 o skuteczno\u015bci tej metody? M\u00f3wi\u0105 nam, \u017ce ten dwutorowy Fine Tuning ca\u0142kowicie zmienia zasady gry. Po tym treningu Lambda drastycznie zmniejsza dystans do ludzkiej wydajno\u015bci w metrykach jako\u015bci. Czyli SSI. Okej. A w jednej kategorii dzieje si\u0119 co\u015b zupe\u0142nie zaskakuj\u0105cego. W tej metryce Interestingness? Z tego co pami\u0119tam model nie tylko dogoni\u0142 ludzi, ale ich przegoni\u0142. Jak to w og\u00f3le mo\u017cliwe? AI jest bardziej interesuj\u0105ca od cz\u0142owieka? Hmm. Autorzy sami byli tym zaskoczeni i podchodz\u0105 do tego z ostro\u017cno\u015bci\u0105. Ich hipoteza jest taka, \u017ce ludzie oceniaj\u0105cy ci crowd workers nie byli specjalnie motywowani, by by\u0107 w swoich odpowiedziach b\u0142yskotliwymi czy dowcipnymi. Odpowiedali po prostu poprawnie. Po prostu poprawnie. A model, wytrenowany na milionach przyk\u0142ad\u00f3w b\u0142yskotliwych tekst\u00f3w z internetu i nagradzany za bycie interesuj\u0105cym, po prostu nauczy\u0142 si\u0119 generowa\u0107 odpowiedzi, kt\u00f3ra przykuwaj\u0105 uwag\u0119. To i tak godny uwagi wynik. Zdecydowanie. No dobrze, ale co z tymi najwa\u017cniejszymi metrykami? Safety i Groundedness. Czy tu te\u017c uda\u0142o si\u0119 dogoni\u0107 cz\u0142owieka? I tu dochodzimy do kluczowego wniosku, w kt\u00f3rym autorzy prace s\u0105 bardzo szczerze. Nie, nie uda\u0142o si\u0119. A\u017c tak. Mimo ogromnego post\u0119pu, wci\u0105\u017c istnieje wyra\u017ana luka mi\u0119dzy modelem a ludzkim poziomem w tych dw\u00f3ch obszarach. Model jest o wiele bezpieczniejszy i bardziej prawdom\u00f3wny ni\u017c przedtem, ale wci\u0105\u017c jest daleki od doskona\u0142o\u015bci. Czyli to nie jest ostateczne rozwi\u0105zanie problemu? Absolutnie nie. I to jest si\u0142a tej pracy. Ona nie twierdzi, \u017ce problem jest rozwi\u0105zany. Ona pokazuje niezwykle pot\u0119\u017cn\u0105 metodologi\u0119. Drogowskaz. Dok\u0142adnie. Dowodzi, \u017ce celowy kierowany przez cz\u0142owieka Fine Tuning jest o wiele wiele skuteczniejszy w radzeniu sobie z tak subtelnymi wyzwaniami ni\u017c \u015blep\u0119 dorzucanie kolejnych miliard\u00f3w parametr\u00f3w. To jest mapa drogowa, a nie koniec podr\u00f3\u017cy. A co z bardziej kreatywnymi zastosowaniami? W artygule jest jeszcze jeden ciekawy przyk\u0142ad, gdzie model wciela si\u0119 w role. G\u00f3ry. Tak, Mount Everestu. Nazywaj\u0105 to Domain Grounding. Pokazuje to, jak elastyczny staje si\u0119 model po takim treningu. Wystarczy prosta instrukcja na pocz\u0105tku rozmowy. Co\u015b w stylu. Cze\u015b\u0107. Jestem Mount Everest. Mo\u017cesz zadawa\u0107 mi pytania. I co? Model zaczyna odpowiada\u0107 z perspektywy g\u00f3ry? Dok\u0142adnie. Przyjmuje t\u0119 rol\u0119 i co najwa\u017cniejsze, kiedy podaje fakty, np. o swojej wysoko\u015bci czy pierwszych zdobywcach, cz\u0119sto korzysta z tego samego mechanizmu Toolset, by upewni\u0107 si\u0119, \u017ce jego odpowiedzi s\u0105 zgodne z prawd\u0105. A model bez tego treningu? Dla por\u00f3wnania pokazuj\u0105 te\u017c odpowied\u017a modelu bez tego specjalistycznego Fine Tuning. Na pytanie o wysoko\u015b\u0107 potrafi odpowiedzie\u0107 w spos\u00f3b wr\u0119cz niegrzeczny, bo nie rozumie kontekstu odgrywania roli. Rozumiem. Fine Tuning nadaje mu nie tylko wiedz\u0119, ale i odpowiedni\u0105, powiedzmy, osobowo\u015b\u0107 do zadania. Zbieraj\u0105c to wszystko razem, wydaje si\u0119, \u017ce Lambda to nie jest po prostu kolejny wielki model j\u0119zykowy. Nie. To bardziej przepis na to, jak uczyni\u0107 te modele bardziej u\u017cytecznymi i odpowiedzialnymi. Kluczowy wniosek jest chyba taki, \u017ce nauczenie modelu jak i kiedy ma sprawdza\u0107 swoj\u0105 prac\u0119 jest r\u00f3wnie wa\u017cne, jak nauczenie go jak w og\u00f3le pisa\u0107. Idealne podsumowanie. W punkt. To jest zmiana paradygmatu. Przechodzimy od my\u015blenia w kategoriach wi\u0119cej, szybciej, mocniej, czyli czystego skalowania. W kierunku kreatyw. W kierunku wbudowywania w architektur\u0119 modelu mechanizm\u00f3w, refleksji, bezpiecze\u0144stwa i weryfikacji fakt\u00f3w. To przej\u015bcie od surowej si\u0142y do prawdziwej inteligencji. To wszystko prowadzi nas do pewnej ingryguj\u0105cej my\u015bli na koniec? Tak. Autorzy prace sami o tym wspominaj\u0105 o ryzyku antropomorfizacji, czyli pod\u015bwiadomego traktowania a i jak cz\u0142owieka. Mhm. I w miar\u0119 jak te modele staj\u0105 si\u0119 coraz lepsze w przyjmowaniu r\u00f3l takich jak Mount Everest i udzielaniu ugruntowanych w faktach ciekawych odpowiedzi pojawia si\u0119 nowe, g\u0142\u0119ksze pytanie. I to ju\u017c nie jest pytanie techniczne? Nie. Ju\u017c nie tylko czy potrafimy technicznie uczyni\u0107 a i prawdom\u00f3wn\u0105 i bezpieczn\u0105? Pytanie brzmi? Jakie s\u0105 etyczne implikacje sytuacji, w kt\u00f3rej prawdom\u00f3wna i bezpieczna a i staje si\u0119 tak dobra w konwersacji, \u017ce zaczynamy zapomina\u0107, \u017ce po drugiej stronie nie ma \u017cadnej osoby?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.32, "text": " Wszyscy chyba jeste\u015bmy pod wra\u017ceniem tego, co potrafi\u0105 wsp\u00f3\u0142czesne modele j\u0119zykowe.", "tokens": [50364, 343, 15453, 38966, 31532, 35928, 2497, 7843, 24930, 4907, 8627, 11, 598, 1847, 10437, 11404, 39069, 3689, 279, 716, 4391, 306, 49055, 74, 6880, 13, 50630], "temperature": 0.0, "avg_logprob": -0.17549876716193252, "compression_ratio": 1.367816091954023, "no_speech_prob": 0.050792619585990906}, {"id": 1, "seek": 0, "start": 5.32, "end": 9.52, "text": " Pisz\u0105, wiersze, koduj\u0105, no tworz\u0105 ca\u0142e eseje.", "tokens": [50630, 430, 23848, 1611, 11, 261, 4890, 1381, 11, 350, 378, 13263, 11, 572, 46288, 8925, 47631, 10167, 2884, 13, 50840], "temperature": 0.0, "avg_logprob": -0.17549876716193252, "compression_ratio": 1.367816091954023, "no_speech_prob": 0.050792619585990906}, {"id": 2, "seek": 0, "start": 9.52, "end": 15.92, "text": " Wydaj\u0105 si\u0119 wr\u0119cz genialne, a jednak jak tylko poprosimy o co\u015b, no wiesz, konkretnego,", "tokens": [50840, 343, 6655, 11133, 3244, 928, 1274, 3689, 48228, 716, 11, 257, 25897, 4207, 13219, 1665, 2635, 13189, 277, 19241, 11, 572, 261, 15347, 11, 36500, 11858, 11, 51160], "temperature": 0.0, "avg_logprob": -0.17549876716193252, "compression_ratio": 1.367816091954023, "no_speech_prob": 0.050792619585990906}, {"id": 3, "seek": 0, "start": 15.92, "end": 21.36, "text": " o jaki\u015b fakt, to nagle potrafi\u0105 zmy\u015bli\u0107 co\u015b, co brzmi super wiarygodnie,", "tokens": [51160, 277, 34721, 21310, 11, 281, 297, 15088, 1847, 10437, 11404, 710, 2226, 15350, 2162, 19241, 11, 598, 738, 89, 3057, 1687, 26393, 822, 21787, 2766, 11, 51432], "temperature": 0.0, "avg_logprob": -0.17549876716193252, "compression_ratio": 1.367816091954023, "no_speech_prob": 0.050792619585990906}, {"id": 4, "seek": 0, "start": 21.36, "end": 24.88, "text": " ale jest kompletn\u0105 bzdur\u0105. Sk\u0105d ten rozdzi\u0119k?", "tokens": [51432, 6775, 3492, 5207, 14657, 13113, 272, 31278, 374, 1611, 13, 7324, 18962, 2064, 9544, 67, 16706, 74, 30, 51608], "temperature": 0.0, "avg_logprob": -0.17549876716193252, "compression_ratio": 1.367816091954023, "no_speech_prob": 0.050792619585990906}, {"id": 5, "seek": 2488, "start": 25.0, "end": 28.56, "text": " I to jest szczerze m\u00f3wi\u0105c pytanie za milion dolar\u00f3w dla ka\u017cdego,", "tokens": [50370, 286, 281, 3492, 22090, 260, 1381, 46591, 66, 36610, 7949, 1962, 313, 360, 2200, 3901, 12285, 21912, 67, 6308, 11, 50548], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 6, "seek": 2488, "start": 28.56, "end": 33.6, "text": " kto dzi\u015b pracuje nad tymi modelami. Jak sprawi\u0107, by chatbot by\u0142 nie tylko,", "tokens": [50548, 23780, 31981, 1788, 22404, 13008, 12617, 1104, 3057, 2316, 4526, 13, 15029, 22734, 12757, 11, 538, 5081, 18870, 16673, 2838, 13219, 11, 50800], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 7, "seek": 2488, "start": 33.6, "end": 38.64, "text": " powiedzmy, elokw\u0119tnym rozm\u00f3wc\u0105, ale te\u017c wiarygodnym \u017ar\u00f3d\u0142em informacji?", "tokens": [50800, 27617, 2226, 11, 806, 453, 86, 46788, 12996, 35234, 3901, 32557, 11, 6775, 9516, 26393, 822, 21787, 12996, 50212, 43678, 11126, 1356, 13152, 30, 51052], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 8, "seek": 2488, "start": 38.64, "end": 42.72, "text": " W\u0142a\u015bnie tego problemu dotyka praca badawcza od Google, kt\u00f3r\u0105 dzi\u015b analizujemy.", "tokens": [51052, 343, 5024, 12221, 8627, 1154, 84, 5893, 88, 2330, 582, 6628, 272, 1538, 86, 41524, 3611, 3329, 11, 37415, 31981, 1788, 2624, 590, 21767, 13, 51256], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 9, "seek": 2488, "start": 42.72, "end": 47.120000000000005, "text": " Nazywa si\u0119 Lambda, Language Models for Dialogue Applications.", "tokens": [51256, 11870, 88, 4151, 3244, 45691, 11, 24445, 6583, 1625, 337, 29658, 7213, 26519, 763, 13, 51476], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 10, "seek": 2488, "start": 47.120000000000005, "end": 53.36, "text": " Lambda, tak ta nazwa przewija\u0142a si\u0119 w mediach, czyli naszym celem jest zrozumienie,", "tokens": [51476, 45691, 11, 991, 1846, 20151, 4151, 39758, 20642, 5024, 3244, 261, 17269, 608, 11, 16591, 48094, 1769, 10386, 3492, 710, 27857, 449, 27385, 11, 51788], "temperature": 0.0, "avg_logprob": -0.1701176961263021, "compression_ratio": 1.4135802469135803, "no_speech_prob": 0.3230476379394531}, {"id": 11, "seek": 5336, "start": 53.36, "end": 58.28, "text": " co jest w niej tak prze\u0142omowego. Z tego, co widz\u0119 w materiale, skupimy si\u0119 na dw\u00f3ch", "tokens": [50364, 598, 3492, 261, 2838, 73, 991, 8325, 1221, 298, 26576, 13, 1176, 8627, 11, 598, 5274, 11052, 261, 2527, 68, 11, 1110, 1010, 13189, 3244, 1667, 27379, 812, 339, 50610], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 12, "seek": 5336, "start": 58.28, "end": 63.6, "text": " kluczowych wyzwaniach. Safety, czyli bezpiecze\u0144stwie i Factual Grounding,", "tokens": [50610, 9671, 1311, 89, 19605, 4628, 14406, 3782, 608, 13, 21340, 11, 16591, 47153, 9680, 12229, 8699, 741, 33375, 901, 2606, 24625, 11, 50876], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 13, "seek": 5336, "start": 63.6, "end": 65.6, "text": " czyli ugruntowaniu w faktach.", "tokens": [50876, 16591, 344, 861, 2760, 305, 25849, 261, 21310, 608, 13, 50976], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 14, "seek": 5336, "start": 65.6, "end": 66.72, "text": " Dok\u0142adnie.", "tokens": [50976, 29768, 10358, 2766, 13, 51032], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 15, "seek": 5336, "start": 66.72, "end": 72.72, "text": " Wygl\u0105da na to, \u017ce autorzy proponuj\u0105 co\u015b wi\u0119cej, ni\u017c tylko zbudujmy wi\u0119kszy model.", "tokens": [51032, 14458, 7191, 26398, 1667, 281, 11, 3561, 19510, 1229, 2365, 266, 13263, 19241, 26004, 11, 28502, 13219, 710, 18281, 4579, 2226, 29968, 1229, 2316, 13, 51332], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 16, "seek": 5336, "start": 72.72, "end": 75.84, "text": " Chc\u0105 go uczyni\u0107 m\u0105drzejszym.", "tokens": [51332, 761, 32557, 352, 344, 6522, 3722, 2162, 275, 18962, 13503, 73, 7706, 76, 13, 51488], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 17, "seek": 5336, "start": 75.84, "end": 80.48, "text": " W\u0142a\u015bnie. Chodzi o to, by nauczy\u0107 go, kiedy ma si\u0119 zatrzyma\u0107 i pomy\u015ble\u0107,", "tokens": [51488, 343, 5024, 12221, 13, 761, 14543, 277, 281, 11, 538, 49103, 27150, 352, 11, 18777, 463, 3244, 35802, 13047, 1696, 2162, 741, 280, 8488, 1788, 306, 2162, 11, 51720], "temperature": 0.0, "avg_logprob": -0.13210353335818728, "compression_ratio": 1.378839590443686, "no_speech_prob": 0.19425532221794128}, {"id": 18, "seek": 8048, "start": 80.56, "end": 83.60000000000001, "text": " a nawet no wiesz sprawdzi\u0107 fakty zanim co\u015b powie.", "tokens": [50368, 257, 22696, 572, 261, 15347, 46192, 28496, 33647, 874, 710, 17869, 19241, 3388, 414, 13, 50520], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 19, "seek": 8048, "start": 83.60000000000001, "end": 85.84, "text": " To jest fundamentalna zmiana w podej\u015bciu.", "tokens": [50520, 1407, 3492, 8088, 629, 17020, 8497, 261, 7468, 73, 6199, 84, 13, 50632], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 20, "seek": 8048, "start": 85.84, "end": 89.84, "text": " Ok, czyli samo powi\u0119kszanie m\u00f3zgu AI nie dzia\u0142a?", "tokens": [50632, 3477, 11, 16591, 36422, 3388, 5034, 1694, 89, 7155, 32515, 89, 2794, 7318, 2838, 37903, 30, 50832], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 21, "seek": 8048, "start": 89.84, "end": 95.60000000000001, "text": " To intuicyjnie ma sens, kto\u015b mo\u017ce zna\u0107 na pami\u0119\u0107 ca\u0142\u0105 bibliotek\u0119, a i tak nie by\u0107 m\u0105dry.", "tokens": [50832, 1407, 560, 84, 2632, 73, 2766, 463, 2923, 11, 32982, 12034, 710, 629, 2162, 1667, 31088, 2162, 1335, 15926, 34344, 310, 916, 1274, 11, 257, 741, 991, 2838, 15069, 275, 18962, 627, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 22, "seek": 8048, "start": 95.60000000000001, "end": 100.88000000000001, "text": " Jaki by\u0142 wi\u0119c dotychczasowy problem z tym podej\u015bciem opartym na czystej skali?", "tokens": [51120, 508, 7421, 16673, 16677, 5893, 16384, 30989, 10089, 1154, 710, 8107, 7468, 73, 9815, 76, 999, 446, 4199, 1667, 6430, 2941, 73, 1110, 5103, 30, 51384], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 23, "seek": 8048, "start": 100.88000000000001, "end": 103.44, "text": " Wi\u0119c problem le\u017cy w samej naturze tych modeli.", "tokens": [51384, 32508, 1154, 476, 7735, 261, 912, 73, 26389, 1381, 15180, 2316, 72, 13, 51512], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 24, "seek": 8048, "start": 103.44, "end": 107.36, "text": " One s\u0105 trenowane, by przewidywa\u0107 nast\u0119pne s\u0142ow\u00f3w sekwencji.", "tokens": [51512, 1485, 9015, 23136, 23066, 11, 538, 39758, 38836, 25234, 39662, 716, 15116, 305, 3901, 17215, 15615, 19649, 13, 51708], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 25, "seek": 8048, "start": 107.36, "end": 108.0, "text": " Aha.", "tokens": [51708, 27448, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14410159462376645, "compression_ratio": 1.4433656957928802, "no_speech_prob": 0.002636983525007963}, {"id": 26, "seek": 10800, "start": 108.0, "end": 114.0, "text": " To sprawia, \u017ce s\u0105 absolutnymi mistrzami w tworzeniu tekstu, kt\u00f3ry jest statystycznie prawdopodobny.", "tokens": [50364, 1407, 22734, 654, 11, 3561, 9015, 18757, 31813, 3544, 19390, 4526, 261, 46288, 39651, 16624, 372, 84, 11, 9913, 3492, 2219, 38593, 17466, 2766, 41175, 46684, 996, 1634, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 27, "seek": 10800, "start": 114.0, "end": 118.0, "text": " Ich celem jest p\u0142ynno\u015b\u0107, sp\u00f3jno\u015b\u0107, a nie prawdziwo\u015b\u0107.", "tokens": [50664, 3141, 1769, 10386, 3492, 28695, 2534, 23293, 11, 637, 18999, 23293, 11, 257, 2838, 41175, 3992, 48847, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 28, "seek": 10800, "start": 118.0, "end": 122.72, "text": " Czyli odpowied\u017a mo\u017ce by\u0107 gramatycznie idealna, logicznie pasowa\u0107?", "tokens": [50864, 37099, 36574, 10659, 12034, 15069, 21353, 267, 17466, 2766, 7157, 629, 11, 9952, 89, 2766, 1736, 11445, 30, 51100], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 29, "seek": 10800, "start": 122.72, "end": 123.52, "text": " Tak, tak.", "tokens": [51100, 9118, 11, 991, 13, 51140], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 30, "seek": 10800, "start": 123.52, "end": 126.72, "text": " A jednocze\u015bnie by\u0107 kompletnym wymis\u0142em?", "tokens": [51140, 316, 5232, 26694, 1381, 12221, 15069, 5207, 14657, 12996, 29764, 271, 11126, 30, 51300], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 31, "seek": 10800, "start": 126.72, "end": 128.0, "text": " Dok\u0142adnie.", "tokens": [51300, 29768, 10358, 2766, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 32, "seek": 10800, "start": 128.0, "end": 134.32, "text": " Jak improwizator, kt\u00f3ry za wszelk\u0105 cen\u0119 chce kontynuowa\u0107 scen\u0119, nawet je\u015bli musi zmy\u015bla\u0107 na poczekaniu.", "tokens": [51364, 15029, 704, 1892, 590, 1639, 11, 9913, 7949, 37647, 12971, 26304, 27900, 1274, 28928, 5897, 874, 16241, 11445, 4191, 1274, 11, 22696, 25630, 37587, 710, 2226, 1788, 875, 2162, 1667, 26423, 916, 25849, 13, 51680], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 33, "seek": 10800, "start": 134.32, "end": 135.76, "text": " \u015awietna analogia.", "tokens": [51680, 27933, 39083, 629, 16660, 654, 13, 51752], "temperature": 0.0, "avg_logprob": -0.10449800226423475, "compression_ratio": 1.4478114478114479, "no_speech_prob": 0.008647274225950241}, {"id": 34, "seek": 13576, "start": 135.76, "end": 139.04, "text": " A praca nad Lambda pokazuje to wprost na danych.", "tokens": [50364, 316, 582, 6628, 12617, 45691, 13010, 43317, 281, 261, 1424, 555, 1667, 274, 34644, 13, 50528], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 35, "seek": 13576, "start": 139.04, "end": 146.72, "text": " Por\u00f3wnuj\u0105 modele o r\u00f3\u017cne wielko\u015bci od dw\u00f3ch miliard\u00f3w parametr\u00f3w a\u017c do 137 miliard\u00f3w.", "tokens": [50528, 5269, 812, 895, 13263, 4391, 306, 277, 47760, 20570, 4093, 6199, 3611, 27379, 812, 339, 1962, 72, 515, 3901, 6220, 27965, 3901, 48134, 360, 3705, 22, 1962, 72, 515, 3901, 13, 50912], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 36, "seek": 13576, "start": 146.72, "end": 151.51999999999998, "text": " I owszem wi\u0119kszy model staje si\u0119 lepszy w og\u00f3lnej jako\u015bci konwersacji.", "tokens": [50912, 286, 11492, 15453, 443, 29968, 1229, 2316, 342, 11153, 3244, 476, 1878, 1229, 261, 5360, 15741, 11794, 17123, 6199, 5897, 5364, 13152, 13, 51152], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 37, "seek": 13576, "start": 151.51999999999998, "end": 154.07999999999998, "text": " M\u00f3wi p\u0142ynniej, jest bardziej elokw\u0119tny.", "tokens": [51152, 376, 3901, 72, 28695, 2534, 10402, 11, 3492, 27209, 806, 453, 86, 46788, 1634, 13, 51280], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 38, "seek": 13576, "start": 154.07999999999998, "end": 154.79999999999998, "text": " Ale.", "tokens": [51280, 9366, 13, 51316], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 39, "seek": 13576, "start": 154.79999999999998, "end": 155.76, "text": " Ale.", "tokens": [51316, 9366, 13, 51364], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 40, "seek": 13576, "start": 155.76, "end": 162.56, "text": " Kiedy spojrzymy na te k\u0142uczowe dla nas metryki, czyli safety i groundedness, post\u0119p jest minimalny.", "tokens": [51364, 591, 16446, 8243, 73, 13047, 2226, 1667, 535, 350, 1221, 1311, 89, 6880, 12285, 5382, 1131, 627, 2984, 11, 16591, 4514, 741, 23535, 1287, 11, 2183, 18085, 3492, 13206, 1634, 13, 51704], "temperature": 0.0, "avg_logprob": -0.15114881727430557, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.04301407188177109}, {"id": 41, "seek": 16256, "start": 162.56, "end": 166.0, "text": " Pami\u0119tam te wykresy z artyku\u0142u figure one i four.", "tokens": [50364, 430, 23806, 37323, 535, 39287, 495, 88, 710, 594, 874, 5279, 24066, 2573, 472, 741, 1451, 13, 50536], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 42, "seek": 16256, "start": 166.0, "end": 172.08, "text": " Te niebieskie s\u0142upki, kt\u00f3re pokazuj\u0105 model zaraz po tym podstawowym treningu, czyli pre-training.", "tokens": [50536, 1989, 2838, 23177, 22872, 15116, 1010, 2984, 11, 8864, 13010, 921, 13263, 2316, 22675, 921, 714, 8107, 43443, 31691, 2192, 773, 84, 11, 16591, 659, 12, 17227, 1760, 13, 50840], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 43, "seek": 16256, "start": 172.08, "end": 177.44, "text": " One ledwo drgn\u0119\u0142y w g\u00f3r\u0119 w tych dw\u00f3ch kategoriach, nawet przy gigantycznym skoku liczby parametr\u00f3w.", "tokens": [50840, 1485, 4684, 6120, 1224, 4568, 1274, 6825, 261, 290, 15614, 1274, 261, 15180, 27379, 812, 339, 350, 2968, 7386, 608, 11, 22696, 6501, 8741, 394, 17466, 12996, 1110, 13275, 6169, 89, 2322, 6220, 27965, 3901, 13, 51108], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 44, "seek": 16256, "start": 177.44, "end": 178.32, "text": " No w\u0142a\u015bnie.", "tokens": [51108, 883, 14234, 13, 51152], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 45, "seek": 16256, "start": 178.32, "end": 183.6, "text": " Czyli dorzucaniem mocy obliczeniowej nie ucz\u0119 modelu etyki ani weryfikacji fakt\u00f3w.", "tokens": [51152, 37099, 26313, 89, 1311, 282, 4907, 705, 1344, 1111, 1050, 42124, 21091, 2838, 35403, 1274, 2316, 84, 1030, 88, 2984, 40477, 261, 2109, 31230, 13152, 21310, 3901, 13, 51416], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 46, "seek": 16256, "start": 183.6, "end": 184.64000000000001, "text": " W\u0142a\u015bnie.", "tokens": [51416, 343, 5024, 12221, 13, 51468], "temperature": 0.0, "avg_logprob": -0.12060717225984763, "compression_ratio": 1.3886792452830188, "no_speech_prob": 0.15375863015651703}, {"id": 47, "seek": 18464, "start": 184.64, "end": 192.95999999999998, "text": " Model staje si\u0119 powiedzmy lepszym gadu\u0142\u0105, ale niekoniecznie m\u0105drzejszym czy bardziej odpowiedzialnym partnerem do rozmowy.", "tokens": [50364, 17105, 342, 11153, 3244, 27617, 2226, 476, 1878, 26681, 21318, 84, 15926, 11, 6775, 2838, 18295, 414, 19923, 275, 18962, 13503, 73, 7706, 76, 6430, 27209, 24314, 15338, 831, 12996, 644, 77, 7333, 360, 35234, 10089, 13, 50780], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 48, "seek": 18464, "start": 192.95999999999998, "end": 197.76, "text": " I to jest \u015bciana, o kt\u00f3r\u0105 rozbi\u0142o si\u0119 podej\u015bcie oparte wy\u0142\u0105cznie na skalowaniu.", "tokens": [50780, 286, 281, 3492, 220, 6199, 2095, 11, 277, 37415, 9544, 5614, 5249, 3244, 7468, 73, 9815, 999, 11026, 4628, 15926, 19923, 1667, 16890, 305, 25849, 13, 51020], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 49, "seek": 18464, "start": 197.76, "end": 198.72, "text": " Rozumiem.", "tokens": [51020, 43313, 449, 4907, 13, 51068], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 50, "seek": 18464, "start": 198.72, "end": 202.32, "text": " Badacze z Google zdali sobie spraw\u0119, \u017ce trzeba czego\u015b wi\u0119cej.", "tokens": [51068, 11523, 326, 1381, 710, 3329, 16221, 5103, 13652, 22734, 1274, 11, 3561, 25860, 36559, 1788, 26004, 13, 51248], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 51, "seek": 18464, "start": 202.32, "end": 206.56, "text": " No dobrze, to je\u015bli nie wi\u0119cej danych i wi\u0119kszy model to co?", "tokens": [51248, 883, 28335, 11, 281, 25630, 2838, 26004, 274, 34644, 741, 29968, 1229, 2316, 281, 598, 30, 51460], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 52, "seek": 18464, "start": 206.56, "end": 207.76, "text": " Lepsze dane?", "tokens": [51460, 441, 10653, 1381, 49206, 30, 51520], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 53, "seek": 18464, "start": 207.76, "end": 209.83999999999997, "text": " Jaki zupe\u0142nie inny rodzaj treningu?", "tokens": [51520, 508, 7421, 49922, 294, 1634, 28607, 1805, 2192, 773, 84, 30, 51624], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 54, "seek": 18464, "start": 209.83999999999997, "end": 212.07999999999998, "text": " Dok\u0142adnie. Inny rodzaj treningu.", "tokens": [51624, 29768, 10358, 2766, 13, 682, 1634, 28607, 1805, 2192, 773, 84, 13, 51736], "temperature": 0.0, "avg_logprob": -0.12076230245093776, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.021128280088305473}, {"id": 55, "seek": 21208, "start": 212.16000000000003, "end": 216.0, "text": " Zastosowali technik\u0119, kt\u00f3r\u0105 znamy jako fine tuning.", "tokens": [50368, 1176, 525, 329, 305, 5103, 1537, 1035, 1274, 11, 37415, 710, 5378, 88, 17123, 2489, 15164, 13, 50560], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 56, "seek": 21208, "start": 216.0, "end": 216.64000000000001, "text": " Okej.", "tokens": [50560, 29094, 73, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 57, "seek": 21208, "start": 216.64000000000001, "end": 220.72000000000003, "text": " Ale zrobili to w bardzo przemy\u015blany dwutorowy spos\u00f3b.", "tokens": [50592, 9366, 44399, 2312, 281, 261, 9034, 6541, 3633, 19212, 1325, 27379, 22163, 10089, 22904, 13, 50796], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 58, "seek": 21208, "start": 220.72000000000003, "end": 228.48000000000002, "text": " Wsieli ten ogromny wst\u0119pnie wytrenowany model i zapisali go na swego rodzaju specjalistyczne korepetycje prowadzone przez ludzi.", "tokens": [50796, 343, 82, 23099, 2064, 34416, 298, 1634, 261, 372, 18085, 2766, 261, 4328, 1095, 23341, 2316, 741, 14223, 271, 5103, 352, 1667, 2484, 1571, 28607, 33166, 46433, 468, 17466, 716, 350, 418, 79, 2210, 44261, 36590, 16896, 14064, 29586, 13, 51184], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 59, "seek": 21208, "start": 228.48000000000002, "end": 230.4, "text": " Korepetycje. Z czego?", "tokens": [51184, 591, 418, 79, 2210, 44261, 13, 1176, 36559, 30, 51280], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 60, "seek": 21208, "start": 230.4, "end": 233.20000000000002, "text": " Z bycia dobrym chatbotem. Mo\u017cna tak powiedzie\u0107.", "tokens": [51280, 1176, 538, 2755, 35884, 76, 5081, 18870, 443, 13, 44736, 629, 991, 27886, 13, 51420], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 61, "seek": 21208, "start": 233.20000000000002, "end": 237.84, "text": " Pierwszy tor korepetycji dotyczy\u0142 og\u00f3lnej jako\u015bci i bezpiecze\u0144stwa rozmowy.", "tokens": [51420, 16676, 30012, 3930, 350, 418, 79, 2210, 19649, 5893, 88, 6522, 1221, 5360, 15741, 11794, 17123, 6199, 741, 47153, 9680, 12229, 4151, 35234, 10089, 13, 51652], "temperature": 0.0, "avg_logprob": -0.10979585853411997, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.05598611384630203}, {"id": 62, "seek": 23784, "start": 237.92000000000002, "end": 243.6, "text": " Zamiast pozwoli\u0107 modelowi po prostu generowa\u0107 tekst, zacz\u0119li go uczy\u0107 jak ocenia\u0107 w\u0142asn\u0105 odpowiedzi.", "tokens": [50368, 1176, 4526, 525, 40557, 9384, 2162, 2316, 24503, 714, 19518, 1337, 11445, 16624, 372, 11, 34430, 11052, 2081, 352, 344, 33967, 4207, 10409, 268, 654, 2162, 43572, 13113, 36574, 3992, 13, 50652], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 63, "seek": 23784, "start": 243.6, "end": 244.4, "text": " Aha.", "tokens": [50652, 27448, 13, 50692], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 64, "seek": 23784, "start": 244.4, "end": 249.68, "text": " Zdefiniowali jako\u015b\u0107 za pomoc\u0105 trzech metryk, kt\u00f3re nazwali w skr\u00f3cie SSI.", "tokens": [50692, 1176, 20595, 3812, 305, 5103, 17123, 7753, 7949, 48962, 1611, 504, 19439, 1131, 627, 74, 11, 8864, 20151, 40054, 261, 1110, 11721, 4260, 12238, 40, 13, 50956], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 65, "seek": 23784, "start": 249.68, "end": 256.4, "text": " SSI. Widz\u0119 tutaj sensibilness, specificity i interestingness.", "tokens": [50956, 12238, 40, 13, 28331, 11052, 12749, 2923, 11607, 1287, 11, 2685, 507, 741, 1880, 1287, 13, 51292], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 66, "seek": 23784, "start": 256.4, "end": 261.68, "text": " Dobra. Sensibilness, czyli sensowno\u015b\u0107. To jest jasne. Odpowied\u017a musi pasowa\u0107 do rozmowy.", "tokens": [51292, 413, 24393, 13, 40926, 11607, 1287, 11, 16591, 2923, 648, 78, 7753, 13, 1407, 3492, 361, 296, 716, 13, 12210, 14701, 1091, 10659, 37587, 1736, 11445, 360, 35234, 10089, 13, 51556], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 67, "seek": 23784, "start": 261.68, "end": 262.16, "text": " Tak.", "tokens": [51556, 9118, 13, 51580], "temperature": 0.0, "avg_logprob": -0.14749192797448024, "compression_ratio": 1.375, "no_speech_prob": 0.033391620963811874}, {"id": 68, "seek": 26216, "start": 262.16, "end": 268.88000000000005, "text": " Specificity, czyli konkretno\u015b\u0107. Te\u017c koniec z odpowiedziami w sty\u0142u. To ciekawe na wszystko.", "tokens": [50364, 20484, 1089, 507, 11, 16591, 36500, 23293, 13, 1989, 1427, 5897, 35733, 710, 36574, 3992, 4526, 261, 7952, 24066, 13, 1407, 30596, 2330, 826, 1667, 22607, 13, 50700], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 69, "seek": 26216, "start": 268.88000000000005, "end": 269.52000000000004, "text": " Dok\u0142adnie.", "tokens": [50700, 29768, 10358, 2766, 13, 50732], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 70, "seek": 26216, "start": 269.52000000000004, "end": 274.8, "text": " Ale interestingness. Jak w og\u00f3le mo\u017cna nauczy\u0107 maszyn\u0119 bycia interesuj\u0105c\u0105?", "tokens": [50732, 9366, 1880, 1287, 13, 15029, 261, 29229, 17790, 49103, 27150, 2300, 1229, 77, 1274, 538, 2755, 20157, 13263, 32557, 30, 50996], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 71, "seek": 26216, "start": 274.8, "end": 279.36, "text": " To jest \u015bwietne pytanie. Zrobili to w bardzo prosty, ale skuteczny spos\u00f3b.", "tokens": [50996, 1407, 3492, 8299, 39083, 716, 36610, 13, 1176, 16614, 2312, 281, 261, 9034, 10293, 88, 11, 6775, 1110, 1169, 3689, 1634, 22904, 13, 51224], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 72, "seek": 26216, "start": 279.36, "end": 287.76000000000005, "text": " Zatrudni\u0107 tysi\u0105ce ludzi, tak zwanych crowd workers, kt\u00f3rzy prowadzili rozmowy z modelem i oceniali jego odpowiedzi w tych trzech kategoriach.", "tokens": [51224, 1176, 267, 47130, 3722, 2162, 38156, 11404, 384, 29586, 11, 991, 11873, 34644, 6919, 5600, 11, 25382, 36590, 89, 2312, 35234, 10089, 710, 4391, 10386, 741, 10409, 268, 831, 72, 26542, 36574, 3992, 261, 15180, 504, 19439, 350, 2968, 7386, 608, 13, 51644], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 73, "seek": 26216, "start": 287.76000000000005, "end": 291.36, "text": " Czyli czy odpowied\u017a by\u0142a wnikliwa, a mo\u017ce do wcipna?", "tokens": [51644, 37099, 6430, 36574, 10659, 23936, 261, 13123, 2081, 4151, 11, 257, 12034, 360, 261, 537, 79, 629, 30, 51824], "temperature": 0.0, "avg_logprob": -0.14251790175566803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 0.056565236300230026}, {"id": 74, "seek": 29136, "start": 291.36, "end": 299.6, "text": " Tak. Czy wnios\u0142a co\u015b nowego? Te oceny stworzy\u0142y ogromny zbi\u00f3r danych, na kt\u00f3rym model uczy\u0142 si\u0119, co ludzie uwa\u017caj\u0105 zainteresuj\u0105ce.", "tokens": [50364, 9118, 13, 19832, 261, 77, 2717, 5024, 19241, 586, 6308, 30, 1989, 10409, 43100, 342, 28321, 1229, 6825, 34416, 298, 1634, 710, 5614, 15614, 274, 34644, 11, 1667, 30120, 2316, 344, 6522, 1221, 3244, 11, 598, 37025, 48089, 11133, 710, 491, 391, 279, 13263, 384, 13, 50776], "temperature": 0.0, "avg_logprob": -0.09424086285244887, "compression_ratio": 1.4851485148514851, "no_speech_prob": 0.013855180703103542}, {"id": 75, "seek": 29136, "start": 299.6, "end": 304.48, "text": " Czyli na podstawie tych ludzkich ocen model nauczy\u0142 si\u0119 sam siebie recenzowa\u0107.", "tokens": [50776, 37099, 1667, 43443, 414, 15180, 15946, 30154, 480, 10409, 268, 2316, 49103, 1229, 1221, 3244, 3247, 39137, 850, 11368, 11445, 13, 51020], "temperature": 0.0, "avg_logprob": -0.09424086285244887, "compression_ratio": 1.4851485148514851, "no_speech_prob": 0.013855180703103542}, {"id": 76, "seek": 29136, "start": 304.48, "end": 309.12, "text": " Dok\u0142adnie. Wytrenowali go by dzia\u0142a\u0142 jako sw\u00f3j w\u0142asny dyskryminator.", "tokens": [51020, 29768, 10358, 2766, 13, 343, 4328, 1095, 305, 5103, 352, 538, 37903, 1221, 17123, 1693, 18999, 43572, 1634, 15243, 43298, 2367, 1639, 13, 51252], "temperature": 0.0, "avg_logprob": -0.09424086285244887, "compression_ratio": 1.4851485148514851, "no_speech_prob": 0.013855180703103542}, {"id": 77, "seek": 29136, "start": 309.12, "end": 310.88, "text": " A to w praktyce co oznacza?", "tokens": [51252, 316, 281, 261, 3206, 74, 874, 384, 598, 277, 22672, 326, 2394, 30, 51340], "temperature": 0.0, "avg_logprob": -0.09424086285244887, "compression_ratio": 1.4851485148514851, "no_speech_prob": 0.013855180703103542}, {"id": 78, "seek": 29136, "start": 310.88, "end": 318.96000000000004, "text": " W praktyce oznacza to, \u017ce zanim lambda udzieli ostatecznej odpowiedzi, wewn\u0119trznie generuje kilka potencjalnych wariant\u00f3w.", "tokens": [51340, 343, 3206, 74, 874, 384, 277, 22672, 326, 2394, 281, 11, 3561, 710, 17869, 13607, 11727, 89, 23099, 277, 15406, 3689, 11794, 36574, 3992, 11, 321, 895, 1274, 6903, 89, 2766, 1337, 13008, 36466, 1847, 22660, 22600, 9399, 1516, 5798, 3901, 13, 51744], "temperature": 0.0, "avg_logprob": -0.09424086285244887, "compression_ratio": 1.4851485148514851, "no_speech_prob": 0.013855180703103542}, {"id": 79, "seek": 31896, "start": 318.96, "end": 328.23999999999995, "text": " Nast\u0119pnie ten wewn\u0119trzny krytyk ocenia je pod k\u0105tem SSI i odrzuca te, kt\u00f3re s\u0105 bezsensowne, zbyt og\u00f3lne albo po prostu nudne.", "tokens": [50364, 42185, 18085, 2766, 2064, 321, 895, 1274, 6903, 89, 1634, 34847, 874, 74, 10409, 268, 654, 1506, 2497, 350, 1611, 18275, 12238, 40, 741, 3611, 81, 11728, 496, 535, 11, 8864, 9015, 10782, 82, 694, 648, 68, 11, 710, 2322, 83, 5360, 15741, 716, 22622, 714, 19518, 40045, 716, 13, 50828], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 80, "seek": 31896, "start": 328.23999999999995, "end": 329.52, "text": " I wybiera najlepsz\u0105?", "tokens": [50828, 286, 45780, 10609, 41903, 1878, 8925, 30, 50892], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 81, "seek": 31896, "start": 329.52, "end": 330.64, "text": " I wybiera najlepsz\u0105.", "tokens": [50892, 286, 45780, 10609, 41903, 1878, 8925, 13, 50948], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 82, "seek": 31896, "start": 330.64, "end": 336.79999999999995, "text": " To ju\u017c jest du\u017cy krok na prz\u00f3d. Ale co z bezpiecze\u0144stwem? Ten sam mechanizm?", "tokens": [50948, 1407, 10678, 3492, 1581, 7735, 350, 31621, 1667, 6541, 17081, 13, 9366, 598, 710, 47153, 9680, 12229, 86, 443, 30, 9380, 3247, 4236, 590, 76, 30, 51256], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 83, "seek": 31896, "start": 336.79999999999995, "end": 340.15999999999997, "text": " Ten sam mechanizm zdefiniowali jasne cele bezpiecze\u0144stwa.", "tokens": [51256, 9380, 3247, 4236, 590, 76, 710, 20595, 3812, 305, 5103, 361, 296, 716, 43165, 47153, 9680, 12229, 4151, 13, 51424], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 84, "seek": 31896, "start": 340.15999999999997, "end": 345.52, "text": " Unikanie generowania szkodliwych tre\u015bci, mowy nienawi\u015bci, uprzedze\u0144, niebezpiecznych porad.", "tokens": [51424, 1156, 1035, 7155, 1337, 21308, 7870, 74, 378, 2081, 9726, 339, 2192, 6199, 11, 275, 10089, 297, 1053, 38402, 6199, 11, 493, 81, 11312, 49689, 11, 2838, 650, 89, 9144, 3689, 9399, 1515, 345, 13, 51692], "temperature": 0.0, "avg_logprob": -0.09392266937449009, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.09697049111127853}, {"id": 85, "seek": 34552, "start": 345.52, "end": 352.64, "text": " I znowu, na podstawie ludzkich adnotacji model nauczy\u0142 si\u0119 rozpoznawa\u0107 i odfiltrowywa\u0107 takie odpowiedzi.", "tokens": [50364, 286, 710, 3785, 84, 11, 1667, 43443, 414, 15946, 30154, 480, 614, 2247, 13152, 2316, 49103, 1229, 1221, 3244, 9544, 2259, 35458, 25234, 741, 3611, 69, 2352, 1892, 88, 25234, 15963, 36574, 3992, 13, 50720], "temperature": 0.0, "avg_logprob": -0.16642670735825588, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.35904908180236816}, {"id": 86, "seek": 34552, "start": 352.64, "end": 355.03999999999996, "text": " I to wida\u0107 na wykresach. Jak najbardziej.", "tokens": [50720, 286, 281, 261, 46898, 1667, 39287, 495, 608, 13, 15029, 41857, 13, 50840], "temperature": 0.0, "avg_logprob": -0.16642670735825588, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.35904908180236816}, {"id": 87, "seek": 34552, "start": 355.03999999999996, "end": 364.08, "text": " Kiedy wr\u00f3cimy do tych wykres\u00f3w zobaczymy, \u017ce r\u00f3\u017cowe s\u0142upki reprezentuj\u0105ce model po finalne tuning wystrzeluj\u0105 w g\u00f3r\u0119 w por\u00f3wnaniu do niebieskich.", "tokens": [50840, 591, 16446, 928, 40993, 13189, 360, 15180, 39287, 495, 3901, 37273, 2226, 11, 3561, 19637, 6880, 15116, 1010, 2984, 1085, 265, 14185, 13263, 384, 2316, 714, 2572, 716, 15164, 4628, 9733, 12971, 13263, 261, 290, 15614, 1274, 261, 1515, 812, 895, 25849, 360, 2838, 23177, 48349, 13, 51292], "temperature": 0.0, "avg_logprob": -0.16642670735825588, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.35904908180236816}, {"id": 88, "seek": 34552, "start": 364.08, "end": 366.08, "text": " Post\u0119p jest gigantyczny.", "tokens": [51292, 10223, 18085, 3492, 8741, 394, 17466, 1634, 13, 51392], "temperature": 0.0, "avg_logprob": -0.16642670735825588, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.35904908180236816}, {"id": 89, "seek": 34552, "start": 366.08, "end": 371.03999999999996, "text": " Ok, to by\u0142 pierwszy tor ataku. Jako\u015b\u0107 i bezpiecze\u0144stwo przez samokrytyk\u0119.", "tokens": [51392, 3477, 11, 281, 16673, 34016, 3930, 412, 15803, 13, 15029, 78, 7753, 741, 47153, 9680, 12229, 6120, 14064, 3247, 453, 627, 874, 15724, 13, 51640], "temperature": 0.0, "avg_logprob": -0.16642670735825588, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.35904908180236816}, {"id": 90, "seek": 37104, "start": 371.12, "end": 375.6, "text": " Ale to wci\u0105\u017c nie rozwi\u0105zuje problemu ze zmy\u015blania fakt\u00f3w. Jaki by\u0142 drugi tor?", "tokens": [50368, 9366, 281, 261, 537, 27242, 2838, 9544, 18234, 11728, 2884, 1154, 84, 5277, 710, 2226, 19212, 5609, 21310, 3901, 13, 508, 7421, 16673, 4110, 72, 3930, 30, 50592], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 91, "seek": 37104, "start": 375.6, "end": 380.56, "text": " I tu dochodzimy do, moim zdaniem, najbardziej rewolucyjnej cz\u0119\u015bci tej pracy.", "tokens": [50592, 286, 2604, 9243, 378, 89, 13189, 360, 11, 48569, 710, 10312, 4907, 11, 41857, 319, 48481, 1311, 88, 73, 11794, 41314, 12573, 35591, 13, 50840], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 92, "seek": 37104, "start": 380.56, "end": 381.44, "text": " A mianowicie?", "tokens": [50840, 316, 275, 952, 305, 28434, 30, 50884], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 93, "seek": 37104, "start": 381.44, "end": 389.20000000000005, "text": " Zamiast pr\u00f3bowa\u0107 wypchn\u0105\u0107 ca\u0142\u0105 wiedz\u0119 \u015bwiata do g\u0142owy modelu, postanowili da\u0107 mu narz\u0119dzia.", "tokens": [50884, 1176, 4526, 525, 8565, 65, 11445, 46392, 1377, 36374, 1335, 15926, 46894, 11052, 21485, 3274, 360, 18117, 10089, 2316, 84, 11, 2183, 282, 305, 2312, 1120, 2162, 2992, 6714, 89, 6298, 40395, 13, 51272], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 94, "seek": 37104, "start": 389.20000000000005, "end": 391.20000000000005, "text": " Narz\u0119dzia? Jakie narz\u0119dzia?", "tokens": [51272, 13512, 89, 6298, 40395, 30, 15029, 414, 6714, 89, 6298, 40395, 30, 51372], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 95, "seek": 37104, "start": 391.20000000000005, "end": 395.36, "text": " Stworzyli co\u015b, co nazywaj\u0105 toolset, w skr\u00f3cie TS.", "tokens": [51372, 745, 28321, 1229, 2081, 19241, 11, 598, 20151, 27112, 11133, 2290, 3854, 11, 261, 1110, 11721, 4260, 37645, 13, 51580], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 96, "seek": 37104, "start": 395.36, "end": 400.56, "text": " To jest zestaw zewn\u0119trznych aplikacji, z kt\u00f3rych model mo\u017ce korzysta\u0107 w czasie rzeczywistym.", "tokens": [51580, 1407, 3492, 37889, 1607, 5277, 895, 1274, 6903, 89, 9399, 25522, 1035, 13152, 11, 710, 30382, 2316, 12034, 14784, 49590, 2162, 261, 42667, 26297, 86, 468, 4199, 13, 51840], "temperature": 0.0, "avg_logprob": -0.10966610764012193, "compression_ratio": 1.434375, "no_speech_prob": 0.045522332191467285}, {"id": 97, "seek": 40056, "start": 400.64, "end": 408.4, "text": " W jego sk\u0142ad wchodzi system wyszukiwania informacji, dzia\u0142aj\u0105cy jak wewn\u0119trzna wyszukiwarka, a tak\u017ce kalkulator i translator.", "tokens": [50368, 343, 26542, 1110, 10358, 261, 34616, 1185, 261, 20589, 11788, 86, 5609, 1356, 13152, 11, 27121, 11133, 1344, 4207, 321, 895, 1274, 6903, 35458, 261, 20589, 11788, 86, 809, 64, 11, 257, 23306, 34960, 16381, 741, 35223, 13, 50756], "temperature": 0.0, "avg_logprob": -0.1344014900882228, "compression_ratio": 1.4595469255663431, "no_speech_prob": 0.006958348676562309}, {"id": 98, "seek": 40056, "start": 408.4, "end": 413.2, "text": " Chwila, chwila. Czyli model mo\u017ce sam co\u015b wygooglowa\u0107, je\u015bli nie jest czego\u015b pewien?", "tokens": [50756, 761, 86, 7371, 11, 26237, 7371, 13, 37099, 2316, 12034, 3247, 19241, 4628, 1571, 664, 75, 11445, 11, 25630, 2838, 3492, 36559, 1788, 25889, 1053, 30, 50996], "temperature": 0.0, "avg_logprob": -0.1344014900882228, "compression_ratio": 1.4595469255663431, "no_speech_prob": 0.006958348676562309}, {"id": 99, "seek": 40056, "start": 413.2, "end": 419.12, "text": " W\u0142a\u015bnie tak. To brzmi jak proste rozwi\u0105zanie, ale musi by\u0107 w tym jaki\u015b haczyk.", "tokens": [50996, 343, 5024, 12221, 991, 13, 1407, 738, 89, 3057, 4207, 10293, 68, 9544, 22620, 7155, 11, 6775, 37587, 15069, 261, 8107, 34721, 324, 6522, 74, 13, 51292], "temperature": 0.0, "avg_logprob": -0.1344014900882228, "compression_ratio": 1.4595469255663431, "no_speech_prob": 0.006958348676562309}, {"id": 100, "seek": 40056, "start": 419.12, "end": 427.36, "text": " Sk\u0105d model wie, kiedy ma szuka\u0107 i co wa\u017cniejsze, jak odr\u00f3\u017cnia wiarygodne \u017ar\u00f3d\u0142o od niewiarygodnego?", "tokens": [51292, 7324, 18962, 2316, 3355, 11, 18777, 463, 7870, 13599, 2162, 741, 598, 27777, 44258, 11, 4207, 3611, 11721, 1427, 12679, 26393, 822, 21787, 716, 50212, 43678, 5249, 3611, 43622, 72, 822, 21787, 11858, 30, 51704], "temperature": 0.0, "avg_logprob": -0.1344014900882228, "compression_ratio": 1.4595469255663431, "no_speech_prob": 0.006958348676562309}, {"id": 101, "seek": 40056, "start": 427.36, "end": 429.76, "text": " Przecie\u017c internet jest pe\u0142en \u015bmieci.", "tokens": [51704, 2114, 1381, 40082, 4705, 3492, 43205, 268, 8299, 25210, 537, 13, 51824], "temperature": 0.0, "avg_logprob": -0.1344014900882228, "compression_ratio": 1.4595469255663431, "no_speech_prob": 0.006958348676562309}, {"id": 102, "seek": 42976, "start": 429.76, "end": 434.0, "text": " Doskona\u0142e pytania, kt\u00f3re pokazuj\u0105 z\u0142o\u017cono\u015b\u0107 problemu.", "tokens": [50364, 33474, 74, 4037, 19827, 25878, 5609, 11, 8864, 13010, 921, 13263, 710, 5249, 1427, 8957, 7753, 1154, 84, 13, 50576], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 103, "seek": 42976, "start": 434.0, "end": 436.64, "text": " Odpowiedzi\u0105 znowu jest fine tuning.", "tokens": [50576, 12210, 14701, 1091, 3992, 1611, 710, 3785, 84, 3492, 2489, 15164, 13, 50708], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 104, "seek": 42976, "start": 436.64, "end": 441.76, "text": " Nauczyli model rozpoznawa\u0107 sytuacj\u0119, w kt\u00f3rych jego wewn\u0119trzna wiedza mo\u017ce by\u0107 niewystarczaj\u0105ca.", "tokens": [50708, 6056, 1311, 1229, 2081, 2316, 9544, 2259, 35458, 25234, 28275, 29924, 11, 261, 30382, 26542, 321, 895, 1274, 6903, 35458, 46894, 2394, 12034, 15069, 43622, 88, 9710, 3689, 11133, 496, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 105, "seek": 42976, "start": 441.76, "end": 443.28, "text": " A \u017ar\u00f3d\u0142a?", "tokens": [50964, 316, 50212, 43678, 5024, 30, 51040], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 106, "seek": 42976, "start": 443.28, "end": 450.64, "text": " A co do \u017ar\u00f3dy? Na tym etapie bada\u0144 korzystali z zamkni\u0119tej wewn\u0119trznej bazy wiedzy, co upraszcza\u0142o problem weryfikacji.", "tokens": [51040, 316, 598, 360, 50212, 11721, 3173, 30, 6056, 8107, 47634, 414, 272, 1538, 5248, 14784, 36049, 5103, 710, 19876, 74, 35938, 975, 73, 321, 895, 1274, 6903, 89, 11794, 27147, 88, 46894, 1229, 11, 598, 493, 3906, 89, 41524, 5249, 1154, 261, 2109, 31230, 13152, 13, 51408], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 107, "seek": 42976, "start": 450.64, "end": 455.59999999999997, "text": " Kluczowo jest jednak to, \u017ce model nauczy\u0142 si\u0119 iteracyjnego procesu dochodzenia do prawdy.", "tokens": [51408, 16053, 1311, 89, 19941, 3492, 25897, 281, 11, 3561, 2316, 49103, 1229, 1221, 3244, 17138, 31285, 11858, 17565, 84, 9243, 378, 14320, 360, 22508, 3173, 13, 51656], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 108, "seek": 42976, "start": 455.59999999999997, "end": 456.64, "text": " Ok.", "tokens": [51656, 3477, 13, 51708], "temperature": 0.0, "avg_logprob": -0.12354260341377016, "compression_ratio": 1.4470198675496688, "no_speech_prob": 0.005237552337348461}, {"id": 109, "seek": 45664, "start": 456.64, "end": 460.96, "text": " Zobaczmy to na przyk\u0142adzie z artyku\u0142u tym o artystce Rosali Gascon.", "tokens": [50364, 1176, 996, 14875, 2226, 281, 1667, 23144, 3283, 710, 594, 874, 5279, 24066, 8107, 277, 594, 874, 372, 384, 11144, 5103, 24025, 1671, 13, 50580], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 110, "seek": 45664, "start": 460.96, "end": 463.84, "text": " Tak, ten przyk\u0142ad by\u0142 fascynuj\u0105cy.", "tokens": [50580, 9118, 11, 2064, 23144, 16673, 30632, 1344, 77, 13263, 1344, 13, 50724], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 111, "seek": 45664, "start": 463.84, "end": 470.64, "text": " U\u017cytkownik pyta o jej rze\u017aby, a model Lambda Base robi to, co potrafi najlepiej.", "tokens": [50724, 624, 1427, 4328, 74, 44895, 10664, 1328, 277, 28924, 16081, 10659, 2322, 11, 257, 2316, 45691, 21054, 47380, 281, 11, 598, 1847, 10437, 72, 41903, 39699, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 112, "seek": 45664, "start": 470.64, "end": 475.12, "text": " Improwizuje, generuje bardzo wiarygodnie brzmi\u0105ce zdanie.", "tokens": [51064, 8270, 1892, 590, 13008, 11, 1337, 13008, 9034, 26393, 822, 21787, 2766, 738, 89, 3057, 1611, 384, 16221, 7155, 13, 51288], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 113, "seek": 45664, "start": 475.12, "end": 479.59999999999997, "text": " Czy wiesz, \u017ce by\u0142a jedn\u0105 z artystek, kt\u00f3re inspirowa\u0142y Miro?", "tokens": [51288, 19832, 261, 15347, 11, 3561, 23936, 5232, 13113, 710, 594, 874, 372, 916, 11, 8864, 17432, 5528, 6825, 376, 5182, 30, 51512], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 114, "seek": 45664, "start": 479.59999999999997, "end": 481.03999999999996, "text": " Brzmi dobrze, prawda?", "tokens": [51512, 1603, 89, 3057, 28335, 11, 43607, 30, 51584], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 115, "seek": 45664, "start": 481.03999999999996, "end": 484.56, "text": " Dw\u00f3ch artyst\u00f3w, podobny okres, brzmi prawdopodobnie.", "tokens": [51584, 41448, 812, 339, 594, 874, 372, 3901, 11, 43024, 1634, 3133, 495, 11, 738, 89, 3057, 41175, 46684, 996, 2766, 13, 51760], "temperature": 0.0, "avg_logprob": -0.16297559673283377, "compression_ratio": 1.4, "no_speech_prob": 0.02043013647198677}, {"id": 116, "seek": 48456, "start": 484.56, "end": 487.52, "text": " Pewnie, ale tu w\u0142\u0105cza si\u0119 nowa umiej\u0119tno\u015b\u0107.", "tokens": [50364, 2396, 14215, 11, 6775, 2604, 261, 15926, 41524, 3244, 586, 64, 1105, 7764, 46788, 23293, 13, 50512], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 117, "seek": 48456, "start": 487.52, "end": 493.12, "text": " Dostrojony model rozpoznaje, \u017ce to jest stwierdzenie faktu, kt\u00f3rego nie jest w 100% pewien.", "tokens": [50512, 413, 555, 340, 73, 2526, 2316, 9544, 2259, 35458, 2884, 11, 3561, 281, 3492, 342, 40717, 67, 16778, 21310, 84, 11, 46951, 2838, 3492, 261, 2319, 4, 25889, 1053, 13, 50792], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 118, "seek": 48456, "start": 493.12, "end": 495.36, "text": " I wtedy odpala ten sw\u00f3j toolset.", "tokens": [50792, 286, 26959, 3611, 79, 5159, 2064, 1693, 18999, 2290, 3854, 13, 50904], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 119, "seek": 48456, "start": 495.36, "end": 499.12, "text": " Dok\u0142adnie. Wewn\u0119trznie generuje zapytanie do wyszukiwarki.", "tokens": [50904, 29768, 10358, 2766, 13, 492, 895, 1274, 6903, 89, 2766, 1337, 13008, 14223, 4328, 7155, 360, 261, 20589, 11788, 86, 809, 72, 13, 51092], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 120, "seek": 48456, "start": 499.12, "end": 502.96, "text": " Co\u015b w stylu Miro and Ein Gascoin.", "tokens": [51092, 3066, 1788, 261, 7952, 2781, 376, 5182, 293, 6391, 24025, 1291, 259, 13, 51284], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 121, "seek": 48456, "start": 502.96, "end": 507.84000000000003, "text": " System przeszukuje baz\u0119 wiedzy i nie znajduje \u017cadnego potwierdzenia dla tej tezy.", "tokens": [51284, 8910, 6541, 10430, 2034, 13008, 27147, 1274, 46894, 1229, 741, 2838, 47570, 2884, 39628, 11858, 1847, 40717, 67, 14320, 12285, 12573, 535, 1229, 13, 51528], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 122, "seek": 48456, "start": 507.84000000000003, "end": 508.8, "text": " Aha.", "tokens": [51528, 27448, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14810799492730034, "compression_ratio": 1.3558052434456929, "no_speech_prob": 0.12166789174079895}, {"id": 123, "seek": 50880, "start": 508.8, "end": 515.36, "text": " I teraz dzieje si\u0119 magia, model widz\u0105c brak dowod\u00f3w odrzuca swoj\u0105 w\u0142asn\u0105, pierwotn\u0105 odpowied\u017a.", "tokens": [50364, 286, 16854, 17953, 2884, 3244, 2258, 654, 11, 2316, 5274, 8925, 66, 1548, 74, 9459, 378, 3901, 3611, 81, 11728, 496, 49194, 43572, 13113, 11, 9766, 86, 310, 13113, 36574, 10659, 13, 50692], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 124, "seek": 50880, "start": 515.36, "end": 519.2, "text": " Czyli sam siebie poprawia, zanim cokolwiek powie na g\u0142os.", "tokens": [50692, 37099, 3247, 39137, 1665, 5131, 654, 11, 710, 17869, 269, 49207, 44674, 3388, 414, 1667, 43767, 13, 50884], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 125, "seek": 50880, "start": 519.2, "end": 520.5600000000001, "text": " Co wi\u0119c zrobi\u0107 zamian?", "tokens": [50884, 3066, 16677, 31785, 19876, 952, 30, 50952], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 126, "seek": 50880, "start": 520.5600000000001, "end": 526.0, "text": " W zamian przeszukuje dalej informacje o Gascoin i znajduje inny, potwierdzony fakt.", "tokens": [50952, 343, 19876, 952, 6541, 10430, 2034, 13008, 34257, 1356, 29293, 277, 24025, 1291, 259, 741, 47570, 2884, 294, 1634, 11, 1847, 40717, 28168, 2526, 21310, 13, 51224], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 127, "seek": 50880, "start": 526.0, "end": 529.36, "text": " Finalna odpowied\u017a, kt\u00f3r\u0105 widzi u\u017cytkownik, brzmi.", "tokens": [51224, 13443, 629, 36574, 10659, 11, 37415, 5274, 3992, 344, 1427, 4328, 74, 44895, 11, 738, 89, 3057, 13, 51392], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 128, "seek": 50880, "start": 529.36, "end": 536.4, "text": " Czy wiesz, \u017ce zajmowa\u0142a si\u0119 japo\u0144sk\u0105 sztuk\u0105 uk\u0142adania kwiat\u00f3w i keban\u0105, zanim zaj\u0119\u0142a si\u0119 rze\u017ab\u0105?", "tokens": [51392, 19832, 261, 15347, 11, 3561, 33729, 76, 5528, 5024, 3244, 361, 37615, 27125, 1611, 262, 2682, 2034, 1611, 344, 15317, 5609, 350, 6253, 267, 3901, 741, 803, 5144, 1611, 11, 710, 17869, 33729, 1274, 5024, 3244, 16081, 10659, 65, 1611, 30, 51744], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 129, "seek": 50880, "start": 536.4, "end": 537.52, "text": " Niesamowite.", "tokens": [51744, 426, 530, 335, 305, 642, 13, 51800], "temperature": 0.0, "avg_logprob": -0.13256421501253857, "compression_ratio": 1.4451612903225806, "no_speech_prob": 0.09307686984539032}, {"id": 130, "seek": 53752, "start": 537.6, "end": 540.96, "text": " I co wi\u0119cej, dodaj\u0119 odno\u015bnik do \u017ar\u00f3d\u0142a tej informacji.", "tokens": [50368, 286, 598, 26004, 11, 13886, 1805, 1274, 3611, 1771, 1788, 13123, 360, 50212, 43678, 5024, 12573, 1356, 13152, 13, 50536], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 131, "seek": 53752, "start": 540.96, "end": 542.96, "text": " To jest fundamentalna zmiana.", "tokens": [50536, 1407, 3492, 8088, 629, 17020, 8497, 13, 50636], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 132, "seek": 53752, "start": 542.96, "end": 546.72, "text": " Od pewnego siebie k\u0142amcy do ostro\u017cnego researchera.", "tokens": [50636, 12210, 25889, 11858, 39137, 350, 20177, 1344, 360, 277, 27616, 1427, 11858, 2132, 1663, 13, 50824], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 133, "seek": 53752, "start": 546.72, "end": 549.84, "text": " To jest niesamowite, bo to nie jest prosta weryfikacja.", "tokens": [50824, 1407, 3492, 48100, 335, 305, 642, 11, 748, 281, 2838, 3492, 582, 8638, 261, 2109, 31230, 23395, 13, 50980], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 134, "seek": 53752, "start": 549.84, "end": 554.88, "text": " Tak, nie. To jest aktywny proces edycji w\u0142asnej my\u015bli w oparciu o zewn\u0119trzne dane.", "tokens": [50980, 9118, 11, 2838, 13, 1407, 3492, 9308, 874, 43682, 17565, 1257, 88, 19649, 43572, 11794, 452, 15350, 261, 999, 289, 30795, 277, 5277, 895, 1274, 6903, 43077, 49206, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 135, "seek": 53752, "start": 554.88, "end": 555.36, "text": " Tak.", "tokens": [51232, 9118, 13, 51256], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 136, "seek": 53752, "start": 555.36, "end": 560.56, "text": " A przyk\u0142ad zwierz\u0105 Eifla, pokazany na figur\u0119 3, idzie nawet okrok dalej.", "tokens": [51256, 316, 23144, 11873, 811, 8925, 462, 351, 875, 11, 13010, 921, 1325, 1667, 31094, 1274, 805, 11, 4496, 3283, 22696, 3133, 31621, 34257, 13, 51516], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 137, "seek": 53752, "start": 560.56, "end": 564.0799999999999, "text": " Tak, bo pokazuje, \u017ce ten proces mo\u017ce by\u0107 wieloetapowy.", "tokens": [51516, 9118, 11, 748, 13010, 43317, 11, 3561, 2064, 17565, 12034, 15069, 20570, 78, 302, 569, 10089, 13, 51692], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 138, "seek": 53752, "start": 564.0799999999999, "end": 566.88, "text": " U\u017cytkownik pyta, kiedy zbudowano wierz\u0119.", "tokens": [51692, 624, 1427, 4328, 74, 44895, 10664, 1328, 11, 18777, 710, 18281, 305, 3730, 261, 811, 11052, 13, 51832], "temperature": 0.0, "avg_logprob": -0.15380885487511045, "compression_ratio": 1.4670846394984327, "no_speech_prob": 0.03957537189126015}, {"id": 139, "seek": 56688, "start": 567.04, "end": 572.16, "text": " Model najpierw generuje niepe\u0142n\u0105 odpowied\u017a w 1887.", "tokens": [50372, 17105, 11212, 45119, 86, 1337, 13008, 2838, 31457, 13113, 36574, 10659, 261, 2443, 23853, 13, 50628], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 140, "seek": 56688, "start": 572.16, "end": 575.4399999999999, "text": " Ale modu\u0142 researchu wysy\u0142a za pytanie.", "tokens": [50628, 9366, 1072, 84, 1221, 2132, 84, 27062, 88, 5024, 7949, 36610, 13, 50792], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 141, "seek": 56688, "start": 575.4399999999999, "end": 577.76, "text": " Eiffel Tower Construction Date.", "tokens": [50792, 462, 3661, 338, 17877, 40017, 31805, 13, 50908], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 142, "seek": 56688, "start": 577.76, "end": 579.28, "text": " I dostaje odpowied\u017a.", "tokens": [50908, 286, 20568, 11153, 36574, 10659, 13, 50984], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 143, "seek": 56688, "start": 579.28, "end": 583.92, "text": " Budowa rozpocz\u0119\u0142a si\u0119 28 stycznia 1887.", "tokens": [50984, 6384, 5528, 47576, 905, 11052, 5024, 3244, 7562, 7952, 3689, 12679, 2443, 23853, 13, 51216], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 144, "seek": 56688, "start": 583.92, "end": 587.84, "text": " Czyli on nie tylko zada\u0142 jedno pytanie i przyj\u0105\u0142 odpowied\u017a.", "tokens": [51216, 37099, 322, 2838, 13219, 710, 1538, 1221, 5232, 1771, 36610, 741, 6501, 8555, 1221, 36574, 10659, 13, 51412], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 145, "seek": 56688, "start": 587.84, "end": 592.0, "text": " Ale sam zorientowa\u0142 si\u0119, \u017ce pierwsza informacja by\u0142a niekompletna.", "tokens": [51412, 9366, 3247, 710, 19521, 30105, 3244, 11, 3561, 27623, 2394, 1356, 23395, 23936, 2838, 20557, 14657, 629, 13, 51620], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 146, "seek": 56688, "start": 592.0, "end": 594.24, "text": " To ju\u017c jest my\u015blenie okrok do przodu.", "tokens": [51620, 1407, 10678, 3492, 48633, 6698, 414, 3133, 31621, 360, 6541, 34873, 13, 51732], "temperature": 0.0, "avg_logprob": -0.18129198090368961, "compression_ratio": 1.4022988505747127, "no_speech_prob": 0.011283449828624725}, {"id": 147, "seek": 59424, "start": 594.24, "end": 595.36, "text": " W\u0142a\u015bnie.", "tokens": [50364, 343, 5024, 12221, 13, 50420], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 148, "seek": 59424, "start": 595.36, "end": 599.04, "text": " Model wie, \u017ce data rozpocz\u0119cia to nie to samo, co data uko\u0144czenia.", "tokens": [50420, 17105, 3355, 11, 3561, 1412, 47576, 905, 11052, 2755, 281, 2838, 281, 36422, 11, 598, 1412, 344, 4093, 5248, 38517, 13, 50604], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 149, "seek": 59424, "start": 599.04, "end": 601.84, "text": " Dlatego generuje drugie, bardziej precyzyjne zapytanie.", "tokens": [50604, 47184, 1337, 13008, 4110, 414, 11, 27209, 659, 1344, 1229, 73, 716, 14223, 4328, 7155, 13, 50744], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 150, "seek": 59424, "start": 601.84, "end": 604.08, "text": " Eiffel Tower Completed When.", "tokens": [50744, 462, 3661, 338, 17877, 33736, 10993, 1133, 13, 50856], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 151, "seek": 59424, "start": 604.08, "end": 605.44, "text": " I dostaje drug\u0105 dat\u0119.", "tokens": [50856, 286, 20568, 11153, 4110, 1611, 1137, 1274, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 152, "seek": 59424, "start": 605.44, "end": 607.36, "text": " Otrzymuje drug\u0105 informacj\u0119.", "tokens": [50924, 422, 6903, 26681, 13008, 4110, 1611, 1356, 29924, 13, 51020], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 153, "seek": 59424, "start": 607.36, "end": 611.44, "text": " Otwarcie 31 marca 1889.", "tokens": [51020, 12936, 6925, 4260, 10353, 30582, 2443, 21115, 13, 51224], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 154, "seek": 59424, "start": 611.44, "end": 613.76, "text": " Dopiero maj\u0105c te dwa zweryfikowane fakty,", "tokens": [51224, 42657, 12030, 26064, 66, 535, 35045, 710, 1554, 88, 31230, 23066, 33647, 874, 11, 51340], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 155, "seek": 59424, "start": 613.76, "end": 617.84, "text": " komponuje ostateczn\u0105, pe\u0142n\u0105 i poprawn\u0105 odpowied\u017a dla u\u017cytkownika.", "tokens": [51340, 5207, 79, 266, 13008, 277, 15406, 3689, 13113, 11, 43205, 13113, 741, 1665, 29603, 1611, 36574, 10659, 12285, 344, 1427, 4328, 74, 648, 5439, 13, 51544], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 156, "seek": 59424, "start": 617.84, "end": 621.6, "text": " Prace nad ni\u0105 rozpocz\u0119\u0142y si\u0119 w styczniu 1887,", "tokens": [51544, 2114, 617, 12617, 3867, 1611, 47576, 905, 11052, 6825, 3244, 261, 7952, 3689, 3722, 84, 2443, 23853, 11, 51732], "temperature": 0.0, "avg_logprob": -0.11386057286480673, "compression_ratio": 1.3924914675767919, "no_speech_prob": 0.02008533664047718}, {"id": 157, "seek": 62160, "start": 621.6800000000001, "end": 625.12, "text": " a zosta\u0142a otwarta w marcu 1889.", "tokens": [50368, 257, 23154, 5024, 4337, 86, 19061, 261, 1849, 12032, 2443, 21115, 13, 50540], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 158, "seek": 62160, "start": 625.12, "end": 626.24, "text": " Dok\u0142adnie tak.", "tokens": [50540, 29768, 10358, 2766, 991, 13, 50596], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 159, "seek": 62160, "start": 626.24, "end": 630.5600000000001, "text": " To wszystko brzmi rewelacyjnie, w teorii i na tych wybranych przyk\u0142adach.", "tokens": [50596, 1407, 22607, 738, 89, 3057, 319, 45512, 31285, 2766, 11, 261, 40238, 5597, 741, 1667, 15180, 4628, 1443, 34644, 23144, 608, 13, 50812], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 160, "seek": 62160, "start": 630.5600000000001, "end": 633.36, "text": " Ale czy to faktycznie zadzia\u0142a\u0142o na du\u017c\u0105 skal\u0119?", "tokens": [50812, 9366, 6430, 281, 33647, 45586, 42788, 89, 25605, 5249, 1667, 21783, 1611, 16890, 1274, 30, 50952], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 161, "seek": 62160, "start": 633.36, "end": 635.0400000000001, "text": " Jakie by\u0142y wymierne efekty?", "tokens": [50952, 15029, 414, 26366, 29764, 811, 716, 31482, 916, 874, 30, 51036], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 162, "seek": 62160, "start": 635.0400000000001, "end": 639.44, "text": " Kiedy spojrzymy na te wykresy, co nam m\u00f3wi\u0105 o skuteczno\u015bci tej metody?", "tokens": [51036, 591, 16446, 8243, 73, 13047, 2226, 1667, 535, 39287, 495, 88, 11, 598, 8835, 46591, 277, 1110, 1169, 3689, 16438, 12573, 1131, 843, 30, 51256], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 163, "seek": 62160, "start": 639.44, "end": 645.2, "text": " M\u00f3wi\u0105 nam, \u017ce ten dwutorowy Fine Tuning ca\u0142kowicie zmienia zasady gry.", "tokens": [51256, 376, 3901, 11404, 8835, 11, 3561, 2064, 27379, 22163, 10089, 12024, 21363, 278, 35224, 74, 305, 28434, 17020, 18811, 26530, 880, 41974, 13, 51544], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 164, "seek": 62160, "start": 645.2, "end": 651.52, "text": " Po tym treningu Lambda drastycznie zmniejsza dystans do ludzkiej wydajno\u015bci w metrykach jako\u015bci.", "tokens": [51544, 6165, 8107, 2192, 773, 84, 45691, 1224, 9820, 19923, 17020, 30295, 2394, 14584, 372, 599, 360, 15946, 30154, 7764, 25984, 1805, 16438, 261, 1131, 627, 41326, 17123, 6199, 13, 51860], "temperature": 0.0, "avg_logprob": -0.11118335965313489, "compression_ratio": 1.4290220820189274, "no_speech_prob": 0.004356853663921356}, {"id": 165, "seek": 65152, "start": 651.52, "end": 652.64, "text": " Czyli SSI.", "tokens": [50364, 37099, 12238, 40, 13, 50420], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 166, "seek": 65152, "start": 652.64, "end": 653.28, "text": " Okej.", "tokens": [50420, 29094, 73, 13, 50452], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 167, "seek": 65152, "start": 653.28, "end": 656.64, "text": " A w jednej kategorii dzieje si\u0119 co\u015b zupe\u0142nie zaskakuj\u0105cego.", "tokens": [50452, 316, 261, 5232, 11794, 350, 2968, 284, 5597, 17953, 2884, 3244, 19241, 49922, 710, 3863, 514, 13263, 384, 1571, 13, 50620], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 168, "seek": 65152, "start": 656.64, "end": 659.04, "text": " W tej metryce Interestingness?", "tokens": [50620, 343, 12573, 1131, 627, 384, 14711, 1287, 30, 50740], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 169, "seek": 65152, "start": 659.04, "end": 663.28, "text": " Z tego co pami\u0119tam model nie tylko dogoni\u0142 ludzi, ale ich przegoni\u0142.", "tokens": [50740, 1176, 8627, 598, 31088, 37323, 2316, 2838, 13219, 3000, 17049, 1221, 29586, 11, 6775, 1893, 6541, 1146, 17049, 1221, 13, 50952], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 170, "seek": 65152, "start": 663.28, "end": 664.56, "text": " Jak to w og\u00f3le mo\u017cliwe?", "tokens": [50952, 15029, 281, 261, 29229, 30854, 826, 30, 51016], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 171, "seek": 65152, "start": 664.56, "end": 667.1999999999999, "text": " AI jest bardziej interesuj\u0105ca od cz\u0142owieka?", "tokens": [51016, 7318, 3492, 27209, 20157, 13263, 496, 3611, 36282, 2330, 30, 51148], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 172, "seek": 65152, "start": 667.1999999999999, "end": 672.16, "text": " Hmm. Autorzy sami byli tym zaskoczeni i podchodz\u0105 do tego z ostro\u017cno\u015bci\u0105.", "tokens": [51148, 8239, 13, 6049, 284, 1229, 3247, 72, 538, 2081, 8107, 710, 3863, 905, 42124, 741, 2497, 29914, 8925, 360, 8627, 710, 277, 27616, 1427, 16438, 1611, 13, 51396], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 173, "seek": 65152, "start": 672.16, "end": 676.72, "text": " Ich hipoteza jest taka, \u017ce ludzie oceniaj\u0105cy ci crowd workers", "tokens": [51396, 3141, 8103, 1370, 2394, 3492, 28017, 11, 3561, 37025, 10409, 268, 48125, 1344, 6983, 6919, 5600, 51624], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 174, "seek": 65152, "start": 676.72, "end": 681.36, "text": " nie byli specjalnie motywowani, by by\u0107 w swoich odpowiedziach b\u0142yskotliwymi czy dowcipnymi.", "tokens": [51624, 2838, 538, 2081, 46433, 2766, 2184, 27112, 305, 3782, 11, 538, 15069, 261, 13291, 480, 36574, 3992, 608, 272, 1221, 749, 74, 310, 2081, 9726, 3057, 6430, 9459, 11371, 31813, 13, 51856], "temperature": 0.0, "avg_logprob": -0.16996454057239352, "compression_ratio": 1.4441176470588235, "no_speech_prob": 0.01990039274096489}, {"id": 175, "seek": 68136, "start": 681.36, "end": 683.36, "text": " Odpowiedali po prostu poprawnie.", "tokens": [50364, 12210, 14701, 1091, 5103, 714, 19518, 1665, 424, 14215, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 176, "seek": 68136, "start": 683.36, "end": 685.2, "text": " Po prostu poprawnie.", "tokens": [50464, 6165, 19518, 1665, 424, 14215, 13, 50556], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 177, "seek": 68136, "start": 685.2, "end": 690.32, "text": " A model, wytrenowany na milionach przyk\u0142ad\u00f3w b\u0142yskotliwych tekst\u00f3w z internetu", "tokens": [50556, 316, 2316, 11, 261, 4328, 1095, 23341, 1667, 1962, 313, 608, 23144, 3901, 272, 1221, 749, 74, 310, 2081, 9726, 339, 16624, 372, 3901, 710, 4705, 84, 50812], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 178, "seek": 68136, "start": 690.32, "end": 698.0, "text": " i nagradzany za bycie interesuj\u0105cym, po prostu nauczy\u0142 si\u0119 generowa\u0107 odpowiedzi, kt\u00f3ra przykuwaj\u0105 uwag\u0119.", "tokens": [50812, 741, 17096, 6206, 89, 1325, 7949, 538, 4260, 20157, 13263, 1344, 76, 11, 714, 19518, 49103, 1229, 1221, 3244, 1337, 11445, 36574, 3992, 11, 19456, 6501, 5279, 86, 11133, 43696, 13, 51196], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 179, "seek": 68136, "start": 698.0, "end": 701.12, "text": " To i tak godny uwagi wynik.", "tokens": [51196, 1407, 741, 991, 3044, 1634, 23147, 20291, 31936, 1035, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 180, "seek": 68136, "start": 701.12, "end": 702.4, "text": " Zdecydowanie.", "tokens": [51352, 1176, 1479, 1344, 67, 22028, 13, 51416], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 181, "seek": 68136, "start": 702.4, "end": 705.44, "text": " No dobrze, ale co z tymi najwa\u017cniejszymi metrykami?", "tokens": [51416, 883, 28335, 11, 6775, 598, 710, 1104, 3057, 11212, 27111, 10402, 7706, 3057, 1131, 627, 48737, 30, 51568], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 182, "seek": 68136, "start": 705.44, "end": 707.84, "text": " Safety i Groundedness.", "tokens": [51568, 21340, 741, 28371, 292, 1287, 13, 51688], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 183, "seek": 68136, "start": 707.84, "end": 710.32, "text": " Czy tu te\u017c uda\u0142o si\u0119 dogoni\u0107 cz\u0142owieka?", "tokens": [51688, 19832, 2604, 9516, 44544, 5249, 3244, 3000, 266, 12757, 36282, 2330, 30, 51812], "temperature": 0.0, "avg_logprob": -0.12811109608617322, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.004534591920673847}, {"id": 184, "seek": 71032, "start": 710.32, "end": 715.0400000000001, "text": " I tu dochodzimy do kluczowego wniosku, w kt\u00f3rym autorzy prace s\u0105 bardzo szczerze.", "tokens": [50364, 286, 2604, 9243, 378, 89, 13189, 360, 9671, 1311, 89, 26576, 45368, 2717, 5279, 11, 261, 30120, 19510, 1229, 582, 617, 9015, 9034, 22090, 260, 1381, 13, 50600], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 185, "seek": 71032, "start": 715.0400000000001, "end": 716.6400000000001, "text": " Nie, nie uda\u0142o si\u0119.", "tokens": [50600, 12016, 11, 2838, 44544, 5249, 3244, 13, 50680], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 186, "seek": 71032, "start": 716.6400000000001, "end": 717.7600000000001, "text": " A\u017c tak.", "tokens": [50680, 316, 1427, 991, 13, 50736], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 187, "seek": 71032, "start": 717.7600000000001, "end": 724.5600000000001, "text": " Mimo ogromnego post\u0119pu, wci\u0105\u017c istnieje wyra\u017ana luka mi\u0119dzy modelem a ludzkim poziomem w tych dw\u00f3ch obszarach.", "tokens": [50736, 376, 6934, 34416, 298, 11858, 2183, 18085, 84, 11, 261, 537, 27242, 1418, 2766, 2884, 4628, 424, 10659, 629, 287, 13599, 33964, 4391, 10386, 257, 15946, 89, 25112, 38503, 423, 76, 261, 15180, 27379, 812, 339, 3181, 26236, 608, 13, 51076], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 188, "seek": 71032, "start": 724.5600000000001, "end": 731.5200000000001, "text": " Model jest o wiele bezpieczniejszy i bardziej prawdom\u00f3wny ni\u017c przedtem, ale wci\u0105\u017c jest daleki od doskona\u0142o\u015bci.", "tokens": [51076, 17105, 3492, 277, 33137, 47153, 3689, 10402, 7706, 741, 27209, 41175, 298, 812, 43682, 28502, 18334, 18275, 11, 6775, 261, 537, 27242, 3492, 11702, 14753, 3611, 4491, 74, 4037, 35059, 13, 51424], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 189, "seek": 71032, "start": 731.5200000000001, "end": 734.4000000000001, "text": " Czyli to nie jest ostateczne rozwi\u0105zanie problemu?", "tokens": [51424, 37099, 281, 2838, 3492, 277, 15406, 38491, 9544, 22620, 7155, 1154, 84, 30, 51568], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 190, "seek": 71032, "start": 734.4000000000001, "end": 739.5200000000001, "text": " Absolutnie nie. I to jest si\u0142a tej pracy. Ona nie twierdzi, \u017ce problem jest rozwi\u0105zany.", "tokens": [51568, 5813, 2308, 2766, 2838, 13, 286, 281, 3492, 1511, 5024, 12573, 35591, 13, 49793, 2838, 683, 811, 67, 3992, 11, 3561, 1154, 3492, 9544, 22620, 1325, 13, 51824], "temperature": 0.0, "avg_logprob": -0.10745999885327888, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.010091733187437057}, {"id": 191, "seek": 73952, "start": 739.52, "end": 742.64, "text": " Ona pokazuje niezwykle pot\u0119\u017cn\u0105 metodologi\u0119.", "tokens": [50364, 49793, 13010, 43317, 33511, 9726, 14677, 1847, 1274, 1427, 13113, 1131, 378, 1132, 5034, 13, 50520], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 192, "seek": 73952, "start": 742.64, "end": 744.0799999999999, "text": " Drogowskaz.", "tokens": [50520, 413, 6675, 1509, 74, 921, 13, 50592], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 193, "seek": 73952, "start": 744.0799999999999, "end": 745.68, "text": " Dok\u0142adnie.", "tokens": [50592, 29768, 10358, 2766, 13, 50672], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 194, "seek": 73952, "start": 745.68, "end": 758.24, "text": " Dowodzi, \u017ce celowy kierowany przez cz\u0142owieka Fine Tuning jest o wiele wiele skuteczniejszy w radzeniu sobie z tak subtelnymi wyzwaniami ni\u017c \u015blep\u0119 dorzucanie kolejnych miliard\u00f3w parametr\u00f3w.", "tokens": [50672, 20947, 14543, 11, 3561, 9277, 10089, 38767, 23341, 14064, 36282, 2330, 12024, 21363, 278, 3492, 277, 33137, 33137, 1110, 1169, 3689, 10402, 7706, 261, 2843, 39651, 13652, 710, 991, 7257, 338, 31813, 4628, 89, 7916, 15568, 28502, 8299, 306, 79, 1274, 26313, 89, 1311, 7155, 23749, 9399, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51300], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 195, "seek": 73952, "start": 758.24, "end": 761.28, "text": " To jest mapa drogowa, a nie koniec podr\u00f3\u017cy.", "tokens": [51300, 1407, 3492, 44025, 3789, 70, 5528, 11, 257, 2838, 5897, 35733, 2497, 11721, 7735, 13, 51452], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 196, "seek": 73952, "start": 761.28, "end": 764.0, "text": " A co z bardziej kreatywnymi zastosowaniami?", "tokens": [51452, 316, 598, 710, 27209, 350, 620, 88, 43682, 3057, 36746, 329, 37345, 15568, 30, 51588], "temperature": 0.0, "avg_logprob": -0.13551214264660347, "compression_ratio": 1.3891050583657587, "no_speech_prob": 0.004766950383782387}, {"id": 197, "seek": 76400, "start": 764.0, "end": 770.88, "text": " W artygule jest jeszcze jeden ciekawy przyk\u0142ad, gdzie model wciela si\u0119 w role. G\u00f3ry.", "tokens": [50364, 343, 594, 874, 70, 2271, 3492, 14168, 12906, 46419, 41961, 23144, 11, 18922, 2316, 261, 537, 4053, 3244, 261, 3090, 13, 460, 812, 627, 13, 50708], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 198, "seek": 76400, "start": 770.88, "end": 775.2, "text": " Tak, Mount Everestu. Nazywaj\u0105 to Domain Grounding.", "tokens": [50708, 9118, 11, 8426, 47591, 84, 13, 11870, 27112, 11133, 281, 16674, 491, 2606, 24625, 13, 50924], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 199, "seek": 76400, "start": 775.2, "end": 779.2, "text": " Pokazuje to, jak elastyczny staje si\u0119 model po takim treningu.", "tokens": [50924, 14958, 43317, 281, 11, 4207, 806, 9820, 3689, 1634, 342, 11153, 3244, 2316, 714, 31732, 2192, 773, 84, 13, 51124], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 200, "seek": 76400, "start": 779.2, "end": 783.12, "text": " Wystarczy prosta instrukcja na pocz\u0105tku rozmowy. Co\u015b w stylu.", "tokens": [51124, 14458, 9710, 6522, 582, 8638, 1058, 25126, 34056, 1667, 43959, 35234, 10089, 13, 3066, 1788, 261, 7952, 2781, 13, 51320], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 201, "seek": 76400, "start": 783.12, "end": 787.44, "text": " Cze\u015b\u0107. Jestem Mount Everest. Mo\u017cesz zadawa\u0107 mi pytania.", "tokens": [51320, 383, 1381, 7753, 13, 24918, 443, 8426, 47591, 13, 44736, 10430, 710, 1538, 25234, 2752, 25878, 5609, 13, 51536], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 202, "seek": 76400, "start": 787.44, "end": 790.64, "text": " I co? Model zaczyna odpowiada\u0107 z perspektywy g\u00f3ry?", "tokens": [51536, 286, 598, 30, 17105, 43811, 629, 24314, 39018, 2162, 710, 868, 32659, 874, 9726, 290, 812, 627, 30, 51696], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 203, "seek": 76400, "start": 790.64, "end": 791.68, "text": " Dok\u0142adnie.", "tokens": [51696, 29768, 10358, 2766, 13, 51748], "temperature": 0.0, "avg_logprob": -0.16532201909307223, "compression_ratio": 1.3851590106007068, "no_speech_prob": 0.20846374332904816}, {"id": 204, "seek": 79168, "start": 791.68, "end": 798.4799999999999, "text": " Przyjmuje t\u0119 rol\u0119 i co najwa\u017cniejsze, kiedy podaje fakty, np. o swojej wysoko\u015bci czy pierwszych zdobywcach,", "tokens": [50364, 39590, 35195, 13008, 32489, 34109, 1274, 741, 598, 11212, 27111, 44258, 11, 18777, 2497, 11153, 33647, 874, 11, 33808, 13, 277, 29489, 73, 27062, 13704, 6199, 6430, 34016, 339, 16221, 13944, 86, 66, 608, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 205, "seek": 79168, "start": 798.4799999999999, "end": 804.4, "text": " cz\u0119sto korzysta z tego samego mechanizmu Toolset, by upewni\u0107 si\u0119, \u017ce jego odpowiedzi s\u0105 zgodne z prawd\u0105.", "tokens": [50704, 34369, 14784, 49590, 710, 8627, 912, 1571, 4236, 590, 20140, 15934, 3854, 11, 538, 493, 68, 895, 12757, 3244, 11, 3561, 26542, 36574, 3992, 9015, 710, 21787, 716, 710, 41175, 1611, 13, 51000], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 206, "seek": 79168, "start": 804.4, "end": 806.2399999999999, "text": " A model bez tego treningu?", "tokens": [51000, 316, 2316, 10782, 8627, 2192, 773, 84, 30, 51092], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 207, "seek": 79168, "start": 806.2399999999999, "end": 812.4, "text": " Dla por\u00f3wnania pokazuj\u0105 te\u017c odpowied\u017a modelu bez tego specjalistycznego Fine Tuning.", "tokens": [51092, 413, 875, 1515, 812, 895, 5609, 13010, 921, 13263, 9516, 36574, 10659, 2316, 84, 10782, 8627, 46433, 468, 17466, 11858, 12024, 21363, 278, 13, 51400], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 208, "seek": 79168, "start": 812.4, "end": 819.68, "text": " Na pytanie o wysoko\u015b\u0107 potrafi odpowiedzie\u0107 w spos\u00f3b wr\u0119cz niegrzeczny, bo nie rozumie kontekstu odgrywania roli.", "tokens": [51400, 6056, 36610, 277, 27062, 13704, 7753, 1847, 10437, 72, 24314, 22078, 261, 22904, 928, 1274, 3689, 2838, 861, 1381, 3689, 1634, 11, 748, 2838, 48797, 414, 14373, 916, 372, 84, 3611, 70, 47705, 5609, 744, 2081, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 209, "seek": 79168, "start": 819.68, "end": 820.8, "text": " Rozumiem.", "tokens": [51764, 43313, 449, 4907, 13, 51820], "temperature": 0.0, "avg_logprob": -0.10112989722908318, "compression_ratio": 1.4654088050314464, "no_speech_prob": 0.012767765671014786}, {"id": 210, "seek": 82080, "start": 820.88, "end": 827.1999999999999, "text": " Fine Tuning nadaje mu nie tylko wiedz\u0119, ale i odpowiedni\u0105, powiedzmy, osobowo\u015b\u0107 do zadania.", "tokens": [50368, 12024, 21363, 278, 8096, 2884, 2992, 2838, 13219, 46894, 11052, 11, 6775, 741, 36574, 3722, 1611, 11, 27617, 2226, 11, 19116, 8202, 78, 7753, 360, 42788, 5609, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10546147562291501, "compression_ratio": 1.5337837837837838, "no_speech_prob": 0.0012351216282695532}, {"id": 211, "seek": 82080, "start": 827.1999999999999, "end": 833.76, "text": " Zbieraj\u0105c to wszystko razem, wydaje si\u0119, \u017ce Lambda to nie jest po prostu kolejny wielki model j\u0119zykowy.", "tokens": [50684, 1176, 65, 811, 38757, 281, 22607, 40225, 11, 49165, 3244, 11, 3561, 45691, 281, 2838, 3492, 714, 19518, 23749, 1634, 20570, 2984, 2316, 49055, 74, 10089, 13, 51012], "temperature": 0.0, "avg_logprob": -0.10546147562291501, "compression_ratio": 1.5337837837837838, "no_speech_prob": 0.0012351216282695532}, {"id": 212, "seek": 82080, "start": 833.76, "end": 834.24, "text": " Nie.", "tokens": [51012, 12016, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10546147562291501, "compression_ratio": 1.5337837837837838, "no_speech_prob": 0.0012351216282695532}, {"id": 213, "seek": 82080, "start": 834.24, "end": 840.4799999999999, "text": " To bardziej przepis na to, jak uczyni\u0107 te modele bardziej u\u017cytecznymi i odpowiedzialnymi.", "tokens": [51036, 1407, 27209, 30829, 271, 1667, 281, 11, 4207, 344, 6522, 3722, 2162, 535, 4391, 306, 27209, 34097, 975, 3689, 31813, 741, 24314, 15338, 831, 31813, 13, 51348], "temperature": 0.0, "avg_logprob": -0.10546147562291501, "compression_ratio": 1.5337837837837838, "no_speech_prob": 0.0012351216282695532}, {"id": 214, "seek": 82080, "start": 840.4799999999999, "end": 850.0, "text": " Kluczowy wniosek jest chyba taki, \u017ce nauczenie modelu jak i kiedy ma sprawdza\u0107 swoj\u0105 prac\u0119 jest r\u00f3wnie wa\u017cne, jak nauczenie go jak w og\u00f3le pisa\u0107.", "tokens": [51348, 16053, 1311, 89, 10089, 261, 3722, 541, 74, 3492, 31532, 20065, 11, 3561, 49103, 16778, 2316, 84, 4207, 741, 18777, 463, 46192, 35873, 49194, 22404, 1274, 3492, 11416, 14215, 46110, 11, 4207, 49103, 16778, 352, 4207, 261, 29229, 280, 3837, 2162, 13, 51824], "temperature": 0.0, "avg_logprob": -0.10546147562291501, "compression_ratio": 1.5337837837837838, "no_speech_prob": 0.0012351216282695532}, {"id": 215, "seek": 85000, "start": 850.0, "end": 851.44, "text": " Idealne podsumowanie.", "tokens": [50364, 13090, 304, 716, 31925, 449, 22028, 13, 50436], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 216, "seek": 85000, "start": 851.44, "end": 854.24, "text": " W punkt. To jest zmiana paradygmatu.", "tokens": [50436, 343, 39561, 13, 1407, 3492, 17020, 8497, 13480, 18103, 15677, 84, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 217, "seek": 85000, "start": 854.24, "end": 860.0, "text": " Przechodzimy od my\u015blenia w kategoriach wi\u0119cej, szybciej, mocniej, czyli czystego skalowania.", "tokens": [50576, 2114, 19439, 378, 89, 13189, 3611, 48633, 6698, 654, 261, 350, 2968, 7386, 608, 26004, 11, 36456, 4260, 73, 11, 34962, 10402, 11, 16591, 6430, 372, 6308, 16890, 21308, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 218, "seek": 85000, "start": 860.0, "end": 861.2, "text": " W kierunku kreatyw.", "tokens": [50864, 343, 38767, 49910, 350, 620, 27112, 13, 50924], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 219, "seek": 85000, "start": 861.2, "end": 869.12, "text": " W kierunku wbudowywania w architektur\u0119 modelu mechanizm\u00f3w, refleksji, bezpiecze\u0144stwa i weryfikacji fakt\u00f3w.", "tokens": [50924, 343, 38767, 49910, 261, 18281, 10089, 86, 5609, 261, 3912, 642, 2320, 374, 1274, 2316, 84, 4236, 590, 76, 3901, 11, 36549, 1694, 4013, 11, 47153, 9680, 12229, 4151, 741, 261, 2109, 31230, 13152, 21310, 3901, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 220, "seek": 85000, "start": 869.12, "end": 873.36, "text": " To przej\u015bcie od surowej si\u0142y do prawdziwej inteligencji.", "tokens": [51320, 1407, 8325, 73, 9815, 3611, 1022, 21091, 1511, 6825, 360, 41175, 3992, 826, 73, 24777, 3213, 19649, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 221, "seek": 85000, "start": 873.36, "end": 876.96, "text": " To wszystko prowadzi nas do pewnej ingryguj\u0105cej my\u015bli na koniec?", "tokens": [51532, 1407, 22607, 36590, 3992, 5382, 360, 25889, 11794, 3957, 627, 2794, 8555, 20811, 452, 15350, 1667, 5897, 35733, 30, 51712], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 222, "seek": 85000, "start": 876.96, "end": 877.84, "text": " Tak.", "tokens": [51712, 9118, 13, 51756], "temperature": 0.0, "avg_logprob": -0.1210125986735026, "compression_ratio": 1.4664310954063604, "no_speech_prob": 0.055268339812755585}, {"id": 223, "seek": 87784, "start": 877.84, "end": 885.0400000000001, "text": " Autorzy prace sami o tym wspominaj\u0105 o ryzyku antropomorfizacji, czyli pod\u015bwiadomego traktowania a i jak cz\u0142owieka.", "tokens": [50364, 6049, 284, 1229, 582, 617, 3247, 72, 277, 8107, 17757, 49217, 8555, 277, 20791, 1229, 5279, 2511, 1513, 298, 28030, 590, 13152, 11, 16591, 2497, 37750, 423, 1571, 944, 2320, 21308, 257, 741, 4207, 36282, 2330, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 224, "seek": 87784, "start": 885.0400000000001, "end": 885.84, "text": " Mhm.", "tokens": [50724, 26272, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 225, "seek": 87784, "start": 885.84, "end": 897.12, "text": " I w miar\u0119 jak te modele staj\u0105 si\u0119 coraz lepsze w przyjmowaniu r\u00f3l takich jak Mount Everest i udzielaniu ugruntowanych w faktach ciekawych odpowiedzi pojawia si\u0119 nowe, g\u0142\u0119ksze pytanie.", "tokens": [50764, 286, 261, 2752, 289, 1274, 4207, 535, 4391, 306, 342, 11133, 3244, 25899, 476, 1878, 1381, 261, 6501, 35195, 305, 25849, 11416, 75, 29607, 4207, 8426, 47591, 741, 11727, 42280, 25849, 344, 861, 2760, 23341, 339, 261, 21310, 608, 46419, 1607, 16384, 36574, 3992, 30655, 654, 3244, 586, 68, 11, 290, 46564, 1694, 1381, 36610, 13, 51328], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 226, "seek": 87784, "start": 897.12, "end": 899.0400000000001, "text": " I to ju\u017c nie jest pytanie techniczne?", "tokens": [51328, 286, 281, 10678, 2838, 3492, 36610, 1537, 17946, 716, 30, 51424], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 227, "seek": 87784, "start": 899.0400000000001, "end": 904.8000000000001, "text": " Nie. Ju\u017c nie tylko czy potrafimy technicznie uczyni\u0107 a i prawdom\u00f3wn\u0105 i bezpieczn\u0105?", "tokens": [51424, 12016, 13, 13582, 1427, 2838, 13219, 6430, 1847, 10437, 13189, 1537, 17946, 2766, 344, 6522, 3722, 2162, 257, 741, 41175, 298, 3901, 13113, 741, 47153, 3689, 13113, 30, 51712], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 228, "seek": 87784, "start": 904.8000000000001, "end": 906.1600000000001, "text": " Pytanie brzmi?", "tokens": [51712, 430, 4328, 7155, 738, 89, 3057, 30, 51780], "temperature": 0.0, "avg_logprob": -0.1339236544324206, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.021551935002207756}, {"id": 229, "seek": 90616, "start": 906.16, "end": 916.3199999999999, "text": " Jakie s\u0105 etyczne implikacje sytuacji, w kt\u00f3rej prawdom\u00f3wna i bezpieczna a i staje si\u0119 tak dobra w konwersacji, \u017ce zaczynamy zapomina\u0107, \u017ce po drugiej stronie nie ma \u017cadnej osoby?", "tokens": [50364, 15029, 414, 9015, 1030, 17466, 716, 8484, 1035, 29293, 28275, 13152, 11, 261, 36023, 41175, 298, 3901, 629, 741, 47153, 3689, 629, 257, 741, 342, 11153, 3244, 991, 360, 6198, 261, 5897, 5364, 13152, 11, 3561, 43811, 5378, 88, 14223, 49217, 2162, 11, 3561, 714, 47373, 1056, 32242, 2838, 463, 39628, 11794, 39737, 30, 50872], "temperature": 0.0, "avg_logprob": -0.09835986087196752, "compression_ratio": 1.2416107382550337, "no_speech_prob": 0.06337340921163559}], "language": "pl"}