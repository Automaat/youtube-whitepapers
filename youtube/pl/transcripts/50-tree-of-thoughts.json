{"text": " Spr\u00f3bujmy rozwi\u0105za\u0107 tak\u0105 zagadk\u0119. Gra w 24. Mamy cztery liczby, no powiedzmy, 4, 9, 10 i 13. I teraz trzeba z nich, u\u017cywaj\u0105c prostych dzia\u0142a\u0144, uzyska\u0107 wynik 24. Wi\u0119kszo\u015b\u0107 z nas pewnie \u0142apie si\u0119 pierwszej my\u015bli, na przyk\u0142ad, aha, 10-4 to jest 6. No i potem pr\u00f3bujemy co\u015b zrobi\u0107 z t\u0105 6, 9, 13. I je\u015bli to nie dzia\u0142a, no to cz\u0119sto wpadamy w takie \u015blepy za\u0142ek. A co gdyby mo\u017cna by\u0142o my\u015ble\u0107 inaczej? Bada\u0107 nie jedn\u0105, ale na przyk\u0142ad 10 r\u00f3\u017cnych \u015bcie\u017cek naraz. Jakby nasz umys\u0142, wiesz, rozga\u0142\u0119zia\u0142 si\u0119 jak drzewo, a jaka\u015b wewn\u0119trzna intuicja m\u00f3wi\u0142a, ta ga\u0142\u0105\u017a jest super, a tamta to strata czasu. Dzisiaj mamy na stole artyku\u0142 naukowy, kt\u00f3ry uczy du\u017ce modele j\u0119zykowe w\u0142a\u015bnie takiego podej\u015bcia. Nazywa si\u0119 Tree of Thoughts \u2013 Deliberate Problem Solving with Large Language Models. I od razu powiem, to nie jest jaka\u015b nowa, sprytna sztuczka z promptowaniem. To wygl\u0105da na co\u015b o wiele g\u0142\u0119bszego, na fundamentalnie now\u0105 ram\u0119 dla maszynowego rozumiewania. Zdecygowanie. I \u017ceby w pe\u0142ni wiesz, doceni\u0107 wag\u0119 tego, trzeba zrozumie\u0107, gdzie jeste\u015bmy teraz. Nawet najpot\u0119\u017cniejsze modele jak GPT-4 dzia\u0142aj\u0105 w spos\u00f3b, kt\u00f3ry jest bardzo liniowy. Generuj\u0105 odpowied\u017a token po tokenie od lewej do prawej. To bardzo przypomina to, co psycholog Daniel Kahneman nazwa\u0142 my\u015bleniem Systemu 1. Czyli to takie szybkie, intuicyjne, prawie automatyczne my\u015blenie. To co nam podpowiada, \u017ce 2 plus 2 to 4 bez zastanowienia? Dok\u0142adnie. Jest niesamowicie wydajne, ale ma swoje powa\u017cne ograniczenia. Zawodzi w zadaniach, kt\u00f3re wymagaj\u0105 planowania, strategii, rozwa\u017cania wielu alternatyw. A przede wszystkim zdolno\u015bci do wycofania si\u0119 z b\u0142\u0119du. A to wszystko s\u0105 cechy Systemu 2 tego powolnego, analitycznego, \u015bwiadomego my\u015blenia. I do tej pory pr\u00f3bowali\u015bmy to jako\u015b symulowa\u0107 za pomoc\u0105 techniki znanej jako Chain of Thought, czyli COT, prawda? Prosili\u015bmy model, \u017ceby my\u015bla\u0142 na g\u0142os krok po kroku. Tak. I to by\u0142 du\u017cy krok do przodu. Zamiast samej odpowiedzi dostawali\u015bmy ca\u0142y proces. Ale to wci\u0105\u017c by\u0142 tylko jeden pojedynczy \u0142a\u0144cuch my\u015bli. Je\u015bli model na samym pocz\u0105tku pope\u0142ni\u0142 jaki\u015b ma\u0142y b\u0142\u0105d, przyj\u0105\u0142 z\u0142\u0105 strategi\u0119... To ju\u017c by\u0142o po wszystkim. No w\u0142a\u015bnie. Ca\u0142e rozwi\u0105zanie by\u0142o skazane na pora\u017ck\u0119. Nie by\u0142o \u017cadnego mechanizmu korekty, \u017cadnego planu B. OK. To roz\u0142\u00f3\u017cmy to na czynniki pierwsze. W takim razie, jak Tree of Thought zmienia t\u0119 gr\u0119. Na czym polega ta rewolucja? Zmienia j\u0105, bo zamiast jednego \u0142a\u0144cucha tworzy ca\u0142e drzewo mo\u017cliwo\u015bci. Troch\u0119 czerpie inspiracje z takich wiesz, klasycznych metod sztucznej inteligencji. Autorzy rozbili ten proces na cztery g\u0142\u00f3wne elementy. Pierwszy to jest thought decomposition, czyli dekompozycja my\u015bli. Czyli problem jest dzielony na mniejsze, sensowne kroki. Dok\u0142adnie. I co jest wa\u017cne, ta my\u015bl to nie jest po prostu kolejne s\u0142owo, tak? To jest co\u015b wi\u0119kszego. W naszej grze w 24 to by\u0142oby ca\u0142e r\u00f3wnanie na przyk\u0142ad 10, 4, r\u00f3wna si\u0119 6. W\u0142a\u015bnie o to chodzi. To nadaje struktur\u0119. Drugi element to thought generator. I tu zaczyna si\u0119 jakby ca\u0142a magia. Na ka\u017cdym kroku model nie generuje jednej kontynuacji. Ale kilka, a czasem nawet kilkana\u015bcie potencjalnych my\u015bli, tworzy nowe ga\u0142\u0119zie. A, czyli tworzymy wachlarz mo\u017cliwo\u015bci zamiast stawia\u0107 wszystko na jedn\u0105 kart\u0119. Ale sk\u0105d model wie, kt\u00f3r\u0105 ga\u0142\u0105\u017a wybra\u0107? I tu dochodzimy do trzeciego i by\u0107 mo\u017ce najwa\u017cniejszego elementu. State Evaluator. To jest ta wewn\u0119trzna intuicja, o kt\u00f3rej m\u00f3wi\u0142a\u015b na pocz\u0105tku. Sam model j\u0119zykowy jest proszony o ocen\u0119 ka\u017cdej z wygenerowanych ga\u0142\u0119ci. Dzia\u0142a jak taki wewn\u0119trzny krytyk, kt\u00f3ry m\u00f3wi, ta \u015bcie\u017cka jest pewna, ta jest obiecuj\u0105ca, a t\u0119 mo\u017cna porzuci\u0107. Chwila, ale czy to nie jest troch\u0119 jak w\u0105\u017c zjadaj\u0105cy w\u0142asny ogon? Ten sam model, kt\u00f3ry generuje pomys\u0142y, ma je potem ocenia\u0107. Sk\u0105d pewno\u015b\u0107, \u017ce jego ocena jest, no wiesz, obiektywnie dobra? To jest doskona\u0142e pytanie i sedno sprawy. Oczywi\u015bcie istnieje takie ryzyko. Ale autorzy pokazuj\u0105, \u017ce nawet niedoskona\u0142a ocena jest orz\u0119dy wielko\u015bci lepsza ni\u017c brak jakiejkolwiek oceny. Model oceniaj\u0105c jest zmuszony do przyj\u0119cia innej perspektywy krytycznej, a nie tylko generatywnej. Poza tym ta ocena nie musi by\u0107 idealna. Wystarczy, \u017ce odsieje te najbardziej absurdalne \u015bcie\u017cki. Rozumiem, czyli nawet prosty filtr jest lepszy ni\u017c \u017caden. A co z czwartym elementem? Czwarte element to search-algorytm, czyli algorytm przeszukiwania. Kiedy mamy ju\u017c drzewo i spos\u00f3b oceny, mo\u017cemy u\u017cy\u0107 systematycznych metod, \u017ceby je eksplorowa\u0107. Autorzy testowali dwa klasyki, breath-first-search, czyli BFS. Przeszukiwanie w search, poziom po poziomie? Tak. I drugi, depth-first-search, czyli DFS, przeszukiwanie w g\u0142\u0105b. I ten drugi wydaje si\u0119 kluczowy dla problem\u00f3w, w kt\u00f3rych trzeba si\u0119 cofa\u0107. Pozwaza na tak zwany backtracking. Idziesz jedn\u0105 \u015bcie\u017ck\u0105, dochodzisz do \u015bciany, wi\u0119c wracasz i probujesz innej drogi. Tego brakowa\u0142o w Chain of Thought. Dok\u0142adnie. To jest wbudowany mechanizm przyznawania si\u0119 do b\u0142\u0119du i korygowania kursu. I tu robi si\u0119 naprawd\u0119 ciekawie. Teoria brzmi pot\u0119\u017cnie. Ale teoria to jedno. Jakie s\u0105 dowody? Autorzy przetestowali Tree of Thought na w trzech bardzo r\u00f3\u017cnych i, co wa\u017cne, bardzo trudnych zadaniach. Zacznijmy od naszej gry w 24. Wyniki s\u0105, no, po prostu mia\u017cd\u017c\u0105ce. Ten sam model GPT-4, u\u017cywaj\u0105c standardowego promptowania z Chain of Thought, rozwi\u0105za\u0142 poprawnie zaledwie 4% zada\u0144. Tylko 4 na 100. To pokazuje, jak trudny jest to problem dla maszyny. A teraz uwaga. Ten sam model, zna\u0142o\u017conym frameworkiem Tree of Thoughts, osi\u0105gn\u0105\u0142 skuteczno\u015b\u0107 na poziomie 74%. Wow, z 4 na 74%. To nie jest poprawa, to jest przepa\u015b\u0107. To jest zupe\u0142nie inna kategoria wydajno\u015bci. Przeskok z pora\u017cki do niezawodno\u015bci. Jak to w og\u00f3le mo\u017cliwe? Jak to dzia\u0142a\u0142o w praktyce? Bardzo elegancko. Na ka\u017cdym etapie COT generowa\u0142o kilka mo\u017cliwych dzia\u0142a\u0144. A potem ewaluator, czyli sam model, ocenia\u0142 ich potencja\u0142. Na przyk\u0142ad, je\u015bli po pierwszym kroku zosta\u0142y nam liczby 1, 2 i 3, model by\u0142 proszony o ocen\u0119 czy z tego da si\u0119 doj\u015b\u0107 do 24. I co odpowiada\u0142? M\u00f3wi\u0142, niemo\u017cliwe, liczby s\u0105 zbyt ma\u0142e. I ca\u0142a ta ga\u0142\u0105\u017a by\u0142a odcinana. Nie marnowano na ni\u0105 wi\u0119cej zasob\u00f3w. To jest w\u0142a\u015bnie to celowe rozumowanie systemu 2 w akcji. A m\u00f3wi\u0142e\u015b o analizie b\u0142\u0119d\u00f3w w Chain of Thought. By\u0142a odkrywcza? Tak, pokaza\u0142a brutaln\u0105 prawd\u0119. A\u017c 60% nieudanych pr\u00f3b z COT ko\u0144czy\u0142o si\u0119 pora\u017ck\u0105 ju\u017c na pierwszym kroku. A\u017c tyle? Model wybiera\u0142 jedno, nieoptymalne dzia\u0142anie na pocz\u0105tku i by\u0142 ugotowany. Niesamowite. To jest zmiana orz\u0105d wielko\u015bci. Czyli w zadaniach z jedn\u0105, tward\u0105 odpowiedzi\u0105, jak matematyka, COT jest bezkonkurencyjne. Ale czy ta sama logika sprawdzi si\u0119 w czym\u015b bardziej rozmytym, gdzie nie ma jednej dobrej odpowiedzi, a liczy si\u0119 kreatywno\u015b\u0107? I to prowadzi nas prosto do drugiego eksperymentu. Kreatywnego pisania. Zadanie by\u0142o piekielnie trudne. Model musia\u0142 napisa\u0107 sp\u00f3jny tekst z czterech akapit\u00f3w, gdzie ka\u017cdy akapit musia\u0142 ko\u0144czy\u0107 si\u0119 jednym z czterech z g\u00f3ry narzuconych, losowych zda\u0144. To brzmi jak koszmar. Nawet dla cz\u0142owieka by\u0142oby to wyzwanie, \u017ceby stworzy\u0107 co\u015b, co ma sens. No w\u0142a\u015bnie, a Tree of Thoughts podesz\u0142o do tego strategicznie. Najpierw model nie pisa\u0142 tekstu, tylko generowa\u0142 pi\u0119\u0107 r\u00f3\u017cnych og\u00f3lnych plan\u00f3w na ca\u0142e opowiadanie. Potem sam na siebie g\u0142osowa\u0142, ocenia\u0142, kt\u00f3ry z tych plan\u00f3w jest najbardziej sp\u00f3jny i obiecuj\u0105cy. To jest fascynuj\u0105ce. Model dzia\u0142a jak w\u0142asny redaktor, kt\u00f3ry wybiera najlepsz\u0105 koncepcj\u0119, zanim w og\u00f3le zacznie pisa\u0107. W\u0142a\u015bnie, a to nie koniec. Na podstawie tego jednego zwyci\u0119skiego planu generowa\u0142 pi\u0119\u0107 pe\u0142nych wersji tekstu i znowu g\u0142osowa\u0142, by wybra\u0107 t\u0119 ostateczn\u0105. A efekt? Zar\u00f3wno ocena automatyczna jak i ludzka wykaza\u0142y, \u017ce teksty Stot by\u0142y znacznie bardziej sp\u00f3jne. Co wi\u0119cej, ludzie w \u015blepej pr\u00f3bie preferowali wersj\u0119 Tot nad wersj\u0105 Kot w stosunku niemal dwa do jednego. Mamy wi\u0119c logik\u0119, mamy kreatywno\u015b\u0107. Zosta\u0142 nam trzeci przyk\u0142ad, kt\u00f3ry, jak rozumiem, mia\u0142 przetestowa\u0107 t\u0119 zdolno\u015b\u0107 do cofania si\u0119. Krzy\u017c\u00f3wka. Dok\u0142adnie. Mini krzy\u017c\u00f3wki pi\u0119\u0107 na pi\u0119\u0107. Tutaj kluczowy by\u0142 algorytm Depth First Search z opcj\u0105 Backtracking. Model dzia\u0142a\u0142 jak cz\u0142owiek. Pr\u00f3bowa\u0142 wpisa\u0107 jedno s\u0142owo. Potem, na podstawie liter, pr\u00f3bowa\u0142 kolejne, pasuj\u0105ce. A\u017c dochodzi\u0142 do momentu, w kt\u00f3rym orientowa\u0142 si\u0119, \u017ce ktory\u015b has\u0142o sta\u0142o si\u0119 niemo\u017cliwe do uzupe\u0142nienia i wtedy musia\u0142 si\u0119 cofn\u0105\u0107. I spr\u00f3bowa\u0107 innego s\u0142owa w poprzednim kroku. Jakby wymaza\u0142 o\u0142\u00f3wkiem has\u0142o i spr\u00f3bowa\u0142 innej opcji. I tu znowu widzimy ogromn\u0105 przepa\u015b\u0107. Standardowe metody mia\u0142y poni\u017cej 16% poprawno\u015bci na poziomie s\u0142\u00f3w. Tree of Tots dobi\u0142o do 60% poprawno\u015bci i w ca\u0142o\u015bci rozwi\u0105za\u0142o 4 z 20 krzy\u017c\u00f3wek. A pozosta\u0142e metody? Ani jednej. W najlepszym radzie po wielu pr\u00f3bach jedn\u0105. To pokazuje, \u017ce dla pewnej klasy problem\u00f3w zdolno\u015b\u0107 do systematycznej eksploracji korygowania b\u0142\u0119d\u00f3w nie jest dodatkiem. Jest absolutnie kluczowa. S\u0142uchaj\u0105c tego wszystkiego mam wra\u017cenie, \u017ce to nie jest po prostu kolejna zaawansowana technika promptowania. To wygl\u0105da na co\u015b znacznie wi\u0119kszego, na now\u0105 architektur\u0119 rozumowania. Cietnie to uj\u0119\u0142a\u015b. Tree of Tots to nie jest prompt, to jest framework. To spos\u00f3b na po\u0142\u0105czenie dw\u00f3ch \u015bwiat\u00f3w. Z jednej strony ogromnej generatywnej mocy LLM-\u00f3w, a z drugiej systematycznej ustrukturyzowanej eksploracji znanej z klasycznych algorytm\u00f3w AI. Ale najwa\u017cniejsz\u0105 innowacj\u0105 jest to, \u017ce rol\u0119 heurystyki tego inteligentnego przewodnika pe\u0142ni sam model. On staje si\u0119 jednocze\u015bnie generatorem, planerem i krytycznym ewaluatorem. A to otwiera drzwi do zastosowa\u0144 w naprawd\u0119 z\u0142o\u017conych dziedzinach. My\u015bl\u0119 o generowaniu skomplikowanego kodu, gdzie jeden b\u0142\u0105d mo\u017ce zepsu\u0107 ca\u0142y problem. Tam zdolno\u015b\u0107 do eksploracji i cofania si\u0119 jest bezcenna. Zdecydowanie. Albo analiza danych, gdzie trzeba testowa\u0107 r\u00f3\u017cnych hipotezy. Czy nawet robotyka, gdzie robot musi zaplanowa\u0107 z\u0142o\u017con\u0105 sekwencj\u0119 ruch\u00f3w. Wsz\u0119dzie tam, gdzie nie ma jednej prostej \u015bcie\u017cki do celu, to podej\u015bcie ma oldrzymi potencja\u0142. Brzmi rewolucyjnie, ale musi by\u0107 jaki\u015b haczyk. Jakie s\u0105 wady tego podej\u015bcia? Gdzie jest koszt tej ca\u0142ej pot\u0119gi? Koszt jest bardzo dos\u0142owny. G\u0142\u00f3wnym ograniczeniem jest zasobo\u017cerno\u015b\u0107. Tree of Thots wymaga znacznie, znacznie wi\u0119cej mocy obliczeniowej i token\u00f3w ni\u017c standardowe promptowanie. To znaczy ile wi\u0119cej? Wr\u00f3\u0107my do gry w 24. Jedna udana pr\u00f3ba rozwi\u0105zania za pomoc\u0105 TOT zu\u017cy\u0142a podobn\u0105 liczb\u0119 token\u00f3w, co oko\u0142o 100 pr\u00f3b metod\u0105 Chain of Thot. 100 pr\u00f3b? To jest ogromna r\u00f3\u017cnica. Tak, ale jest tu wa\u017cny niuans. Mimo podobnego kosztu, TOT osi\u0105gn\u0119\u0142o 74% skuteczno\u015bci. A nawet je\u015bli z dmy Chain of Thot 100 pr\u00f3b i wzi\u0119li\u015bmy najlepszy wynik, to i tak jego skuteczno\u015b\u0107 wynios\u0142a tylko 49%. Czyli p\u0142acimy znacznie wi\u0119cej, ale nie za wi\u0119cej liczb\u0119 losowych strza\u0142\u00f3w, tylko za jeden dobrze zaplanowany. To kompromis mi\u0119dzy brutaln\u0105 si\u0142\u0105 a inteligencj\u0105. Dok\u0142adnie. P\u0142acimy za niezawodno\u015b\u0107. A w wielu zastosowaniach jedna odpowied\u017a z prawdopodobie\u0144stwem sukcesu 74% jest niesko\u0144czenie cenniejsza ni\u017c 100 odpowiedzi z prawdopodobie\u0144stwem 4%. Gdyby\u015b mia\u0142 podsumowa\u0107 esencj\u0119 Tree of Thot w jednym kluczowym zdaniu, jakby ono brzmia\u0142o. Powiedzia\u0142bym, \u017ce przewodzimy od modeli, kt\u00f3re s\u0105 genialnymi na\u015bladowcami i generuj\u0105 statystycznie prawdopodobny tekst do system\u00f3w, kt\u00f3re s\u0105 zdolne do celowego i ustrukturyzowanego rozwi\u0105zywania problem\u00f3w. To tak, jakby\u015bmy dali genialnemu, ale bardzo impulsywnemu umys\u0142owi systemu 1 narz\u0119dzia do metodycznego planowania i samokrytyki, czyli atrybuty systemu 2. To \u015bwietnie zamyka nasz\u0105 analiz\u0119, ale zostawi\u0119 jeszcze naszych s\u0142uchaczy z jedn\u0105 prowokacyjn\u0105 my\u015bl\u0105. Autorzy tej pracy skupili si\u0119 na zastosowaniu Tree of Thot jako takie nak\u0142adki na ju\u017c istniej\u0105ce modele. A teraz pomy\u017amy, co si\u0119 stanie, gdy zaczniemy trenowa\u0107 modele od podstaw, wbudowuj\u0105c w nie ten celowy, wielo\u015b\u0107 ci\u0119\u017ckowy i samokoryguj\u0105cy si\u0119 proces my\u015blenia na najbardziej fundamentalnym poziomie. Czy w\u0142a\u015bnie patrzymy na zarys fundamentalnie bardziej zaawansowanej formy sztucznej inteligencji?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.3, "text": " Spr\u00f3bujmy rozwi\u0105za\u0107 tak\u0105 zagadk\u0119. Gra w 24. Mamy cztery liczby, no powiedzmy, 4, 9, 10 i 13.", "tokens": [50364, 7702, 14216, 4579, 2226, 9544, 18234, 35873, 31069, 27001, 345, 15724, 13, 8985, 261, 4022, 13, 376, 7804, 6472, 12733, 6169, 89, 2322, 11, 572, 27617, 2226, 11, 1017, 11, 1722, 11, 1266, 741, 3705, 13, 50929], "temperature": 0.0, "avg_logprob": -0.2072487479762027, "compression_ratio": 1.219626168224299, "no_speech_prob": 0.012487438507378101}, {"id": 1, "seek": 0, "start": 11.3, "end": 17.7, "text": " I teraz trzeba z nich, u\u017cywaj\u0105c prostych dzia\u0142a\u0144, uzyska\u0107 wynik 24.", "tokens": [50929, 286, 16854, 25860, 710, 25570, 11, 34097, 86, 38757, 10293, 16384, 37903, 5248, 11, 16851, 749, 2330, 2162, 31936, 1035, 4022, 13, 51249], "temperature": 0.0, "avg_logprob": -0.2072487479762027, "compression_ratio": 1.219626168224299, "no_speech_prob": 0.012487438507378101}, {"id": 2, "seek": 0, "start": 17.7, "end": 25.5, "text": " Wi\u0119kszo\u015b\u0107 z nas pewnie \u0142apie si\u0119 pierwszej my\u015bli, na przyk\u0142ad, aha, 10-4 to jest 6.", "tokens": [51249, 30127, 1694, 4765, 7753, 710, 5382, 520, 14215, 25387, 569, 414, 3244, 27623, 16920, 452, 15350, 11, 1667, 23144, 11, 47340, 11, 1266, 12, 19, 281, 3492, 1386, 13, 51639], "temperature": 0.0, "avg_logprob": -0.2072487479762027, "compression_ratio": 1.219626168224299, "no_speech_prob": 0.012487438507378101}, {"id": 3, "seek": 2550, "start": 25.5, "end": 30.7, "text": " No i potem pr\u00f3bujemy co\u015b zrobi\u0107 z t\u0105 6, 9, 13.", "tokens": [50364, 883, 741, 36513, 8565, 65, 21767, 19241, 31785, 710, 32294, 1386, 11, 1722, 11, 3705, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 4, "seek": 2550, "start": 30.7, "end": 35.5, "text": " I je\u015bli to nie dzia\u0142a, no to cz\u0119sto wpadamy w takie \u015blepy za\u0142ek.", "tokens": [50624, 286, 25630, 281, 2838, 37903, 11, 572, 281, 34369, 261, 13647, 7804, 261, 15963, 8299, 306, 8200, 7949, 1221, 916, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 5, "seek": 2550, "start": 35.5, "end": 38.2, "text": " A co gdyby mo\u017cna by\u0142o my\u015ble\u0107 inaczej?", "tokens": [50864, 316, 598, 28405, 2322, 17790, 14811, 48633, 306, 2162, 33230, 16920, 30, 50999], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 6, "seek": 2550, "start": 38.2, "end": 42.8, "text": " Bada\u0107 nie jedn\u0105, ale na przyk\u0142ad 10 r\u00f3\u017cnych \u015bcie\u017cek naraz.", "tokens": [50999, 363, 1538, 2162, 2838, 5232, 13113, 11, 6775, 1667, 23144, 1266, 42602, 8299, 40082, 916, 6714, 921, 13, 51229], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 7, "seek": 2550, "start": 42.8, "end": 49.1, "text": " Jakby nasz umys\u0142, wiesz, rozga\u0142\u0119zia\u0142 si\u0119 jak drzewo, a jaka\u015b wewn\u0119trzna intuicja m\u00f3wi\u0142a,", "tokens": [51229, 15029, 2322, 5382, 89, 1105, 39508, 11, 261, 15347, 11, 9544, 3680, 46564, 40395, 1221, 3244, 4207, 1224, 43551, 78, 11, 257, 4207, 64, 1788, 321, 895, 1274, 6903, 35458, 560, 84, 299, 2938, 24592, 5024, 11, 51544], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 8, "seek": 2550, "start": 49.1, "end": 52.900000000000006, "text": " ta ga\u0142\u0105\u017a jest super, a tamta to strata czasu.", "tokens": [51544, 1846, 5959, 15926, 10659, 3492, 1687, 11, 257, 7677, 1328, 281, 1056, 3274, 40860, 13, 51734], "temperature": 0.0, "avg_logprob": -0.13058062962123326, "compression_ratio": 1.3392857142857142, "no_speech_prob": 0.15129540860652924}, {"id": 9, "seek": 5290, "start": 53.0, "end": 60.199999999999996, "text": " Dzisiaj mamy na stole artyku\u0142 naukowy, kt\u00f3ry uczy du\u017ce modele j\u0119zykowe w\u0142a\u015bnie takiego podej\u015bcia.", "tokens": [50369, 39448, 22356, 17335, 1667, 16326, 594, 874, 5279, 1221, 35616, 74, 10089, 11, 9913, 344, 6522, 1581, 2875, 4391, 306, 49055, 74, 6880, 14234, 32296, 7468, 73, 1788, 2755, 13, 50729], "temperature": 0.0, "avg_logprob": -0.08665543087458207, "compression_ratio": 1.3261648745519714, "no_speech_prob": 0.04925825446844101}, {"id": 10, "seek": 5290, "start": 60.199999999999996, "end": 68.6, "text": " Nazywa si\u0119 Tree of Thoughts \u2013 Deliberate Problem Solving with Large Language Models.", "tokens": [50729, 11870, 88, 4151, 3244, 22291, 295, 23058, 82, 1662, 5831, 5331, 473, 11676, 7026, 798, 365, 33092, 24445, 6583, 1625, 13, 51149], "temperature": 0.0, "avg_logprob": -0.08665543087458207, "compression_ratio": 1.3261648745519714, "no_speech_prob": 0.04925825446844101}, {"id": 11, "seek": 5290, "start": 68.6, "end": 73.1, "text": " I od razu powiem, to nie jest jaka\u015b nowa, sprytna sztuczka z promptowaniem.", "tokens": [51149, 286, 3611, 367, 8813, 3388, 4907, 11, 281, 2838, 3492, 4207, 64, 1788, 586, 64, 11, 637, 627, 83, 629, 262, 2682, 1311, 89, 2330, 710, 12391, 37345, 4907, 13, 51374], "temperature": 0.0, "avg_logprob": -0.08665543087458207, "compression_ratio": 1.3261648745519714, "no_speech_prob": 0.04925825446844101}, {"id": 12, "seek": 5290, "start": 73.1, "end": 79.5, "text": " To wygl\u0105da na co\u015b o wiele g\u0142\u0119bszego, na fundamentalnie now\u0105 ram\u0119 dla maszynowego rozumiewania.", "tokens": [51374, 1407, 32015, 1667, 19241, 277, 33137, 18117, 1274, 929, 27725, 11, 1667, 8088, 2766, 586, 1611, 10211, 1274, 12285, 2300, 1229, 3785, 6308, 48797, 1093, 5609, 13, 51694], "temperature": 0.0, "avg_logprob": -0.08665543087458207, "compression_ratio": 1.3261648745519714, "no_speech_prob": 0.04925825446844101}, {"id": 13, "seek": 7950, "start": 79.5, "end": 85.9, "text": " Zdecygowanie. I \u017ceby w pe\u0142ni wiesz, doceni\u0107 wag\u0119 tego, trzeba zrozumie\u0107, gdzie jeste\u015bmy teraz.", "tokens": [50364, 1176, 1479, 1344, 70, 22028, 13, 286, 11316, 261, 43205, 3722, 261, 15347, 11, 3211, 268, 12757, 36854, 1274, 8627, 11, 25860, 710, 27857, 449, 414, 2162, 11, 18922, 35928, 16854, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 14, "seek": 7950, "start": 85.9, "end": 92.2, "text": " Nawet najpot\u0119\u017cniejsze modele jak GPT-4 dzia\u0142aj\u0105 w spos\u00f3b, kt\u00f3ry jest bardzo liniowy.", "tokens": [50684, 40315, 302, 11212, 17698, 1274, 1427, 44258, 4391, 306, 4207, 26039, 51, 12, 19, 27121, 11133, 261, 22904, 11, 9913, 3492, 9034, 287, 3812, 10089, 13, 50999], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 15, "seek": 7950, "start": 92.2, "end": 95.9, "text": " Generuj\u0105 odpowied\u017a token po tokenie od lewej do prawej.", "tokens": [50999, 15409, 13263, 36574, 10659, 14862, 714, 281, 2653, 414, 3611, 476, 826, 73, 360, 3206, 826, 73, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 16, "seek": 7950, "start": 95.9, "end": 101.1, "text": " To bardzo przypomina to, co psycholog Daniel Kahneman nazwa\u0142 my\u015bleniem Systemu 1.", "tokens": [51184, 1407, 9034, 41780, 49217, 281, 11, 598, 4681, 1132, 8033, 591, 12140, 15023, 20151, 44603, 48633, 6698, 4907, 8910, 84, 502, 13, 51444], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 17, "seek": 7950, "start": 101.1, "end": 105.2, "text": " Czyli to takie szybkie, intuicyjne, prawie automatyczne my\u015blenie.", "tokens": [51444, 37099, 281, 15963, 36456, 22872, 11, 560, 84, 2632, 73, 716, 11, 3206, 8699, 28034, 17466, 716, 48633, 6698, 414, 13, 51649], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 18, "seek": 7950, "start": 105.2, "end": 108.6, "text": " To co nam podpowiada, \u017ce 2 plus 2 to 4 bez zastanowienia?", "tokens": [51649, 1407, 598, 8835, 2497, 14701, 39018, 11, 3561, 568, 1804, 568, 281, 1017, 10782, 36746, 282, 305, 18811, 30, 51819], "temperature": 0.0, "avg_logprob": -0.11626202181765907, "compression_ratio": 1.3909090909090909, "no_speech_prob": 0.02479402720928192}, {"id": 19, "seek": 10860, "start": 108.69999999999999, "end": 114.5, "text": " Dok\u0142adnie. Jest niesamowicie wydajne, ale ma swoje powa\u017cne ograniczenia.", "tokens": [50369, 29768, 10358, 2766, 13, 24918, 48100, 335, 305, 28434, 25984, 1805, 716, 11, 6775, 463, 29489, 3388, 18264, 716, 34416, 30732, 14320, 13, 50659], "temperature": 0.0, "avg_logprob": -0.08934998857802239, "compression_ratio": 1.4131147540983606, "no_speech_prob": 0.0012753534829244018}, {"id": 20, "seek": 10860, "start": 114.5, "end": 119.8, "text": " Zawodzi w zadaniach, kt\u00f3re wymagaj\u0105 planowania, strategii, rozwa\u017cania wielu alternatyw.", "tokens": [50659, 1176, 1607, 14543, 261, 42788, 3782, 608, 11, 8864, 29764, 559, 11133, 1393, 21308, 11, 5464, 5597, 11, 9544, 27111, 5609, 40437, 5400, 21398, 86, 13, 50924], "temperature": 0.0, "avg_logprob": -0.08934998857802239, "compression_ratio": 1.4131147540983606, "no_speech_prob": 0.0012753534829244018}, {"id": 21, "seek": 10860, "start": 119.8, "end": 123.3, "text": " A przede wszystkim zdolno\u015bci do wycofania si\u0119 z b\u0142\u0119du.", "tokens": [50924, 316, 44786, 30481, 16221, 401, 16438, 360, 4628, 1291, 69, 5609, 3244, 710, 272, 46564, 769, 13, 51099], "temperature": 0.0, "avg_logprob": -0.08934998857802239, "compression_ratio": 1.4131147540983606, "no_speech_prob": 0.0012753534829244018}, {"id": 22, "seek": 10860, "start": 123.3, "end": 128.5, "text": " A to wszystko s\u0105 cechy Systemu 2 tego powolnego, analitycznego, \u015bwiadomego my\u015blenia.", "tokens": [51099, 316, 281, 22607, 9015, 1769, 28629, 8910, 84, 568, 8627, 3388, 401, 11858, 11, 2624, 507, 3689, 11858, 11, 21485, 345, 423, 1571, 48633, 6698, 654, 13, 51359], "temperature": 0.0, "avg_logprob": -0.08934998857802239, "compression_ratio": 1.4131147540983606, "no_speech_prob": 0.0012753534829244018}, {"id": 23, "seek": 10860, "start": 128.5, "end": 136.9, "text": " I do tej pory pr\u00f3bowali\u015bmy to jako\u015b symulowa\u0107 za pomoc\u0105 techniki znanej jako Chain of Thought, czyli COT, prawda?", "tokens": [51359, 286, 360, 12573, 280, 827, 8565, 8202, 33955, 281, 17123, 1788, 6697, 425, 11445, 7949, 48962, 1611, 1537, 9850, 15397, 1929, 73, 17123, 33252, 295, 23058, 11, 16591, 3002, 51, 11, 43607, 30, 51779], "temperature": 0.0, "avg_logprob": -0.08934998857802239, "compression_ratio": 1.4131147540983606, "no_speech_prob": 0.0012753534829244018}, {"id": 24, "seek": 13690, "start": 137.0, "end": 140.20000000000002, "text": " Prosili\u015bmy model, \u017ceby my\u015bla\u0142 na g\u0142os krok po kroku.", "tokens": [50369, 26024, 43912, 2316, 11, 11316, 48633, 875, 1221, 1667, 43767, 350, 31621, 714, 45909, 5279, 13, 50529], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 25, "seek": 13690, "start": 140.20000000000002, "end": 143.0, "text": " Tak. I to by\u0142 du\u017cy krok do przodu.", "tokens": [50529, 9118, 13, 286, 281, 16673, 1581, 7735, 350, 31621, 360, 6541, 34873, 13, 50669], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 26, "seek": 13690, "start": 143.0, "end": 146.9, "text": " Zamiast samej odpowiedzi dostawali\u015bmy ca\u0142y proces.", "tokens": [50669, 1176, 4526, 525, 912, 73, 36574, 3992, 20568, 1607, 33955, 35226, 17565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 27, "seek": 13690, "start": 146.9, "end": 150.20000000000002, "text": " Ale to wci\u0105\u017c by\u0142 tylko jeden pojedynczy \u0142a\u0144cuch my\u015bli.", "tokens": [50864, 9366, 281, 261, 537, 27242, 16673, 13219, 12906, 714, 40543, 2534, 6522, 220, 5024, 5248, 66, 625, 452, 15350, 13, 51029], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 28, "seek": 13690, "start": 150.20000000000002, "end": 154.6, "text": " Je\u015bli model na samym pocz\u0105tku pope\u0142ni\u0142 jaki\u015b ma\u0142y b\u0142\u0105d, przyj\u0105\u0142 z\u0142\u0105 strategi\u0119...", "tokens": [51029, 37086, 2316, 1667, 3247, 4199, 43959, 42248, 1221, 3722, 1221, 34721, 463, 6825, 272, 15926, 67, 11, 6501, 8555, 1221, 710, 15926, 5464, 5034, 485, 51249], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 29, "seek": 13690, "start": 154.6, "end": 156.1, "text": " To ju\u017c by\u0142o po wszystkim.", "tokens": [51249, 1407, 10678, 14811, 714, 30481, 13, 51324], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 30, "seek": 13690, "start": 156.1, "end": 159.8, "text": " No w\u0142a\u015bnie. Ca\u0142e rozwi\u0105zanie by\u0142o skazane na pora\u017ck\u0119.", "tokens": [51324, 883, 14234, 13, 7544, 19827, 9544, 22620, 7155, 14811, 1110, 921, 1929, 1667, 1515, 18264, 15724, 13, 51509], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 31, "seek": 13690, "start": 159.8, "end": 163.3, "text": " Nie by\u0142o \u017cadnego mechanizmu korekty, \u017cadnego planu B.", "tokens": [51509, 12016, 14811, 39628, 11858, 4236, 590, 20140, 350, 418, 74, 874, 11, 39628, 11858, 1393, 84, 363, 13, 51684], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 32, "seek": 13690, "start": 163.3, "end": 166.4, "text": " OK. To roz\u0142\u00f3\u017cmy to na czynniki pierwsze.", "tokens": [51684, 2264, 13, 1407, 9544, 1221, 812, 1427, 2226, 281, 1667, 6430, 26384, 9850, 45994, 13, 51839], "temperature": 0.0, "avg_logprob": -0.09627315310612777, "compression_ratio": 1.4954407294832828, "no_speech_prob": 0.018986200913786888}, {"id": 33, "seek": 16640, "start": 166.4, "end": 170.6, "text": " W takim razie, jak Tree of Thought zmienia t\u0119 gr\u0119.", "tokens": [50364, 343, 31732, 9639, 414, 11, 4207, 22291, 295, 23058, 17020, 18811, 32489, 677, 1274, 13, 50574], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 34, "seek": 16640, "start": 170.6, "end": 172.3, "text": " Na czym polega ta rewolucja?", "tokens": [50574, 6056, 31466, 13208, 3680, 1846, 319, 48481, 1311, 2938, 30, 50659], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 35, "seek": 16640, "start": 172.3, "end": 176.9, "text": " Zmienia j\u0105, bo zamiast jednego \u0142a\u0144cucha tworzy ca\u0142e drzewo mo\u017cliwo\u015bci.", "tokens": [50659, 1176, 76, 18811, 35692, 11, 748, 710, 4526, 525, 5232, 11858, 220, 5024, 5248, 66, 26042, 46288, 1229, 47631, 1224, 43551, 78, 30854, 36476, 13, 50889], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 36, "seek": 16640, "start": 176.9, "end": 181.5, "text": " Troch\u0119 czerpie inspiracje z takich wiesz, klasycznych metod sztucznej inteligencji.", "tokens": [50889, 19406, 23006, 269, 4527, 9144, 17432, 29293, 710, 29607, 261, 15347, 11, 9671, 5871, 3689, 9399, 1131, 378, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 13, 51119], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 37, "seek": 16640, "start": 181.5, "end": 184.8, "text": " Autorzy rozbili ten proces na cztery g\u0142\u00f3wne elementy.", "tokens": [51119, 6049, 284, 1229, 9544, 65, 2312, 2064, 17565, 1667, 6472, 12733, 18117, 3901, 716, 4478, 88, 13, 51284], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 38, "seek": 16640, "start": 184.8, "end": 189.0, "text": " Pierwszy to jest thought decomposition, czyli dekompozycja my\u015bli.", "tokens": [51284, 16676, 30012, 281, 3492, 1194, 48356, 11, 16591, 368, 20557, 2259, 1229, 34056, 452, 15350, 13, 51494], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 39, "seek": 16640, "start": 189.0, "end": 192.0, "text": " Czyli problem jest dzielony na mniejsze, sensowne kroki.", "tokens": [51494, 37099, 1154, 3492, 9758, 1187, 2526, 1667, 275, 44258, 11, 2923, 648, 68, 45909, 2984, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 40, "seek": 16640, "start": 192.0, "end": 192.9, "text": " Dok\u0142adnie.", "tokens": [51644, 29768, 10358, 2766, 13, 51689], "temperature": 0.0, "avg_logprob": -0.10088943146370552, "compression_ratio": 1.4123376623376624, "no_speech_prob": 0.0032624925952404737}, {"id": 41, "seek": 19290, "start": 192.9, "end": 197.70000000000002, "text": " I co jest wa\u017cne, ta my\u015bl to nie jest po prostu kolejne s\u0142owo, tak?", "tokens": [50364, 286, 598, 3492, 46110, 11, 1846, 452, 19212, 281, 2838, 3492, 714, 19518, 23749, 716, 15116, 19941, 11, 991, 30, 50604], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 42, "seek": 19290, "start": 197.70000000000002, "end": 199.20000000000002, "text": " To jest co\u015b wi\u0119kszego.", "tokens": [50604, 1407, 3492, 19241, 29968, 27725, 13, 50679], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 43, "seek": 19290, "start": 199.20000000000002, "end": 206.3, "text": " W naszej grze w 24 to by\u0142oby ca\u0142e r\u00f3wnanie na przyk\u0142ad 10, 4, r\u00f3wna si\u0119 6.", "tokens": [50679, 343, 42946, 677, 1381, 261, 4022, 281, 16673, 13944, 47631, 11416, 895, 7155, 1667, 23144, 1266, 11, 1017, 11, 367, 3901, 629, 3244, 1386, 13, 51034], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 44, "seek": 19290, "start": 206.3, "end": 208.8, "text": " W\u0142a\u015bnie o to chodzi. To nadaje struktur\u0119.", "tokens": [51034, 343, 5024, 12221, 277, 281, 23998, 13, 1407, 8096, 2884, 342, 31543, 1274, 13, 51159], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 45, "seek": 19290, "start": 208.8, "end": 212.3, "text": " Drugi element to thought generator.", "tokens": [51159, 2491, 24780, 4478, 281, 1194, 19265, 13, 51334], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 46, "seek": 19290, "start": 212.3, "end": 215.6, "text": " I tu zaczyna si\u0119 jakby ca\u0142a magia.", "tokens": [51334, 286, 2604, 43811, 629, 3244, 28976, 1335, 5024, 2258, 654, 13, 51499], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 47, "seek": 19290, "start": 215.6, "end": 219.6, "text": " Na ka\u017cdym kroku model nie generuje jednej kontynuacji.", "tokens": [51499, 6056, 31615, 76, 45909, 5279, 2316, 2838, 1337, 13008, 5232, 11794, 5897, 874, 16241, 13152, 13, 51699], "temperature": 0.0, "avg_logprob": -0.1790275242017663, "compression_ratio": 1.3794466403162056, "no_speech_prob": 0.0015620669582858682}, {"id": 48, "seek": 21960, "start": 219.79999999999998, "end": 225.29999999999998, "text": " Ale kilka, a czasem nawet kilkana\u015bcie potencjalnych my\u015bli, tworzy nowe ga\u0142\u0119zie.", "tokens": [50374, 9366, 36466, 11, 257, 13190, 443, 22696, 5128, 74, 2095, 9815, 1847, 22660, 22600, 9399, 452, 15350, 11, 46288, 1229, 586, 68, 5959, 46564, 3283, 13, 50649], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 49, "seek": 21960, "start": 225.29999999999998, "end": 230.1, "text": " A, czyli tworzymy wachlarz mo\u017cliwo\u015bci zamiast stawia\u0107 wszystko na jedn\u0105 kart\u0119.", "tokens": [50649, 316, 11, 16591, 46288, 1229, 2226, 261, 608, 2200, 89, 30854, 36476, 710, 4526, 525, 342, 34953, 2162, 22607, 1667, 5232, 13113, 29120, 1274, 13, 50889], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 50, "seek": 21960, "start": 230.1, "end": 233.4, "text": " Ale sk\u0105d model wie, kt\u00f3r\u0105 ga\u0142\u0105\u017a wybra\u0107?", "tokens": [50889, 9366, 1110, 18962, 2316, 3355, 11, 37415, 5959, 15926, 10659, 4628, 6198, 2162, 30, 51054], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 51, "seek": 21960, "start": 233.4, "end": 237.1, "text": " I tu dochodzimy do trzeciego i by\u0107 mo\u017ce najwa\u017cniejszego elementu.", "tokens": [51054, 286, 2604, 9243, 378, 89, 13189, 360, 22266, 4260, 1571, 741, 15069, 12034, 11212, 27111, 10402, 15453, 6308, 4478, 84, 13, 51239], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 52, "seek": 21960, "start": 237.1, "end": 239.2, "text": " State Evaluator.", "tokens": [51239, 4533, 462, 3337, 84, 1639, 13, 51344], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 53, "seek": 21960, "start": 239.2, "end": 242.6, "text": " To jest ta wewn\u0119trzna intuicja, o kt\u00f3rej m\u00f3wi\u0142a\u015b na pocz\u0105tku.", "tokens": [51344, 1407, 3492, 1846, 321, 895, 1274, 6903, 35458, 560, 84, 299, 2938, 11, 277, 36023, 24592, 5024, 1788, 1667, 43959, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 54, "seek": 21960, "start": 242.6, "end": 247.4, "text": " Sam model j\u0119zykowy jest proszony o ocen\u0119 ka\u017cdej z wygenerowanych ga\u0142\u0119ci.", "tokens": [51514, 4832, 2316, 49055, 74, 10089, 3492, 6267, 44479, 277, 10409, 268, 1274, 21912, 1479, 73, 710, 4628, 21848, 23341, 339, 5959, 46564, 537, 13, 51754], "temperature": 0.0, "avg_logprob": -0.07231774049646714, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004338542465120554}, {"id": 55, "seek": 24740, "start": 247.4, "end": 252.0, "text": " Dzia\u0142a jak taki wewn\u0119trzny krytyk, kt\u00f3ry m\u00f3wi, ta \u015bcie\u017cka jest pewna,", "tokens": [50364, 39448, 25605, 4207, 20065, 321, 895, 1274, 6903, 89, 1634, 34847, 874, 74, 11, 9913, 24592, 11, 1846, 8299, 40082, 2330, 3492, 25889, 629, 11, 50594], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 56, "seek": 24740, "start": 252.0, "end": 255.0, "text": " ta jest obiecuj\u0105ca, a t\u0119 mo\u017cna porzuci\u0107.", "tokens": [50594, 1846, 3492, 1111, 35733, 13263, 496, 11, 257, 32489, 17790, 1515, 11728, 39162, 13, 50744], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 57, "seek": 24740, "start": 255.0, "end": 261.0, "text": " Chwila, ale czy to nie jest troch\u0119 jak w\u0105\u017c zjadaj\u0105cy w\u0142asny ogon?", "tokens": [50744, 761, 86, 7371, 11, 6775, 6430, 281, 2838, 3492, 24926, 4207, 261, 27242, 710, 73, 1538, 8555, 1344, 43572, 1634, 5360, 266, 30, 51044], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 58, "seek": 24740, "start": 261.0, "end": 266.2, "text": " Ten sam model, kt\u00f3ry generuje pomys\u0142y, ma je potem ocenia\u0107.", "tokens": [51044, 9380, 3247, 2316, 11, 9913, 1337, 13008, 12991, 749, 6825, 11, 463, 1506, 36513, 10409, 268, 654, 2162, 13, 51304], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 59, "seek": 24740, "start": 266.2, "end": 271.8, "text": " Sk\u0105d pewno\u015b\u0107, \u017ce jego ocena jest, no wiesz, obiektywnie dobra?", "tokens": [51304, 7324, 18962, 33002, 7753, 11, 3561, 26542, 10409, 4118, 3492, 11, 572, 261, 15347, 11, 1111, 19487, 874, 14215, 360, 6198, 30, 51584], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 60, "seek": 24740, "start": 271.8, "end": 275.0, "text": " To jest doskona\u0142e pytanie i sedno sprawy.", "tokens": [51584, 1407, 3492, 4491, 74, 4037, 19827, 36610, 741, 9643, 1771, 22734, 88, 13, 51744], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 61, "seek": 24740, "start": 275.0, "end": 277.2, "text": " Oczywi\u015bcie istnieje takie ryzyko.", "tokens": [51744, 42980, 1418, 2766, 2884, 15963, 20791, 1229, 4093, 13, 51854], "temperature": 0.0, "avg_logprob": -0.07643362816343917, "compression_ratio": 1.435251798561151, "no_speech_prob": 0.0010167345171794295}, {"id": 62, "seek": 27720, "start": 277.2, "end": 285.0, "text": " Ale autorzy pokazuj\u0105, \u017ce nawet niedoskona\u0142a ocena jest orz\u0119dy wielko\u015bci lepsza ni\u017c brak jakiejkolwiek oceny.", "tokens": [50364, 9366, 19510, 1229, 13010, 921, 13263, 11, 3561, 22696, 32488, 329, 74, 4037, 5024, 10409, 4118, 3492, 420, 11052, 3173, 20570, 4093, 6199, 476, 1878, 2394, 28502, 1548, 74, 4207, 7764, 36620, 44674, 10409, 43100, 13, 50754], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 63, "seek": 27720, "start": 285.0, "end": 291.4, "text": " Model oceniaj\u0105c jest zmuszony do przyj\u0119cia innej perspektywy krytycznej, a nie tylko generatywnej.", "tokens": [50754, 17105, 10409, 268, 48125, 66, 3492, 17020, 22378, 2526, 360, 6501, 11115, 2755, 294, 11794, 868, 32659, 874, 9726, 34847, 874, 3689, 11794, 11, 257, 2838, 13219, 1337, 21398, 86, 11794, 13, 51074], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 64, "seek": 27720, "start": 291.4, "end": 294.09999999999997, "text": " Poza tym ta ocena nie musi by\u0107 idealna.", "tokens": [51074, 6165, 2394, 8107, 1846, 10409, 4118, 2838, 37587, 15069, 7157, 629, 13, 51209], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 65, "seek": 27720, "start": 294.09999999999997, "end": 297.4, "text": " Wystarczy, \u017ce odsieje te najbardziej absurdalne \u015bcie\u017cki.", "tokens": [51209, 14458, 9710, 6522, 11, 3561, 3611, 82, 414, 2884, 535, 41857, 19774, 304, 716, 8299, 40082, 2984, 13, 51374], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 66, "seek": 27720, "start": 297.4, "end": 301.3, "text": " Rozumiem, czyli nawet prosty filtr jest lepszy ni\u017c \u017caden.", "tokens": [51374, 43313, 449, 4907, 11, 16591, 22696, 10293, 88, 1387, 6903, 3492, 476, 1878, 1229, 28502, 19625, 14771, 13, 51569], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 67, "seek": 27720, "start": 301.3, "end": 303.2, "text": " A co z czwartym elementem?", "tokens": [51569, 316, 598, 710, 6472, 29587, 4199, 4478, 443, 30, 51664], "temperature": 0.0, "avg_logprob": -0.09397421637885005, "compression_ratio": 1.4548736462093863, "no_speech_prob": 0.0012424997985363007}, {"id": 68, "seek": 30320, "start": 303.2, "end": 308.09999999999997, "text": " Czwarte element to search-algorytm, czyli algorytm przeszukiwania.", "tokens": [50364, 383, 14406, 11026, 4478, 281, 3164, 12, 20422, 827, 83, 76, 11, 16591, 3501, 827, 83, 76, 6541, 10430, 11788, 86, 5609, 13, 50609], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 69, "seek": 30320, "start": 308.09999999999997, "end": 314.0, "text": " Kiedy mamy ju\u017c drzewo i spos\u00f3b oceny, mo\u017cemy u\u017cy\u0107 systematycznych metod, \u017ceby je eksplorowa\u0107.", "tokens": [50609, 591, 16446, 17335, 10678, 1224, 43551, 78, 741, 22904, 10409, 43100, 11, 26500, 34097, 2162, 1185, 267, 17466, 9399, 1131, 378, 11, 11316, 1506, 30724, 564, 284, 11445, 13, 50904], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 70, "seek": 30320, "start": 314.0, "end": 319.4, "text": " Autorzy testowali dwa klasyki, breath-first-search, czyli BFS.", "tokens": [50904, 6049, 284, 1229, 1500, 305, 5103, 35045, 9671, 5871, 2984, 11, 6045, 12, 29581, 12, 405, 1178, 11, 16591, 363, 29318, 13, 51174], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 71, "seek": 30320, "start": 319.4, "end": 322.2, "text": " Przeszukiwanie w search, poziom po poziomie?", "tokens": [51174, 2114, 89, 10430, 11788, 86, 7155, 261, 3164, 11, 38503, 298, 714, 38503, 40120, 30, 51314], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 72, "seek": 30320, "start": 322.2, "end": 322.9, "text": " Tak.", "tokens": [51314, 9118, 13, 51349], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 73, "seek": 30320, "start": 322.9, "end": 327.9, "text": " I drugi, depth-first-search, czyli DFS, przeszukiwanie w g\u0142\u0105b.", "tokens": [51349, 286, 4110, 72, 11, 7161, 12, 29581, 12, 405, 1178, 11, 16591, 413, 29318, 11, 6541, 10430, 11788, 86, 7155, 261, 290, 15926, 65, 13, 51599], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 74, "seek": 30320, "start": 327.9, "end": 332.3, "text": " I ten drugi wydaje si\u0119 kluczowy dla problem\u00f3w, w kt\u00f3rych trzeba si\u0119 cofa\u0107.", "tokens": [51599, 286, 2064, 4110, 72, 49165, 3244, 9671, 1311, 89, 10089, 12285, 1154, 3901, 11, 261, 30382, 25860, 3244, 598, 11771, 2162, 13, 51819], "temperature": 0.0, "avg_logprob": -0.10107062698958756, "compression_ratio": 1.5070921985815602, "no_speech_prob": 0.06543637812137604}, {"id": 75, "seek": 33230, "start": 332.3, "end": 334.8, "text": " Pozwaza na tak zwany backtracking.", "tokens": [50364, 6165, 14406, 12257, 1667, 991, 11873, 1325, 646, 6903, 14134, 13, 50489], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 76, "seek": 33230, "start": 334.8, "end": 340.2, "text": " Idziesz jedn\u0105 \u015bcie\u017ck\u0105, dochodzisz do \u015bciany, wi\u0119c wracasz i probujesz innej drogi.", "tokens": [50489, 11506, 89, 15347, 5232, 13113, 8299, 40082, 26304, 11, 9243, 378, 89, 23848, 360, 220, 6199, 1325, 11, 16677, 928, 326, 19601, 741, 1239, 4579, 10430, 294, 11794, 3789, 7834, 13, 50759], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 77, "seek": 33230, "start": 340.2, "end": 342.1, "text": " Tego brakowa\u0142o w Chain of Thought.", "tokens": [50759, 314, 6308, 1548, 74, 5528, 5249, 261, 33252, 295, 23058, 13, 50854], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 78, "seek": 33230, "start": 342.1, "end": 343.2, "text": " Dok\u0142adnie.", "tokens": [50854, 29768, 10358, 2766, 13, 50909], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 79, "seek": 33230, "start": 343.2, "end": 347.6, "text": " To jest wbudowany mechanizm przyznawania si\u0119 do b\u0142\u0119du i korygowania kursu.", "tokens": [50909, 1407, 3492, 261, 18281, 23341, 4236, 590, 76, 6501, 35458, 86, 5609, 3244, 360, 272, 46564, 769, 741, 350, 827, 70, 21308, 350, 2156, 84, 13, 51129], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 80, "seek": 33230, "start": 347.6, "end": 349.8, "text": " I tu robi si\u0119 naprawd\u0119 ciekawie.", "tokens": [51129, 286, 2604, 47380, 3244, 20970, 46419, 1607, 414, 13, 51239], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 81, "seek": 33230, "start": 349.8, "end": 351.3, "text": " Teoria brzmi pot\u0119\u017cnie.", "tokens": [51239, 1989, 8172, 738, 89, 3057, 1847, 1274, 1427, 2766, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 82, "seek": 33230, "start": 351.3, "end": 352.7, "text": " Ale teoria to jedno.", "tokens": [51314, 9366, 535, 8172, 281, 5232, 1771, 13, 51384], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 83, "seek": 33230, "start": 352.7, "end": 354.1, "text": " Jakie s\u0105 dowody?", "tokens": [51384, 15029, 414, 9015, 9459, 843, 30, 51454], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 84, "seek": 33230, "start": 354.1, "end": 361.40000000000003, "text": " Autorzy przetestowali Tree of Thought na w trzech bardzo r\u00f3\u017cnych i, co wa\u017cne, bardzo trudnych zadaniach.", "tokens": [51454, 6049, 284, 1229, 6541, 302, 377, 305, 5103, 22291, 295, 23058, 1667, 261, 504, 19439, 9034, 42602, 741, 11, 598, 46110, 11, 9034, 32007, 9399, 42788, 3782, 608, 13, 51819], "temperature": 0.0, "avg_logprob": -0.09814118764486658, "compression_ratio": 1.4757281553398058, "no_speech_prob": 0.04907650500535965}, {"id": 85, "seek": 36140, "start": 361.4, "end": 364.09999999999997, "text": " Zacznijmy od naszej gry w 24.", "tokens": [50364, 1176, 14875, 77, 1718, 2226, 3611, 42946, 41974, 261, 4022, 13, 50499], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 86, "seek": 36140, "start": 364.09999999999997, "end": 367.4, "text": " Wyniki s\u0105, no, po prostu mia\u017cd\u017c\u0105ce.", "tokens": [50499, 343, 2534, 9850, 9015, 11, 572, 11, 714, 19518, 21290, 1427, 67, 1427, 1611, 384, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 87, "seek": 36140, "start": 367.4, "end": 375.29999999999995, "text": " Ten sam model GPT-4, u\u017cywaj\u0105c standardowego promptowania z Chain of Thought, rozwi\u0105za\u0142 poprawnie zaledwie 4% zada\u0144.", "tokens": [50664, 9380, 3247, 2316, 26039, 51, 12, 19, 11, 34097, 86, 38757, 3832, 26576, 12391, 21308, 710, 33252, 295, 23058, 11, 9544, 18234, 2394, 1221, 1665, 424, 14215, 710, 5573, 8699, 1017, 4, 710, 1538, 5248, 13, 51059], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 88, "seek": 36140, "start": 375.29999999999995, "end": 377.0, "text": " Tylko 4 na 100.", "tokens": [51059, 49286, 4093, 1017, 1667, 2319, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 89, "seek": 36140, "start": 377.0, "end": 380.2, "text": " To pokazuje, jak trudny jest to problem dla maszyny.", "tokens": [51144, 1407, 13010, 43317, 11, 4207, 32007, 1634, 3492, 281, 1154, 12285, 2300, 1229, 1634, 13, 51304], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 90, "seek": 36140, "start": 380.2, "end": 381.59999999999997, "text": " A teraz uwaga.", "tokens": [51304, 316, 16854, 23147, 9286, 13, 51374], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 91, "seek": 36140, "start": 381.59999999999997, "end": 388.2, "text": " Ten sam model, zna\u0142o\u017conym frameworkiem Tree of Thoughts, osi\u0105gn\u0105\u0142 skuteczno\u015b\u0107 na poziomie 74%.", "tokens": [51374, 9380, 3247, 2316, 11, 710, 629, 5249, 1427, 12732, 8388, 4907, 22291, 295, 23058, 82, 11, 3003, 11404, 4568, 1611, 1221, 1110, 1169, 3689, 23293, 1667, 38503, 40120, 28868, 6856, 51704], "temperature": 0.0, "avg_logprob": -0.11390753851996528, "compression_ratio": 1.3574007220216606, "no_speech_prob": 0.028070472180843353}, {"id": 92, "seek": 38820, "start": 388.2, "end": 393.09999999999997, "text": " Wow, z 4 na 74%.", "tokens": [50364, 3153, 11, 710, 1017, 1667, 28868, 6856, 50609], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 93, "seek": 38820, "start": 393.09999999999997, "end": 395.4, "text": " To nie jest poprawa, to jest przepa\u015b\u0107.", "tokens": [50609, 1407, 2838, 3492, 1665, 424, 4151, 11, 281, 3492, 30829, 64, 7753, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 94, "seek": 38820, "start": 395.4, "end": 398.3, "text": " To jest zupe\u0142nie inna kategoria wydajno\u015bci.", "tokens": [50724, 1407, 3492, 49922, 294, 629, 350, 2968, 8172, 25984, 1805, 16438, 13, 50869], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 95, "seek": 38820, "start": 398.3, "end": 400.7, "text": " Przeskok z pora\u017cki do niezawodno\u015bci.", "tokens": [50869, 2114, 12214, 33754, 710, 1515, 18264, 2984, 360, 33511, 1607, 378, 16438, 13, 50989], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 96, "seek": 38820, "start": 400.7, "end": 402.59999999999997, "text": " Jak to w og\u00f3le mo\u017cliwe?", "tokens": [50989, 15029, 281, 261, 29229, 30854, 826, 30, 51084], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 97, "seek": 38820, "start": 402.59999999999997, "end": 404.4, "text": " Jak to dzia\u0142a\u0142o w praktyce?", "tokens": [51084, 15029, 281, 37903, 5249, 261, 3206, 74, 874, 384, 30, 51174], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 98, "seek": 38820, "start": 404.4, "end": 405.9, "text": " Bardzo elegancko.", "tokens": [51174, 38559, 1118, 1275, 41416, 13, 51249], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 99, "seek": 38820, "start": 405.9, "end": 409.59999999999997, "text": " Na ka\u017cdym etapie COT generowa\u0142o kilka mo\u017cliwych dzia\u0142a\u0144.", "tokens": [51249, 6056, 31615, 76, 47634, 414, 3002, 51, 1337, 5528, 5249, 36466, 30854, 9726, 339, 37903, 5248, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 100, "seek": 38820, "start": 409.59999999999997, "end": 413.8, "text": " A potem ewaluator, czyli sam model, ocenia\u0142 ich potencja\u0142.", "tokens": [51434, 316, 36513, 43364, 4929, 1639, 11, 16591, 3247, 2316, 11, 10409, 268, 8908, 1893, 1847, 22660, 2938, 1221, 13, 51644], "temperature": 0.0, "avg_logprob": -0.1110371380317502, "compression_ratio": 1.4008264462809918, "no_speech_prob": 0.002836132887750864}, {"id": 101, "seek": 41380, "start": 413.8, "end": 422.0, "text": " Na przyk\u0142ad, je\u015bli po pierwszym kroku zosta\u0142y nam liczby 1, 2 i 3, model by\u0142 proszony o ocen\u0119 czy z tego da si\u0119 doj\u015b\u0107 do 24.", "tokens": [50364, 6056, 23144, 11, 25630, 714, 34016, 76, 45909, 5279, 23154, 6825, 8835, 6169, 89, 2322, 502, 11, 568, 741, 805, 11, 2316, 16673, 6267, 44479, 277, 10409, 268, 1274, 6430, 710, 8627, 1120, 3244, 360, 44536, 360, 4022, 13, 50774], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 102, "seek": 41380, "start": 422.0, "end": 423.40000000000003, "text": " I co odpowiada\u0142?", "tokens": [50774, 286, 598, 24314, 39018, 1221, 30, 50844], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 103, "seek": 41380, "start": 423.40000000000003, "end": 426.8, "text": " M\u00f3wi\u0142, niemo\u017cliwe, liczby s\u0105 zbyt ma\u0142e.", "tokens": [50844, 376, 3901, 40622, 11, 2838, 3280, 1427, 2081, 826, 11, 6169, 89, 2322, 9015, 710, 2322, 83, 463, 19827, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 104, "seek": 41380, "start": 426.8, "end": 428.8, "text": " I ca\u0142a ta ga\u0142\u0105\u017a by\u0142a odcinana.", "tokens": [51014, 286, 1335, 5024, 1846, 5959, 15926, 10659, 23936, 3611, 20021, 2095, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 105, "seek": 41380, "start": 428.8, "end": 431.0, "text": " Nie marnowano na ni\u0105 wi\u0119cej zasob\u00f3w.", "tokens": [51114, 12016, 275, 1083, 305, 3730, 1667, 3867, 1611, 26004, 26530, 996, 3901, 13, 51224], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 106, "seek": 41380, "start": 431.0, "end": 434.7, "text": " To jest w\u0142a\u015bnie to celowe rozumowanie systemu 2 w akcji.", "tokens": [51224, 1407, 3492, 14234, 281, 9277, 6880, 48797, 22028, 1185, 84, 568, 261, 9308, 19649, 13, 51409], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 107, "seek": 41380, "start": 434.7, "end": 437.7, "text": " A m\u00f3wi\u0142e\u015b o analizie b\u0142\u0119d\u00f3w w Chain of Thought.", "tokens": [51409, 316, 24592, 19827, 1788, 277, 2624, 590, 414, 272, 1221, 6298, 3901, 261, 33252, 295, 23058, 13, 51559], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 108, "seek": 41380, "start": 437.7, "end": 438.8, "text": " By\u0142a odkrywcza?", "tokens": [51559, 3146, 5024, 3611, 43298, 86, 41524, 30, 51614], "temperature": 0.0, "avg_logprob": -0.08786925491021604, "compression_ratio": 1.3732876712328768, "no_speech_prob": 0.11365476995706558}, {"id": 109, "seek": 43880, "start": 438.8, "end": 440.8, "text": " Tak, pokaza\u0142a brutaln\u0105 prawd\u0119.", "tokens": [50364, 9118, 11, 13010, 12257, 5024, 17878, 13113, 41175, 1274, 13, 50464], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 110, "seek": 43880, "start": 440.8, "end": 446.0, "text": " A\u017c 60% nieudanych pr\u00f3b z COT ko\u0144czy\u0142o si\u0119 pora\u017ck\u0105 ju\u017c na pierwszym kroku.", "tokens": [50464, 316, 1427, 4060, 4, 2838, 532, 34644, 8565, 65, 710, 3002, 51, 26470, 6522, 5249, 3244, 1515, 18264, 26304, 10678, 1667, 34016, 76, 45909, 5279, 13, 50724], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 111, "seek": 43880, "start": 446.0, "end": 447.0, "text": " A\u017c tyle?", "tokens": [50724, 316, 1427, 39293, 30, 50774], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 112, "seek": 43880, "start": 447.0, "end": 451.5, "text": " Model wybiera\u0142 jedno, nieoptymalne dzia\u0142anie na pocz\u0105tku i by\u0142 ugotowany.", "tokens": [50774, 17105, 45780, 10609, 1221, 5232, 1771, 11, 2838, 404, 874, 5579, 716, 27121, 7155, 1667, 43959, 741, 16673, 10743, 310, 23341, 13, 50999], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 113, "seek": 43880, "start": 451.5, "end": 452.90000000000003, "text": " Niesamowite.", "tokens": [50999, 426, 530, 335, 305, 642, 13, 51069], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 114, "seek": 43880, "start": 452.90000000000003, "end": 455.7, "text": " To jest zmiana orz\u0105d wielko\u015bci.", "tokens": [51069, 1407, 3492, 17020, 8497, 420, 23876, 20570, 4093, 6199, 13, 51209], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 115, "seek": 43880, "start": 455.7, "end": 462.5, "text": " Czyli w zadaniach z jedn\u0105, tward\u0105 odpowiedzi\u0105, jak matematyka, COT jest bezkonkurencyjne.", "tokens": [51209, 37099, 261, 42788, 3782, 608, 710, 5232, 13113, 11, 683, 515, 1611, 36574, 3992, 1611, 11, 4207, 3803, 8615, 88, 2330, 11, 3002, 51, 3492, 10782, 18295, 74, 9873, 42949, 716, 13, 51549], "temperature": 0.0, "avg_logprob": -0.11275234676542736, "compression_ratio": 1.33984375, "no_speech_prob": 0.04885439947247505}, {"id": 116, "seek": 46250, "start": 462.5, "end": 466.2, "text": " Ale czy ta sama logika sprawdzi si\u0119 w czym\u015b bardziej rozmytym,", "tokens": [50364, 9366, 6430, 1846, 17768, 3565, 5439, 46192, 3992, 3244, 261, 31466, 1788, 27209, 9544, 2226, 874, 76, 11, 50549], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 117, "seek": 46250, "start": 466.2, "end": 470.1, "text": " gdzie nie ma jednej dobrej odpowiedzi, a liczy si\u0119 kreatywno\u015b\u0107?", "tokens": [50549, 18922, 2838, 463, 5232, 11794, 41959, 73, 36574, 3992, 11, 257, 6169, 1229, 3244, 350, 620, 88, 20944, 7753, 30, 50744], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 118, "seek": 46250, "start": 470.1, "end": 473.0, "text": " I to prowadzi nas prosto do drugiego eksperymentu.", "tokens": [50744, 286, 281, 36590, 3992, 5382, 10293, 78, 360, 4110, 12200, 30724, 610, 88, 518, 84, 13, 50889], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 119, "seek": 46250, "start": 473.0, "end": 474.9, "text": " Kreatywnego pisania.", "tokens": [50889, 591, 620, 27112, 11858, 26584, 5609, 13, 50984], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 120, "seek": 46250, "start": 474.9, "end": 477.2, "text": " Zadanie by\u0142o piekielnie trudne.", "tokens": [50984, 1176, 345, 7155, 14811, 1730, 74, 1187, 2766, 32007, 716, 13, 51099], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 121, "seek": 46250, "start": 477.2, "end": 480.5, "text": " Model musia\u0142 napisa\u0107 sp\u00f3jny tekst z czterech akapit\u00f3w,", "tokens": [51099, 17105, 1038, 8908, 9296, 3837, 2162, 637, 18999, 1634, 16624, 372, 710, 269, 2682, 323, 339, 9308, 569, 270, 3901, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 122, "seek": 46250, "start": 480.5, "end": 485.7, "text": " gdzie ka\u017cdy akapit musia\u0142 ko\u0144czy\u0107 si\u0119 jednym z czterech z g\u00f3ry narzuconych, losowych zda\u0144.", "tokens": [51264, 18922, 31615, 9308, 569, 270, 1038, 8908, 26470, 33967, 3244, 5232, 12996, 710, 269, 2682, 323, 339, 710, 290, 812, 627, 6714, 89, 1311, 2526, 339, 11, 1750, 19605, 710, 2675, 5248, 13, 51524], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 123, "seek": 46250, "start": 485.7, "end": 487.0, "text": " To brzmi jak koszmar.", "tokens": [51524, 1407, 738, 89, 3057, 4207, 19532, 89, 6209, 13, 51589], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 124, "seek": 46250, "start": 487.0, "end": 492.0, "text": " Nawet dla cz\u0142owieka by\u0142oby to wyzwanie, \u017ceby stworzy\u0107 co\u015b, co ma sens.", "tokens": [51589, 40315, 302, 12285, 36282, 2330, 16673, 13944, 281, 4628, 14406, 7155, 11, 11316, 342, 28321, 27150, 19241, 11, 598, 463, 2923, 13, 51839], "temperature": 0.0, "avg_logprob": -0.08405396089715472, "compression_ratio": 1.5061349693251533, "no_speech_prob": 0.38060256838798523}, {"id": 125, "seek": 49200, "start": 492.0, "end": 496.0, "text": " No w\u0142a\u015bnie, a Tree of Thoughts podesz\u0142o do tego strategicznie.", "tokens": [50364, 883, 14234, 11, 257, 22291, 295, 23058, 82, 2497, 10430, 5249, 360, 8627, 10924, 89, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08890102386474609, "compression_ratio": 1.463768115942029, "no_speech_prob": 0.016169510781764984}, {"id": 126, "seek": 49200, "start": 496.0, "end": 502.2, "text": " Najpierw model nie pisa\u0142 tekstu, tylko generowa\u0142 pi\u0119\u0107 r\u00f3\u017cnych og\u00f3lnych plan\u00f3w na ca\u0142e opowiadanie.", "tokens": [50564, 31576, 45119, 86, 2316, 2838, 280, 3837, 1221, 16624, 372, 84, 11, 13219, 1337, 30105, 32677, 2162, 42602, 5360, 15741, 9399, 1393, 3901, 1667, 47631, 999, 24503, 345, 7155, 13, 50874], "temperature": 0.0, "avg_logprob": -0.08890102386474609, "compression_ratio": 1.463768115942029, "no_speech_prob": 0.016169510781764984}, {"id": 127, "seek": 49200, "start": 502.2, "end": 508.5, "text": " Potem sam na siebie g\u0142osowa\u0142, ocenia\u0142, kt\u00f3ry z tych plan\u00f3w jest najbardziej sp\u00f3jny i obiecuj\u0105cy.", "tokens": [50874, 9145, 443, 3247, 1667, 39137, 43767, 30105, 11, 10409, 268, 8908, 11, 9913, 710, 15180, 1393, 3901, 3492, 41857, 637, 18999, 1634, 741, 1111, 35733, 13263, 1344, 13, 51189], "temperature": 0.0, "avg_logprob": -0.08890102386474609, "compression_ratio": 1.463768115942029, "no_speech_prob": 0.016169510781764984}, {"id": 128, "seek": 49200, "start": 508.5, "end": 510.0, "text": " To jest fascynuj\u0105ce.", "tokens": [51189, 1407, 3492, 30632, 1344, 77, 13263, 384, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08890102386474609, "compression_ratio": 1.463768115942029, "no_speech_prob": 0.016169510781764984}, {"id": 129, "seek": 49200, "start": 510.0, "end": 516.3, "text": " Model dzia\u0142a jak w\u0142asny redaktor, kt\u00f3ry wybiera najlepsz\u0105 koncepcj\u0119, zanim w og\u00f3le zacznie pisa\u0107.", "tokens": [51264, 17105, 37903, 4207, 43572, 1634, 2182, 5886, 284, 11, 9913, 45780, 10609, 41903, 1878, 8925, 5897, 27493, 41960, 11, 710, 17869, 261, 29229, 710, 14875, 2766, 280, 3837, 2162, 13, 51579], "temperature": 0.0, "avg_logprob": -0.08890102386474609, "compression_ratio": 1.463768115942029, "no_speech_prob": 0.016169510781764984}, {"id": 130, "seek": 51630, "start": 516.3, "end": 518.3, "text": " W\u0142a\u015bnie, a to nie koniec.", "tokens": [50364, 343, 5024, 12221, 11, 257, 281, 2838, 5897, 35733, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10936621463660037, "compression_ratio": 1.3927272727272728, "no_speech_prob": 0.13174982368946075}, {"id": 131, "seek": 51630, "start": 518.3, "end": 527.3, "text": " Na podstawie tego jednego zwyci\u0119skiego planu generowa\u0142 pi\u0119\u0107 pe\u0142nych wersji tekstu i znowu g\u0142osowa\u0142, by wybra\u0107 t\u0119 ostateczn\u0105.", "tokens": [50464, 6056, 43443, 414, 8627, 5232, 11858, 43436, 537, 1274, 5161, 12200, 1393, 84, 1337, 30105, 32677, 2162, 43205, 9399, 261, 433, 4013, 16624, 372, 84, 741, 710, 3785, 84, 43767, 30105, 11, 538, 4628, 6198, 2162, 32489, 277, 15406, 3689, 13113, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10936621463660037, "compression_ratio": 1.3927272727272728, "no_speech_prob": 0.13174982368946075}, {"id": 132, "seek": 51630, "start": 527.3, "end": 528.3, "text": " A efekt?", "tokens": [50914, 316, 31482, 8192, 30, 50964], "temperature": 0.0, "avg_logprob": -0.10936621463660037, "compression_ratio": 1.3927272727272728, "no_speech_prob": 0.13174982368946075}, {"id": 133, "seek": 51630, "start": 528.3, "end": 535.3, "text": " Zar\u00f3wno ocena automatyczna jak i ludzka wykaza\u0142y, \u017ce teksty Stot by\u0142y znacznie bardziej sp\u00f3jne.", "tokens": [50964, 41580, 812, 20944, 10409, 4118, 28034, 17466, 629, 4207, 741, 15946, 89, 2330, 39287, 12257, 6825, 11, 3561, 16624, 25134, 745, 310, 26366, 15397, 14875, 2766, 27209, 637, 18999, 716, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10936621463660037, "compression_ratio": 1.3927272727272728, "no_speech_prob": 0.13174982368946075}, {"id": 134, "seek": 51630, "start": 535.3, "end": 542.3, "text": " Co wi\u0119cej, ludzie w \u015blepej pr\u00f3bie preferowali wersj\u0119 Tot nad wersj\u0105 Kot w stosunku niemal dwa do jednego.", "tokens": [51314, 3066, 26004, 11, 37025, 261, 8299, 306, 494, 73, 8565, 7392, 4382, 305, 5103, 261, 433, 11115, 11236, 12617, 261, 433, 8555, 30123, 261, 43581, 49910, 2838, 5579, 35045, 360, 5232, 11858, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10936621463660037, "compression_ratio": 1.3927272727272728, "no_speech_prob": 0.13174982368946075}, {"id": 135, "seek": 54230, "start": 542.3, "end": 545.3, "text": " Mamy wi\u0119c logik\u0119, mamy kreatywno\u015b\u0107.", "tokens": [50364, 376, 7804, 16677, 3565, 1035, 1274, 11, 17335, 350, 620, 88, 20944, 7753, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 136, "seek": 54230, "start": 545.3, "end": 551.3, "text": " Zosta\u0142 nam trzeci przyk\u0142ad, kt\u00f3ry, jak rozumiem, mia\u0142 przetestowa\u0107 t\u0119 zdolno\u015b\u0107 do cofania si\u0119.", "tokens": [50514, 1176, 8638, 1221, 8835, 22266, 537, 23144, 11, 9913, 11, 4207, 48797, 4907, 11, 27989, 6541, 302, 377, 11445, 32489, 16221, 401, 23293, 360, 598, 69, 5609, 3244, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 137, "seek": 54230, "start": 551.3, "end": 552.3, "text": " Krzy\u017c\u00f3wka.", "tokens": [50814, 6332, 1229, 1427, 3901, 2330, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 138, "seek": 54230, "start": 552.3, "end": 553.3, "text": " Dok\u0142adnie.", "tokens": [50864, 29768, 10358, 2766, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 139, "seek": 54230, "start": 553.3, "end": 555.3, "text": " Mini krzy\u017c\u00f3wki pi\u0119\u0107 na pi\u0119\u0107.", "tokens": [50914, 18239, 350, 13047, 1427, 3901, 2984, 32677, 2162, 1667, 32677, 2162, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 140, "seek": 54230, "start": 555.3, "end": 560.3, "text": " Tutaj kluczowy by\u0142 algorytm Depth First Search z opcj\u0105 Backtracking.", "tokens": [51014, 41819, 9671, 1311, 89, 10089, 16673, 3501, 827, 83, 76, 4056, 392, 2386, 17180, 710, 999, 66, 8555, 5833, 6903, 14134, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 141, "seek": 54230, "start": 560.3, "end": 562.3, "text": " Model dzia\u0142a\u0142 jak cz\u0142owiek.", "tokens": [51264, 17105, 37903, 1221, 4207, 36282, 74, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 142, "seek": 54230, "start": 562.3, "end": 564.3, "text": " Pr\u00f3bowa\u0142 wpisa\u0107 jedno s\u0142owo.", "tokens": [51364, 2114, 14216, 30105, 32444, 3837, 2162, 5232, 1771, 15116, 19941, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 143, "seek": 54230, "start": 564.3, "end": 567.3, "text": " Potem, na podstawie liter, pr\u00f3bowa\u0142 kolejne, pasuj\u0105ce.", "tokens": [51464, 9145, 443, 11, 1667, 43443, 414, 2733, 11, 8565, 65, 30105, 23749, 716, 11, 1736, 13263, 384, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08427411192780608, "compression_ratio": 1.4042553191489362, "no_speech_prob": 0.1643500179052353}, {"id": 144, "seek": 56730, "start": 567.3, "end": 574.3, "text": " A\u017c dochodzi\u0142 do momentu, w kt\u00f3rym orientowa\u0142 si\u0119, \u017ce ktory\u015b has\u0142o sta\u0142o si\u0119 niemo\u017cliwe do uzupe\u0142nienia i wtedy musia\u0142 si\u0119 cofn\u0105\u0107.", "tokens": [50364, 316, 1427, 9243, 14543, 1221, 360, 1623, 84, 11, 261, 30120, 8579, 30105, 3244, 11, 3561, 350, 83, 827, 1788, 575, 5249, 11135, 5249, 3244, 2838, 3280, 1427, 2081, 826, 360, 344, 11728, 31457, 77, 18811, 741, 26959, 1038, 8908, 3244, 598, 69, 13113, 2162, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 145, "seek": 56730, "start": 574.3, "end": 576.3, "text": " I spr\u00f3bowa\u0107 innego s\u0142owa w poprzednim kroku.", "tokens": [50714, 286, 6103, 14216, 11445, 294, 11858, 15116, 5528, 261, 1665, 81, 11312, 39223, 45909, 5279, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 146, "seek": 56730, "start": 576.3, "end": 580.3, "text": " Jakby wymaza\u0142 o\u0142\u00f3wkiem has\u0142o i spr\u00f3bowa\u0142 innej opcji.", "tokens": [50814, 15029, 2322, 29764, 12257, 1221, 277, 1221, 3901, 26116, 575, 5249, 741, 6103, 14216, 30105, 294, 11794, 999, 19649, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 147, "seek": 56730, "start": 580.3, "end": 582.3, "text": " I tu znowu widzimy ogromn\u0105 przepa\u015b\u0107.", "tokens": [51014, 286, 2604, 710, 3785, 84, 27486, 13189, 34416, 298, 13113, 30829, 64, 7753, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 148, "seek": 56730, "start": 582.3, "end": 587.3, "text": " Standardowe metody mia\u0142y poni\u017cej 16% poprawno\u015bci na poziomie s\u0142\u00f3w.", "tokens": [51114, 21298, 6880, 1131, 843, 21290, 6825, 9224, 72, 38493, 3165, 4, 1665, 424, 20944, 6199, 1667, 38503, 40120, 15116, 3901, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 149, "seek": 56730, "start": 587.3, "end": 593.3, "text": " Tree of Tots dobi\u0142o do 60% poprawno\u015bci i w ca\u0142o\u015bci rozwi\u0105za\u0142o 4 z 20 krzy\u017c\u00f3wek.", "tokens": [51364, 22291, 295, 314, 1971, 360, 5614, 5249, 360, 4060, 4, 1665, 424, 20944, 6199, 741, 261, 1335, 35059, 9544, 18234, 2394, 5249, 1017, 710, 945, 350, 13047, 1427, 812, 826, 74, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 150, "seek": 56730, "start": 593.3, "end": 594.3, "text": " A pozosta\u0142e metody?", "tokens": [51664, 316, 21281, 8638, 19827, 1131, 843, 30, 51714], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 151, "seek": 56730, "start": 594.3, "end": 595.3, "text": " Ani jednej.", "tokens": [51714, 1107, 72, 5232, 11794, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06477317064168067, "compression_ratio": 1.49079754601227, "no_speech_prob": 0.23723386228084564}, {"id": 152, "seek": 59530, "start": 596.3, "end": 598.3, "text": " W najlepszym radzie po wielu pr\u00f3bach jedn\u0105.", "tokens": [50414, 343, 41903, 1878, 26681, 2843, 3283, 714, 40437, 8565, 32096, 5232, 13113, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07593872547149658, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.05990573391318321}, {"id": 153, "seek": 59530, "start": 598.3, "end": 606.3, "text": " To pokazuje, \u017ce dla pewnej klasy problem\u00f3w zdolno\u015b\u0107 do systematycznej eksploracji korygowania b\u0142\u0119d\u00f3w nie jest dodatkiem.", "tokens": [50514, 1407, 13010, 43317, 11, 3561, 12285, 25889, 11794, 9671, 5871, 1154, 3901, 16221, 401, 23293, 360, 1185, 267, 17466, 11794, 30724, 564, 284, 13152, 350, 827, 70, 21308, 272, 1221, 6298, 3901, 2838, 3492, 13886, 267, 26116, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07593872547149658, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.05990573391318321}, {"id": 154, "seek": 59530, "start": 606.3, "end": 608.3, "text": " Jest absolutnie kluczowa.", "tokens": [50914, 24918, 18757, 2766, 9671, 1311, 89, 5528, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07593872547149658, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.05990573391318321}, {"id": 155, "seek": 59530, "start": 608.3, "end": 614.3, "text": " S\u0142uchaj\u0105c tego wszystkiego mam wra\u017cenie, \u017ce to nie jest po prostu kolejna zaawansowana technika promptowania.", "tokens": [51014, 318, 1221, 625, 38757, 8627, 14615, 12200, 13524, 7843, 41118, 11, 3561, 281, 2838, 3492, 714, 19518, 23749, 629, 7949, 1607, 599, 40458, 1537, 5439, 12391, 21308, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07593872547149658, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.05990573391318321}, {"id": 156, "seek": 59530, "start": 614.3, "end": 619.3, "text": " To wygl\u0105da na co\u015b znacznie wi\u0119kszego, na now\u0105 architektur\u0119 rozumowania.", "tokens": [51314, 1407, 32015, 1667, 19241, 15397, 14875, 2766, 29968, 27725, 11, 1667, 586, 1611, 3912, 642, 2320, 374, 1274, 48797, 21308, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07593872547149658, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.05990573391318321}, {"id": 157, "seek": 61930, "start": 619.3, "end": 624.3, "text": " Cietnie to uj\u0119\u0142a\u015b. Tree of Tots to nie jest prompt, to jest framework.", "tokens": [50364, 383, 1684, 2766, 281, 344, 11115, 5024, 1788, 13, 22291, 295, 314, 1971, 281, 2838, 3492, 12391, 11, 281, 3492, 8388, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 158, "seek": 61930, "start": 624.3, "end": 626.3, "text": " To spos\u00f3b na po\u0142\u0105czenie dw\u00f3ch \u015bwiat\u00f3w.", "tokens": [50614, 1407, 22904, 1667, 714, 15926, 39043, 27379, 812, 339, 36425, 3901, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 159, "seek": 61930, "start": 626.3, "end": 630.3, "text": " Z jednej strony ogromnej generatywnej mocy LLM-\u00f3w,", "tokens": [50714, 1176, 5232, 11794, 32406, 34416, 298, 11794, 1337, 21398, 86, 11794, 705, 1344, 441, 43, 44, 12, 3901, 11, 50914], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 160, "seek": 61930, "start": 630.3, "end": 636.3, "text": " a z drugiej systematycznej ustrukturyzowanej eksploracji znanej z klasycznych algorytm\u00f3w AI.", "tokens": [50914, 257, 710, 47373, 1185, 267, 17466, 11794, 26189, 19977, 2598, 89, 23066, 73, 30724, 564, 284, 13152, 15397, 1929, 73, 710, 9671, 5871, 3689, 9399, 3501, 827, 83, 76, 3901, 7318, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 161, "seek": 61930, "start": 636.3, "end": 643.3, "text": " Ale najwa\u017cniejsz\u0105 innowacj\u0105 jest to, \u017ce rol\u0119 heurystyki tego inteligentnego przewodnika pe\u0142ni sam model.", "tokens": [51214, 9366, 11212, 27111, 30295, 8925, 294, 3785, 326, 8555, 3492, 281, 11, 3561, 34109, 1274, 415, 2598, 25134, 2984, 8627, 24777, 25002, 11858, 39758, 378, 77, 5439, 43205, 3722, 3247, 2316, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 162, "seek": 61930, "start": 643.3, "end": 647.3, "text": " On staje si\u0119 jednocze\u015bnie generatorem, planerem i krytycznym ewaluatorem.", "tokens": [51564, 1282, 342, 11153, 3244, 5232, 26694, 1381, 12221, 1337, 267, 37956, 11, 1393, 7333, 741, 34847, 874, 3689, 12996, 43364, 4929, 267, 37956, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07207669904155116, "compression_ratio": 1.4408945686900958, "no_speech_prob": 0.11449252814054489}, {"id": 163, "seek": 64730, "start": 647.3, "end": 651.3, "text": " A to otwiera drzwi do zastosowa\u0144 w naprawd\u0119 z\u0142o\u017conych dziedzinach.", "tokens": [50364, 316, 281, 4337, 86, 10609, 1224, 89, 6253, 360, 36746, 329, 5528, 5248, 261, 20970, 710, 5249, 1427, 2526, 339, 9758, 15338, 259, 608, 13, 50564], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 164, "seek": 64730, "start": 651.3, "end": 657.3, "text": " My\u015bl\u0119 o generowaniu skomplikowanego kodu, gdzie jeden b\u0142\u0105d mo\u017ce zepsu\u0107 ca\u0142y problem.", "tokens": [50564, 1222, 28749, 277, 1337, 305, 25849, 1110, 298, 564, 1035, 37345, 6308, 350, 34873, 11, 18922, 12906, 272, 15926, 67, 12034, 710, 10653, 84, 2162, 35226, 1154, 13, 50864], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 165, "seek": 64730, "start": 657.3, "end": 661.3, "text": " Tam zdolno\u015b\u0107 do eksploracji i cofania si\u0119 jest bezcenna.", "tokens": [50864, 8540, 16221, 401, 23293, 360, 30724, 564, 284, 13152, 741, 598, 69, 5609, 3244, 3492, 10782, 13037, 629, 13, 51064], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 166, "seek": 64730, "start": 661.3, "end": 666.3, "text": " Zdecydowanie. Albo analiza danych, gdzie trzeba testowa\u0107 r\u00f3\u017cnych hipotezy.", "tokens": [51064, 1176, 1479, 1344, 67, 22028, 13, 967, 1763, 2624, 13427, 274, 34644, 11, 18922, 25860, 1500, 11445, 42602, 8103, 1370, 1229, 13, 51314], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 167, "seek": 64730, "start": 666.3, "end": 670.3, "text": " Czy nawet robotyka, gdzie robot musi zaplanowa\u0107 z\u0142o\u017con\u0105 sekwencj\u0119 ruch\u00f3w.", "tokens": [51314, 19832, 22696, 3870, 6737, 2330, 11, 18922, 7881, 37587, 7949, 16554, 11445, 710, 5249, 1427, 266, 1611, 17215, 15615, 41960, 367, 625, 3901, 13, 51514], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 168, "seek": 64730, "start": 670.3, "end": 675.3, "text": " Wsz\u0119dzie tam, gdzie nie ma jednej prostej \u015bcie\u017cki do celu, to podej\u015bcie ma oldrzymi potencja\u0142.", "tokens": [51514, 343, 15453, 42643, 7677, 11, 18922, 2838, 463, 5232, 11794, 10293, 40779, 8299, 40082, 2984, 360, 9277, 84, 11, 281, 7468, 73, 9815, 463, 2545, 16753, 1229, 3057, 1847, 22660, 2938, 1221, 13, 51764], "temperature": 0.0, "avg_logprob": -0.04936641346324574, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.05054652690887451}, {"id": 169, "seek": 67530, "start": 676.3, "end": 681.3, "text": " Brzmi rewolucyjnie, ale musi by\u0107 jaki\u015b haczyk. Jakie s\u0105 wady tego podej\u015bcia?", "tokens": [50414, 1603, 89, 3057, 319, 48481, 1311, 88, 73, 2766, 11, 6775, 37587, 15069, 34721, 324, 6522, 74, 13, 15029, 414, 9015, 261, 880, 8627, 7468, 73, 1788, 2755, 30, 50664], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 170, "seek": 67530, "start": 681.3, "end": 684.3, "text": " Gdzie jest koszt tej ca\u0142ej pot\u0119gi?", "tokens": [50664, 460, 13096, 3492, 19532, 2682, 12573, 47631, 73, 1847, 1274, 7834, 30, 50814], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 171, "seek": 67530, "start": 684.3, "end": 690.3, "text": " Koszt jest bardzo dos\u0142owny. G\u0142\u00f3wnym ograniczeniem jest zasobo\u017cerno\u015b\u0107.", "tokens": [50814, 36909, 2682, 3492, 9034, 4491, 1221, 648, 88, 13, 460, 1221, 812, 895, 4199, 34416, 30732, 2904, 4907, 3492, 26530, 996, 78, 1427, 1248, 78, 7753, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 172, "seek": 67530, "start": 690.3, "end": 696.3, "text": " Tree of Thots wymaga znacznie, znacznie wi\u0119cej mocy obliczeniowej i token\u00f3w ni\u017c standardowe promptowanie.", "tokens": [51114, 22291, 295, 334, 1971, 29764, 9286, 15397, 14875, 2766, 11, 15397, 14875, 2766, 26004, 705, 1344, 1111, 1050, 42124, 21091, 741, 14862, 3901, 28502, 3832, 6880, 12391, 22028, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 173, "seek": 67530, "start": 696.3, "end": 698.3, "text": " To znaczy ile wi\u0119cej?", "tokens": [51414, 1407, 36584, 15465, 26004, 30, 51514], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 174, "seek": 67530, "start": 698.3, "end": 700.3, "text": " Wr\u00f3\u0107my do gry w 24.", "tokens": [51514, 10159, 812, 2162, 2226, 360, 41974, 261, 4022, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0877856674194336, "compression_ratio": 1.3607843137254902, "no_speech_prob": 0.15974628925323486}, {"id": 175, "seek": 70030, "start": 700.3, "end": 708.3, "text": " Jedna udana pr\u00f3ba rozwi\u0105zania za pomoc\u0105 TOT zu\u017cy\u0142a podobn\u0105 liczb\u0119 token\u00f3w, co oko\u0142o 100 pr\u00f3b metod\u0105 Chain of Thot.", "tokens": [50364, 27076, 629, 11727, 2095, 8565, 4231, 9544, 22620, 5609, 7949, 48962, 1611, 314, 5068, 2164, 7735, 5024, 43024, 13113, 6169, 89, 65, 1274, 14862, 3901, 11, 598, 45730, 5249, 2319, 8565, 65, 1131, 378, 1611, 33252, 295, 334, 310, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12453738125887784, "compression_ratio": 1.4089219330855018, "no_speech_prob": 0.4739895462989807}, {"id": 176, "seek": 70030, "start": 708.3, "end": 711.3, "text": " 100 pr\u00f3b? To jest ogromna r\u00f3\u017cnica.", "tokens": [50764, 2319, 8565, 65, 30, 1407, 3492, 34416, 298, 629, 19637, 32687, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12453738125887784, "compression_ratio": 1.4089219330855018, "no_speech_prob": 0.4739895462989807}, {"id": 177, "seek": 70030, "start": 711.3, "end": 718.3, "text": " Tak, ale jest tu wa\u017cny niuans. Mimo podobnego kosztu, TOT osi\u0105gn\u0119\u0142o 74% skuteczno\u015bci.", "tokens": [50914, 9118, 11, 6775, 3492, 2604, 27777, 1634, 3867, 84, 599, 13, 376, 6934, 43024, 11858, 19532, 2682, 84, 11, 314, 5068, 3003, 11404, 4568, 1274, 5249, 28868, 4, 1110, 1169, 3689, 16438, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12453738125887784, "compression_ratio": 1.4089219330855018, "no_speech_prob": 0.4739895462989807}, {"id": 178, "seek": 70030, "start": 718.3, "end": 726.3, "text": " A nawet je\u015bli z dmy Chain of Thot 100 pr\u00f3b i wzi\u0119li\u015bmy najlepszy wynik, to i tak jego skuteczno\u015b\u0107 wynios\u0142a tylko 49%.", "tokens": [51264, 316, 22696, 25630, 710, 274, 2226, 33252, 295, 334, 310, 2319, 8565, 65, 741, 261, 16706, 38452, 41903, 1878, 1229, 31936, 1035, 11, 281, 741, 991, 26542, 1110, 1169, 3689, 23293, 31936, 2717, 5024, 13219, 16513, 6856, 51664], "temperature": 0.0, "avg_logprob": -0.12453738125887784, "compression_ratio": 1.4089219330855018, "no_speech_prob": 0.4739895462989807}, {"id": 179, "seek": 72630, "start": 726.3, "end": 734.3, "text": " Czyli p\u0142acimy znacznie wi\u0119cej, ale nie za wi\u0119cej liczb\u0119 losowych strza\u0142\u00f3w, tylko za jeden dobrze zaplanowany.", "tokens": [50364, 37099, 28695, 326, 13189, 15397, 14875, 2766, 26004, 11, 6775, 2838, 7949, 26004, 6169, 89, 65, 1274, 1750, 19605, 1056, 2394, 1221, 3901, 11, 13219, 7949, 12906, 28335, 7949, 16554, 23341, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05416034843962071, "compression_ratio": 1.4092664092664093, "no_speech_prob": 0.01911408081650734}, {"id": 180, "seek": 72630, "start": 734.3, "end": 738.3, "text": " To kompromis mi\u0119dzy brutaln\u0105 si\u0142\u0105 a inteligencj\u0105.", "tokens": [50764, 1407, 5207, 28722, 271, 33964, 17878, 13113, 1511, 15926, 257, 24777, 3213, 66, 8555, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05416034843962071, "compression_ratio": 1.4092664092664093, "no_speech_prob": 0.01911408081650734}, {"id": 181, "seek": 72630, "start": 738.3, "end": 741.3, "text": " Dok\u0142adnie. P\u0142acimy za niezawodno\u015b\u0107.", "tokens": [50964, 29768, 10358, 2766, 13, 430, 1221, 326, 13189, 7949, 33511, 1607, 378, 23293, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05416034843962071, "compression_ratio": 1.4092664092664093, "no_speech_prob": 0.01911408081650734}, {"id": 182, "seek": 72630, "start": 741.3, "end": 753.3, "text": " A w wielu zastosowaniach jedna odpowied\u017a z prawdopodobie\u0144stwem sukcesu 74% jest niesko\u0144czenie cenniejsza ni\u017c 100 odpowiedzi z prawdopodobie\u0144stwem 4%.", "tokens": [51114, 316, 261, 40437, 36746, 329, 305, 3782, 608, 5232, 629, 36574, 10659, 710, 41175, 46684, 996, 414, 12229, 86, 443, 46432, 887, 84, 28868, 4, 3492, 48100, 4093, 5248, 39043, 27900, 30295, 2394, 28502, 2319, 36574, 3992, 710, 41175, 46684, 996, 414, 12229, 86, 443, 1017, 6856, 51714], "temperature": 0.0, "avg_logprob": -0.05416034843962071, "compression_ratio": 1.4092664092664093, "no_speech_prob": 0.01911408081650734}, {"id": 183, "seek": 75330, "start": 753.3, "end": 758.3, "text": " Gdyby\u015b mia\u0142 podsumowa\u0107 esencj\u0119 Tree of Thot w jednym kluczowym zdaniu, jakby ono brzmia\u0142o.", "tokens": [50364, 460, 3173, 2322, 1788, 27989, 31925, 449, 11445, 785, 22660, 11115, 22291, 295, 334, 310, 261, 5232, 12996, 9671, 1311, 89, 31691, 16221, 25849, 11, 28976, 322, 78, 738, 89, 29958, 5249, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07300120744949733, "compression_ratio": 1.4968152866242037, "no_speech_prob": 0.04107503965497017}, {"id": 184, "seek": 75330, "start": 758.3, "end": 771.3, "text": " Powiedzia\u0142bym, \u017ce przewodzimy od modeli, kt\u00f3re s\u0105 genialnymi na\u015bladowcami i generuj\u0105 statystycznie prawdopodobny tekst do system\u00f3w, kt\u00f3re s\u0105 zdolne do celowego i ustrukturyzowanego rozwi\u0105zywania problem\u00f3w.", "tokens": [50614, 14762, 15338, 8908, 2322, 76, 11, 3561, 39758, 378, 89, 13189, 3611, 2316, 72, 11, 8864, 9015, 48228, 31813, 1667, 1788, 9290, 305, 66, 4526, 741, 1337, 13263, 2219, 38593, 17466, 2766, 41175, 46684, 996, 1634, 16624, 372, 360, 1185, 3901, 11, 8864, 9015, 16221, 401, 716, 360, 9277, 26576, 741, 26189, 19977, 2598, 89, 37345, 6308, 9544, 18234, 1229, 86, 5609, 1154, 3901, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07300120744949733, "compression_ratio": 1.4968152866242037, "no_speech_prob": 0.04107503965497017}, {"id": 185, "seek": 75330, "start": 771.3, "end": 782.3, "text": " To tak, jakby\u015bmy dali genialnemu, ale bardzo impulsywnemu umys\u0142owi systemu 1 narz\u0119dzia do metodycznego planowania i samokrytyki, czyli atrybuty systemu 2.", "tokens": [51264, 1407, 991, 11, 28976, 10513, 274, 5103, 48228, 25989, 84, 11, 6775, 9034, 704, 9468, 27112, 25989, 84, 1105, 39508, 24503, 1185, 84, 502, 6714, 89, 6298, 40395, 360, 1131, 843, 3689, 11858, 1393, 21308, 741, 3247, 453, 627, 874, 2984, 11, 16591, 412, 627, 5955, 88, 1185, 84, 568, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07300120744949733, "compression_ratio": 1.4968152866242037, "no_speech_prob": 0.04107503965497017}, {"id": 186, "seek": 78330, "start": 783.3, "end": 790.3, "text": " To \u015bwietnie zamyka nasz\u0105 analiz\u0119, ale zostawi\u0119 jeszcze naszych s\u0142uchaczy z jedn\u0105 prowokacyjn\u0105 my\u015bl\u0105.", "tokens": [50364, 1407, 8299, 39083, 2766, 710, 7804, 2330, 5382, 8925, 2624, 590, 1274, 11, 6775, 31873, 1607, 5034, 14168, 45002, 15116, 625, 14691, 710, 5232, 13113, 45553, 453, 31285, 13113, 452, 19212, 1611, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0801894303524133, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.03992125019431114}, {"id": 187, "seek": 78330, "start": 790.3, "end": 797.3, "text": " Autorzy tej pracy skupili si\u0119 na zastosowaniu Tree of Thot jako takie nak\u0142adki na ju\u017c istniej\u0105ce modele.", "tokens": [50714, 6049, 284, 1229, 12573, 35591, 1110, 1010, 2312, 3244, 1667, 36746, 329, 305, 25849, 22291, 295, 334, 310, 17123, 15963, 20332, 10358, 2984, 1667, 10678, 1418, 2766, 8555, 384, 4391, 306, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0801894303524133, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.03992125019431114}, {"id": 188, "seek": 78330, "start": 797.3, "end": 810.3, "text": " A teraz pomy\u017amy, co si\u0119 stanie, gdy zaczniemy trenowa\u0107 modele od podstaw, wbudowuj\u0105c w nie ten celowy, wielo\u015b\u0107 ci\u0119\u017ckowy i samokoryguj\u0105cy si\u0119 proces my\u015blenia na najbardziej fundamentalnym poziomie.", "tokens": [51064, 316, 16854, 280, 8488, 10659, 2226, 11, 598, 3244, 40013, 11, 28405, 710, 14875, 2766, 2226, 23136, 11445, 4391, 306, 3611, 43443, 11, 261, 18281, 305, 44733, 261, 2838, 2064, 9277, 10089, 11, 20570, 78, 7753, 35484, 1427, 74, 10089, 741, 3247, 453, 827, 2794, 8555, 1344, 3244, 17565, 48633, 6698, 654, 1667, 41857, 8088, 12996, 38503, 40120, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0801894303524133, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.03992125019431114}, {"id": 189, "seek": 81030, "start": 810.3, "end": 815.3, "text": " Czy w\u0142a\u015bnie patrzymy na zarys fundamentalnie bardziej zaawansowanej formy sztucznej inteligencji?", "tokens": [50364, 19832, 14234, 1947, 13047, 2226, 1667, 22675, 749, 8088, 2766, 27209, 7949, 1607, 599, 23066, 73, 1254, 88, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 30, 50614], "temperature": 0.0, "avg_logprob": -0.03984483083089193, "compression_ratio": 1.064516129032258, "no_speech_prob": 0.1670965552330017}], "language": "pl"}