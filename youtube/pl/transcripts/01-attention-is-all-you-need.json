{"text": " Witam w The Deep Dive. Wyobra\u017cmy sobie tak\u0105 sytuacj\u0119. Ca\u0142a nauka w jakiej\u015b dziedzinie od lat buduje coraz wy\u017csze, coraz bardziej skomplikowane drapacze chmur. Ale wszystkie stoj\u0105 na jednym fundamentalnym za\u0142o\u017ceniu. I nagle w 2017 roku pojawia si\u0119 artyku\u0142, kt\u00f3re m\u00f3wi, a co je\u015bli te fundamenty s\u0105 w og\u00f3le niepotrzebne? To znaczy, \u017ce mo\u017cna budowa\u0107 inaczej. Dok\u0142adnie, \u017ce mo\u017cna budowa\u0107 wy\u017cej, szybciej i opieraj\u0105c wszystko na zupe\u0142nie innej zasadzie. Tym artyku\u0142em by\u0142o attention is all you need. I to by\u0142a prawdziwa rewolucja w \u015bwiecie AI. Bez dw\u00f3ch zdanie. Dzisiaj w\u0142a\u015bnie w ten dokument si\u0119 zag\u0142\u0119bimy. Chcemy zrozumie\u0107, co by\u0142o tak prze\u0142omowego w pomy\u015ble, kt\u00f3ry wydawa\u0142 si\u0119 prawie zuchwa\u0142y. Autorzy postawili proste pytanie. Tak. Co by by\u0142o, gdyby model j\u0119zykowy nie musia\u0142 czyta\u0107 zdania s\u0142owo po s\u0142owie? Sekwencyjnie, ale m\u00f3g\u0142 spojrze\u0107 na nieca\u0142o\u015bciowo. Od razu. Jak to by wp\u0142yn\u0105\u0142 na przyk\u0142ad na t\u0142umaczenie maszynowe? I to jest wiesz absolutnie kluczowe pytanie. Bo ono dotyka sedna problemu, z kt\u00f3rym boryka\u0142a si\u0119 ca\u0142a dziedzina. Czyli z czym dok\u0142adnie? Przed 2017 rokiem kr\u00f3lowa\u0142y modele sekwencyjne. G\u0142\u00f3wnie sieci rekurencyjne, czyli recurrent neural networks w skr\u00f3cie RNN. I te s\u0142ynne LSTM. Tak, i ich ulepszone wersje, jak LSTM. Ale wszystkie dzia\u0142a\u0142y tak samo, krok po kroku. To mia\u0142o jedn\u0105 fundamentaln\u0105 wad\u0119. I jak\u0105? No, uniemo\u017cliwia\u0142o efektywn\u0105 paralelizacj\u0119, czyli r\u00f3wnoleg\u0142e przetwarzanie. Trening by\u0142 przez to koszmarnie wolny i, co gorsza, modele mia\u0142y gigantyczny problem z zapami\u0119tywaniem zale\u017cno\u015bci mi\u0119dzy odleg\u0142ymi od siebie s\u0142owami. Czyli wracaj\u0105c do naszej metafory, budowano coraz wy\u017csze pi\u0119tra, ale na fundamencie, kt\u00f3ry po prostu ogranicza\u0142 i tempo i wysoko\u015b\u0107. Dok\u0142adnie. Tak, autorzy Attention Is All You Need zburzyli ten stary porz\u0105dek i zaproponowali now\u0105 prost\u0105 architektur\u0119. Opart\u0105 tylko na mechanizmie Attention. I nazwali j\u0105 Transformer. W\u0142a\u015bnie tak. Dobrze, to zacznijmy od tego, co leg\u0142o w gruzach. M\u00f3wisz, \u017ce modele sekwencyjne jak RNN czy LSTM by\u0142y problematyczne. Ale przecie\u017c jako\u015b dzia\u0142a\u0142y, osi\u0105ga\u0142y coraz lepsze wyniki. Dzia\u0142a\u0142y, jasne, ale z trudem. Na czym dok\u0142adnie polega\u0142o to w\u0105skie gard\u0142o? Wyobra\u017c sobie, \u017ce czytasz bardzo d\u0142ugie, z\u0142o\u017cone zdanie. W architekturze RNN, \u017ceby zrozumie\u0107 sens, powiedzmy, 20 s\u0142owa, model musi najpierw przetworzy\u0107 19 poprzednich. Jedno po drugim. Tak, jedno po drugim. Przekazuj\u0105c sobie tak\u0105 pami\u0119\u0107 z kroku na krok. To jest troch\u0119 jak zabawa w g\u0142uchy telefon. Aha, czyli informacja si\u0119 zniekszta\u0142ca po drodze? Dok\u0142adnie. Informacja z pocz\u0105tku zdania, zanim dotrze na koniec, ulega za tarciu. Ten problem, znany jako vanishing gradient, sprawia\u0142, \u017ce modelom by\u0142o extremalnie trudno nauczy\u0107 si\u0119 tak zwanych long range dependencies. Czyli tych zale\u017cno\u015bci na du\u017ce odlego\u015bci. Tak, na przyk\u0142ad w zdaniu ch\u0142opiec, kt\u00f3ry przez ca\u0142e popo\u0142udnie bawi\u0142 si\u0119 z psami na \u0142\u0105ce, by\u0142 bardzo zm\u0119czony. Model musia\u0142 jako\u015b powi\u0105za\u0107 ch\u0142opiec zby\u0142. A dzieli\u0142o je kilkana\u015bcie s\u0142\u00f3w. No w\u0142a\u015bnie, dla RNN to by\u0142o ogromne wyzwanie. Rozumiem. Czyli im d\u0142u\u017cszy kontekst, tym mo\u017cna powiedzie\u0107 wi\u0119ksza amnezja modelu. I pewnie pr\u00f3bowano to jako\u015b \u0142ata\u0107? Oczywi\u015bcie. Stosowano r\u00f3\u017cne triki, jak te wspomniane sieci LSTM z ich systemem bramek, kt\u00f3re mia\u0142y zarz\u0105dza\u0107 pami\u0119ci\u0105. By\u0142y nawet sieci konwolucyjne w modelach jak ConfS2S. Ale to by\u0142y tylko protezy. Tak, to wszystko by\u0142y usprawnienia, a nie rozwi\u0105zanie fundamentalnego problemu. Wci\u0105\u017c istnia\u0142a ta \u015bcie\u017cka, kt\u00f3r\u0105 informacja musia\u0142a pokona\u0107. A jej d\u0142ugo\u015b\u0107 ros\u0142a z odleg\u0142o\u015bci\u0105. To tak jakby\u015b pr\u00f3bowa\u0142a krzycze\u0107 do kogo\u015b po drugiej stronie boiska. Im dalej, tym gorzej ci\u0119 s\u0142ycha\u0107. I wtedy, gdy wszyscy pr\u00f3buj\u0105 wymy\u015bli\u0107 g\u0142o\u015bniejszy megafon, pojawia si\u0119 ten artyku\u0142. A jego tytu\u0142 brzmi jak manifest. Uwaga to wszystko, czego potrzebujesz. Dok\u0142adnie. To brzmi a\u017c zbyt prosto. Gdzie jest magia tego mechanizmu self-attention? Jak on m\u00f3g\u0142 zast\u0105pi\u0107 ca\u0142\u0105 t\u0105 skomplikowan\u0105 sekwencyjn\u0105 maszyneri\u0119? Na tym, \u017ce on kompletnie zmienia zasady gry. Transformer by\u0142 pierwsz\u0105 architektur\u0105, kt\u00f3ra w og\u00f3le nie u\u017cywa\u0142a rekurencji. W og\u00f3le. A zamiast tego? Zamiast tego w 100% oparli si\u0119 na self-attention. A idea tego mechanizmu jest, no, rewolucyjna w swojej prostocie. To znaczy? S\u0142owa. I oceni\u0107 ich wag\u0119. Ich istotno\u015b\u0107 dla kontekstu tego jednego konkretnego s\u0142owa. Czyli to ju\u017c nie jest g\u0142uchy telefon. To bardziej jak okr\u0105g\u0142y st\u00f3\u0142. O, dobre por\u00f3wnanie. Wszystkie s\u0142owa siedz\u0105 razem i mog\u0105 ze sob\u0105 rozmawia\u0107 jednocze\u015bnie bez \u017cadnych po\u015brednik\u00f3w. Dok\u0142adnie tak. Ka\u017cde s\u0142owo mo\u017ce bezpo\u015brednio zapyta\u0107 ka\u017cde inne. Hej, jak bardzo jeste\u015b dla mnie wa\u017cny w tym kontek\u015bcie? To prowadzi do dw\u00f3ch, no, prze\u0142omowych konsekwencji. Pierwsza? Po pierwsze problem odleg\u0142o\u015bci znika. W starych modelach \u015bcie\u017cka informacji ros\u0142a liniowo z odleg\u0142o\u015bci\u0105. Tu w Transformerze ta odlego\u015b\u0107 jest zawsze sta\u0142a i wynosi jeden. Ka\u017cde s\u0142owo ma bezpo\u015brednie po\u0142\u0105czenie z ka\u017cdym innym. To musia\u0142o radykalnie u\u0142atwi\u0107 nauk\u0119 tych dalekosi\u0119\u017cnych zale\u017cno\u015bci. Oczywi\u015bcie. To by\u0142a pierwsza rzecz. A druga? Paralelizacja. Skoro nie ma tej zale\u017cno\u015bci krok po kroku, obliczenia dla ka\u017cdego s\u0142owa mo\u017cna robi\u0107 w tym samym czasie. R\u00f3wnolegle. I to by\u0142 ten prze\u0142om? Absolutne. Training modeli przesta\u0142 by\u0107 procesem, kt\u00f3ry ci\u0105gnie si\u0119 w niesko\u0144czono\u015b\u0107. To tak jakby zamiast budowa\u0107 wie\u017cowiec pi\u0119tro po pi\u0119trze, mog\u0142a budowa\u0107 wszystkie pi\u0119tra naraz i na ko\u0144cu je z\u0142o\u017cy\u0107. To otworzy\u0142o drzwi do eksperyment\u00f3w na zupe\u0142nie now\u0105 skal\u0119. Na skal\u0119, kt\u00f3ra wcze\u015bniej by\u0142a po prostu niemo\u017cliwa z powodu barieru obliczeniowych. Ok. Koncepcja jest naprawd\u0119 pot\u0119\u017cna. Ale jak to wygl\u0105da w praktyce? W artykule jest ten s\u0142ynny diagram, kt\u00f3ry sta\u0142 si\u0119 ju\u017c ikon\u0105. Roz\u0142\u00f3\u017cmy t\u0119 architektur\u0119 naczynniki pierwsze. Jasne. Ten diagram pokazuje klasyczn\u0105 struktur\u0119 encoder-decoder. To by\u0142o bardzo popularne w t\u0142umaczeniach maszynowych. Czyli mamy dwie cz\u0119\u015bci. Tak. Po lewej stronie jest encoder, po prawej decoder. Zadaniem encodera jest powiedzmy przeczytanie i zrozumienie zdania wej\u015bciowego. Na przyk\u0142ad po niemiecku. Jak to robi? Przepu\u015bcia je przez stos sze\u015bciu identycznych warstw. A ka\u017cda z tych warstw ma dwa g\u0142\u00f3wne elementy. Mechanizm multi-head self-attention, o kt\u00f3rym zaraz powiemy. I prost\u0105 sie\u0107 neuronow\u0105, tak zwan\u0105 feed-forward network. Czyli encoder tworzy tak\u0105 bogat\u0105, numeryczn\u0105 reprezentacj\u0119 znaczenia zdania. A co z decoderem? A decoder bierze te reprezentacje i s\u0142owo po s\u0142owie generuje t\u0142umaczenie. Na przyk\u0142ad na angielski. On te\u017c ma te warstwy? Te\u017c ma sze\u015b\u0107 warstw, bardzo podobnych do tych w encoderze, ale z jednym kluczowym dodatkiem. Opr\u00f3cz self-attention, kt\u00f3re patrzy na to, co ju\u017c przet\u0142umaczy\u0142, ma drug\u0105 warstw\u0119 attention, kt\u00f3ra patrzy na wyj\u015bcie z encodera. \u017beby wiedzie\u0107, na czym si\u0119 skupi\u0107 w oryginalnym zdaniu? Dok\u0142adnie. To pozwola mu w ka\u017cdym kroku skupi\u0107 si\u0119 na najwa\u017cniejszych fragmentach orygina\u0142u. Czekaj, pojawi\u0142o si\u0119 tu okre\u015blenie multi-head attention. Wielog\u0142owa uwaga. To brzmi, jak przerost formy nad tre\u015bci\u0105. Dlaczego model musi patrze\u0107 na relacje mi\u0119dzy s\u0142owami nieraz, a jak czytamy, osiem razy naraz? To \u015bwietne pytanie, bo dotyka geniuszu tego rozwi\u0105zania. No w\u0142a\u015bnie, czy te g\u0142owy nie robi\u0105 w k\u00f3\u0142ko tego samego? Nie do ko\u0144ca. Jedna g\u0142owa, czyli jeden head uwagi, mog\u0142aby si\u0119 nauczy\u0107 rozpoznawa\u0107 powiedzmy jeden rodzaj zale\u017cno\u015bci. Na przyk\u0142ad relacje podmiot o \u017cyczenie. Ale j\u0119zyk jest bardziej z\u0142o\u017cony. Znacznie. I multi-head attention pozwala modelowi jednocze\u015bnie, r\u00f3wnolegle, analizowa\u0107 zdanie pod r\u00f3\u017cnymi k\u0105tami. Mo\u017cna sobie wyobrazi\u0107, \u017ce jedna g\u0142owa skupia si\u0119 na sk\u0142adni. Druga na tym, co logicznie wynika z czego. Trzecia mo\u017ce \u015bledzi\u0107 zajmki, a czwarta analizuje relacje semantyczne. Czyli to tak, jakby mie\u0107 zesp\u00f3\u0142 specjalist\u00f3w. Dok\u0142adnie. To nie jest robienie tego samego osiem razy. To jak posiadanie o\u015bmiu wyspecjalizowanych analityk\u00f3w, kt\u00f3rzy patrz\u0105 na ten sam problem i na ko\u0144cu dziel\u0105 si\u0119 swoimi wnioskami. Dopiero to daje pe\u0142ny obraz. To ma sens. Ale jest jeszcze jedna rzecz. Je\u015bli porzucamy przetwarzanie sekwencyjne, to sk\u0105d model wie, w jakiej kolejno\u015bci s\u0105 s\u0142owa? Przecie\u017c pies gonikota to co\u015b zupe\u0142nie innego ni\u017c kot gonipsa. Bez rekurencji ta informacja o kolejno\u015bci wydaje si\u0119 gin\u0105\u0107. I tu dochodzimy do kolejnego, genialnego w swojej prostocie rozwi\u0105zania. Nazwali je Positional Encoding. To by\u0142a niezwykle sprytna sztuczka. Na czym polega\u0142a? Zanim s\u0142owa trafi\u0105 do modelu ich wektorowe reprezentacje, czyli embeddings, s\u0105 wzbogacane o dodatkowy wektor. Wektor, kt\u00f3ry koduje pozycj\u0119 s\u0142owa w zdaniu. I nie u\u017cyli do tego zwyk\u0142ego licznika 1, 2, 3? Nie. Zamiast tego wykorzystali zestaw funkcji sinusoidalnych, sinus\u00f3w i cosinus\u00f3w o r\u00f3\u017cnych cz\u0119stotliwo\u015bciach. Dlaczego akurat sinus i cosinus? To wydaje si\u0119 do\u015b\u0107 abstrakcyjna. Poniewa\u017c funkcje te maj\u0105 regularne, przewidywalne w\u0142a\u015bciwo\u015bci. To pozwala modelowi \u0142atwo uczy\u0107 si\u0119 relatywnych pozycji. Co wi\u0119cej, ta metoda potencjalnie pozwala mu generalizowa\u0107 na zdania d\u0142u\u017csze ni\u017c te, kt\u00f3re widzia\u0142 w treningu. To du\u017cy plus. Ogromny. Wcze\u015bniej model musia\u0142 si\u0119 uczy\u0107 ka\u017cdej pozycji z osobna. A tutaj, to tak jakby ka\u017cde s\u0142owo dostawa\u0142o unikalny kod pocztowy, kt\u00f3ry m\u00f3wi, gdzie jest i jak daleko ma do s\u0105siad\u00f3w. Dobrze, teoria brzmi niesamowicie sp\u00f3jnie i elegancko. Ale teoria to jedno. Pora na dowody. Jak ta pi\u0119kna architektura poradzi\u0142a sobie w zderzeniu z rzeczywisto\u015bci\u0105? I tu, no c\u00f3\u017c, tu zaczyna si\u0119 prawdziwy knockout. Wyniki, kt\u00f3re przedstawili by\u0142y nie tyle lepsze, co po prostu deklasuj\u0105ce konkurencje. A\u017c tak? We\u017amy standardowe zadanie t\u0142umaczenia maszynowego na zbiorze danych WMT 2014 z angielskiego na niemiecki. Najlepsze dotyczczasowe modele, cz\u0119sto skomplikowane hybrydy r\u00f3\u017cnych architektur, tak zwane ensemble, mia\u0142y pewien pu\u0142ap. Transformer w swojej du\u017cej wersji, Transformer Big, osi\u0105gn\u0105\u0142 wynik 28 i 40 blu. By\u0142o o ponad dwa punkty wi\u0119cej. Wow, zatrzymajmy si\u0119 na chwil\u0119. Wiem, \u017ce w tamtych czasach ka\u017cdy u\u0142amek punktu blu by\u0142 na wag\u0119 z\u0142ota. Dok\u0142adnie. Dwa punkty przewagi nad absolutnie najlepszymi modelami \u015bwiata to nie jest drobna poprawka. To jakby w biegu na 100 metr\u00f3w kto\u015b pobi\u0142 rekord \u015bwiata o p\u00f3\u0142 sekundy. To jest \u015bwietne por\u00f3wnanie. To w\u0142a\u015bnie pokazuje si\u0142\u0119 tej architektury. A to nie wszystko. Co jeszcze? Na parze angielski-francuski Transformer ustanowi\u0142 nowy rekord \u015bwiata dla pojedynczego modelu, osi\u0105gaj\u0105c 41 i 80 blu. Ale jest jeszcze co\u015b, co mo\u017ce by\u0107 nawet wa\u017cniejsze ni\u017c sam wynik. Mianowicie. Koszt treningu. Te rewolucyjne wyniki osi\u0105gni\u0119to w radykalnie kr\u00f3tszym czasie. Model Transformer Big trenowa\u0142 si\u0119 zalednie trzy i p\u00f3\u0142 dnia na o\u015bmiu kartach GPU P100. Tylko trzy i p\u00f3\u0142 dnia? Tak. To by\u0142 u\u0142amek zasob\u00f3w obliczeniowych, jakich wymaga\u0142y poprzednie, gorsze od niego modele. Czyli m\u00f3wimy nie tylko o lepszych wynikach, ale o zupe\u0142nie innej skali. To tak jakby kto\u015b wynalaz\u0142 metod\u0119 budowy wie\u017cowca w tydzie\u0144, a nie w dwa lata. Dok\u0142adnie. To nie jest usprawnienie, to zmienia zasady gry. Otwiera drzwi do budowania modeli, o kt\u00f3rych wcze\u015bniej nikt nawet nie marzy\u0142 z powodu barier obliczeniowych. To by\u0142a swego rodzaju demokratyzacja mocy obliczeniowej w badaniach nad AI. Nagle okawa\u0142o si\u0119, \u017ce nie trzeba farm serwer\u00f3w pracuj\u0105cych tygodniami, by osi\u0105gn\u0105\u0107 najnowocze\u015bniejsze wyniki. A co z innymi zadaniami? Czy to by\u0142a tylko doskona\u0142a maszyna do t\u0142umaczenia, czy ta architektura okaza\u0142a si\u0119 bardziej uniwersalna? Autorzy doskonale zdawali sobie z tego spraw\u0119. Dlatego przetestowali Transformera na zupe\u0142nie innym polu bitwy. Jakim? Na parsowaniu sk\u0142adniowym zdanie angielskich. To bardzo trudne zadanie analizy struktury gramatycznej. I tutaj, jak sami napisali, wyniki by\u0142y zaskakuj\u0105co dobre. Zaskakuj\u0105co, czyli sami nie byli pewni. Chyba tak. Transformer, kt\u00f3ry w og\u00f3le nie by\u0142 do tego projektowany, osi\u0105gn\u0105\u0142 wynik F1 na porzemie 92.7, pokonuj\u0105c wiele wyspecjalizowanych architektur. Niesamowite. Co wi\u0119cej, pokaza\u0142 swoj\u0105 si\u0142\u0119 nawet przy ma\u0142ej ilo\u015bci danych. Trenuj\u0105c na zbiorze zaledwie 40 tysi\u0119cy zda\u0144, przewy\u017cszy\u0142 bardzo silny klasyczny model Berkeley-Parser. A wcze\u015bniejsze modele? Wcze\u015bniejsze modele oparte na RNN kompletnie sobie z tym nie radzi\u0142y. To by\u0142 ostateczny dow\u00f3d na niesamowit\u0105 zdolno\u015b\u0107 tej architektury do generalizacji. Wi\u0119c co to wszystko oznacza? Wygl\u0105da na to, \u017ce ta jedna odwa\u017cna decyzja o ca\u0142kowitym porzuceniu rekurencji na rzecz attention okaza\u0142a si\u0119 absolutnym strza\u0142em dziesi\u0105tk\u0119. Nie by\u0142a ewolucja, to by\u0142a rewolucja. Transformer otworzy\u0142 wrota do R wielkich modeli j\u0119zykowych. Jego zdolno\u015b\u0107 do paralelizacji i modelowania dalekich zale\u017cno\u015bci pozwoli\u0142a na skalowanie. I dzi\u0119ki temu mamy to, co mamy dzisiaj. Nagle mo\u017cna by\u0142o trenowa\u0107 znacznie, znacznie wi\u0119ksze modele na niewieobra\u017calnie wielkich zbiorach danych. To jest bezpo\u015brednia linia, kt\u00f3ra prowadzi do modeli BERT, GPT i ca\u0142ej reszty. Wszystkie stoj\u0105 na ramionach tego jednego artyku\u0142u. Dok\u0142adnie tak. Z 2017 roku. Ale jest co\u015b, co pokazuje, \u017ce autorzy sami byli zaskoczeni tym, co odkryli jakie\u015b \u015blady procesu badawczego? Tak, jest taka ciekawa cz\u0119\u015b\u0107, gdzie analizuj\u0105 r\u00f3\u017cne warianty swojej architektury. Experimentowali na przyk\u0142ad z liczb\u0105 tych g\u0142\u00f3w w Multi-head attention. A co im wysz\u0142o? Okaza\u0142o si\u0119, \u017ce jedna g\u0142owa to za ma\u0142o. Model nie by\u0142 w stanie uchwyci\u0107 z\u0142o\u017cono\u015bci j\u0119zyka. Ale co ciekawe, zbyt wiele g\u0142\u00f3w, na przyk\u0142ad 16, r\u00f3wnie\u017c pogarsza\u0142o wyniki na niekt\u00f3rych zadaniach. Czyli wi\u0119cej nie zawsze znaczy lepiej. W\u0142a\u015bnie. To pokazuje, \u017ce projektowanie tych architektur to sztuka kompromisu. Zwi\u0119kszanie z\u0142o\u017cono\u015bci w niesko\u0144czono\u015b\u0107 nie zawsze prowadzi do lepszych rezultat\u00f3w. Trzeba znale\u017a\u0107 ten z\u0142oty \u015brodek. Co wymaga\u0142o \u017cmudnych eksperyment\u00f3w? Dok\u0142adnie. To fascynuj\u0105ce. A zatem podsumowuj\u0105c. Transformer to prostsza koncepcyjnie, szybsza w treningu i ostatecznie znacznie pot\u0119\u017cniejsza architektura. I zdefiniowa\u0142a now\u0105 er\u0119 w AI. A wszystko dzi\u0119ki jednej idei. Self attention. A je\u015bli spojrzymy na to z jeszcze szanszej perspektywy, autorzy ko\u0144cz\u0105 sw\u00f3j artyku\u0142 pisz\u0105c o planach rozszerzenia Transformera na inne modalno\u015bci. Obrazy, audio, wideo. Wtedy to musia\u0142o brzmie\u0107 jak science fiction. Jak ambitne marzenie. A dzi\u015b po latach wiemy, \u017ce dok\u0142adnie to si\u0119 sta\u0142o. Architektury oparte na Transformerze dominuj\u0105 nie tylko w j\u0119zyku, ale i w generowaniu obraz\u00f3w, analizie wideo, rozpoznawaniu mowy. To prawda. I to prowadzi do naprawd\u0119 prowokuj\u0105cej my\u015bli na koniec. S\u0142ucham. Skoro tak fundamentalne za\u0142o\u017cenie jak konieczno\u015b\u0107 sekwencyjnego przetwarzania danych okaza\u0142o si\u0119 niepotrzebnym ograniczeniem, to warto si\u0119 zastanowi\u0107. Jakie inne fundamentalne za\u0142o\u017cenie, kt\u00f3re dzi\u015b wydaje nam si\u0119 oczywiste w budowie AI, mo\u017ce okaza\u0107 si\u0119 kolejn\u0105 tak\u0105 barier\u0105? Co jest dzisiejszym odpowiednikiem rekurrencji, kt\u00f3ry czeka na swoj\u0105 rewolucj\u0119 w stylu attention is all you need?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.4, "text": " Witam w The Deep Dive. Wyobra\u017cmy sobie tak\u0105 sytuacj\u0119.", "tokens": [50364, 42299, 335, 261, 440, 14895, 413, 488, 13, 14458, 24393, 1427, 2226, 13652, 31069, 28275, 29924, 13, 50534], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 1, "seek": 0, "start": 3.6, "end": 10.4, "text": " Ca\u0142a nauka w jakiej\u015b dziedzinie od lat buduje coraz wy\u017csze, coraz bardziej skomplikowane drapacze chmur.", "tokens": [50544, 7544, 5024, 35616, 2330, 261, 4207, 7764, 1788, 9758, 15338, 259, 414, 3611, 4465, 3265, 13008, 25899, 4628, 1427, 82, 1381, 11, 25899, 27209, 1110, 298, 564, 1035, 23066, 1617, 79, 326, 1381, 417, 76, 374, 13, 50884], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 2, "seek": 0, "start": 10.6, "end": 14.4, "text": " Ale wszystkie stoj\u0105 na jednym fundamentalnym za\u0142o\u017ceniu.", "tokens": [50894, 9366, 31723, 22784, 8555, 1667, 5232, 12996, 8088, 12996, 7949, 5249, 24930, 5951, 13, 51084], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 3, "seek": 0, "start": 14.6, "end": 19.2, "text": " I nagle w 2017 roku pojawia si\u0119 artyku\u0142, kt\u00f3re m\u00f3wi,", "tokens": [51094, 286, 297, 15088, 261, 6591, 19451, 30655, 654, 3244, 594, 874, 5279, 1221, 11, 8864, 24592, 11, 51324], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 4, "seek": 0, "start": 19.400000000000002, "end": 22.8, "text": " a co je\u015bli te fundamenty s\u0105 w og\u00f3le niepotrzebne?", "tokens": [51334, 257, 598, 25630, 535, 6073, 88, 9015, 261, 29229, 2838, 17698, 13503, 65, 716, 30, 51504], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 5, "seek": 0, "start": 23.0, "end": 24.6, "text": " To znaczy, \u017ce mo\u017cna budowa\u0107 inaczej.", "tokens": [51514, 1407, 36584, 11, 3561, 17790, 3265, 11445, 33230, 16920, 13, 51594], "temperature": 0.0, "avg_logprob": -0.14913878902312247, "compression_ratio": 1.3369175627240144, "no_speech_prob": 0.04047417268157005}, {"id": 6, "seek": 2460, "start": 24.6, "end": 30.8, "text": " Dok\u0142adnie, \u017ce mo\u017cna budowa\u0107 wy\u017cej, szybciej i opieraj\u0105c wszystko na zupe\u0142nie innej zasadzie.", "tokens": [50364, 29768, 10358, 2766, 11, 3561, 17790, 3265, 11445, 4628, 38493, 11, 36456, 4260, 73, 741, 999, 811, 38757, 22607, 1667, 49922, 294, 11794, 44585, 3283, 13, 50674], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 7, "seek": 2460, "start": 31.0, "end": 34.2, "text": " Tym artyku\u0142em by\u0142o attention is all you need.", "tokens": [50684, 314, 4199, 594, 874, 5279, 11126, 14811, 3202, 307, 439, 291, 643, 13, 50844], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 8, "seek": 2460, "start": 34.400000000000006, "end": 37.0, "text": " I to by\u0142a prawdziwa rewolucja w \u015bwiecie AI.", "tokens": [50854, 286, 281, 23936, 41175, 3992, 4151, 319, 48481, 1311, 2938, 261, 40078, 4260, 7318, 13, 50984], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 9, "seek": 2460, "start": 37.2, "end": 38.2, "text": " Bez dw\u00f3ch zdanie.", "tokens": [50994, 879, 89, 27379, 812, 339, 16221, 7155, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 10, "seek": 2460, "start": 38.400000000000006, "end": 40.6, "text": " Dzisiaj w\u0142a\u015bnie w ten dokument si\u0119 zag\u0142\u0119bimy.", "tokens": [51054, 39448, 22356, 14234, 261, 2064, 40858, 3244, 27001, 46564, 65, 13189, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 11, "seek": 2460, "start": 40.8, "end": 47.6, "text": " Chcemy zrozumie\u0107, co by\u0142o tak prze\u0142omowego w pomy\u015ble, kt\u00f3ry wydawa\u0142 si\u0119 prawie zuchwa\u0142y.", "tokens": [51174, 761, 384, 2226, 710, 27857, 449, 414, 2162, 11, 598, 14811, 991, 8325, 1221, 298, 26576, 261, 280, 8488, 1788, 306, 11, 9913, 25984, 10449, 1221, 3244, 3206, 8699, 710, 625, 4151, 6825, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 12, "seek": 2460, "start": 47.8, "end": 49.400000000000006, "text": " Autorzy postawili proste pytanie.", "tokens": [51524, 6049, 284, 1229, 2183, 1607, 2312, 10293, 68, 36610, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 13, "seek": 2460, "start": 49.6, "end": 50.0, "text": " Tak.", "tokens": [51614, 9118, 13, 51634], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 14, "seek": 2460, "start": 50.2, "end": 54.0, "text": " Co by by\u0142o, gdyby model j\u0119zykowy nie musia\u0142 czyta\u0107 zdania s\u0142owo po s\u0142owie?", "tokens": [51644, 3066, 538, 14811, 11, 28405, 2322, 2316, 49055, 74, 10089, 2838, 1038, 8908, 6430, 42931, 16221, 5609, 15116, 19941, 714, 15116, 13998, 30, 51834], "temperature": 0.0, "avg_logprob": -0.11636477745383796, "compression_ratio": 1.4501510574018126, "no_speech_prob": 0.6508201360702515}, {"id": 15, "seek": 5400, "start": 54.2, "end": 57.4, "text": " Sekwencyjnie, ale m\u00f3g\u0142 spojrze\u0107 na nieca\u0142o\u015bciowo.", "tokens": [50374, 24285, 86, 3020, 73, 2766, 11, 6775, 275, 14047, 1221, 8243, 73, 13503, 2162, 1667, 2838, 496, 35059, 19941, 13, 50534], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 16, "seek": 5400, "start": 57.6, "end": 58.4, "text": " Od razu.", "tokens": [50544, 12210, 367, 8813, 13, 50584], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 17, "seek": 5400, "start": 58.6, "end": 61.2, "text": " Jak to by wp\u0142yn\u0105\u0142 na przyk\u0142ad na t\u0142umaczenie maszynowe?", "tokens": [50594, 15029, 281, 538, 32444, 1221, 2534, 1611, 1221, 1667, 23144, 1667, 256, 49166, 326, 16778, 2300, 1229, 3785, 68, 30, 50724], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 18, "seek": 5400, "start": 61.4, "end": 64.2, "text": " I to jest wiesz absolutnie kluczowe pytanie.", "tokens": [50734, 286, 281, 3492, 261, 15347, 18757, 2766, 9671, 1311, 89, 6880, 36610, 13, 50874], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 19, "seek": 5400, "start": 64.4, "end": 68.6, "text": " Bo ono dotyka sedna problemu, z kt\u00f3rym boryka\u0142a si\u0119 ca\u0142a dziedzina.", "tokens": [50884, 3286, 322, 78, 5893, 88, 2330, 9643, 629, 1154, 84, 11, 710, 30120, 272, 827, 2330, 5024, 3244, 1335, 5024, 9758, 15338, 1426, 13, 51094], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 20, "seek": 5400, "start": 68.8, "end": 70.4, "text": " Czyli z czym dok\u0142adnie?", "tokens": [51104, 37099, 710, 31466, 45864, 2766, 30, 51184], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 21, "seek": 5400, "start": 70.6, "end": 74.6, "text": " Przed 2017 rokiem kr\u00f3lowa\u0142y modele sekwencyjne.", "tokens": [51194, 2114, 11312, 6591, 744, 26116, 42366, 75, 5528, 6825, 4391, 306, 17215, 86, 3020, 73, 716, 13, 51394], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 22, "seek": 5400, "start": 74.8, "end": 80.8, "text": " G\u0142\u00f3wnie sieci rekurencyjne, czyli recurrent neural networks w skr\u00f3cie RNN.", "tokens": [51404, 460, 1221, 812, 14215, 2804, 537, 33881, 9873, 42949, 716, 11, 16591, 18680, 1753, 18161, 9590, 261, 1110, 11721, 4260, 45702, 45, 13, 51704], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 23, "seek": 5400, "start": 81.0, "end": 82.4, "text": " I te s\u0142ynne LSTM.", "tokens": [51714, 286, 535, 15116, 2534, 716, 441, 6840, 44, 13, 51784], "temperature": 0.0, "avg_logprob": -0.12970383961995444, "compression_ratio": 1.3812709030100334, "no_speech_prob": 0.004524638876318932}, {"id": 24, "seek": 8240, "start": 82.4, "end": 85.80000000000001, "text": " Tak, i ich ulepszone wersje, jak LSTM.", "tokens": [50364, 9118, 11, 741, 1893, 344, 306, 1878, 16896, 261, 433, 2884, 11, 4207, 441, 6840, 44, 13, 50534], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 25, "seek": 8240, "start": 86.0, "end": 88.4, "text": " Ale wszystkie dzia\u0142a\u0142y tak samo, krok po kroku.", "tokens": [50544, 9366, 31723, 37903, 6825, 991, 36422, 11, 350, 31621, 714, 45909, 5279, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 26, "seek": 8240, "start": 88.60000000000001, "end": 91.2, "text": " To mia\u0142o jedn\u0105 fundamentaln\u0105 wad\u0119.", "tokens": [50674, 1407, 21290, 5249, 5232, 13113, 8088, 13113, 261, 345, 1274, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 27, "seek": 8240, "start": 91.4, "end": 92.0, "text": " I jak\u0105?", "tokens": [50814, 286, 46719, 30, 50844], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 28, "seek": 8240, "start": 92.2, "end": 97.60000000000001, "text": " No, uniemo\u017cliwia\u0142o efektywn\u0105 paralelizacj\u0119, czyli r\u00f3wnoleg\u0142e przetwarzanie.", "tokens": [50854, 883, 11, 517, 414, 3280, 1427, 2081, 86, 654, 5249, 31482, 916, 874, 895, 1611, 26009, 338, 590, 29924, 11, 16591, 11416, 895, 4812, 70, 19827, 6541, 302, 31991, 7155, 13, 51124], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 29, "seek": 8240, "start": 97.80000000000001, "end": 103.60000000000001, "text": " Trening by\u0142 przez to koszmarnie wolny i, co gorsza, modele mia\u0142y gigantyczny problem", "tokens": [51134, 8648, 773, 16673, 14064, 281, 19532, 89, 76, 1083, 414, 20960, 1634, 741, 11, 598, 290, 830, 2394, 11, 4391, 306, 21290, 6825, 8741, 394, 17466, 1634, 1154, 51424], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 30, "seek": 8240, "start": 103.80000000000001, "end": 107.2, "text": " z zapami\u0119tywaniem zale\u017cno\u015bci mi\u0119dzy odleg\u0142ymi od siebie s\u0142owami.", "tokens": [51434, 710, 14223, 23806, 874, 7916, 4907, 710, 45494, 16438, 33964, 277, 2285, 70, 6825, 3057, 3611, 39137, 15116, 305, 4526, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 31, "seek": 8240, "start": 107.4, "end": 111.4, "text": " Czyli wracaj\u0105c do naszej metafory, budowano coraz wy\u017csze pi\u0119tra,", "tokens": [51614, 37099, 928, 326, 38757, 360, 42946, 1131, 2792, 827, 11, 3265, 305, 3730, 25899, 4628, 1427, 82, 1381, 32677, 17227, 11, 51814], "temperature": 0.0, "avg_logprob": -0.10505192996534102, "compression_ratio": 1.4185303514376997, "no_speech_prob": 0.008562719449400902}, {"id": 32, "seek": 11140, "start": 111.4, "end": 115.2, "text": " ale na fundamencie, kt\u00f3ry po prostu ogranicza\u0142 i tempo i wysoko\u015b\u0107.", "tokens": [50364, 6775, 1667, 2374, 22403, 4260, 11, 9913, 714, 19518, 34416, 30732, 2394, 1221, 741, 8972, 741, 27062, 13704, 7753, 13, 50554], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 33, "seek": 11140, "start": 115.4, "end": 116.0, "text": " Dok\u0142adnie.", "tokens": [50564, 29768, 10358, 2766, 13, 50594], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 34, "seek": 11140, "start": 116.2, "end": 120.4, "text": " Tak, autorzy Attention Is All You Need zburzyli ten stary porz\u0105dek", "tokens": [50604, 9118, 11, 19510, 1229, 31858, 1119, 1057, 509, 16984, 710, 13243, 1229, 2081, 2064, 342, 822, 1515, 23876, 916, 50814], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 35, "seek": 11140, "start": 120.60000000000001, "end": 124.0, "text": " i zaproponowali now\u0105 prost\u0105 architektur\u0119.", "tokens": [50824, 741, 14223, 1513, 266, 305, 5103, 586, 1611, 10293, 1611, 3912, 642, 2320, 374, 1274, 13, 50994], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 36, "seek": 11140, "start": 124.2, "end": 126.80000000000001, "text": " Opart\u0105 tylko na mechanizmie Attention.", "tokens": [51004, 12011, 446, 1611, 13219, 1667, 4236, 590, 25210, 31858, 13, 51134], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 37, "seek": 11140, "start": 127.0, "end": 128.6, "text": " I nazwali j\u0105 Transformer.", "tokens": [51144, 286, 20151, 40054, 35692, 27938, 260, 13, 51224], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 38, "seek": 11140, "start": 128.8, "end": 129.8, "text": " W\u0142a\u015bnie tak.", "tokens": [51234, 343, 5024, 12221, 991, 13, 51284], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 39, "seek": 11140, "start": 130.0, "end": 133.20000000000002, "text": " Dobrze, to zacznijmy od tego, co leg\u0142o w gruzach.", "tokens": [51294, 29679, 13503, 11, 281, 710, 14875, 77, 1718, 2226, 3611, 8627, 11, 598, 1676, 5249, 261, 677, 3334, 608, 13, 51454], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 40, "seek": 11140, "start": 133.4, "end": 139.0, "text": " M\u00f3wisz, \u017ce modele sekwencyjne jak RNN czy LSTM by\u0142y problematyczne.", "tokens": [51464, 376, 3901, 23848, 11, 3561, 4391, 306, 17215, 86, 3020, 73, 716, 4207, 45702, 45, 6430, 441, 6840, 44, 26366, 1154, 267, 17466, 716, 13, 51744], "temperature": 0.0, "avg_logprob": -0.12592299996990047, "compression_ratio": 1.347972972972973, "no_speech_prob": 0.004144657403230667}, {"id": 41, "seek": 13900, "start": 139.2, "end": 142.6, "text": " Ale przecie\u017c jako\u015b dzia\u0142a\u0142y, osi\u0105ga\u0142y coraz lepsze wyniki.", "tokens": [50374, 9366, 8325, 40082, 17123, 1788, 37903, 6825, 11, 3003, 11404, 3680, 6825, 25899, 476, 1878, 1381, 31936, 9850, 13, 50544], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 42, "seek": 13900, "start": 142.8, "end": 145.0, "text": " Dzia\u0142a\u0142y, jasne, ale z trudem.", "tokens": [50554, 39448, 25605, 6825, 11, 361, 296, 716, 11, 6775, 710, 32007, 443, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 43, "seek": 13900, "start": 145.2, "end": 148.0, "text": " Na czym dok\u0142adnie polega\u0142o to w\u0105skie gard\u0142o?", "tokens": [50674, 6056, 31466, 45864, 2766, 13208, 3680, 5249, 281, 261, 1611, 5161, 414, 5628, 5249, 30, 50814], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 44, "seek": 13900, "start": 148.2, "end": 151.4, "text": " Wyobra\u017c sobie, \u017ce czytasz bardzo d\u0142ugie, z\u0142o\u017cone zdanie.", "tokens": [50824, 14458, 24393, 1427, 13652, 11, 3561, 6430, 83, 19601, 9034, 274, 34077, 414, 11, 710, 5249, 1427, 546, 16221, 7155, 13, 50984], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 45, "seek": 13900, "start": 151.6, "end": 155.8, "text": " W architekturze RNN, \u017ceby zrozumie\u0107 sens, powiedzmy, 20 s\u0142owa,", "tokens": [50994, 343, 3912, 642, 2320, 374, 1381, 45702, 45, 11, 11316, 710, 27857, 449, 414, 2162, 2923, 11, 27617, 2226, 11, 945, 15116, 5528, 11, 51204], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 46, "seek": 13900, "start": 156.0, "end": 159.4, "text": " model musi najpierw przetworzy\u0107 19 poprzednich.", "tokens": [51214, 2316, 37587, 11212, 45119, 86, 6541, 302, 28321, 27150, 1294, 1665, 81, 11312, 77, 480, 13, 51384], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 47, "seek": 13900, "start": 159.6, "end": 160.4, "text": " Jedno po drugim.", "tokens": [51394, 27076, 1771, 714, 4110, 332, 13, 51434], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 48, "seek": 13900, "start": 160.6, "end": 162.0, "text": " Tak, jedno po drugim.", "tokens": [51444, 9118, 11, 5232, 1771, 714, 4110, 332, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 49, "seek": 13900, "start": 162.2, "end": 165.2, "text": " Przekazuj\u0105c sobie tak\u0105 pami\u0119\u0107 z kroku na krok.", "tokens": [51524, 2114, 19878, 921, 44733, 13652, 31069, 31088, 2162, 710, 45909, 5279, 1667, 350, 31621, 13, 51674], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 50, "seek": 13900, "start": 165.4, "end": 167.4, "text": " To jest troch\u0119 jak zabawa w g\u0142uchy telefon.", "tokens": [51684, 1407, 3492, 24926, 4207, 24838, 10449, 261, 18117, 625, 88, 26812, 13, 51784], "temperature": 0.0, "avg_logprob": -0.07976413749114812, "compression_ratio": 1.4479495268138802, "no_speech_prob": 0.006534858141094446}, {"id": 51, "seek": 16740, "start": 167.6, "end": 170.4, "text": " Aha, czyli informacja si\u0119 zniekszta\u0142ca po drodze?", "tokens": [50374, 27448, 11, 16591, 1356, 23395, 3244, 710, 2766, 1694, 89, 46426, 496, 714, 3789, 67, 1381, 30, 50514], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 52, "seek": 16740, "start": 170.6, "end": 173.4, "text": " Dok\u0142adnie. Informacja z pocz\u0105tku zdania,", "tokens": [50524, 29768, 10358, 2766, 13, 34301, 23395, 710, 43959, 16221, 5609, 11, 50664], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 53, "seek": 16740, "start": 173.6, "end": 176.4, "text": " zanim dotrze na koniec, ulega za tarciu.", "tokens": [50674, 710, 17869, 5893, 13503, 1667, 5897, 35733, 11, 344, 306, 3680, 7949, 3112, 30795, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 54, "seek": 16740, "start": 176.6, "end": 179.4, "text": " Ten problem, znany jako vanishing gradient,", "tokens": [50824, 9380, 1154, 11, 15397, 1325, 17123, 3161, 3807, 16235, 11, 50964], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 55, "seek": 16740, "start": 179.6, "end": 185.6, "text": " sprawia\u0142, \u017ce modelom by\u0142o extremalnie trudno nauczy\u0107 si\u0119 tak zwanych long range dependencies.", "tokens": [50974, 22734, 8908, 11, 3561, 2316, 298, 14811, 4040, 304, 2766, 32007, 1771, 49103, 27150, 3244, 991, 11873, 34644, 938, 3613, 36606, 13, 51274], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 56, "seek": 16740, "start": 185.8, "end": 188.6, "text": " Czyli tych zale\u017cno\u015bci na du\u017ce odlego\u015bci.", "tokens": [51284, 37099, 15180, 710, 45494, 16438, 1667, 1581, 2875, 277, 2285, 1571, 6199, 13, 51424], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 57, "seek": 16740, "start": 188.8, "end": 194.4, "text": " Tak, na przyk\u0142ad w zdaniu ch\u0142opiec, kt\u00f3ry przez ca\u0142e popo\u0142udnie bawi\u0142 si\u0119 z psami na \u0142\u0105ce,", "tokens": [51434, 9118, 11, 1667, 23144, 261, 16221, 25849, 417, 1221, 404, 35733, 11, 9913, 14064, 47631, 1665, 78, 1221, 532, 2766, 272, 38402, 1221, 3244, 710, 18815, 4526, 1667, 220, 15926, 384, 11, 51714], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 58, "seek": 16740, "start": 194.6, "end": 196.0, "text": " by\u0142 bardzo zm\u0119czony.", "tokens": [51724, 16673, 9034, 17020, 1274, 3689, 2526, 13, 51794], "temperature": 0.0, "avg_logprob": -0.14111788519497576, "compression_ratio": 1.4622950819672131, "no_speech_prob": 0.006379920523613691}, {"id": 59, "seek": 19600, "start": 196.0, "end": 199.0, "text": " Model musia\u0142 jako\u015b powi\u0105za\u0107 ch\u0142opiec zby\u0142.", "tokens": [50364, 17105, 1038, 8908, 17123, 1788, 3388, 11404, 35873, 417, 1221, 404, 35733, 710, 2322, 1221, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 60, "seek": 19600, "start": 199.2, "end": 201.2, "text": " A dzieli\u0142o je kilkana\u015bcie s\u0142\u00f3w.", "tokens": [50524, 316, 9758, 23099, 5249, 1506, 5128, 74, 2095, 9815, 15116, 3901, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 61, "seek": 19600, "start": 201.4, "end": 204.2, "text": " No w\u0142a\u015bnie, dla RNN to by\u0142o ogromne wyzwanie.", "tokens": [50634, 883, 14234, 11, 12285, 45702, 45, 281, 14811, 34416, 298, 716, 4628, 14406, 7155, 13, 50774], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 62, "seek": 19600, "start": 204.4, "end": 205.4, "text": " Rozumiem.", "tokens": [50784, 43313, 449, 4907, 13, 50834], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 63, "seek": 19600, "start": 205.6, "end": 210.4, "text": " Czyli im d\u0142u\u017cszy kontekst, tym mo\u017cna powiedzie\u0107 wi\u0119ksza amnezja modelu.", "tokens": [50844, 37099, 566, 274, 24066, 1427, 7706, 14373, 916, 372, 11, 8107, 17790, 27886, 29968, 2394, 669, 28018, 2938, 2316, 84, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 64, "seek": 19600, "start": 210.6, "end": 212.8, "text": " I pewnie pr\u00f3bowano to jako\u015b \u0142ata\u0107?", "tokens": [51094, 286, 520, 14215, 8565, 8202, 3730, 281, 17123, 1788, 25387, 3274, 2162, 30, 51204], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 65, "seek": 19600, "start": 213.0, "end": 218.8, "text": " Oczywi\u015bcie. Stosowano r\u00f3\u017cne triki, jak te wspomniane sieci LSTM z ich systemem bramek,", "tokens": [51214, 42980, 13, 745, 329, 305, 3730, 47760, 1376, 2984, 11, 4207, 535, 17757, 38131, 21133, 2804, 537, 441, 6840, 44, 710, 1893, 1185, 443, 738, 529, 74, 11, 51504], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 66, "seek": 19600, "start": 219.0, "end": 220.8, "text": " kt\u00f3re mia\u0142y zarz\u0105dza\u0107 pami\u0119ci\u0105.", "tokens": [51514, 8864, 21290, 6825, 22675, 23876, 35873, 31088, 34381, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 67, "seek": 19600, "start": 221.0, "end": 224.6, "text": " By\u0142y nawet sieci konwolucyjne w modelach jak ConfS2S.", "tokens": [51614, 3146, 6825, 22696, 2804, 537, 5897, 48481, 1311, 88, 73, 716, 261, 2316, 608, 4207, 11701, 50, 17, 50, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1332241372217106, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0008514540968462825}, {"id": 68, "seek": 22460, "start": 224.6, "end": 226.4, "text": " Ale to by\u0142y tylko protezy.", "tokens": [50364, 9366, 281, 26366, 13219, 5631, 1229, 13, 50454], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 69, "seek": 22460, "start": 226.6, "end": 233.0, "text": " Tak, to wszystko by\u0142y usprawnienia, a nie rozwi\u0105zanie fundamentalnego problemu.", "tokens": [50464, 9118, 11, 281, 22607, 26366, 505, 79, 29603, 18811, 11, 257, 2838, 9544, 22620, 7155, 8088, 11858, 1154, 84, 13, 50784], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 70, "seek": 22460, "start": 233.2, "end": 236.6, "text": " Wci\u0105\u017c istnia\u0142a ta \u015bcie\u017cka, kt\u00f3r\u0105 informacja musia\u0142a pokona\u0107.", "tokens": [50794, 343, 537, 27242, 1418, 12679, 5024, 1846, 8299, 40082, 2330, 11, 37415, 1356, 23395, 1038, 25605, 13010, 4037, 2162, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 71, "seek": 22460, "start": 236.79999999999998, "end": 239.2, "text": " A jej d\u0142ugo\u015b\u0107 ros\u0142a z odleg\u0142o\u015bci\u0105.", "tokens": [50974, 316, 28924, 44042, 20746, 7753, 18953, 5024, 710, 277, 2285, 70, 35059, 1611, 13, 51094], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 72, "seek": 22460, "start": 239.4, "end": 243.4, "text": " To tak jakby\u015b pr\u00f3bowa\u0142a krzycze\u0107 do kogo\u015b po drugiej stronie boiska.", "tokens": [51104, 1407, 991, 28976, 1788, 8565, 65, 5528, 5024, 350, 13047, 9680, 2162, 360, 350, 23515, 1788, 714, 47373, 1056, 32242, 748, 21945, 13, 51304], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 73, "seek": 22460, "start": 243.6, "end": 245.6, "text": " Im dalej, tym gorzej ci\u0119 s\u0142ycha\u0107.", "tokens": [51314, 4331, 34257, 11, 8107, 24012, 16920, 35484, 262, 6825, 4413, 2162, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 74, "seek": 22460, "start": 245.79999999999998, "end": 251.0, "text": " I wtedy, gdy wszyscy pr\u00f3buj\u0105 wymy\u015bli\u0107 g\u0142o\u015bniejszy megafon, pojawia si\u0119 ten artyku\u0142.", "tokens": [51424, 286, 26959, 11, 28405, 44232, 8565, 65, 13263, 4628, 2226, 15350, 2162, 290, 5249, 37511, 7706, 10816, 2792, 266, 11, 30655, 654, 3244, 2064, 594, 874, 5279, 1221, 13, 51684], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 75, "seek": 22460, "start": 251.2, "end": 253.4, "text": " A jego tytu\u0142 brzmi jak manifest.", "tokens": [51694, 316, 26542, 1104, 9179, 1221, 738, 89, 3057, 4207, 10067, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0861200543193074, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.004598093219101429}, {"id": 76, "seek": 25340, "start": 253.4, "end": 256.2, "text": " Uwaga to wszystko, czego potrzebujesz.", "tokens": [50364, 624, 86, 9286, 281, 22607, 11, 36559, 37595, 4579, 10430, 13, 50504], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 77, "seek": 25340, "start": 256.4, "end": 257.4, "text": " Dok\u0142adnie.", "tokens": [50514, 29768, 10358, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 78, "seek": 25340, "start": 257.6, "end": 261.2, "text": " To brzmi a\u017c zbyt prosto. Gdzie jest magia tego mechanizmu self-attention?", "tokens": [50574, 1407, 738, 89, 3057, 48134, 710, 2322, 83, 10293, 78, 13, 460, 13096, 3492, 2258, 654, 8627, 4236, 590, 20140, 2698, 12, 1591, 1251, 30, 50754], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 79, "seek": 25340, "start": 261.4, "end": 266.2, "text": " Jak on m\u00f3g\u0142 zast\u0105pi\u0107 ca\u0142\u0105 t\u0105 skomplikowan\u0105 sekwencyjn\u0105 maszyneri\u0119?", "tokens": [50764, 15029, 322, 275, 14047, 1221, 36746, 1611, 79, 12757, 1335, 15926, 32294, 1110, 298, 564, 1035, 37345, 1611, 17215, 15615, 42949, 13113, 2300, 1229, 1193, 5034, 30, 51004], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 80, "seek": 25340, "start": 266.4, "end": 269.2, "text": " Na tym, \u017ce on kompletnie zmienia zasady gry.", "tokens": [51014, 6056, 8107, 11, 3561, 322, 5207, 14657, 2766, 17020, 18811, 26530, 880, 41974, 13, 51154], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 81, "seek": 25340, "start": 269.4, "end": 275.2, "text": " Transformer by\u0142 pierwsz\u0105 architektur\u0105, kt\u00f3ra w og\u00f3le nie u\u017cywa\u0142a rekurencji. W og\u00f3le.", "tokens": [51164, 27938, 260, 16673, 27623, 8925, 3912, 642, 2320, 374, 1611, 11, 19456, 261, 29229, 2838, 34097, 4151, 5024, 33881, 9873, 19649, 13, 343, 29229, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 82, "seek": 25340, "start": 275.4, "end": 276.2, "text": " A zamiast tego?", "tokens": [51464, 316, 710, 4526, 525, 8627, 30, 51504], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 83, "seek": 25340, "start": 276.4, "end": 280.2, "text": " Zamiast tego w 100% oparli si\u0119 na self-attention.", "tokens": [51514, 1176, 4526, 525, 8627, 261, 2319, 4, 999, 289, 2081, 3244, 1667, 2698, 12, 1591, 1251, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1252231857403606, "compression_ratio": 1.3911564625850341, "no_speech_prob": 0.03290862217545509}, {"id": 84, "seek": 28020, "start": 280.2, "end": 286.0, "text": " A idea tego mechanizmu jest, no, rewolucyjna w swojej prostocie.", "tokens": [50364, 316, 1558, 8627, 4236, 590, 20140, 3492, 11, 572, 11, 319, 48481, 1311, 88, 73, 629, 261, 29489, 73, 10293, 905, 414, 13, 50654], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 85, "seek": 28020, "start": 286.2, "end": 287.0, "text": " To znaczy?", "tokens": [50664, 1407, 36584, 30, 50704], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 86, "seek": 28020, "start": 287.2, "end": 289.0, "text": " S\u0142owa. I oceni\u0107 ich wag\u0119.", "tokens": [50714, 318, 1221, 5528, 13, 286, 10409, 268, 12757, 1893, 36854, 1274, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 87, "seek": 28020, "start": 289.2, "end": 293.0, "text": " Ich istotno\u015b\u0107 dla kontekstu tego jednego konkretnego s\u0142owa.", "tokens": [50814, 3141, 1418, 310, 23293, 12285, 14373, 916, 372, 84, 8627, 5232, 11858, 36500, 11858, 15116, 5528, 13, 51004], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 88, "seek": 28020, "start": 293.2, "end": 297.0, "text": " Czyli to ju\u017c nie jest g\u0142uchy telefon. To bardziej jak okr\u0105g\u0142y st\u00f3\u0142.", "tokens": [51014, 37099, 281, 10678, 2838, 3492, 18117, 625, 88, 26812, 13, 1407, 27209, 4207, 3133, 32881, 70, 6825, 342, 16181, 13, 51204], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 89, "seek": 28020, "start": 297.2, "end": 299.0, "text": " O, dobre por\u00f3wnanie.", "tokens": [51214, 422, 11, 41959, 1515, 812, 895, 7155, 13, 51304], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 90, "seek": 28020, "start": 299.2, "end": 305.0, "text": " Wszystkie s\u0142owa siedz\u0105 razem i mog\u0105 ze sob\u0105 rozmawia\u0107 jednocze\u015bnie bez \u017cadnych po\u015brednik\u00f3w.", "tokens": [51314, 343, 10424, 22872, 15116, 5528, 262, 1091, 8925, 40225, 741, 34123, 5277, 18253, 1611, 35234, 34953, 2162, 5232, 26694, 1381, 12221, 10782, 39628, 9399, 714, 1788, 986, 47447, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 91, "seek": 28020, "start": 305.2, "end": 306.2, "text": " Dok\u0142adnie tak.", "tokens": [51614, 29768, 10358, 2766, 991, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10134095085991754, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.10985793173313141}, {"id": 92, "seek": 30620, "start": 306.2, "end": 309.0, "text": " Ka\u017cde s\u0142owo mo\u017ce bezpo\u015brednio zapyta\u0107 ka\u017cde inne.", "tokens": [50364, 10988, 1427, 1479, 15116, 19941, 12034, 10782, 2259, 1788, 986, 41084, 14223, 88, 42931, 21912, 1479, 24170, 13, 50504], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 93, "seek": 30620, "start": 309.2, "end": 313.0, "text": " Hej, jak bardzo jeste\u015b dla mnie wa\u017cny w tym kontek\u015bcie?", "tokens": [50514, 44567, 11, 4207, 9034, 25255, 1788, 12285, 17661, 27777, 1634, 261, 8107, 14373, 916, 9815, 30, 50704], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 94, "seek": 30620, "start": 313.2, "end": 316.0, "text": " To prowadzi do dw\u00f3ch, no, prze\u0142omowych konsekwencji.", "tokens": [50714, 1407, 36590, 3992, 360, 27379, 812, 339, 11, 572, 11, 8325, 1221, 298, 19605, 47020, 74, 15615, 19649, 13, 50854], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 95, "seek": 30620, "start": 316.2, "end": 317.0, "text": " Pierwsza?", "tokens": [50864, 16676, 14358, 2394, 30, 50904], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 96, "seek": 30620, "start": 317.2, "end": 320.0, "text": " Po pierwsze problem odleg\u0142o\u015bci znika.", "tokens": [50914, 6165, 45994, 1154, 277, 2285, 70, 35059, 15397, 5439, 13, 51054], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 97, "seek": 30620, "start": 320.2, "end": 324.0, "text": " W starych modelach \u015bcie\u017cka informacji ros\u0142a liniowo z odleg\u0142o\u015bci\u0105.", "tokens": [51064, 343, 342, 822, 339, 2316, 608, 8299, 40082, 2330, 1356, 13152, 18953, 5024, 287, 3812, 19941, 710, 277, 2285, 70, 35059, 1611, 13, 51254], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 98, "seek": 30620, "start": 324.2, "end": 328.0, "text": " Tu w Transformerze ta odlego\u015b\u0107 jest zawsze sta\u0142a i wynosi jeden.", "tokens": [51264, 7836, 261, 27938, 260, 1381, 1846, 277, 2285, 1571, 7753, 3492, 30964, 11135, 5024, 741, 31936, 21521, 12906, 13, 51454], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 99, "seek": 30620, "start": 328.2, "end": 331.0, "text": " Ka\u017cde s\u0142owo ma bezpo\u015brednie po\u0142\u0105czenie z ka\u017cdym innym.", "tokens": [51464, 10988, 1427, 1479, 15116, 19941, 463, 10782, 2259, 1788, 986, 2766, 714, 15926, 39043, 710, 31615, 76, 294, 12996, 13, 51604], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 100, "seek": 30620, "start": 331.2, "end": 336.0, "text": " To musia\u0142o radykalnie u\u0142atwi\u0107 nauk\u0119 tych dalekosi\u0119\u017cnych zale\u017cno\u015bci.", "tokens": [51614, 1407, 1038, 654, 5249, 367, 880, 19990, 2766, 344, 1221, 267, 6253, 2162, 35616, 15724, 15180, 11702, 916, 329, 5034, 1427, 9399, 710, 45494, 16438, 13, 51854], "temperature": 0.0, "avg_logprob": -0.07438186119342673, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.026863714680075645}, {"id": 101, "seek": 33620, "start": 336.2, "end": 339.0, "text": " Oczywi\u015bcie. To by\u0142a pierwsza rzecz.", "tokens": [50364, 42980, 13, 1407, 23936, 27623, 2394, 36833, 13, 50504], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 102, "seek": 33620, "start": 339.2, "end": 340.0, "text": " A druga?", "tokens": [50514, 316, 4110, 64, 30, 50554], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 103, "seek": 33620, "start": 340.2, "end": 341.0, "text": " Paralelizacja.", "tokens": [50564, 3457, 304, 338, 590, 23395, 13, 50604], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 104, "seek": 33620, "start": 341.2, "end": 347.0, "text": " Skoro nie ma tej zale\u017cno\u015bci krok po kroku, obliczenia dla ka\u017cdego s\u0142owa mo\u017cna robi\u0107 w tym samym czasie.", "tokens": [50614, 7324, 10780, 2838, 463, 12573, 710, 45494, 16438, 350, 31621, 714, 45909, 5279, 11, 1111, 1050, 14320, 12285, 21912, 67, 6308, 15116, 5528, 17790, 46900, 261, 8107, 3247, 4199, 42667, 13, 50904], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 105, "seek": 33620, "start": 347.2, "end": 348.0, "text": " R\u00f3wnolegle.", "tokens": [50914, 497, 812, 895, 4812, 22631, 13, 50954], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 106, "seek": 33620, "start": 348.2, "end": 350.0, "text": " I to by\u0142 ten prze\u0142om?", "tokens": [50964, 286, 281, 16673, 2064, 8325, 1221, 298, 30, 51054], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 107, "seek": 33620, "start": 350.2, "end": 351.0, "text": " Absolutne.", "tokens": [51064, 5813, 2308, 716, 13, 51104], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 108, "seek": 33620, "start": 351.2, "end": 354.0, "text": " Training modeli przesta\u0142 by\u0107 procesem, kt\u00f3ry ci\u0105gnie si\u0119 w niesko\u0144czono\u015b\u0107.", "tokens": [51114, 20620, 2316, 72, 6541, 7841, 1221, 15069, 17565, 443, 11, 9913, 42398, 70, 2766, 3244, 261, 48100, 4093, 5248, 3689, 8957, 7753, 13, 51254], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 109, "seek": 33620, "start": 354.2, "end": 361.0, "text": " To tak jakby zamiast budowa\u0107 wie\u017cowiec pi\u0119tro po pi\u0119trze, mog\u0142a budowa\u0107 wszystkie pi\u0119tra naraz i na ko\u0144cu je z\u0142o\u017cy\u0107.", "tokens": [51264, 1407, 991, 28976, 710, 4526, 525, 3265, 11445, 3355, 1427, 13998, 66, 32677, 38604, 714, 32677, 6903, 1381, 11, 13172, 5024, 3265, 11445, 31723, 32677, 17227, 6714, 921, 741, 1667, 26470, 12032, 1506, 710, 5249, 39687, 13, 51604], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 110, "seek": 33620, "start": 361.2, "end": 365.0, "text": " To otworzy\u0142o drzwi do eksperyment\u00f3w na zupe\u0142nie now\u0105 skal\u0119.", "tokens": [51614, 1407, 4337, 28321, 1229, 5249, 1224, 89, 6253, 360, 30724, 610, 88, 518, 3901, 1667, 49922, 586, 1611, 16890, 1274, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0952437905704274, "compression_ratio": 1.4688427299703264, "no_speech_prob": 0.0013780300505459309}, {"id": 111, "seek": 36500, "start": 365.0, "end": 368.8, "text": " Na skal\u0119, kt\u00f3ra wcze\u015bniej by\u0142a po prostu niemo\u017cliwa z powodu barieru obliczeniowych.", "tokens": [50364, 6056, 16890, 1274, 11, 19456, 40785, 23936, 714, 19518, 2838, 3280, 1427, 2081, 4151, 710, 3388, 34873, 2159, 811, 84, 1111, 1050, 42124, 19605, 13, 50554], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 112, "seek": 36500, "start": 369.0, "end": 371.8, "text": " Ok. Koncepcja jest naprawd\u0119 pot\u0119\u017cna.", "tokens": [50564, 3477, 13, 12718, 27493, 34056, 3492, 20970, 1847, 1274, 1427, 629, 13, 50704], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 113, "seek": 36500, "start": 372.0, "end": 373.8, "text": " Ale jak to wygl\u0105da w praktyce?", "tokens": [50714, 9366, 4207, 281, 32015, 261, 3206, 74, 874, 384, 30, 50804], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 114, "seek": 36500, "start": 374.0, "end": 378.8, "text": " W artykule jest ten s\u0142ynny diagram, kt\u00f3ry sta\u0142 si\u0119 ju\u017c ikon\u0105.", "tokens": [50814, 343, 594, 874, 74, 2271, 3492, 2064, 15116, 2534, 1634, 10686, 11, 9913, 11135, 1221, 3244, 10678, 4320, 266, 1611, 13, 51054], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 115, "seek": 36500, "start": 379.0, "end": 381.8, "text": " Roz\u0142\u00f3\u017cmy t\u0119 architektur\u0119 naczynniki pierwsze.", "tokens": [51064, 43313, 1221, 812, 1427, 2226, 32489, 3912, 642, 2320, 374, 1274, 297, 14691, 26384, 9850, 45994, 13, 51204], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 116, "seek": 36500, "start": 382.0, "end": 385.8, "text": " Jasne. Ten diagram pokazuje klasyczn\u0105 struktur\u0119 encoder-decoder.", "tokens": [51214, 34023, 716, 13, 9380, 10686, 13010, 43317, 9671, 5871, 3689, 13113, 342, 31543, 1274, 2058, 19866, 12, 42821, 19866, 13, 51404], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 117, "seek": 36500, "start": 386.0, "end": 388.8, "text": " To by\u0142o bardzo popularne w t\u0142umaczeniach maszynowych.", "tokens": [51414, 1407, 14811, 9034, 3743, 716, 261, 256, 49166, 326, 42124, 608, 2300, 1229, 3785, 16384, 13, 51554], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 118, "seek": 36500, "start": 389.0, "end": 389.8, "text": " Czyli mamy dwie cz\u0119\u015bci.", "tokens": [51564, 37099, 17335, 274, 8699, 41314, 13, 51604], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 119, "seek": 36500, "start": 390.0, "end": 394.8, "text": " Tak. Po lewej stronie jest encoder, po prawej decoder.", "tokens": [51614, 9118, 13, 6165, 476, 826, 73, 1056, 32242, 3492, 2058, 19866, 11, 714, 3206, 826, 73, 979, 19866, 13, 51854], "temperature": 0.0, "avg_logprob": -0.08481201403068774, "compression_ratio": 1.4534534534534536, "no_speech_prob": 0.010960431769490242}, {"id": 120, "seek": 39500, "start": 395.0, "end": 400.8, "text": " Zadaniem encodera jest powiedzmy przeczytanie i zrozumienie zdania wej\u015bciowego.", "tokens": [50364, 1176, 11338, 4907, 2058, 378, 1663, 3492, 27617, 2226, 8325, 6522, 83, 7155, 741, 710, 27857, 449, 27385, 16221, 5609, 321, 73, 6199, 26576, 13, 50654], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 121, "seek": 39500, "start": 401.0, "end": 402.8, "text": " Na przyk\u0142ad po niemiecku.", "tokens": [50664, 6056, 23144, 714, 2838, 25210, 547, 84, 13, 50754], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 122, "seek": 39500, "start": 403.0, "end": 403.8, "text": " Jak to robi?", "tokens": [50764, 15029, 281, 47380, 30, 50804], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 123, "seek": 39500, "start": 404.0, "end": 407.8, "text": " Przepu\u015bcia je przez stos sze\u015bciu identycznych warstw.", "tokens": [50814, 2114, 46342, 84, 1788, 2755, 1506, 14064, 43581, 262, 1381, 6199, 84, 2473, 17466, 9399, 1516, 372, 86, 13, 51004], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 124, "seek": 39500, "start": 408.0, "end": 410.8, "text": " A ka\u017cda z tych warstw ma dwa g\u0142\u00f3wne elementy.", "tokens": [51014, 316, 21912, 2675, 710, 15180, 1516, 372, 86, 463, 35045, 18117, 3901, 716, 4478, 88, 13, 51154], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 125, "seek": 39500, "start": 411.0, "end": 415.8, "text": " Mechanizm multi-head self-attention, o kt\u00f3rym zaraz powiemy.", "tokens": [51164, 30175, 590, 76, 4825, 12, 1934, 2698, 12, 1591, 1251, 11, 277, 30120, 22675, 921, 3388, 414, 2226, 13, 51404], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 126, "seek": 39500, "start": 416.0, "end": 419.8, "text": " I prost\u0105 sie\u0107 neuronow\u0105, tak zwan\u0105 feed-forward network.", "tokens": [51414, 286, 10293, 1611, 2804, 2162, 34090, 30297, 11, 991, 710, 7916, 1611, 3154, 12, 13305, 3209, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11037647339605516, "compression_ratio": 1.3754940711462451, "no_speech_prob": 0.0004350707458797842}, {"id": 127, "seek": 41980, "start": 419.8, "end": 425.6, "text": " Czyli encoder tworzy tak\u0105 bogat\u0105, numeryczn\u0105 reprezentacj\u0119 znaczenia zdania.", "tokens": [50364, 37099, 2058, 19866, 46288, 1229, 31069, 26132, 267, 1611, 11, 1031, 2109, 3689, 13113, 1085, 265, 14185, 29924, 15397, 326, 14320, 16221, 5609, 13, 50654], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 128, "seek": 41980, "start": 425.8, "end": 427.6, "text": " A co z decoderem?", "tokens": [50664, 316, 598, 710, 979, 19866, 443, 30, 50754], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 129, "seek": 41980, "start": 427.8, "end": 432.6, "text": " A decoder bierze te reprezentacje i s\u0142owo po s\u0142owie generuje t\u0142umaczenie.", "tokens": [50764, 316, 979, 19866, 272, 811, 1381, 535, 1085, 265, 14185, 29293, 741, 15116, 19941, 714, 15116, 13998, 1337, 13008, 256, 49166, 326, 16778, 13, 51004], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 130, "seek": 41980, "start": 432.8, "end": 434.6, "text": " Na przyk\u0142ad na angielski.", "tokens": [51014, 6056, 23144, 1667, 2562, 1187, 18020, 13, 51104], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 131, "seek": 41980, "start": 434.8, "end": 435.6, "text": " On te\u017c ma te warstwy?", "tokens": [51114, 1282, 9516, 463, 535, 1516, 372, 9726, 30, 51154], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 132, "seek": 41980, "start": 435.8, "end": 441.6, "text": " Te\u017c ma sze\u015b\u0107 warstw, bardzo podobnych do tych w encoderze, ale z jednym kluczowym dodatkiem.", "tokens": [51164, 1989, 1427, 463, 262, 1381, 7753, 1516, 372, 86, 11, 9034, 43024, 9399, 360, 15180, 261, 2058, 19866, 1381, 11, 6775, 710, 5232, 12996, 9671, 1311, 89, 31691, 13886, 267, 26116, 13, 51454], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 133, "seek": 41980, "start": 441.8, "end": 445.6, "text": " Opr\u00f3cz self-attention, kt\u00f3re patrzy na to, co ju\u017c przet\u0142umaczy\u0142,", "tokens": [51464, 422, 1424, 812, 3689, 2698, 12, 1591, 1251, 11, 8864, 1947, 13047, 1667, 281, 11, 598, 10678, 6541, 302, 49166, 14691, 1221, 11, 51654], "temperature": 0.0, "avg_logprob": -0.07153392007164922, "compression_ratio": 1.4699248120300752, "no_speech_prob": 0.03337046131491661}, {"id": 134, "seek": 44560, "start": 445.6, "end": 450.40000000000003, "text": " ma drug\u0105 warstw\u0119 attention, kt\u00f3ra patrzy na wyj\u015bcie z encodera.", "tokens": [50364, 463, 4110, 1611, 1516, 372, 86, 1274, 3202, 11, 19456, 1947, 13047, 1667, 4628, 73, 9815, 710, 2058, 378, 1663, 13, 50604], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 135, "seek": 44560, "start": 450.6, "end": 453.40000000000003, "text": " \u017beby wiedzie\u0107, na czym si\u0119 skupi\u0107 w oryginalnym zdaniu?", "tokens": [50614, 46864, 2322, 261, 22078, 11, 1667, 31466, 3244, 1110, 1010, 12757, 261, 420, 88, 1494, 304, 12996, 16221, 25849, 30, 50754], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 136, "seek": 44560, "start": 453.6, "end": 454.40000000000003, "text": " Dok\u0142adnie.", "tokens": [50764, 29768, 10358, 2766, 13, 50804], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 137, "seek": 44560, "start": 454.6, "end": 459.40000000000003, "text": " To pozwola mu w ka\u017cdym kroku skupi\u0107 si\u0119 na najwa\u017cniejszych fragmentach orygina\u0142u.", "tokens": [50814, 1407, 40557, 4711, 2992, 261, 31615, 76, 45909, 5279, 1110, 1010, 12757, 3244, 1667, 11212, 27111, 10402, 45021, 26424, 608, 420, 18103, 1426, 24066, 13, 51054], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 138, "seek": 44560, "start": 459.6, "end": 464.40000000000003, "text": " Czekaj, pojawi\u0142o si\u0119 tu okre\u015blenie multi-head attention.", "tokens": [51064, 383, 19878, 1805, 11, 30655, 72, 5249, 3244, 2604, 3133, 265, 1788, 6698, 414, 4825, 12, 1934, 3202, 13, 51304], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 139, "seek": 44560, "start": 464.6, "end": 466.40000000000003, "text": " Wielog\u0142owa uwaga.", "tokens": [51314, 343, 1187, 664, 1221, 5528, 23147, 9286, 13, 51404], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 140, "seek": 44560, "start": 466.6, "end": 470.40000000000003, "text": " To brzmi, jak przerost formy nad tre\u015bci\u0105.", "tokens": [51414, 1407, 738, 89, 3057, 11, 4207, 582, 4527, 555, 1254, 88, 12617, 2192, 50227, 13, 51604], "temperature": 0.0, "avg_logprob": -0.08318653702735901, "compression_ratio": 1.3686274509803922, "no_speech_prob": 0.05028941109776497}, {"id": 141, "seek": 47040, "start": 470.4, "end": 477.2, "text": " Dlaczego model musi patrze\u0107 na relacje mi\u0119dzy s\u0142owami nieraz, a jak czytamy, osiem razy naraz?", "tokens": [50364, 413, 75, 39329, 2316, 37587, 1947, 13503, 2162, 1667, 1039, 29293, 33964, 15116, 305, 4526, 297, 811, 921, 11, 257, 4207, 6430, 83, 7804, 11, 3003, 4907, 9639, 88, 6714, 921, 30, 50704], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 142, "seek": 47040, "start": 477.4, "end": 481.2, "text": " To \u015bwietne pytanie, bo dotyka geniuszu tego rozwi\u0105zania.", "tokens": [50714, 1407, 8299, 39083, 716, 36610, 11, 748, 5893, 88, 2330, 14017, 11728, 8627, 9544, 22620, 5609, 13, 50904], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 143, "seek": 47040, "start": 481.4, "end": 484.2, "text": " No w\u0142a\u015bnie, czy te g\u0142owy nie robi\u0105 w k\u00f3\u0142ko tego samego?", "tokens": [50914, 883, 14234, 11, 6430, 535, 18117, 10089, 2838, 3870, 11404, 261, 350, 16181, 4093, 8627, 912, 1571, 30, 51054], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 144, "seek": 47040, "start": 484.4, "end": 485.2, "text": " Nie do ko\u0144ca.", "tokens": [51064, 12016, 360, 26470, 496, 13, 51104], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 145, "seek": 47040, "start": 485.4, "end": 493.2, "text": " Jedna g\u0142owa, czyli jeden head uwagi, mog\u0142aby si\u0119 nauczy\u0107 rozpoznawa\u0107 powiedzmy jeden rodzaj zale\u017cno\u015bci.", "tokens": [51114, 27076, 629, 18117, 5528, 11, 16591, 12906, 1378, 23147, 20291, 11, 13172, 1221, 2509, 3244, 49103, 27150, 9544, 2259, 35458, 25234, 27617, 2226, 12906, 28607, 1805, 710, 45494, 16438, 13, 51504], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 146, "seek": 47040, "start": 493.4, "end": 496.2, "text": " Na przyk\u0142ad relacje podmiot o \u017cyczenie.", "tokens": [51514, 6056, 23144, 1039, 29293, 2497, 3057, 310, 277, 16136, 39043, 13, 51654], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 147, "seek": 47040, "start": 496.4, "end": 498.2, "text": " Ale j\u0119zyk jest bardziej z\u0142o\u017cony.", "tokens": [51664, 9366, 49055, 74, 3492, 27209, 710, 5249, 1427, 2526, 13, 51754], "temperature": 0.0, "avg_logprob": -0.10785634569126926, "compression_ratio": 1.4402730375426622, "no_speech_prob": 0.03133662790060043}, {"id": 148, "seek": 49820, "start": 498.2, "end": 506.0, "text": " Znacznie. I multi-head attention pozwala modelowi jednocze\u015bnie, r\u00f3wnolegle, analizowa\u0107 zdanie pod r\u00f3\u017cnymi k\u0105tami.", "tokens": [50364, 1176, 77, 14875, 2766, 13, 286, 4825, 12, 1934, 3202, 40557, 5159, 2316, 24503, 5232, 26694, 1381, 12221, 11, 11416, 895, 4812, 22631, 11, 2624, 590, 11445, 16221, 7155, 2497, 19637, 31813, 350, 23430, 4526, 13, 50754], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 149, "seek": 49820, "start": 506.2, "end": 510.0, "text": " Mo\u017cna sobie wyobrazi\u0107, \u017ce jedna g\u0142owa skupia si\u0119 na sk\u0142adni.", "tokens": [50764, 44736, 629, 13652, 4628, 24393, 28496, 11, 3561, 5232, 629, 18117, 5528, 1110, 1010, 654, 3244, 1667, 1110, 10358, 3722, 13, 50954], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 150, "seek": 49820, "start": 510.2, "end": 513.0, "text": " Druga na tym, co logicznie wynika z czego.", "tokens": [50964, 2491, 19364, 1667, 8107, 11, 598, 9952, 89, 2766, 31936, 5439, 710, 36559, 13, 51104], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 151, "seek": 49820, "start": 513.2, "end": 517.0, "text": " Trzecia mo\u017ce \u015bledzi\u0107 zajmki, a czwarta analizuje relacje semantyczne.", "tokens": [51114, 1765, 1381, 2755, 12034, 8299, 1493, 28496, 33729, 76, 2984, 11, 257, 6472, 86, 19061, 2624, 590, 13008, 1039, 29293, 4361, 394, 17466, 716, 13, 51304], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 152, "seek": 49820, "start": 517.2, "end": 520.0, "text": " Czyli to tak, jakby mie\u0107 zesp\u00f3\u0142 specjalist\u00f3w.", "tokens": [51314, 37099, 281, 991, 11, 28976, 35612, 710, 13361, 16181, 46433, 468, 3901, 13, 51454], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 153, "seek": 49820, "start": 520.2, "end": 521.0, "text": " Dok\u0142adnie.", "tokens": [51464, 29768, 10358, 2766, 13, 51504], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 154, "seek": 49820, "start": 521.2, "end": 524.0, "text": " To nie jest robienie tego samego osiem razy.", "tokens": [51514, 1407, 2838, 3492, 3870, 27385, 8627, 912, 1571, 3003, 4907, 9639, 88, 13, 51654], "temperature": 0.0, "avg_logprob": -0.07499997716554453, "compression_ratio": 1.4350877192982456, "no_speech_prob": 0.009439692832529545}, {"id": 155, "seek": 52400, "start": 524.0, "end": 531.8, "text": " To jak posiadanie o\u015bmiu wyspecjalizowanych analityk\u00f3w, kt\u00f3rzy patrz\u0105 na ten sam problem i na ko\u0144cu dziel\u0105 si\u0119 swoimi wnioskami.", "tokens": [50364, 1407, 4207, 1366, 38069, 7155, 277, 1788, 3057, 84, 27062, 494, 66, 22600, 590, 23341, 339, 364, 1860, 23849, 11, 25382, 1947, 81, 8925, 1667, 2064, 3247, 1154, 741, 1667, 26470, 12032, 9758, 1187, 1611, 3244, 13291, 10121, 45368, 2717, 48737, 13, 50754], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 156, "seek": 52400, "start": 532.0, "end": 533.8, "text": " Dopiero to daje pe\u0142ny obraz.", "tokens": [50764, 42657, 12030, 281, 1120, 2884, 43205, 1634, 22798, 89, 13, 50854], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 157, "seek": 52400, "start": 534.0, "end": 535.8, "text": " To ma sens.", "tokens": [50864, 1407, 463, 2923, 13, 50954], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 158, "seek": 52400, "start": 536.0, "end": 537.8, "text": " Ale jest jeszcze jedna rzecz.", "tokens": [50964, 9366, 3492, 14168, 5232, 629, 36833, 13, 51054], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 159, "seek": 52400, "start": 538.0, "end": 544.8, "text": " Je\u015bli porzucamy przetwarzanie sekwencyjne, to sk\u0105d model wie, w jakiej kolejno\u015bci s\u0105 s\u0142owa?", "tokens": [51064, 37086, 1515, 89, 1311, 7804, 6541, 302, 31991, 7155, 17215, 15615, 42949, 716, 11, 281, 1110, 18962, 2316, 3355, 11, 261, 4207, 7764, 23749, 16438, 9015, 15116, 5528, 30, 51404], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 160, "seek": 52400, "start": 545.0, "end": 549.8, "text": " Przecie\u017c pies gonikota to co\u015b zupe\u0142nie innego ni\u017c kot gonipsa.", "tokens": [51414, 2114, 1381, 40082, 29640, 26307, 1035, 5377, 281, 19241, 49922, 294, 11858, 28502, 43029, 26307, 2600, 64, 13, 51654], "temperature": 0.0, "avg_logprob": -0.08314957157258064, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.01641283556818962}, {"id": 161, "seek": 54980, "start": 549.8, "end": 554.5999999999999, "text": " Bez rekurencji ta informacja o kolejno\u015bci wydaje si\u0119 gin\u0105\u0107.", "tokens": [50364, 879, 89, 33881, 9873, 19649, 1846, 1356, 23395, 277, 23749, 16438, 49165, 3244, 36604, 36374, 13, 50604], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 162, "seek": 54980, "start": 554.8, "end": 559.5999999999999, "text": " I tu dochodzimy do kolejnego, genialnego w swojej prostocie rozwi\u0105zania.", "tokens": [50614, 286, 2604, 9243, 378, 89, 13189, 360, 23749, 11858, 11, 48228, 11858, 261, 29489, 73, 10293, 905, 414, 9544, 22620, 5609, 13, 50854], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 163, "seek": 54980, "start": 559.8, "end": 561.5999999999999, "text": " Nazwali je Positional Encoding.", "tokens": [50864, 11870, 40054, 1506, 25906, 2628, 29584, 8616, 13, 50954], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 164, "seek": 54980, "start": 561.8, "end": 564.5999999999999, "text": " To by\u0142a niezwykle sprytna sztuczka.", "tokens": [50964, 1407, 23936, 33511, 9726, 14677, 637, 627, 83, 629, 262, 2682, 1311, 89, 2330, 13, 51104], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 165, "seek": 54980, "start": 564.8, "end": 565.5999999999999, "text": " Na czym polega\u0142a?", "tokens": [51114, 6056, 31466, 13208, 3680, 5024, 30, 51154], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 166, "seek": 54980, "start": 565.8, "end": 572.5999999999999, "text": " Zanim s\u0142owa trafi\u0105 do modelu ich wektorowe reprezentacje, czyli embeddings, s\u0105 wzbogacane o dodatkowy wektor.", "tokens": [51164, 1176, 17869, 15116, 5528, 944, 69, 11404, 360, 2316, 84, 1893, 321, 28359, 6880, 1085, 265, 14185, 29293, 11, 16591, 12240, 29432, 11, 9015, 24809, 65, 664, 326, 1929, 277, 13886, 33525, 10089, 321, 28359, 13, 51504], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 167, "seek": 54980, "start": 572.8, "end": 575.5999999999999, "text": " Wektor, kt\u00f3ry koduje pozycj\u0119 s\u0142owa w zdaniu.", "tokens": [51514, 492, 28359, 11, 9913, 350, 378, 13008, 49358, 41960, 15116, 5528, 261, 16221, 25849, 13, 51654], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 168, "seek": 54980, "start": 575.8, "end": 578.5999999999999, "text": " I nie u\u017cyli do tego zwyk\u0142ego licznika 1, 2, 3?", "tokens": [51664, 286, 2838, 34097, 2081, 360, 8627, 43436, 74, 1221, 6308, 6169, 22672, 5439, 502, 11, 568, 11, 805, 30, 51804], "temperature": 0.0, "avg_logprob": -0.09513028667819115, "compression_ratio": 1.389776357827476, "no_speech_prob": 0.05148034170269966}, {"id": 169, "seek": 57860, "start": 578.6, "end": 587.4, "text": " Nie. Zamiast tego wykorzystali zestaw funkcji sinusoidalnych, sinus\u00f3w i cosinus\u00f3w o r\u00f3\u017cnych cz\u0119stotliwo\u015bciach.", "tokens": [50364, 12016, 13, 1176, 4526, 525, 8627, 43606, 36049, 5103, 37889, 1607, 26476, 19649, 41503, 17079, 304, 9399, 11, 3343, 301, 3901, 741, 3792, 259, 301, 3901, 277, 42602, 18544, 372, 310, 2081, 36476, 608, 13, 50804], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 170, "seek": 57860, "start": 587.6, "end": 589.4, "text": " Dlaczego akurat sinus i cosinus?", "tokens": [50814, 413, 75, 39329, 9308, 44108, 3343, 301, 741, 3792, 259, 301, 30, 50904], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 171, "seek": 57860, "start": 589.6, "end": 592.4, "text": " To wydaje si\u0119 do\u015b\u0107 abstrakcyjna.", "tokens": [50914, 1407, 49165, 3244, 49333, 10823, 11272, 42949, 629, 13, 51054], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 172, "seek": 57860, "start": 592.6, "end": 596.4, "text": " Poniewa\u017c funkcje te maj\u0105 regularne, przewidywalne w\u0142a\u015bciwo\u015bci.", "tokens": [51064, 31756, 27806, 26476, 44261, 535, 26064, 3890, 716, 11, 39758, 327, 27112, 304, 716, 40112, 36476, 13, 51254], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 173, "seek": 57860, "start": 596.6, "end": 600.4, "text": " To pozwala modelowi \u0142atwo uczy\u0107 si\u0119 relatywnych pozycji.", "tokens": [51264, 1407, 40557, 5159, 2316, 24503, 47759, 6120, 344, 33967, 3244, 1039, 21398, 895, 16384, 49358, 19649, 13, 51454], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 174, "seek": 57860, "start": 600.6, "end": 607.4, "text": " Co wi\u0119cej, ta metoda potencjalnie pozwala mu generalizowa\u0107 na zdania d\u0142u\u017csze ni\u017c te, kt\u00f3re widzia\u0142 w treningu.", "tokens": [51464, 3066, 26004, 11, 1846, 1131, 13449, 1847, 22660, 22600, 2766, 40557, 5159, 2992, 2674, 590, 11445, 1667, 16221, 5609, 274, 24066, 1427, 82, 1381, 28502, 535, 11, 8864, 27486, 8908, 261, 2192, 773, 84, 13, 51804], "temperature": 0.0, "avg_logprob": -0.07622236485103909, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.01705109141767025}, {"id": 175, "seek": 60740, "start": 607.4, "end": 608.1999999999999, "text": " To du\u017cy plus.", "tokens": [50364, 1407, 1581, 7735, 1804, 13, 50404], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 176, "seek": 60740, "start": 608.4, "end": 613.1999999999999, "text": " Ogromny. Wcze\u015bniej model musia\u0142 si\u0119 uczy\u0107 ka\u017cdej pozycji z osobna.", "tokens": [50414, 422, 861, 298, 1634, 13, 343, 9680, 37511, 2316, 1038, 8908, 3244, 344, 33967, 21912, 1479, 73, 49358, 19649, 710, 41518, 629, 13, 50654], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 177, "seek": 60740, "start": 613.4, "end": 620.1999999999999, "text": " A tutaj, to tak jakby ka\u017cde s\u0142owo dostawa\u0142o unikalny kod pocztowy, kt\u00f3ry m\u00f3wi, gdzie jest i jak daleko ma do s\u0105siad\u00f3w.", "tokens": [50664, 316, 12749, 11, 281, 991, 28976, 21912, 1479, 15116, 19941, 20568, 10449, 5249, 517, 41216, 1634, 350, 378, 714, 66, 2682, 10089, 11, 9913, 24592, 11, 18922, 3492, 741, 4207, 11702, 34241, 463, 360, 9015, 7691, 345, 3901, 13, 51004], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 178, "seek": 60740, "start": 620.4, "end": 624.1999999999999, "text": " Dobrze, teoria brzmi niesamowicie sp\u00f3jnie i elegancko.", "tokens": [51014, 29679, 13503, 11, 535, 8172, 738, 89, 3057, 48100, 335, 305, 28434, 637, 18999, 2766, 741, 1118, 1275, 41416, 13, 51204], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 179, "seek": 60740, "start": 624.4, "end": 626.1999999999999, "text": " Ale teoria to jedno.", "tokens": [51214, 9366, 535, 8172, 281, 5232, 1771, 13, 51304], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 180, "seek": 60740, "start": 626.4, "end": 627.1999999999999, "text": " Pora na dowody.", "tokens": [51314, 430, 3252, 1667, 9459, 843, 13, 51354], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 181, "seek": 60740, "start": 627.4, "end": 631.1999999999999, "text": " Jak ta pi\u0119kna architektura poradzi\u0142a sobie w zderzeniu z rzeczywisto\u015bci\u0105?", "tokens": [51364, 15029, 1846, 48085, 629, 3912, 642, 2320, 2991, 1515, 345, 3992, 5024, 13652, 261, 710, 1068, 39651, 710, 26297, 86, 9334, 50227, 30, 51554], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 182, "seek": 60740, "start": 631.4, "end": 635.1999999999999, "text": " I tu, no c\u00f3\u017c, tu zaczyna si\u0119 prawdziwy knockout.", "tokens": [51564, 286, 2604, 11, 572, 6333, 1427, 11, 2604, 43811, 629, 3244, 41175, 3992, 9726, 6728, 346, 13, 51754], "temperature": 0.0, "avg_logprob": -0.07993052277383925, "compression_ratio": 1.4077669902912622, "no_speech_prob": 0.026383688673377037}, {"id": 183, "seek": 63520, "start": 635.2, "end": 641.0, "text": " Wyniki, kt\u00f3re przedstawili by\u0142y nie tyle lepsze, co po prostu deklasuj\u0105ce konkurencje.", "tokens": [50364, 343, 2534, 9850, 11, 8864, 45616, 2312, 26366, 2838, 39293, 476, 1878, 1381, 11, 598, 714, 19518, 368, 74, 7743, 13263, 384, 21428, 9873, 44261, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1111808280422263, "compression_ratio": 1.3672131147540985, "no_speech_prob": 0.08180145174264908}, {"id": 184, "seek": 63520, "start": 641.2, "end": 642.0, "text": " A\u017c tak?", "tokens": [50664, 316, 1427, 991, 30, 50704], "temperature": 0.0, "avg_logprob": -0.1111808280422263, "compression_ratio": 1.3672131147540985, "no_speech_prob": 0.08180145174264908}, {"id": 185, "seek": 63520, "start": 642.2, "end": 649.0, "text": " We\u017amy standardowe zadanie t\u0142umaczenia maszynowego na zbiorze danych WMT 2014 z angielskiego na niemiecki.", "tokens": [50714, 492, 10659, 2226, 3832, 6880, 42788, 7155, 256, 49166, 326, 14320, 2300, 1229, 3785, 6308, 1667, 710, 33362, 1381, 274, 34644, 343, 44, 51, 8227, 710, 2562, 1187, 5161, 12200, 1667, 2838, 25210, 547, 72, 13, 51054], "temperature": 0.0, "avg_logprob": -0.1111808280422263, "compression_ratio": 1.3672131147540985, "no_speech_prob": 0.08180145174264908}, {"id": 186, "seek": 63520, "start": 649.2, "end": 656.0, "text": " Najlepsze dotyczczasowe modele, cz\u0119sto skomplikowane hybrydy r\u00f3\u017cnych architektur, tak zwane ensemble, mia\u0142y pewien pu\u0142ap.", "tokens": [51064, 31576, 306, 1878, 1381, 5893, 17466, 30989, 6880, 4391, 306, 11, 34369, 1110, 298, 564, 1035, 23066, 2477, 65, 627, 3173, 42602, 3912, 642, 2320, 374, 11, 991, 11873, 1929, 19492, 11, 21290, 6825, 25889, 1053, 2362, 1221, 569, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1111808280422263, "compression_ratio": 1.3672131147540985, "no_speech_prob": 0.08180145174264908}, {"id": 187, "seek": 63520, "start": 656.2, "end": 663.0, "text": " Transformer w swojej du\u017cej wersji, Transformer Big, osi\u0105gn\u0105\u0142 wynik 28 i 40 blu.", "tokens": [51414, 27938, 260, 261, 29489, 73, 1581, 38493, 261, 433, 4013, 11, 27938, 260, 5429, 11, 3003, 11404, 4568, 1611, 1221, 31936, 1035, 7562, 741, 3356, 888, 84, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1111808280422263, "compression_ratio": 1.3672131147540985, "no_speech_prob": 0.08180145174264908}, {"id": 188, "seek": 66300, "start": 663.0, "end": 664.8, "text": " By\u0142o o ponad dwa punkty wi\u0119cej.", "tokens": [50364, 3146, 5249, 277, 9224, 345, 35045, 25188, 874, 26004, 13, 50454], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 189, "seek": 66300, "start": 665.0, "end": 667.8, "text": " Wow, zatrzymajmy si\u0119 na chwil\u0119.", "tokens": [50464, 3153, 11, 35802, 13047, 1696, 73, 2226, 3244, 1667, 41941, 1274, 13, 50604], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 190, "seek": 66300, "start": 668.0, "end": 671.8, "text": " Wiem, \u017ce w tamtych czasach ka\u017cdy u\u0142amek punktu blu by\u0142 na wag\u0119 z\u0142ota.", "tokens": [50614, 343, 4907, 11, 3561, 261, 7677, 874, 339, 13190, 608, 31615, 344, 1221, 529, 74, 39561, 84, 888, 84, 16673, 1667, 36854, 1274, 31614, 5377, 13, 50804], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 191, "seek": 66300, "start": 672.0, "end": 672.8, "text": " Dok\u0142adnie.", "tokens": [50814, 29768, 10358, 2766, 13, 50854], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 192, "seek": 66300, "start": 673.0, "end": 678.8, "text": " Dwa punkty przewagi nad absolutnie najlepszymi modelami \u015bwiata to nie jest drobna poprawka.", "tokens": [50864, 413, 4151, 25188, 874, 39758, 20291, 12617, 18757, 2766, 41903, 1878, 1229, 3057, 2316, 4526, 21485, 3274, 281, 2838, 3492, 3789, 65, 629, 1665, 5131, 2330, 13, 51154], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 193, "seek": 66300, "start": 679.0, "end": 682.8, "text": " To jakby w biegu na 100 metr\u00f3w kto\u015b pobi\u0142 rekord \u015bwiata o p\u00f3\u0142 sekundy.", "tokens": [51164, 1407, 28976, 261, 272, 414, 2794, 1667, 2319, 1131, 81, 3901, 32982, 714, 5614, 1221, 33881, 765, 21485, 3274, 277, 47907, 17215, 49996, 13, 51354], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 194, "seek": 66300, "start": 683.0, "end": 684.8, "text": " To jest \u015bwietne por\u00f3wnanie.", "tokens": [51364, 1407, 3492, 8299, 39083, 716, 1515, 812, 895, 7155, 13, 51454], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 195, "seek": 66300, "start": 685.0, "end": 686.8, "text": " To w\u0142a\u015bnie pokazuje si\u0142\u0119 tej architektury.", "tokens": [51464, 1407, 14234, 13010, 43317, 1511, 46564, 12573, 3912, 642, 2320, 2598, 13, 51554], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 196, "seek": 66300, "start": 687.0, "end": 687.8, "text": " A to nie wszystko.", "tokens": [51564, 316, 281, 2838, 22607, 13, 51604], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 197, "seek": 66300, "start": 688.0, "end": 688.8, "text": " Co jeszcze?", "tokens": [51614, 3066, 14168, 30, 51654], "temperature": 0.0, "avg_logprob": -0.06273804326211252, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.0801432728767395}, {"id": 198, "seek": 68880, "start": 688.8, "end": 697.5999999999999, "text": " Na parze angielski-francuski Transformer ustanowi\u0142 nowy rekord \u015bwiata dla pojedynczego modelu, osi\u0105gaj\u0105c 41 i 80 blu.", "tokens": [50364, 6056, 971, 1381, 2562, 1187, 18020, 12, 69, 4257, 1149, 2984, 27938, 260, 26189, 282, 24503, 1221, 586, 88, 33881, 765, 21485, 3274, 12285, 714, 40543, 2534, 3689, 6308, 2316, 84, 11, 3003, 11404, 70, 38757, 18173, 741, 4688, 888, 84, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 199, "seek": 68880, "start": 697.8, "end": 700.5999999999999, "text": " Ale jest jeszcze co\u015b, co mo\u017ce by\u0107 nawet wa\u017cniejsze ni\u017c sam wynik.", "tokens": [50814, 9366, 3492, 14168, 19241, 11, 598, 12034, 15069, 22696, 27777, 44258, 28502, 3247, 31936, 1035, 13, 50954], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 200, "seek": 68880, "start": 700.8, "end": 701.5999999999999, "text": " Mianowicie.", "tokens": [50964, 376, 952, 305, 28434, 13, 51004], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 201, "seek": 68880, "start": 701.8, "end": 702.5999999999999, "text": " Koszt treningu.", "tokens": [51014, 36909, 2682, 2192, 773, 84, 13, 51054], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 202, "seek": 68880, "start": 702.8, "end": 706.5999999999999, "text": " Te rewolucyjne wyniki osi\u0105gni\u0119to w radykalnie kr\u00f3tszym czasie.", "tokens": [51064, 1989, 319, 48481, 1311, 88, 73, 716, 31936, 9850, 3003, 11404, 70, 35938, 1353, 261, 367, 880, 19990, 2766, 42366, 1373, 26681, 42667, 13, 51254], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 203, "seek": 68880, "start": 706.8, "end": 713.5999999999999, "text": " Model Transformer Big trenowa\u0142 si\u0119 zalednie trzy i p\u00f3\u0142 dnia na o\u015bmiu kartach GPU P100.", "tokens": [51264, 17105, 27938, 260, 5429, 23136, 30105, 3244, 710, 5573, 2766, 34573, 741, 47907, 274, 12679, 1667, 277, 1788, 3057, 84, 29120, 608, 18407, 430, 6879, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 204, "seek": 68880, "start": 713.8, "end": 715.5999999999999, "text": " Tylko trzy i p\u00f3\u0142 dnia?", "tokens": [51614, 49286, 4093, 34573, 741, 47907, 274, 12679, 30, 51704], "temperature": 0.0, "avg_logprob": -0.10227046646438279, "compression_ratio": 1.389655172413793, "no_speech_prob": 0.19366884231567383}, {"id": 205, "seek": 71560, "start": 715.6, "end": 722.4, "text": " Tak. To by\u0142 u\u0142amek zasob\u00f3w obliczeniowych, jakich wymaga\u0142y poprzednie, gorsze od niego modele.", "tokens": [50364, 9118, 13, 1407, 16673, 344, 1221, 529, 74, 26530, 996, 3901, 1111, 1050, 42124, 19605, 11, 4207, 480, 29764, 9286, 6825, 1665, 81, 11312, 2766, 11, 290, 830, 1381, 3611, 49615, 4391, 306, 13, 50704], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 206, "seek": 71560, "start": 722.6, "end": 727.4, "text": " Czyli m\u00f3wimy nie tylko o lepszych wynikach, ale o zupe\u0142nie innej skali.", "tokens": [50714, 37099, 13489, 13189, 2838, 13219, 277, 476, 1878, 28051, 31936, 1035, 608, 11, 6775, 277, 49922, 294, 11794, 1110, 5103, 13, 50954], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 207, "seek": 71560, "start": 727.6, "end": 731.4, "text": " To tak jakby kto\u015b wynalaz\u0142 metod\u0119 budowy wie\u017cowca w tydzie\u0144, a nie w dwa lata.", "tokens": [50964, 1407, 991, 28976, 32982, 31936, 304, 921, 1221, 1131, 378, 1274, 3265, 10089, 3355, 1427, 305, 496, 261, 1104, 13096, 5248, 11, 257, 2838, 261, 35045, 46722, 13, 51154], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 208, "seek": 71560, "start": 731.6, "end": 732.4, "text": " Dok\u0142adnie.", "tokens": [51164, 29768, 10358, 2766, 13, 51204], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 209, "seek": 71560, "start": 732.6, "end": 735.4, "text": " To nie jest usprawnienie, to zmienia zasady gry.", "tokens": [51214, 1407, 2838, 3492, 505, 79, 29603, 27385, 11, 281, 17020, 18811, 26530, 880, 41974, 13, 51354], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 210, "seek": 71560, "start": 735.6, "end": 741.4, "text": " Otwiera drzwi do budowania modeli, o kt\u00f3rych wcze\u015bniej nikt nawet nie marzy\u0142 z powodu barier obliczeniowych.", "tokens": [51364, 12936, 86, 10609, 1224, 89, 6253, 360, 3265, 21308, 2316, 72, 11, 277, 30382, 40785, 297, 9874, 22696, 2838, 1849, 1229, 1221, 710, 3388, 34873, 2159, 811, 1111, 1050, 42124, 19605, 13, 51654], "temperature": 0.0, "avg_logprob": -0.05389283476649104, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.049807507544755936}, {"id": 211, "seek": 74140, "start": 741.4, "end": 746.1999999999999, "text": " To by\u0142a swego rodzaju demokratyzacja mocy obliczeniowej w badaniach nad AI.", "tokens": [50364, 1407, 23936, 2484, 1571, 28607, 33166, 49432, 37433, 23395, 705, 1344, 1111, 1050, 42124, 21091, 261, 1578, 3782, 608, 12617, 7318, 13, 50604], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 212, "seek": 74140, "start": 746.4, "end": 752.1999999999999, "text": " Nagle okawa\u0142o si\u0119, \u017ce nie trzeba farm serwer\u00f3w pracuj\u0105cych tygodniami, by osi\u0105gn\u0105\u0107 najnowocze\u015bniejsze wyniki.", "tokens": [50614, 426, 15088, 3133, 10449, 5249, 3244, 11, 3561, 2838, 25860, 5421, 816, 1554, 3901, 22404, 13263, 31306, 1104, 21787, 77, 15568, 11, 538, 3003, 11404, 4568, 36374, 11212, 3785, 905, 1381, 37511, 82, 1381, 31936, 9850, 13, 50904], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 213, "seek": 74140, "start": 752.4, "end": 754.1999999999999, "text": " A co z innymi zadaniami?", "tokens": [50914, 316, 598, 710, 294, 31813, 710, 11338, 15568, 30, 51004], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 214, "seek": 74140, "start": 754.4, "end": 759.1999999999999, "text": " Czy to by\u0142a tylko doskona\u0142a maszyna do t\u0142umaczenia, czy ta architektura okaza\u0142a si\u0119 bardziej uniwersalna?", "tokens": [51014, 19832, 281, 23936, 13219, 4491, 74, 4037, 5024, 2300, 1229, 629, 360, 256, 49166, 326, 14320, 11, 6430, 1846, 3912, 642, 2320, 2991, 3133, 12257, 5024, 3244, 27209, 36435, 5364, 304, 629, 30, 51254], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 215, "seek": 74140, "start": 759.4, "end": 762.1999999999999, "text": " Autorzy doskonale zdawali sobie z tego spraw\u0119.", "tokens": [51264, 6049, 284, 1229, 4491, 18295, 1220, 16221, 1607, 5103, 13652, 710, 8627, 22734, 1274, 13, 51404], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 216, "seek": 74140, "start": 762.4, "end": 766.1999999999999, "text": " Dlatego przetestowali Transformera na zupe\u0142nie innym polu bitwy.", "tokens": [51414, 47184, 6541, 302, 377, 305, 5103, 27938, 1663, 1667, 49922, 294, 12996, 1180, 84, 857, 9726, 13, 51604], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 217, "seek": 74140, "start": 766.4, "end": 767.1999999999999, "text": " Jakim?", "tokens": [51614, 15029, 332, 30, 51654], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 218, "seek": 74140, "start": 767.4, "end": 770.1999999999999, "text": " Na parsowaniu sk\u0142adniowym zdanie angielskich.", "tokens": [51664, 6056, 21156, 305, 25849, 1110, 10358, 3722, 31691, 16221, 7155, 2562, 1187, 5161, 480, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0802752421452449, "compression_ratio": 1.4421965317919074, "no_speech_prob": 0.27945780754089355}, {"id": 219, "seek": 77020, "start": 770.2, "end": 774.0, "text": " To bardzo trudne zadanie analizy struktury gramatycznej.", "tokens": [50364, 1407, 9034, 32007, 716, 42788, 7155, 2624, 590, 88, 342, 19977, 2598, 21353, 267, 17466, 11794, 13, 50554], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 220, "seek": 77020, "start": 774.2, "end": 779.0, "text": " I tutaj, jak sami napisali, wyniki by\u0142y zaskakuj\u0105co dobre.", "tokens": [50564, 286, 12749, 11, 4207, 3247, 72, 9296, 271, 5103, 11, 31936, 9850, 26366, 710, 3863, 514, 13263, 1291, 41959, 13, 50804], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 221, "seek": 77020, "start": 779.2, "end": 782.0, "text": " Zaskakuj\u0105co, czyli sami nie byli pewni.", "tokens": [50814, 1176, 3863, 514, 13263, 1291, 11, 16591, 3247, 72, 2838, 538, 2081, 47160, 72, 13, 50954], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 222, "seek": 77020, "start": 782.2, "end": 783.2, "text": " Chyba tak.", "tokens": [50964, 761, 28375, 991, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 223, "seek": 77020, "start": 783.4000000000001, "end": 793.0, "text": " Transformer, kt\u00f3ry w og\u00f3le nie by\u0142 do tego projektowany, osi\u0105gn\u0105\u0142 wynik F1 na porzemie 92.7, pokonuj\u0105c wiele wyspecjalizowanych architektur.", "tokens": [51024, 27938, 260, 11, 9913, 261, 29229, 2838, 16673, 360, 8627, 26261, 23341, 11, 3003, 11404, 4568, 1611, 1221, 31936, 1035, 479, 16, 1667, 1515, 89, 32163, 28225, 13, 22, 11, 13010, 266, 44733, 33137, 27062, 494, 66, 22600, 590, 23341, 339, 3912, 642, 2320, 374, 13, 51504], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 224, "seek": 77020, "start": 793.2, "end": 794.0, "text": " Niesamowite.", "tokens": [51514, 426, 530, 335, 305, 642, 13, 51554], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 225, "seek": 77020, "start": 794.2, "end": 798.0, "text": " Co wi\u0119cej, pokaza\u0142 swoj\u0105 si\u0142\u0119 nawet przy ma\u0142ej ilo\u015bci danych.", "tokens": [51564, 3066, 26004, 11, 13010, 12257, 1221, 49194, 1511, 46564, 22696, 6501, 463, 19827, 73, 1930, 44468, 274, 34644, 13, 51754], "temperature": 0.0, "avg_logprob": -0.07428466690170181, "compression_ratio": 1.4049295774647887, "no_speech_prob": 0.0059424638748168945}, {"id": 226, "seek": 79800, "start": 798.0, "end": 805.8, "text": " Trenuj\u0105c na zbiorze zaledwie 40 tysi\u0119cy zda\u0144, przewy\u017cszy\u0142 bardzo silny klasyczny model Berkeley-Parser.", "tokens": [50364, 314, 1095, 44733, 1667, 710, 33362, 1381, 710, 5573, 8699, 3356, 38156, 47303, 710, 2675, 5248, 11, 39758, 88, 1427, 7706, 1221, 9034, 3425, 1634, 9671, 5871, 3689, 1634, 2316, 23684, 12, 47, 685, 260, 13, 50754], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 227, "seek": 79800, "start": 806.0, "end": 806.8, "text": " A wcze\u015bniejsze modele?", "tokens": [50764, 316, 38533, 1788, 44258, 4391, 306, 30, 50804], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 228, "seek": 79800, "start": 807.0, "end": 810.8, "text": " Wcze\u015bniejsze modele oparte na RNN kompletnie sobie z tym nie radzi\u0142y.", "tokens": [50814, 343, 9680, 37511, 82, 1381, 4391, 306, 999, 11026, 1667, 45702, 45, 5207, 14657, 2766, 13652, 710, 8107, 2838, 2843, 3992, 6825, 13, 51004], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 229, "seek": 79800, "start": 811.0, "end": 815.8, "text": " To by\u0142 ostateczny dow\u00f3d na niesamowit\u0105 zdolno\u015b\u0107 tej architektury do generalizacji.", "tokens": [51014, 1407, 16673, 277, 15406, 3689, 1634, 9459, 17081, 1667, 48100, 335, 305, 270, 1611, 16221, 401, 23293, 12573, 3912, 642, 2320, 2598, 360, 2674, 590, 13152, 13, 51254], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 230, "seek": 79800, "start": 816.0, "end": 818.8, "text": " Wi\u0119c co to wszystko oznacza?", "tokens": [51264, 32508, 598, 281, 22607, 277, 22672, 326, 2394, 30, 51404], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 231, "seek": 79800, "start": 819.0, "end": 827.8, "text": " Wygl\u0105da na to, \u017ce ta jedna odwa\u017cna decyzja o ca\u0142kowitym porzuceniu rekurencji na rzecz attention okaza\u0142a si\u0119 absolutnym strza\u0142em dziesi\u0105tk\u0119.", "tokens": [51414, 14458, 7191, 26398, 1667, 281, 11, 3561, 1846, 5232, 629, 3611, 27111, 629, 979, 37433, 2938, 277, 35224, 74, 305, 507, 76, 1515, 89, 1311, 268, 5951, 33881, 9873, 19649, 1667, 36833, 3202, 3133, 12257, 5024, 3244, 18757, 12996, 1056, 2394, 11126, 9758, 530, 11404, 83, 15724, 13, 51854], "temperature": 0.0, "avg_logprob": -0.09417353671021257, "compression_ratio": 1.4346504559270516, "no_speech_prob": 0.0025892681442201138}, {"id": 232, "seek": 82800, "start": 828.0, "end": 830.8, "text": " Nie by\u0142a ewolucja, to by\u0142a rewolucja.", "tokens": [50364, 12016, 23936, 43364, 401, 1311, 2938, 11, 281, 23936, 319, 48481, 1311, 2938, 13, 50504], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 233, "seek": 82800, "start": 831.0, "end": 834.8, "text": " Transformer otworzy\u0142 wrota do R wielkich modeli j\u0119zykowych.", "tokens": [50514, 27938, 260, 4337, 28321, 1229, 1221, 928, 5377, 360, 497, 20570, 48349, 2316, 72, 49055, 74, 19605, 13, 50704], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 234, "seek": 82800, "start": 835.0, "end": 839.8, "text": " Jego zdolno\u015b\u0107 do paralelizacji i modelowania dalekich zale\u017cno\u015bci pozwoli\u0142a na skalowanie.", "tokens": [50714, 508, 6308, 16221, 401, 23293, 360, 26009, 338, 590, 13152, 741, 2316, 21308, 11702, 916, 480, 710, 45494, 16438, 40557, 9384, 5024, 1667, 16890, 22028, 13, 50954], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 235, "seek": 82800, "start": 840.0, "end": 841.8, "text": " I dzi\u0119ki temu mamy to, co mamy dzisiaj.", "tokens": [50964, 286, 45003, 33346, 17335, 281, 11, 598, 17335, 25772, 13, 51054], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 236, "seek": 82800, "start": 842.0, "end": 847.8, "text": " Nagle mo\u017cna by\u0142o trenowa\u0107 znacznie, znacznie wi\u0119ksze modele na niewieobra\u017calnie wielkich zbiorach danych.", "tokens": [51064, 426, 15088, 17790, 14811, 23136, 11445, 15397, 14875, 2766, 11, 15397, 14875, 2766, 29968, 1381, 4391, 306, 1667, 43622, 414, 24393, 1427, 304, 2766, 20570, 48349, 710, 33362, 608, 274, 34644, 13, 51354], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 237, "seek": 82800, "start": 848.0, "end": 852.8, "text": " To jest bezpo\u015brednia linia, kt\u00f3ra prowadzi do modeli BERT, GPT i ca\u0142ej reszty.", "tokens": [51364, 1407, 3492, 10782, 2259, 1788, 986, 12679, 22896, 654, 11, 19456, 36590, 3992, 360, 2316, 72, 363, 31479, 11, 26039, 51, 741, 47631, 73, 725, 89, 874, 13, 51604], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 238, "seek": 82800, "start": 853.0, "end": 854.8, "text": " Wszystkie stoj\u0105 na ramionach tego jednego artyku\u0142u.", "tokens": [51614, 343, 10424, 22872, 22784, 8555, 1667, 10211, 313, 608, 8627, 5232, 11858, 594, 874, 5279, 24066, 13, 51704], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 239, "seek": 82800, "start": 855.0, "end": 855.8, "text": " Dok\u0142adnie tak.", "tokens": [51714, 29768, 10358, 2766, 991, 13, 51754], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 240, "seek": 82800, "start": 856.0, "end": 857.8, "text": " Z 2017 roku.", "tokens": [51764, 1176, 6591, 19451, 13, 51854], "temperature": 0.0, "avg_logprob": -0.07676877589584086, "compression_ratio": 1.4912790697674418, "no_speech_prob": 0.008373873308300972}, {"id": 241, "seek": 85800, "start": 858.0, "end": 864.8, "text": " Ale jest co\u015b, co pokazuje, \u017ce autorzy sami byli zaskoczeni tym, co odkryli jakie\u015b \u015blady procesu badawczego?", "tokens": [50364, 9366, 3492, 19241, 11, 598, 13010, 43317, 11, 3561, 19510, 1229, 3247, 72, 538, 2081, 710, 3863, 905, 42124, 8107, 11, 598, 3611, 43298, 2081, 31163, 8299, 75, 880, 17565, 84, 272, 1538, 86, 3689, 6308, 30, 50704], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 242, "seek": 85800, "start": 865.0, "end": 868.8, "text": " Tak, jest taka ciekawa cz\u0119\u015b\u0107, gdzie analizuj\u0105 r\u00f3\u017cne warianty swojej architektury.", "tokens": [50714, 9118, 11, 3492, 28017, 46419, 10449, 47149, 11, 18922, 2624, 590, 13263, 47760, 1516, 5798, 88, 29489, 73, 3912, 642, 2320, 2598, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 243, "seek": 85800, "start": 869.0, "end": 872.8, "text": " Experimentowali na przyk\u0142ad z liczb\u0105 tych g\u0142\u00f3w w Multi-head attention.", "tokens": [50914, 37933, 305, 5103, 1667, 23144, 710, 6169, 89, 65, 1611, 15180, 18117, 3901, 261, 29238, 12, 1934, 3202, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 244, "seek": 85800, "start": 873.0, "end": 873.8, "text": " A co im wysz\u0142o?", "tokens": [51114, 316, 598, 566, 261, 20589, 5249, 30, 51154], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 245, "seek": 85800, "start": 874.0, "end": 876.8, "text": " Okaza\u0142o si\u0119, \u017ce jedna g\u0142owa to za ma\u0142o.", "tokens": [51164, 3477, 12257, 5249, 3244, 11, 3561, 5232, 629, 18117, 5528, 281, 7949, 463, 5249, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 246, "seek": 85800, "start": 877.0, "end": 880.8, "text": " Model nie by\u0142 w stanie uchwyci\u0107 z\u0142o\u017cono\u015bci j\u0119zyka.", "tokens": [51314, 17105, 2838, 16673, 261, 40013, 344, 339, 9726, 39162, 710, 5249, 1427, 8957, 6199, 42309, 40940, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1077985330061479, "compression_ratio": 1.3551724137931034, "no_speech_prob": 0.009563849307596684}, {"id": 247, "seek": 88080, "start": 880.8, "end": 887.5999999999999, "text": " Ale co ciekawe, zbyt wiele g\u0142\u00f3w, na przyk\u0142ad 16, r\u00f3wnie\u017c pogarsza\u0142o wyniki na niekt\u00f3rych zadaniach.", "tokens": [50364, 9366, 598, 30596, 2330, 826, 11, 710, 2322, 83, 33137, 18117, 3901, 11, 1667, 23144, 3165, 11, 20532, 32037, 685, 2394, 5249, 31936, 9850, 1667, 2838, 43073, 627, 339, 42788, 3782, 608, 13, 50704], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 248, "seek": 88080, "start": 887.8, "end": 890.5999999999999, "text": " Czyli wi\u0119cej nie zawsze znaczy lepiej.", "tokens": [50714, 37099, 26004, 2838, 30964, 36584, 476, 39699, 13, 50854], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 249, "seek": 88080, "start": 890.8, "end": 891.5999999999999, "text": " W\u0142a\u015bnie.", "tokens": [50864, 343, 5024, 12221, 13, 50904], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 250, "seek": 88080, "start": 891.8, "end": 895.5999999999999, "text": " To pokazuje, \u017ce projektowanie tych architektur to sztuka kompromisu.", "tokens": [50914, 1407, 13010, 43317, 11, 3561, 26261, 22028, 15180, 3912, 642, 2320, 374, 281, 262, 2682, 13599, 5207, 28722, 25871, 13, 51104], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 251, "seek": 88080, "start": 895.8, "end": 900.5999999999999, "text": " Zwi\u0119kszanie z\u0142o\u017cono\u015bci w niesko\u0144czono\u015b\u0107 nie zawsze prowadzi do lepszych rezultat\u00f3w.", "tokens": [51114, 1176, 22423, 1694, 89, 7155, 710, 5249, 1427, 8957, 6199, 261, 48100, 4093, 5248, 3689, 8957, 7753, 2838, 30964, 36590, 3992, 360, 476, 1878, 28051, 48060, 723, 267, 3901, 13, 51354], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 252, "seek": 88080, "start": 900.8, "end": 903.5999999999999, "text": " Trzeba znale\u017a\u0107 ten z\u0142oty \u015brodek.", "tokens": [51364, 1765, 1381, 4231, 15397, 1220, 10659, 2162, 2064, 31614, 6737, 28580, 916, 13, 51504], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 253, "seek": 88080, "start": 903.8, "end": 905.5999999999999, "text": " Co wymaga\u0142o \u017cmudnych eksperyment\u00f3w?", "tokens": [51514, 3066, 29764, 9286, 5249, 19625, 31916, 9399, 30724, 610, 88, 518, 3901, 30, 51604], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 254, "seek": 88080, "start": 905.8, "end": 906.5999999999999, "text": " Dok\u0142adnie.", "tokens": [51614, 29768, 10358, 2766, 13, 51654], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 255, "seek": 88080, "start": 906.8, "end": 907.8, "text": " To fascynuj\u0105ce.", "tokens": [51664, 1407, 30632, 1344, 77, 13263, 384, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 256, "seek": 88080, "start": 908.0, "end": 909.5999999999999, "text": " A zatem podsumowuj\u0105c.", "tokens": [51724, 316, 710, 26851, 31925, 449, 305, 44733, 13, 51804], "temperature": 0.0, "avg_logprob": -0.07629016593650535, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.10126519948244095}, {"id": 257, "seek": 90960, "start": 909.6, "end": 916.4, "text": " Transformer to prostsza koncepcyjnie, szybsza w treningu i ostatecznie znacznie pot\u0119\u017cniejsza architektura.", "tokens": [50364, 27938, 260, 281, 10293, 82, 2394, 5897, 27493, 42949, 2766, 11, 30526, 929, 2394, 261, 2192, 773, 84, 741, 277, 15406, 19923, 15397, 14875, 2766, 1847, 1274, 1427, 30295, 2394, 3912, 642, 2320, 2991, 13, 50704], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 258, "seek": 90960, "start": 916.6, "end": 919.4, "text": " I zdefiniowa\u0142a now\u0105 er\u0119 w AI.", "tokens": [50714, 286, 710, 20595, 3812, 5528, 5024, 586, 1611, 1189, 1274, 261, 7318, 13, 50854], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 259, "seek": 90960, "start": 919.6, "end": 921.4, "text": " A wszystko dzi\u0119ki jednej idei.", "tokens": [50864, 316, 22607, 45003, 5232, 11794, 1153, 72, 13, 50954], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 260, "seek": 90960, "start": 921.6, "end": 923.4, "text": " Self attention.", "tokens": [50964, 16348, 3202, 13, 51054], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 261, "seek": 90960, "start": 923.6, "end": 926.4, "text": " A je\u015bli spojrzymy na to z jeszcze szanszej perspektywy,", "tokens": [51064, 316, 25630, 8243, 73, 13047, 2226, 1667, 281, 710, 14168, 7870, 599, 16920, 868, 32659, 874, 9726, 11, 51204], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 262, "seek": 90960, "start": 926.6, "end": 931.4, "text": " autorzy ko\u0144cz\u0105 sw\u00f3j artyku\u0142 pisz\u0105c o planach rozszerzenia Transformera na inne modalno\u015bci.", "tokens": [51214, 19510, 1229, 26470, 3689, 1611, 1693, 18999, 594, 874, 5279, 1221, 26584, 8925, 66, 277, 1393, 608, 9544, 82, 4527, 14320, 27938, 1663, 1667, 24170, 39745, 16438, 13, 51454], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 263, "seek": 90960, "start": 931.6, "end": 933.4, "text": " Obrazy, audio, wideo.", "tokens": [51464, 4075, 424, 1229, 11, 6278, 11, 4874, 78, 13, 51554], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 264, "seek": 90960, "start": 933.6, "end": 936.4, "text": " Wtedy to musia\u0142o brzmie\u0107 jak science fiction.", "tokens": [51564, 343, 83, 6038, 281, 1038, 654, 5249, 738, 89, 25210, 2162, 4207, 3497, 13266, 13, 51704], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 265, "seek": 90960, "start": 936.6, "end": 938.4, "text": " Jak ambitne marzenie.", "tokens": [51714, 15029, 3913, 270, 716, 1849, 16778, 13, 51804], "temperature": 0.0, "avg_logprob": -0.09285696347554524, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.004635164979845285}, {"id": 266, "seek": 93840, "start": 938.4, "end": 942.1999999999999, "text": " A dzi\u015b po latach wiemy, \u017ce dok\u0142adnie to si\u0119 sta\u0142o.", "tokens": [50364, 316, 31981, 1788, 714, 4465, 608, 3355, 2226, 11, 3561, 45864, 2766, 281, 3244, 11135, 5249, 13, 50554], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 267, "seek": 93840, "start": 942.4, "end": 947.1999999999999, "text": " Architektury oparte na Transformerze dominuj\u0105 nie tylko w j\u0119zyku, ale i w generowaniu obraz\u00f3w,", "tokens": [50564, 10984, 642, 2320, 2598, 999, 11026, 1667, 27938, 260, 1381, 8859, 13263, 2838, 13219, 261, 49055, 5279, 11, 6775, 741, 261, 1337, 305, 25849, 22798, 89, 3901, 11, 50804], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 268, "seek": 93840, "start": 947.4, "end": 950.1999999999999, "text": " analizie wideo, rozpoznawaniu mowy.", "tokens": [50814, 2624, 590, 414, 4874, 78, 11, 9544, 2259, 35458, 86, 25849, 275, 10089, 13, 50954], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 269, "seek": 93840, "start": 950.4, "end": 951.1999999999999, "text": " To prawda.", "tokens": [50964, 1407, 43607, 13, 51004], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 270, "seek": 93840, "start": 951.4, "end": 954.1999999999999, "text": " I to prowadzi do naprawd\u0119 prowokuj\u0105cej my\u015bli na koniec.", "tokens": [51014, 286, 281, 36590, 3992, 360, 20970, 45553, 453, 13263, 20811, 452, 15350, 1667, 5897, 35733, 13, 51154], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 271, "seek": 93840, "start": 954.4, "end": 955.1999999999999, "text": " S\u0142ucham.", "tokens": [51164, 318, 1221, 625, 335, 13, 51204], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 272, "seek": 93840, "start": 955.4, "end": 960.1999999999999, "text": " Skoro tak fundamentalne za\u0142o\u017cenie jak konieczno\u015b\u0107 sekwencyjnego przetwarzania danych", "tokens": [51214, 7324, 10780, 991, 8088, 716, 7949, 5249, 41118, 4207, 5897, 414, 3689, 23293, 17215, 86, 3020, 73, 11858, 6541, 302, 31991, 5609, 274, 34644, 51454], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 273, "seek": 93840, "start": 960.4, "end": 964.1999999999999, "text": " okaza\u0142o si\u0119 niepotrzebnym ograniczeniem, to warto si\u0119 zastanowi\u0107.", "tokens": [51464, 3133, 12257, 5249, 3244, 2838, 17698, 13503, 65, 12996, 34416, 30732, 2904, 4907, 11, 281, 31830, 3244, 36746, 282, 305, 12757, 13, 51654], "temperature": 0.0, "avg_logprob": -0.06756460747751249, "compression_ratio": 1.4508474576271186, "no_speech_prob": 0.0026972871273756027}, {"id": 274, "seek": 96420, "start": 964.2, "end": 970.0, "text": " Jakie inne fundamentalne za\u0142o\u017cenie, kt\u00f3re dzi\u015b wydaje nam si\u0119 oczywiste w budowie AI,", "tokens": [50364, 15029, 414, 24170, 8088, 716, 7949, 5249, 41118, 11, 8864, 31981, 1788, 49165, 8835, 3244, 277, 6522, 86, 8375, 261, 3265, 13998, 7318, 11, 50654], "temperature": 0.0, "avg_logprob": -0.08467908958335976, "compression_ratio": 1.2871794871794873, "no_speech_prob": 0.04844295233488083}, {"id": 275, "seek": 96420, "start": 970.2, "end": 973.0, "text": " mo\u017ce okaza\u0107 si\u0119 kolejn\u0105 tak\u0105 barier\u0105?", "tokens": [50664, 12034, 3133, 12257, 2162, 3244, 23749, 13113, 31069, 2159, 811, 1611, 30, 50804], "temperature": 0.0, "avg_logprob": -0.08467908958335976, "compression_ratio": 1.2871794871794873, "no_speech_prob": 0.04844295233488083}, {"id": 276, "seek": 96420, "start": 973.2, "end": 977.0, "text": " Co jest dzisiejszym odpowiednikiem rekurrencji,", "tokens": [50814, 3066, 3492, 9758, 50117, 7706, 76, 36574, 13123, 4907, 319, 33503, 1095, 19649, 11, 51004], "temperature": 0.0, "avg_logprob": -0.08467908958335976, "compression_ratio": 1.2871794871794873, "no_speech_prob": 0.04844295233488083}, {"id": 277, "seek": 96420, "start": 977.2, "end": 981.0, "text": " kt\u00f3ry czeka na swoj\u0105 rewolucj\u0119 w stylu attention is all you need?", "tokens": [51014, 9913, 6472, 36361, 1667, 49194, 319, 48481, 1311, 11115, 261, 7952, 2781, 3202, 307, 439, 291, 643, 30, 51204], "temperature": 0.0, "avg_logprob": -0.08467908958335976, "compression_ratio": 1.2871794871794873, "no_speech_prob": 0.04844295233488083}], "language": "pl"}