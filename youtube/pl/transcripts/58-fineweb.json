{"text": " W \u015bwiecie sztucznej inteligencji, a zw\u0142aszcza przy tych gigantycznych modelach j\u0119zykowych, jak Lama 3 czy Mixtral, jest taki jeden pilnie strze\u017cony sekret. I nie chodzi wcale o architektur\u0119 modelu, chodzi o co\u015b znacznie bardziej podstawowego. Przepis na idealne dane treningowe. To jest \u015bwietne por\u00f3wnanie naprawd\u0119, bo to jest tak jakby\u015bmy widzieli jakie\u015b rewolucyjne, wspania\u0142e dania, ale nikt absolutnie nie chce si\u0119 podzieli\u0107 listom sk\u0142adnik\u00f3w, ani technik\u0105. Dok\u0142adnie. Wielkie laboratoria traktuj\u0105 swojej receptury jak tajemnice handlowe. I to tworzy wiesz, rosn\u0105c\u0105 przepa\u015b\u0107 mi\u0119dzy nimi, a ca\u0142\u0105 reszt\u0105 \u015bwiata. No tak, bo ca\u0142a spo\u0142eczno\u015b\u0107 Open Source pr\u00f3buje odtworzy\u0107 te rezultaty, ale bez dost\u0119pu do tej kluczowej wiedzy to jest no niezwykle trudne. I dok\u0142adnie w t\u0119 luk\u0119 wchodzi praca naukowa, kt\u00f3rej si\u0119 dzisiaj przyjrzymy. Nazywa si\u0119 The Fine Web Data Set i jest o Hugging Face. I to nie jest po prostu kolejne og\u0142oszenie, \u017ce hej mamy nowy wielki zbi\u00f3r dany, w to jest co\u015b o wiele cennijszego. To jest szczeg\u00f3\u0142owa, transparentna dokumentacja ca\u0142ego procesu, krok po kroku. I to jest w tym prze\u0142omowe. To jakby kto\u015b w ko\u0144cu opublikowa\u0142 t\u0119 tajn\u0105 receptur\u0119. W\u0142a\u015bnie. Bo celem nie by\u0142o tylko wiesz dostarczenie produktu ko\u0144cowego. Chodzi\u0142o o pokazanie ca\u0142ej metodologii, kt\u00f3ra za tym stoi. Daj\u0105 spo\u0142eczno\u015bci nie tylko ryb\u0119, ale i bardzo, bardzo zaawansowan\u0105 w\u0119dk\u0119. To mo\u017ce naprawd\u0119 zmieni\u0107 zasady gry. Fundamentalnie. Nasz\u0105 misj\u0105 dzisiaj jest wi\u0119c zanurzenie si\u0119 w t\u0119 powiedzmy kuchni\u0119 danych. Chcemy zrozumie\u0107 nauk\u0119 i sztuk\u0119 utworzenia danych najwy\u017cszej klasy dla modeli LLM. Zobaczymy jakie by\u0142y kluczowe decyzje, jakie zaskakuj\u0105ce odkrycia i co to wszystko oznacza dla przysz\u0142o\u015bci otwartej a.i. Ok, to roz\u0142\u00f3\u017cmy to na czynniki pierwsze, zanim wejdziemy w szczeg\u00f3\u0142y. Powiedzmy co badacze z Huggingface tak naprawd\u0119 stworzyli. Jak jest ten namacalny rezultat? Mamy tu generalnie dwa g\u0142\u00f3wne rezultaty. Pierwszy to FineWeb. To jest gigantyczny zbi\u00f3r danych, kt\u00f3ry liczy uwaga. 15 bilion\u00f3w, czyli 15 tetoken\u00f3w. 15 bilion\u00f3w, wow. Tak. Zosta\u0142 zebrany i przefiltrowany z 96 r\u00f3\u017cnych zrzut\u00f3w archiwum internetowego, kt\u00f3re znamy jako Common Crawl. Sama skala jest imponuj\u0105ca. To wystarczaj\u0105co du\u017co, \u017ceby trenowa\u0107 modele wagi super ci\u0119\u017ckiej, takie powy\u017cej 500 miliard\u00f3w parametr\u00f3w. Nie wyobra\u017calna ilo\u015b\u0107 tekstu, a ten drugi rezultat? Wspomnia\u0142e\u015b, \u017ce s\u0105 dwa? Drugi, i by\u0107 mo\u017ce nawet ciekawszy, to FineWeb.edu. To jest taki starannie wyselekcjonowany pod zbi\u00f3r FineWeb, kt\u00f3ry ma 1,3 biliona token\u00f3w i zosta\u0142 specjalnie przefiltrowany pod k\u0105tem tre\u015bci o wysokiej warto\u015bci edukacyjnej. Czyli jakby z ogromnej chaotycznej biblioteki internetu wyci\u0105gn\u0105\u0107 tylko te najlepsze ksi\u0105\u017cki i artyku\u0142y? Dok\u0142adnie tak. Tylko te, kt\u00f3re najlepiej nadaj\u0105 si\u0119 do nauki. Chwila, ale samo archiwum Common Crawl jest publicznie dost\u0119pne od lat. No tak. Wiele otwartych projekt\u00f3w z niego korzysta\u0142o. Skoro surowiec jest ten sam, to gdzie tu jest prawdziwa innowacja? Dlaczego to jest co\u015b wi\u0119cej ni\u017c, no nie wiem, kolejny zrzut danych? I to jest sedno sprawy, bo problemem nigdy nie by\u0142a ilo\u015b\u0107 danych w Common Crawl. To jest ocean tekstu. Jasne. Problem w tym, \u017ce ten ocean jest pe\u0142en \u015bmieci. M\u00f3wimy tu o szablonowych tekstach, stopkach, menu, jakim\u015b be\u0142kocie generowanym maszynowo o spami\u0119, instrukcje i ulotki reklamowe. To nie tylko nie pomaga, ale wr\u0119cz szkodzi jego zdolno\u015bciom. Czyli ca\u0142a warto\u015b\u0107 nie le\u017cy w danych, a w tym, co z nimi zrobili? W procesie? W\u0142a\u015bnie. Ca\u0142a magia, ten sekretny sk\u0142adnik, o kt\u00f3rym m\u00f3wi\u0142y\u015bmy, to w\u0142a\u015bnie ten proces. Autorzy nie tylko pokazali sw\u00f3j ko\u0144cowy produkt, oni udokumentowali ca\u0142y przepis. Krok po kroku wyja\u015bnili, jakich filtr\u00f3w u\u017cyli, jakie techniki i co najwa\u017cniejsze udowodnili empirycznie, \u017ce ich metoda jest lepsza od innych. Lepsza ni\u017c te u\u017cyte do cztery czy Refined Web. To jest fundamentalna zmiana. I tu robi si\u0119 naprawd\u0119 ciekawie. Wejd\u017amy wi\u0119c do tej kuchni danych. Badacze u\u017cyli bardzo systematycznego podej\u015bcia, kt\u00f3re nazywaj\u0105 Data Ablation. Co to takiego, jak to dzia\u0142a? To jest niezwykle rygorystyczne naukowe podej\u015bcie. Zamiast po prostu stworzy\u0107 jeden finalny zbi\u00f3r i powiedzie\u0107 o to on, ufajcie nam, jest dobry. Oni testowali ka\u017cd\u0105 decyzj\u0119 osobno. Dok\u0142adnie. Wyobra\u017a sobie, \u017ce pieczesz ciasto. Zamiast upiec jedno, pieczesz kilkana\u015bcie ma\u0142ych wersji. Jedn\u0105 z wi\u0119ksz\u0105 ilo\u015bci\u0105 cukru, drug\u0105 bez proszku, trzeci\u0105 z inn\u0105 m\u0105k\u0105. A potem profesjonalny panel degustator\u00f3w ocenia, kt\u00f3ra zmiana faktycznie poprawi\u0142a smak. Czyli to takie testy AB dla ka\u017cdego sk\u0142adnika w przepisie? Co\u015b w tym stylu, ale nawet bardziej szczeg\u00f3\u0142owe. Oni trenowali seri\u0119 ma\u0142ych modeli, 1,7 miliarda parametr\u00f3w na r\u00f3\u017cnych wariantach danych. Na przyk\u0142ad brali dane, sposowali jeden konkretny filter, trenowali na nich model. A potem drugi identyczny model na danych bez tego filtra? Tak. I na koniec por\u00f3wnywali wyniki obu modeli na standardowych benchmarkach. Mierzyli, czy dana decyzja przynios\u0142a statystycznie istotn\u0105 popraw\u0119. To zamienia intuicje w twarde dane. Genialne w swoje prostocie. Prze\u015bwda\u0107my wi\u0119c te kluczowe kroki i ich, jak si\u0119 okazuje, zaskakuj\u0105ce wyniki. Od czego zacz\u0119li? Od samej podstawy, ekstrakcji tekstu. Dane w Common Crawl s\u0105 dost\u0119pne w dw\u00f3ch formatach. Surowych plik\u00f3w WARK, z ca\u0142ym kodem HTTML i ju\u017c przetworzonych plik\u00f3w WET. I wi\u0119kszo\u015b\u0107 projekt\u00f3w si\u0119ga po te WET, bo jest po prostu \u0142atwiej, tak? No w\u0142a\u015bnie, ale badaczy odkryli, \u017ce u\u017cycie specjalistycznego narz\u0119dzia, trafilatura, do wyci\u0105gni\u0119cia tekstu prosto z surowych plik\u00f3w WET daje o wiele lepsze rezultaty. Pozwala to starannie oddzieli\u0107, wiesz, tre\u015b\u0107 artyku\u0142u od ca\u0142ej reszty menu, stopek, reklam. Ju\u017c ten jeden wydawa\u0142oby si\u0119 techniczny krok, da\u0142 wyra\u017an\u0105 popraw\u0119. OK, mamy czystszy tekst. Nast\u0119pny logiczny krok to deduplikacja. Usuwanie powt\u00f3rze\u0144. Moja intuicja podpowiada, \u017ce tu trzeba by\u0107 jak najbardziej agresywnym. Znale\u017a\u0107 i usun\u0105\u0107 ka\u017cdy duplikat w ca\u0142ym archiwom internetu. To jest dok\u0142adnie to, co podpowiada logika. I dok\u0142adnie to, co spr\u00f3bowali na pocz\u0105tku. Zastosowali strategi\u0119, kt\u00f3r\u0105 nazwali globaln\u0105 deduplikacj\u0105. Wzi\u0119li wszystkie 96 zrzut\u00f3w, potraktowali je jak jeden gigantyczny zbi\u00f3r i wywalili ka\u017cdy dokument, kt\u00f3ry mia\u0142 sw\u00f3j duplikat, gdziekolwiek indziej. I jaki by\u0142 efekt? To musia\u0142o da\u0107 ogromny skok jako\u015bci, prawda? I tu dochodzimy do najbardziej zaskakuj\u0105cego odkrycia w ca\u0142ej tej pracy. No. Wynik by\u0142 szokuj\u0105cy. Prawie \u017cadnej poprawy. \u017badnej? Prawie \u017cadnej. A kiedy zacz\u0119li bada\u0107, dlaczego, odkryli co\u015b jeszcze dziwniejszego. W przypadku starszych zrzut\u00f3w internetu z lat 2013-2014 ten proces zachowywa\u0142 dane o ni\u017cszej jako\u015bci. Jakie\u015b porzucone strony, listy s\u0142\u00f3w kluczowych spam, a odrzuca\u0142 te bardziej warto\u015bciowe. Jak to w og\u00f3le mo\u017cliwe? To brzmi wbrew wszelkiej logice. Autorzy u\u017cywaj\u0105 \u015bwietnej analogii. Wyobra\u017a sobie, \u017ce porz\u0105dkujemy ogromn\u0105 bibliotek\u0119. Ksi\u0105\u017cki z ca\u0142ego \u015bwiata i z r\u00f3\u017cnych epok i przyjmujemy zasad\u0119. Wyrzucamy ka\u017cd\u0105 ksi\u0105\u017ck\u0119, kt\u00f3ra ma sw\u00f3j duplikat, gdziekolwiek indziej. Co by nam zosta\u0142o? No, pewnie pozbyliby\u015bmy si\u0119 wszystkich klasyk\u00f3w, bo s\u0105 powielane w milionach egzemplarzy, a zostaliby\u015bmy z jakimi\u015b ma\u0142o znanymi broszurami, bo s\u0105 unikalne. Winko, dok\u0142adnie. Warto\u015bciowe tre\u015bci s\u0105 cz\u0119\u015bciej powielane w internecie, a globalna deduplikacja omy\u0142kowo traktowa\u0142a jej jak \u015bmieci. Rozumiem. Niesamowite. Jakie wi\u0119c by\u0142o rozwi\u0105zanie? Zmienili perspektyw\u0119. Zamiast traktowa\u0107 96 zrzut\u00f3w jako jeden gigantyczny zbi\u00f3r, potraktowali ka\u017cdy zrzut jako osobn\u0105 bibliotek\u0119 i wykonali deduplikacje tylko wezn\u0105\u0107 ka\u017cdego z nich. Indywidualnie. Aha. U\u017cyli do tego algorytmu minhash i okaza\u0142o si\u0119, \u017ce takie lokalne podej\u015bcie to by\u0142 strza\u0142 w dziesi\u0105tk\u0119. Ten jeden ruch pozwoli\u0142 im dogoni\u0107 wydajno\u015bci\u0105 czo\u0142owy wtedy publiczny zbi\u00f3r, Refined Web. Niesamowite. Mniej agresywna, bardziej kontekstowa deduplikacja, a co z filtrowaniem tre\u015bci? Wiem, \u017ce inspirowali si\u0119 klasycznym zbiorem C4. Tak, to by\u0142 kolejny krok. Zauwa\u017cyli, \u017ce modele trenowane na starym, ale dobrym zbiorze C4, radz\u0105 sobie \u015bwietnie na niekt\u00f3rych benchmarkach. Postanowili wi\u0119c, \u017ce tak powiem, uczy\u0107 si\u0119 od mistrz\u00f3w i przeanalizowali filtry u\u017cyte w C4. I co odkreli? \u017be jeden z nich ten, kt\u00f3ry wymaga\u0142, aby ka\u017cda linia tekstu ko\u0144czy\u0142a si\u0119 znakiem interpunkcyjnym, by\u0142 bardzo skuteczny w usuwaniu \u015bmieci, ale by\u0142 te\u017c niezwykle agresywny. Odrzuca\u0142 a\u017c 30 proc. danych. 30 proc. to jest masakra, to mn\u00f3stwo potencjalnie warto\u015bciowych informacji. Zdecydowanie za du\u017co. Zdecydowali wi\u0119c, \u017ce zastosuj\u0105 pozosta\u0142e filtry z C4, te mniej inwazyjne, ale ten jeden odpuszcz\u0105. Co wi\u0119cej, stworzyli w\u0142asne, ulepszone filtry. I to w bardzo przemy\u015blany spos\u00f3b. Jak? Wykorzystali te dwa zbiory danych, kt\u00f3re powsta\u0142y podczas tego niefortunnego eksperymentu z globaln\u0105 deduplikacj\u0105. Ten dobry i ten z\u0142y i przeanalizowali je statystycznie, szukaj\u0105c cech, kt\u00f3re je odr\u00f3\u017cniaj\u0105. Czyli zamiast zgadywa\u0107, co charakteryzuje tekst niskiej jako\u015bci, u\u017cyli danych, \u017ceby im to pokaza\u0142y. W\u0142a\u015bnie tak. Zauwa\u017cyli na przyk\u0142ad, \u017ce w z\u0142ym zbiorze jest znacznie wi\u0119cej dokument\u00f3w, kt\u00f3rych bardzo ma\u0142y odsetek linii ko\u0144czy si\u0119 kropk\u0105 czy przecinkiem. Na tej podstawie stworzyli nowy, inteligentny filtr. Us\u00f3j dokument, je\u015bli mniej ni\u017c 12% jego linii ko\u0144czy si\u0119 znakiem interpunkcyjnym. Rozumiem. To pozwoli\u0142o im osi\u0105gn\u0105\u0107 podobny efekt, ale zachowuj\u0105c znacznie wi\u0119cej danych. Dok\u0142adnie. I to podej\u015bcie, oparte na danych, pozwoli\u0142o im ostatecznie przewy\u017cszy\u0107 jako\u015b\u0107 C4. Ok. Mamy wi\u0119c FineWeb, ogromny 15-billionowy zbi\u00f3r, kt\u00f3rego stworzenie by\u0142o seri\u0105 przemy\u015blanych, przetestowanych decyzji. Ale oni posznie okrok dalej, tworz\u0105c co\u015b, co nazywaj\u0105 per\u0142\u0105 w koronie. FineWeb Edu. Jaki by\u0142 cel? To jest chyba najbardziej innowacyjna cz\u0119\u015b\u0107 tej pracy. Zainspirowali si\u0119, wiesz, sukcesem modeli jak Lama3. Wok\u00f3\u0142 kt\u00f3rych kr\u0105\u017c\u0105 spekulacje, \u017ce by\u0142y trenowane na specjalnie wyselekcjonowanych danych. Na danych syntetycznych, bardzo wysokiej jako\u015bci. W\u0142a\u015bnie. Postanowili wi\u0119c sprawdzi\u0107, czy da si\u0119 przefiltrowa\u0107 ich gigantyczny zbi\u00f3r FineWeb pod k\u0105tem warto\u015bci edukacyjnej. To brzmi niezwykle subiektywnie. Jak w og\u00f3le mo\u017cna zdefiniowa\u0107 i zmierzy\u0107 co\u015b tak abstrakcyjnego na skal\u0119 bilion\u00f3w token\u00f3w? I tu metodologia jest absolutnie fascynuj\u0105ca. Zrobili co\u015b, co mo\u017cna nazwa\u0107 u\u017cyciem jednej zaawansowanej AI do uczenia drugiej. Wzi\u0119li pot\u0119\u017cny ju\u017c istniej\u0105cy model Lama370B Instrakt. OK. I poprosili go o ocen\u0119 prawie p\u00f3\u0142 miliona losowych stron internetowych z FineWeb. Model mia\u0142 za zadanie oceni\u0107 ka\u017cd\u0105 stron\u0119 w skali od zera do pi\u0119ciu. Pod k\u0105tem warto\u015bci edukacyjnej. A jakiej konkretnie? Z naciskiem na wiedz\u0119 na poziomie szkolnego, \u017ceby unikn\u0105\u0107 faworyzowania bardzo niszowych technicznych artyku\u0142\u00f3w naukowych. Czyli de facto u\u017cyli jednego z najlepszych modeli, \u017ceby stworzy\u0142 im etykiety i nauczy\u0142 kolejny, mniejszy model. Jak rozpoznawa\u0107 warto\u015bciowe tre\u015bci? Precyzyjnie. Te prawie p\u00f3\u0142 miliona ocen od Lama3 pos\u0142u\u017cy\u0142o jako zbi\u00f3r treningowy do wytrenowania znacznie mniejszego, ale bardzo wydajnego i szybkiego klasyfikatora. I ten ma\u0142y klasyfikator przeanalizowa\u0142 ca\u0142y pi\u0119tna\u015bcie bilion\u00f3w token\u00f3w. Tak i wybra\u0142 z nich jeden trzy biliona tych najlepszych, tych z ocen\u0105 trzy lub wy\u017csz\u0105 i tak powsta\u0142 FineWeb edu. A wi\u0119c jaki by\u0142 efekt ko\u0144cowy? Czy ta ca\u0142a operacja by\u0142a warta w wysi\u0142ku? Wyniki s\u0105 spektakularne. My\u015bl\u0119, \u017ce przeros\u0142y oczekiwania samych autor\u00f3w. Modele trenowane na FineWeb edu dos\u0142ownie deklasuj\u0105 inne na benchmarkach mierz\u0105cych wiedz\u0119 i rozumowanie jak MMLu czy ARK. Daj jaki\u015b przyk\u0142ad. Prosz\u0119 bardzo. Na te\u015bcie MMLu model trenowany na FineWeb edu osi\u0105gn\u0105\u0142 wynik, na kt\u00f3ry konkurencyjny model potrzebowa\u0142 prawie dziesi\u0119\u0107 razy wi\u0119cej danych treningowych. Dziesi\u0119\u0107 razy mniej danych, \u017ceby osi\u0105gn\u0105\u0107 ten sam poziom wiedzy. To jest gigantyczna r\u00f3\u017cnica. Ogromna to twardy dow\u00f3d na to, \u017ce precyzyjne kuratorstwo danych pod k\u0105tem okre\u015blonego rodzaju jako\u015bci, w tym przypadku edukacyjnej, przynosi niewsp\u00f3\u0142miernie du\u017ce korzy\u015bci. Czyli to ju\u017c nie jest tylko kwestia usuwania \u015bmieci, ale aktywnego wybierania pere\u0142ek? Dok\u0142adnie. To sugeruje, \u017ce takie dane nie tylko ucz\u0105 model fakt\u00f3w, ale mo\u017ce ucz\u0105 go lepszych wzorc\u00f3w, rozumowania i wnioskowania. I to filtrowanie, jak si\u0119 domy\u015blam, kompletnie zmienia sk\u0142ad tematyczny zbioru? Zdecydowanie. Analiza pokaza\u0142a, \u017ce FineWeb edu faworyzuje tematy takie jak edukacja, nauka czy historia, kultura, polityka. A jednocze\u015bnie marginalizuje kategorie typu biznes, finanse czy rozrywka. Ciekawe. I co jeszcze ciekawsze? Modele trenowane na tym zbiorze lepiej radz\u0105 sobie te\u017c z tekstami akademickimi i kodem programistycznym, mimo \u017ce to nie by\u0142 cel bezpo\u015bredni. Brzmi jak ogromny krok na prz\u00f3d dla otwartej AI, ale jak zawsze s\u0105 jakie\u015b ograniczenia. Jakie s\u0105 minusy? O czym musimy pami\u0119ta\u0107? Autorzy s\u0105 bardzo transparentni w tej kwestii. Po pierwsze podkre\u015blaj\u0105, \u017ce to w cia\u0142\u017c s\u0105 tylko dane z internetu. Zbi\u00f3r mo\u017cna by wzbogaci\u0107 o ksi\u0105\u017cki, transkrypcje artyku\u0142y naukowe. I to pewnie przynios\u0142oby dalsz\u0105 popraw\u0119? Z pewno\u015bci\u0105. Po drugie, wszystkie ich eksperymenty typu Data Ablation by\u0142y prowadzone na stosunkowo ma\u0142ych modelach. 1,7 miliarda parametr\u00f3w. Z oczywistych wzgl\u0119d\u00f3w kosztowych? No tak. I zaznaczaj\u0105, \u017ce efekty z gigantycznej skali na modelach z setkami miliard\u00f3w parametr\u00f3w mog\u0105 by\u0107 inne. Chocia\u017c wszystko wskazuje na to, \u017ce te wnioski powinny si\u0119 dobrze skalowa\u0107. A to samo zawarto\u015bci\u0105. Internet nie jest neutralny. Czy przyjrzeli si\u0119, jak ten proces wp\u0142yn\u0105\u0142 na, no nie wiem, stereotypy w danych? Tak, to bardzo wa\u017cny punkt. I tak przeprowadzili tak\u0105 analiz\u0119. Otkryli, co nie jest z zaskoczeniem, \u017ce FineWeb odzwierciedla stereotypy z sieci. Nadreprezentowane s\u0105 terminy m\u0119\u017cczyzna czy chrze\u015bcijanin. OK. Ale co ciekawe, filtrowanie pod k\u0105tem warto\u015bci edukacyjnej w FineWeb edu zmienia charakter tych skojarze\u0144. Na przyk\u0142ad s\u0142owo kobieta w og\u00f3lnym zbiorze jest silnie kojarzone z randkowaniem. A w edukacyjnym? W edukacyjnym te skojarzenia przesuwaj\u0105 si\u0119 w kierunku ci\u0105\u017cy, matki i rodziny. Czyli bajas nie znika, tylko zmienia sw\u00f3j charakter na powiedzmy bardziej biologiczny czy historyczny. Dok\u0142adnie. To nie eliminuje problemu, ale pokazuje, jak proces kuracji danych kszta\u0142tuje osobowo\u015b\u0107 i \u015bwiatopogl\u0105d modelu. To bardzo wa\u017cne odkrycie samo w sobie. Podsumowuj\u0105c, mamy nowy, czo\u0142owy, otwarty zbi\u00f3r danych oraz, co chyba wa\u017cniejsze, publiczny, powtarzalny przepis na jego stworzenie. Ogromny wk\u0142ad w spo\u0142eczno\u015b\u0107 Open Source. Zdecydowanie. Ta praca przenosi akcent z podej\u015bcia wi\u0119cej danych za wszelk\u0105 cen\u0119 na m\u0105drzejsze, lepiej przygotowane dane. Pokazuje, \u017ce systematyczne, empiryczne podej\u015bcie jak Data Ablation i to jako\u015bciowe filtrowanie z pomoc\u0105 AI to kluczowe lekcje. Zanim sko\u0144czymy, nasuwa mi si\u0119 jedna taka troch\u0119 prowokuj\u0105ca my\u015bl. Jest tu pewien fascynuj\u0105cy paradoks. \u017beby stworzy\u0107 ten najlepszy w swojej klasie otwarty zbi\u00f3r danych, FineWebEdu, badacze musieli polega\u0107 na pot\u0119\u017cnym, ale zamkni\u0119tym i komercyjnym modelu Lama3. To on dostarczy\u0142 im etykiety. Czy to nie oznacza, \u017ce spo\u0142eczno\u015b\u0107 Open Source jest skazana na bycie okrok w tyle? Zale\u017cna od narz\u0119dzi z wielkich zamkni\u0119tych laboratori\u00f3w? To jest pytanie za milion dolar\u00f3w i to jest rdze\u0144 obecnej debaty, ale ta praca wskazuje te\u017c potencjaln\u0105 \u015bcie\u017ck\u0119 wyj\u015bcia z tej p\u0119tli. To znaczy? W miar\u0119 jak otwarte modele, trenowane na zbiorach takich jak FineWeb, staj\u0105 si\u0119 coraz lepsze? Czy nie dojdziemy do punktu, w kt\u00f3rym b\u0119d\u0105 w stanie same nap\u0119dza\u0107 ten proces? Czy otwarty model przysz\u0142o\u015bci, nazwijmy go FineWeb model 2.0, b\u0119dzie na tyle dobry, by tworzy\u0107 etykiety dla danych treningowych nast\u0119pnej generacji? Tworz\u0105c w ten spos\u00f3b samo nap\u0119dzaj\u0105ce si\u0119 ko\u0142o, kt\u00f3re pozwoli\u0142oby spo\u0142eczno\u015bci Open Source nie tylko goni\u0107, ale mo\u017ce nawet przegoni\u0107 systemy zamkni\u0119te? W\u0142a\u015bnie. Mo\u017cemy by\u0107 \u015bwiadkami pierwszego obrotu tego ko\u0142a zamachowego. Ta praca dostarczy\u0142a spo\u0142eczno\u015bci przepis i sk\u0142adniki. Teraz gdy otwarte modele staj\u0105 si\u0119 coraz pot\u0119\u017cniejsze, by\u0107 mo\u017ce nied\u0142ugo b\u0119d\u0105 w stanie same zacz\u0105\u0107 pisa\u0107 nowe, jeszcze lepsze przepisy. To naprawd\u0119 ekscytuj\u0105ca perspektywa.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.04, "text": " W \u015bwiecie sztucznej inteligencji, a zw\u0142aszcza przy tych gigantycznych modelach j\u0119zykowych,", "tokens": [50364, 343, 40078, 4260, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 11, 257, 11873, 1221, 19601, 41524, 6501, 15180, 8741, 394, 17466, 9399, 2316, 608, 49055, 74, 19605, 11, 50616], "temperature": 0.0, "avg_logprob": -0.16892383944603703, "compression_ratio": 1.4194756554307115, "no_speech_prob": 0.004336240701377392}, {"id": 1, "seek": 0, "start": 5.04, "end": 11.040000000000001, "text": " jak Lama 3 czy Mixtral, jest taki jeden pilnie strze\u017cony sekret.", "tokens": [50616, 4207, 441, 2404, 805, 6430, 10204, 734, 2155, 11, 3492, 20065, 12906, 6429, 2766, 1056, 1381, 1427, 2526, 17215, 1505, 13, 50916], "temperature": 0.0, "avg_logprob": -0.16892383944603703, "compression_ratio": 1.4194756554307115, "no_speech_prob": 0.004336240701377392}, {"id": 2, "seek": 0, "start": 12.040000000000001, "end": 17.52, "text": " I nie chodzi wcale o architektur\u0119 modelu, chodzi o co\u015b znacznie bardziej podstawowego.", "tokens": [50966, 286, 2838, 23998, 261, 37088, 277, 3912, 642, 2320, 374, 1274, 2316, 84, 11, 23998, 277, 19241, 15397, 14875, 2766, 27209, 43443, 26576, 13, 51240], "temperature": 0.0, "avg_logprob": -0.16892383944603703, "compression_ratio": 1.4194756554307115, "no_speech_prob": 0.004336240701377392}, {"id": 3, "seek": 0, "start": 18.12, "end": 20.6, "text": " Przepis na idealne dane treningowe.", "tokens": [51270, 2114, 46342, 271, 1667, 7157, 716, 49206, 2192, 773, 6880, 13, 51394], "temperature": 0.0, "avg_logprob": -0.16892383944603703, "compression_ratio": 1.4194756554307115, "no_speech_prob": 0.004336240701377392}, {"id": 4, "seek": 0, "start": 21.36, "end": 26.52, "text": " To jest \u015bwietne por\u00f3wnanie naprawd\u0119, bo to jest tak jakby\u015bmy widzieli jakie\u015b rewolucyjne,", "tokens": [51432, 1407, 3492, 8299, 39083, 716, 1515, 812, 895, 7155, 20970, 11, 748, 281, 3492, 991, 28976, 10513, 27486, 23099, 31163, 319, 48481, 1311, 88, 73, 716, 11, 51690], "temperature": 0.0, "avg_logprob": -0.16892383944603703, "compression_ratio": 1.4194756554307115, "no_speech_prob": 0.004336240701377392}, {"id": 5, "seek": 2652, "start": 26.56, "end": 33.4, "text": " wspania\u0142e dania, ale nikt absolutnie nie chce si\u0119 podzieli\u0107 listom sk\u0142adnik\u00f3w, ani technik\u0105.", "tokens": [50366, 17757, 5609, 19827, 3277, 654, 11, 6775, 297, 9874, 18757, 2766, 2838, 28928, 3244, 2497, 42280, 12757, 1329, 298, 1110, 10358, 47447, 11, 40477, 1537, 1035, 1611, 13, 50708], "temperature": 0.0, "avg_logprob": -0.18203581350821035, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08605862408876419}, {"id": 6, "seek": 2652, "start": 33.72, "end": 38.879999999999995, "text": " Dok\u0142adnie. Wielkie laboratoria traktuj\u0105 swojej receptury jak tajemnice handlowe.", "tokens": [50724, 29768, 10358, 2766, 13, 343, 1187, 22872, 5938, 1639, 654, 944, 2320, 13263, 29489, 73, 15263, 2598, 4207, 256, 1805, 443, 77, 573, 1011, 75, 6880, 13, 50982], "temperature": 0.0, "avg_logprob": -0.18203581350821035, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08605862408876419}, {"id": 7, "seek": 2652, "start": 39.56, "end": 43.96, "text": " I to tworzy wiesz, rosn\u0105c\u0105 przepa\u015b\u0107 mi\u0119dzy nimi, a ca\u0142\u0105 reszt\u0105 \u015bwiata.", "tokens": [51016, 286, 281, 46288, 1229, 261, 15347, 11, 18953, 13113, 32557, 30829, 64, 7753, 33964, 297, 10121, 11, 257, 1335, 15926, 725, 2682, 1611, 21485, 3274, 13, 51236], "temperature": 0.0, "avg_logprob": -0.18203581350821035, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08605862408876419}, {"id": 8, "seek": 2652, "start": 44.120000000000005, "end": 52.92, "text": " No tak, bo ca\u0142a spo\u0142eczno\u015b\u0107 Open Source pr\u00f3buje odtworzy\u0107 te rezultaty, ale bez dost\u0119pu do tej kluczowej wiedzy to jest no niezwykle trudne.", "tokens": [51244, 883, 991, 11, 748, 1335, 5024, 36851, 89, 23293, 7238, 29629, 8565, 6021, 2884, 3611, 20270, 284, 27150, 535, 48060, 723, 21398, 11, 6775, 10782, 48209, 84, 360, 12573, 9671, 1311, 89, 21091, 46894, 1229, 281, 3492, 572, 33511, 9726, 14677, 32007, 716, 13, 51684], "temperature": 0.0, "avg_logprob": -0.18203581350821035, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08605862408876419}, {"id": 9, "seek": 5292, "start": 53.2, "end": 56.84, "text": " I dok\u0142adnie w t\u0119 luk\u0119 wchodzi praca naukowa, kt\u00f3rej si\u0119 dzisiaj przyjrzymy.", "tokens": [50378, 286, 45864, 2766, 261, 32489, 287, 2034, 1274, 261, 34616, 582, 6628, 35616, 74, 5528, 11, 36023, 3244, 25772, 6501, 73, 13047, 2226, 13, 50560], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 10, "seek": 5292, "start": 57.2, "end": 60.84, "text": " Nazywa si\u0119 The Fine Web Data Set i jest o Hugging Face.", "tokens": [50578, 11870, 88, 4151, 3244, 440, 12024, 9573, 11888, 8928, 741, 3492, 277, 46892, 3249, 4047, 13, 50760], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 11, "seek": 5292, "start": 61.6, "end": 67.64, "text": " I to nie jest po prostu kolejne og\u0142oszenie, \u017ce hej mamy nowy wielki zbi\u00f3r dany, w to jest co\u015b o wiele cennijszego.", "tokens": [50798, 286, 281, 2838, 3492, 714, 19518, 23749, 716, 5360, 48584, 16778, 11, 3561, 415, 73, 17335, 586, 88, 20570, 2984, 710, 5614, 15614, 274, 1325, 11, 261, 281, 3492, 19241, 277, 33137, 269, 1857, 1718, 15453, 6308, 13, 51100], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 12, "seek": 5292, "start": 68.12, "end": 73.36, "text": " To jest szczeg\u00f3\u0142owa, transparentna dokumentacja ca\u0142ego procesu, krok po kroku.", "tokens": [51124, 1407, 3492, 22090, 1146, 16181, 5528, 11, 12737, 629, 40858, 23395, 35224, 6308, 17565, 84, 11, 350, 31621, 714, 45909, 5279, 13, 51386], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 13, "seek": 5292, "start": 73.6, "end": 75.12, "text": " I to jest w tym prze\u0142omowe.", "tokens": [51398, 286, 281, 3492, 261, 8107, 8325, 1221, 298, 6880, 13, 51474], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 14, "seek": 5292, "start": 75.6, "end": 78.96000000000001, "text": " To jakby kto\u015b w ko\u0144cu opublikowa\u0142 t\u0119 tajn\u0105 receptur\u0119.", "tokens": [51498, 1407, 28976, 32982, 261, 26470, 12032, 999, 48620, 30105, 32489, 256, 1805, 13113, 15263, 374, 1274, 13, 51666], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 15, "seek": 5292, "start": 79.28, "end": 79.96000000000001, "text": " W\u0142a\u015bnie.", "tokens": [51682, 343, 5024, 12221, 13, 51716], "temperature": 0.0, "avg_logprob": -0.19439576596629862, "compression_ratio": 1.4455445544554455, "no_speech_prob": 0.03408238664269447}, {"id": 16, "seek": 7996, "start": 80.32, "end": 83.75999999999999, "text": " Bo celem nie by\u0142o tylko wiesz dostarczenie produktu ko\u0144cowego.", "tokens": [50382, 3286, 1769, 10386, 2838, 14811, 13219, 261, 15347, 20568, 289, 39043, 42816, 84, 26470, 66, 26576, 13, 50554], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 17, "seek": 7996, "start": 84.11999999999999, "end": 87.55999999999999, "text": " Chodzi\u0142o o pokazanie ca\u0142ej metodologii, kt\u00f3ra za tym stoi.", "tokens": [50572, 761, 14543, 5249, 277, 13010, 921, 7155, 47631, 73, 1131, 378, 1132, 5597, 11, 19456, 7949, 8107, 342, 4869, 13, 50744], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 18, "seek": 7996, "start": 88.03999999999999, "end": 92.83999999999999, "text": " Daj\u0105 spo\u0142eczno\u015bci nie tylko ryb\u0119, ale i bardzo, bardzo zaawansowan\u0105 w\u0119dk\u0119.", "tokens": [50768, 413, 11133, 36851, 89, 16438, 2838, 13219, 20791, 65, 1274, 11, 6775, 741, 9034, 11, 9034, 7949, 1607, 599, 37345, 1611, 261, 6298, 15724, 13, 51008], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 19, "seek": 7996, "start": 93.24, "end": 95.36, "text": " To mo\u017ce naprawd\u0119 zmieni\u0107 zasady gry.", "tokens": [51028, 1407, 12034, 20970, 17020, 1053, 12757, 26530, 880, 41974, 13, 51134], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 20, "seek": 7996, "start": 95.72, "end": 96.6, "text": " Fundamentalnie.", "tokens": [51152, 13493, 44538, 2766, 13, 51196], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 21, "seek": 7996, "start": 96.88, "end": 102.47999999999999, "text": " Nasz\u0105 misj\u0105 dzisiaj jest wi\u0119c zanurzenie si\u0119 w t\u0119 powiedzmy kuchni\u0119 danych.", "tokens": [51210, 16151, 8925, 3346, 8555, 25772, 3492, 16677, 710, 282, 374, 16778, 3244, 261, 32489, 27617, 2226, 350, 625, 35938, 274, 34644, 13, 51490], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 22, "seek": 7996, "start": 102.8, "end": 108.88, "text": " Chcemy zrozumie\u0107 nauk\u0119 i sztuk\u0119 utworzenia danych najwy\u017cszej klasy dla modeli LLM.", "tokens": [51506, 761, 384, 2226, 710, 27857, 449, 414, 2162, 35616, 15724, 741, 262, 2682, 2034, 1274, 2839, 28321, 14320, 274, 34644, 11212, 9726, 1427, 82, 16920, 9671, 5871, 12285, 2316, 72, 441, 43, 44, 13, 51810], "temperature": 0.0, "avg_logprob": -0.11374393669334618, "compression_ratio": 1.4290429042904291, "no_speech_prob": 0.009748157113790512}, {"id": 23, "seek": 10888, "start": 109.24, "end": 117.47999999999999, "text": " Zobaczymy jakie by\u0142y kluczowe decyzje, jakie zaskakuj\u0105ce odkrycia i co to wszystko oznacza dla przysz\u0142o\u015bci otwartej a.i.", "tokens": [50382, 1176, 996, 14691, 2226, 22124, 26366, 9671, 1311, 89, 6880, 979, 37433, 2884, 11, 22124, 710, 3863, 514, 13263, 384, 3611, 43298, 2755, 741, 598, 281, 22607, 277, 22672, 326, 2394, 12285, 44018, 35059, 4337, 86, 11026, 73, 257, 13, 72, 13, 50794], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 24, "seek": 10888, "start": 117.88, "end": 122.64, "text": " Ok, to roz\u0142\u00f3\u017cmy to na czynniki pierwsze, zanim wejdziemy w szczeg\u00f3\u0142y.", "tokens": [50814, 3477, 11, 281, 9544, 1221, 812, 1427, 2226, 281, 1667, 6430, 26384, 9850, 45994, 11, 710, 17869, 321, 73, 13096, 2226, 261, 22090, 1146, 812, 6825, 13, 51052], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 25, "seek": 10888, "start": 122.92, "end": 126.12, "text": " Powiedzmy co badacze z Huggingface tak naprawd\u0119 stworzyli.", "tokens": [51066, 14762, 15338, 2226, 598, 1578, 326, 1381, 710, 46892, 3249, 2868, 991, 20970, 342, 28321, 1229, 2081, 13, 51226], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 26, "seek": 10888, "start": 126.36, "end": 128.35999999999999, "text": " Jak jest ten namacalny rezultat?", "tokens": [51238, 15029, 3492, 2064, 8835, 326, 304, 1634, 48060, 723, 267, 30, 51338], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 27, "seek": 10888, "start": 128.64, "end": 130.84, "text": " Mamy tu generalnie dwa g\u0142\u00f3wne rezultaty.", "tokens": [51352, 376, 7804, 2604, 2674, 2766, 35045, 18117, 3901, 716, 48060, 723, 21398, 13, 51462], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 28, "seek": 10888, "start": 131.12, "end": 132.51999999999998, "text": " Pierwszy to FineWeb.", "tokens": [51476, 16676, 30012, 281, 12024, 4360, 65, 13, 51546], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 29, "seek": 10888, "start": 133.0, "end": 136.72, "text": " To jest gigantyczny zbi\u00f3r danych, kt\u00f3ry liczy uwaga.", "tokens": [51570, 1407, 3492, 8741, 394, 17466, 1634, 710, 5614, 15614, 274, 34644, 11, 9913, 6169, 1229, 23147, 9286, 13, 51756], "temperature": 0.0, "avg_logprob": -0.19240356746472811, "compression_ratio": 1.4172413793103449, "no_speech_prob": 0.005112200044095516}, {"id": 30, "seek": 13672, "start": 137.12, "end": 140.08, "text": " 15 bilion\u00f3w, czyli 15 tetoken\u00f3w.", "tokens": [50384, 2119, 8588, 313, 3901, 11, 16591, 2119, 23319, 8406, 3901, 13, 50532], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 31, "seek": 13672, "start": 140.28, "end": 142.2, "text": " 15 bilion\u00f3w, wow.", "tokens": [50542, 2119, 8588, 313, 3901, 11, 6076, 13, 50638], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 32, "seek": 13672, "start": 142.28, "end": 150.56, "text": " Tak. Zosta\u0142 zebrany i przefiltrowany z 96 r\u00f3\u017cnych zrzut\u00f3w archiwum internetowego, kt\u00f3re znamy jako Common Crawl.", "tokens": [50642, 9118, 13, 1176, 8638, 1221, 5277, 1443, 1325, 741, 8325, 69, 2352, 1892, 1325, 710, 24124, 42602, 710, 19390, 325, 3901, 3912, 72, 86, 449, 4705, 26576, 11, 8864, 710, 5378, 88, 17123, 18235, 37877, 75, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 33, "seek": 13672, "start": 151.2, "end": 152.76, "text": " Sama skala jest imponuj\u0105ca.", "tokens": [51088, 318, 2404, 1110, 5159, 3492, 704, 266, 13263, 496, 13, 51166], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 34, "seek": 13672, "start": 153.16, "end": 158.84, "text": " To wystarczaj\u0105co du\u017co, \u017ceby trenowa\u0107 modele wagi super ci\u0119\u017ckiej, takie powy\u017cej 500 miliard\u00f3w parametr\u00f3w.", "tokens": [51186, 1407, 4628, 9710, 3689, 11133, 1291, 26673, 11, 11316, 23136, 11445, 4391, 306, 261, 20291, 1687, 35484, 1427, 45145, 11, 15963, 3388, 88, 38493, 5923, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51470], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 35, "seek": 13672, "start": 159.16, "end": 162.76, "text": " Nie wyobra\u017calna ilo\u015b\u0107 tekstu, a ten drugi rezultat?", "tokens": [51486, 12016, 4628, 24393, 1427, 304, 629, 1930, 78, 7753, 16624, 372, 84, 11, 257, 2064, 4110, 72, 48060, 723, 267, 30, 51666], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 36, "seek": 13672, "start": 162.92, "end": 164.32, "text": " Wspomnia\u0142e\u015b, \u017ce s\u0105 dwa?", "tokens": [51674, 343, 4952, 38131, 8908, 68, 1788, 11, 3561, 9015, 35045, 30, 51744], "temperature": 0.0, "avg_logprob": -0.2078116429995184, "compression_ratio": 1.3457627118644069, "no_speech_prob": 0.01366002019494772}, {"id": 37, "seek": 16432, "start": 164.6, "end": 169.2, "text": " Drugi, i by\u0107 mo\u017ce nawet ciekawszy, to FineWeb.edu.", "tokens": [50378, 2491, 24780, 11, 741, 15069, 12034, 22696, 46419, 1607, 7706, 11, 281, 12024, 4360, 65, 13, 22938, 13, 50608], "temperature": 0.0, "avg_logprob": -0.15599924059056525, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.0010745461331680417}, {"id": 38, "seek": 16432, "start": 169.72, "end": 182.56, "text": " To jest taki starannie wyselekcjonowany pod zbi\u00f3r FineWeb, kt\u00f3ry ma 1,3 biliona token\u00f3w i zosta\u0142 specjalnie przefiltrowany pod k\u0105tem tre\u015bci o wysokiej warto\u015bci edukacyjnej.", "tokens": [50634, 1407, 3492, 20065, 3543, 43433, 4628, 405, 29205, 45677, 23341, 2497, 710, 5614, 15614, 12024, 4360, 65, 11, 9913, 463, 502, 11, 18, 8588, 21758, 14862, 3901, 741, 23154, 1221, 46433, 2766, 8325, 69, 2352, 1892, 1325, 2497, 350, 1611, 18275, 2192, 6199, 277, 27062, 453, 7764, 31830, 6199, 1257, 2034, 31285, 11794, 13, 51276], "temperature": 0.0, "avg_logprob": -0.15599924059056525, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.0010745461331680417}, {"id": 39, "seek": 16432, "start": 182.88, "end": 190.48, "text": " Czyli jakby z ogromnej chaotycznej biblioteki internetu wyci\u0105gn\u0105\u0107 tylko te najlepsze ksi\u0105\u017cki i artyku\u0142y?", "tokens": [51292, 37099, 28976, 710, 34416, 298, 11794, 6294, 6737, 3689, 11794, 34344, 310, 14753, 4705, 84, 4628, 34381, 4568, 36374, 13219, 535, 41903, 1878, 1381, 39311, 2984, 741, 594, 874, 5279, 6825, 30, 51672], "temperature": 0.0, "avg_logprob": -0.15599924059056525, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.0010745461331680417}, {"id": 40, "seek": 16432, "start": 190.6, "end": 191.44, "text": " Dok\u0142adnie tak.", "tokens": [51678, 29768, 10358, 2766, 991, 13, 51720], "temperature": 0.0, "avg_logprob": -0.15599924059056525, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.0010745461331680417}, {"id": 41, "seek": 16432, "start": 191.84, "end": 194.2, "text": " Tylko te, kt\u00f3re najlepiej nadaj\u0105 si\u0119 do nauki.", "tokens": [51740, 49286, 4093, 535, 11, 8864, 41903, 39699, 8096, 8555, 3244, 360, 35616, 2984, 13, 51858], "temperature": 0.0, "avg_logprob": -0.15599924059056525, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.0010745461331680417}, {"id": 42, "seek": 19432, "start": 194.44, "end": 199.35999999999999, "text": " Chwila, ale samo archiwum Common Crawl jest publicznie dost\u0119pne od lat.", "tokens": [50370, 761, 86, 7371, 11, 6775, 36422, 3912, 72, 86, 449, 18235, 37877, 75, 3492, 1908, 89, 2766, 48209, 716, 3611, 4465, 13, 50616], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 43, "seek": 19432, "start": 199.48, "end": 199.95999999999998, "text": " No tak.", "tokens": [50622, 883, 991, 13, 50646], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 44, "seek": 19432, "start": 200.2, "end": 202.84, "text": " Wiele otwartych projekt\u00f3w z niego korzysta\u0142o.", "tokens": [50658, 9233, 306, 4337, 29587, 16384, 26261, 3901, 710, 49615, 14784, 49590, 5249, 13, 50790], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 45, "seek": 19432, "start": 203.48, "end": 208.28, "text": " Skoro surowiec jest ten sam, to gdzie tu jest prawdziwa innowacja?", "tokens": [50822, 7324, 10780, 1022, 13998, 66, 3492, 2064, 3247, 11, 281, 18922, 2604, 3492, 41175, 3992, 4151, 294, 3785, 23395, 30, 51062], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 46, "seek": 19432, "start": 208.72, "end": 213.32, "text": " Dlaczego to jest co\u015b wi\u0119cej ni\u017c, no nie wiem, kolejny zrzut danych?", "tokens": [51084, 413, 75, 39329, 281, 3492, 19241, 26004, 28502, 11, 572, 2838, 26522, 11, 23749, 1634, 710, 19390, 325, 274, 34644, 30, 51314], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 47, "seek": 19432, "start": 213.4, "end": 218.56, "text": " I to jest sedno sprawy, bo problemem nigdy nie by\u0142a ilo\u015b\u0107 danych w Common Crawl.", "tokens": [51318, 286, 281, 3492, 9643, 1771, 22734, 88, 11, 748, 1154, 443, 26996, 3173, 2838, 23936, 1930, 78, 7753, 274, 34644, 261, 18235, 37877, 75, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 48, "seek": 19432, "start": 218.92, "end": 220.12, "text": " To jest ocean tekstu.", "tokens": [51594, 1407, 3492, 7810, 16624, 372, 84, 13, 51654], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 49, "seek": 19432, "start": 220.44, "end": 220.92, "text": " Jasne.", "tokens": [51670, 34023, 716, 13, 51694], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 50, "seek": 19432, "start": 221.07999999999998, "end": 223.51999999999998, "text": " Problem w tym, \u017ce ten ocean jest pe\u0142en \u015bmieci.", "tokens": [51702, 11676, 261, 8107, 11, 3561, 2064, 7810, 3492, 43205, 268, 8299, 25210, 537, 13, 51824], "temperature": 0.0, "avg_logprob": -0.14791095578992688, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.0037418261636048555}, {"id": 51, "seek": 22352, "start": 224.0, "end": 232.24, "text": " M\u00f3wimy tu o szablonowych tekstach, stopkach, menu, jakim\u015b be\u0142kocie generowanym maszynowo o spami\u0119, instrukcje i ulotki reklamowe.", "tokens": [50388, 376, 3901, 13189, 2604, 277, 7870, 455, 14864, 19605, 16624, 372, 608, 11, 1590, 41326, 11, 6510, 11, 49410, 1788, 312, 1221, 74, 905, 414, 1337, 23341, 76, 2300, 1229, 3785, 78, 277, 637, 23806, 11, 1058, 25126, 44261, 741, 20352, 310, 2984, 33881, 4326, 6880, 13, 50800], "temperature": 0.0, "avg_logprob": -0.1374955248476854, "compression_ratio": 1.4097744360902256, "no_speech_prob": 0.01111493818461895}, {"id": 52, "seek": 22352, "start": 232.8, "end": 236.16000000000003, "text": " To nie tylko nie pomaga, ale wr\u0119cz szkodzi jego zdolno\u015bciom.", "tokens": [50828, 1407, 2838, 13219, 2838, 12991, 9286, 11, 6775, 928, 1274, 3689, 7870, 74, 14543, 26542, 16221, 401, 16438, 298, 13, 50996], "temperature": 0.0, "avg_logprob": -0.1374955248476854, "compression_ratio": 1.4097744360902256, "no_speech_prob": 0.01111493818461895}, {"id": 53, "seek": 22352, "start": 236.52, "end": 241.08, "text": " Czyli ca\u0142a warto\u015b\u0107 nie le\u017cy w danych, a w tym, co z nimi zrobili?", "tokens": [51014, 37099, 1335, 5024, 31830, 7753, 2838, 476, 7735, 261, 274, 34644, 11, 257, 261, 8107, 11, 598, 710, 297, 10121, 44399, 2312, 30, 51242], "temperature": 0.0, "avg_logprob": -0.1374955248476854, "compression_ratio": 1.4097744360902256, "no_speech_prob": 0.01111493818461895}, {"id": 54, "seek": 22352, "start": 241.24, "end": 241.96, "text": " W procesie?", "tokens": [51250, 343, 17565, 414, 30, 51286], "temperature": 0.0, "avg_logprob": -0.1374955248476854, "compression_ratio": 1.4097744360902256, "no_speech_prob": 0.01111493818461895}, {"id": 55, "seek": 22352, "start": 242.20000000000002, "end": 247.96, "text": " W\u0142a\u015bnie. Ca\u0142a magia, ten sekretny sk\u0142adnik, o kt\u00f3rym m\u00f3wi\u0142y\u015bmy, to w\u0142a\u015bnie ten proces.", "tokens": [51298, 343, 5024, 12221, 13, 7544, 5024, 2258, 654, 11, 2064, 17215, 1505, 1634, 1110, 10358, 13123, 11, 277, 30120, 24592, 6825, 10513, 11, 281, 14234, 2064, 17565, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1374955248476854, "compression_ratio": 1.4097744360902256, "no_speech_prob": 0.01111493818461895}, {"id": 56, "seek": 24796, "start": 248.44, "end": 253.64000000000001, "text": " Autorzy nie tylko pokazali sw\u00f3j ko\u0144cowy produkt, oni udokumentowali ca\u0142y przepis.", "tokens": [50388, 6049, 284, 1229, 2838, 13219, 13010, 921, 5103, 1693, 18999, 26470, 66, 10089, 42816, 11, 36317, 11727, 453, 2206, 305, 5103, 35226, 30829, 271, 13, 50648], "temperature": 0.0, "avg_logprob": -0.15081475675106049, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.07407598942518234}, {"id": 57, "seek": 24796, "start": 254.16, "end": 263.44, "text": " Krok po kroku wyja\u015bnili, jakich filtr\u00f3w u\u017cyli, jakie techniki i co najwa\u017cniejsze udowodnili empirycznie, \u017ce ich metoda jest lepsza od innych.", "tokens": [50674, 591, 31621, 714, 45909, 5279, 4628, 2938, 1788, 77, 2312, 11, 4207, 480, 1387, 6903, 3901, 34097, 2081, 11, 22124, 1537, 9850, 741, 598, 11212, 27111, 44258, 11727, 305, 378, 77, 2312, 4012, 12781, 19923, 11, 3561, 1893, 1131, 13449, 3492, 476, 1878, 2394, 3611, 36286, 13, 51138], "temperature": 0.0, "avg_logprob": -0.15081475675106049, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.07407598942518234}, {"id": 58, "seek": 24796, "start": 264.0, "end": 266.52, "text": " Lepsza ni\u017c te u\u017cyte do cztery czy Refined Web.", "tokens": [51166, 441, 10653, 2394, 28502, 535, 34097, 975, 360, 6472, 12733, 6430, 16957, 2001, 9573, 13, 51292], "temperature": 0.0, "avg_logprob": -0.15081475675106049, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.07407598942518234}, {"id": 59, "seek": 24796, "start": 267.16, "end": 268.92, "text": " To jest fundamentalna zmiana.", "tokens": [51324, 1407, 3492, 8088, 629, 17020, 8497, 13, 51412], "temperature": 0.0, "avg_logprob": -0.15081475675106049, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.07407598942518234}, {"id": 60, "seek": 24796, "start": 269.12, "end": 273.44, "text": " I tu robi si\u0119 naprawd\u0119 ciekawie. Wejd\u017amy wi\u0119c do tej kuchni danych.", "tokens": [51422, 286, 2604, 47380, 3244, 20970, 46419, 1607, 414, 13, 492, 37109, 10659, 2226, 16677, 360, 12573, 350, 625, 3722, 274, 34644, 13, 51638], "temperature": 0.0, "avg_logprob": -0.15081475675106049, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.07407598942518234}, {"id": 61, "seek": 27344, "start": 273.84, "end": 279.12, "text": " Badacze u\u017cyli bardzo systematycznego podej\u015bcia, kt\u00f3re nazywaj\u0105 Data Ablation.", "tokens": [50384, 11523, 326, 1381, 34097, 2081, 9034, 1185, 267, 17466, 11858, 7468, 73, 1788, 2755, 11, 8864, 20151, 27112, 11133, 11888, 2847, 24278, 13, 50648], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 62, "seek": 27344, "start": 279.6, "end": 281.08, "text": " Co to takiego, jak to dzia\u0142a?", "tokens": [50672, 3066, 281, 32296, 11, 4207, 281, 37903, 30, 50746], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 63, "seek": 27344, "start": 281.36, "end": 285.04, "text": " To jest niezwykle rygorystyczne naukowe podej\u015bcie.", "tokens": [50760, 1407, 3492, 33511, 9726, 14677, 367, 18103, 827, 372, 17466, 716, 35616, 74, 6880, 7468, 73, 9815, 13, 50944], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 64, "seek": 27344, "start": 285.4, "end": 291.76, "text": " Zamiast po prostu stworzy\u0107 jeden finalny zbi\u00f3r i powiedzie\u0107 o to on, ufajcie nam, jest dobry.", "tokens": [50962, 1176, 4526, 525, 714, 19518, 342, 28321, 27150, 12906, 2572, 1634, 710, 5614, 15614, 741, 27886, 277, 281, 322, 11, 344, 69, 47276, 8835, 11, 3492, 35884, 13, 51280], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 65, "seek": 27344, "start": 291.96, "end": 294.96, "text": " Oni testowali ka\u017cd\u0105 decyzj\u0119 osobno.", "tokens": [51290, 1282, 72, 1500, 305, 5103, 21912, 67, 1611, 979, 37433, 11115, 41518, 1771, 13, 51440], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 66, "seek": 27344, "start": 295.15999999999997, "end": 298.2, "text": " Dok\u0142adnie. Wyobra\u017a sobie, \u017ce pieczesz ciasto.", "tokens": [51450, 29768, 10358, 2766, 13, 14458, 24393, 10659, 13652, 11, 3561, 1730, 3689, 10430, 6983, 33869, 13, 51602], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 67, "seek": 27344, "start": 298.48, "end": 302.2, "text": " Zamiast upiec jedno, pieczesz kilkana\u015bcie ma\u0142ych wersji.", "tokens": [51616, 1176, 4526, 525, 493, 35733, 5232, 1771, 11, 1730, 3689, 10430, 5128, 74, 2095, 9815, 463, 47655, 261, 433, 4013, 13, 51802], "temperature": 0.0, "avg_logprob": -0.12634789943695068, "compression_ratio": 1.4265734265734267, "no_speech_prob": 0.05222149193286896}, {"id": 68, "seek": 30220, "start": 302.76, "end": 307.52, "text": " Jedn\u0105 z wi\u0119ksz\u0105 ilo\u015bci\u0105 cukru, drug\u0105 bez proszku, trzeci\u0105 z inn\u0105 m\u0105k\u0105.", "tokens": [50392, 27076, 13113, 710, 29968, 8925, 1930, 44468, 1611, 37485, 894, 11, 4110, 1611, 10782, 6267, 89, 5279, 11, 22266, 34381, 710, 7714, 1611, 275, 1611, 26304, 13, 50630], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 69, "seek": 30220, "start": 308.0, "end": 313.28, "text": " A potem profesjonalny panel degustator\u00f3w ocenia, kt\u00f3ra zmiana faktycznie poprawi\u0142a smak.", "tokens": [50654, 316, 36513, 22912, 15735, 304, 1634, 4831, 2821, 381, 1639, 3901, 10409, 268, 654, 11, 19456, 17020, 8497, 33647, 45586, 1665, 5131, 72, 5024, 899, 514, 13, 50918], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 70, "seek": 30220, "start": 313.47999999999996, "end": 316.56, "text": " Czyli to takie testy AB dla ka\u017cdego sk\u0142adnika w przepisie?", "tokens": [50928, 37099, 281, 15963, 1500, 88, 13838, 12285, 21912, 67, 6308, 1110, 10358, 77, 5439, 261, 30829, 271, 414, 30, 51082], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 71, "seek": 30220, "start": 316.92, "end": 319.48, "text": " Co\u015b w tym stylu, ale nawet bardziej szczeg\u00f3\u0142owe.", "tokens": [51100, 3066, 1788, 261, 8107, 7952, 2781, 11, 6775, 22696, 27209, 22090, 1146, 16181, 6880, 13, 51228], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 72, "seek": 30220, "start": 320.03999999999996, "end": 325.91999999999996, "text": " Oni trenowali seri\u0119 ma\u0142ych modeli, 1,7 miliarda parametr\u00f3w na r\u00f3\u017cnych wariantach danych.", "tokens": [51256, 1282, 72, 23136, 305, 5103, 816, 5034, 463, 47655, 2316, 72, 11, 502, 11, 22, 1962, 72, 19218, 6220, 27965, 3901, 1667, 42602, 1516, 5798, 608, 274, 34644, 13, 51550], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 73, "seek": 30220, "start": 326.12, "end": 330.68, "text": " Na przyk\u0142ad brali dane, sposowali jeden konkretny filter, trenowali na nich model.", "tokens": [51560, 6056, 23144, 738, 5103, 49206, 11, 20443, 305, 5103, 12906, 36500, 1634, 1387, 391, 11, 23136, 305, 5103, 1667, 25570, 2316, 13, 51788], "temperature": 0.0, "avg_logprob": -0.12174693587558721, "compression_ratio": 1.45141065830721, "no_speech_prob": 0.002457018243148923}, {"id": 74, "seek": 33068, "start": 331.0, "end": 334.68, "text": " A potem drugi identyczny model na danych bez tego filtra?", "tokens": [50380, 316, 36513, 4110, 72, 2473, 17466, 1634, 2316, 1667, 274, 34644, 10782, 8627, 1387, 17227, 30, 50564], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 75, "seek": 33068, "start": 334.96, "end": 340.24, "text": " Tak. I na koniec por\u00f3wnywali wyniki obu modeli na standardowych benchmarkach.", "tokens": [50578, 9118, 13, 286, 1667, 5897, 35733, 1515, 812, 895, 27112, 5103, 31936, 9850, 1111, 84, 2316, 72, 1667, 3832, 19605, 18927, 608, 13, 50842], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 76, "seek": 33068, "start": 340.64, "end": 344.56, "text": " Mierzyli, czy dana decyzja przynios\u0142a statystycznie istotn\u0105 popraw\u0119.", "tokens": [50862, 376, 811, 1229, 2081, 11, 6430, 274, 2095, 979, 37433, 2938, 6501, 77, 2717, 5024, 2219, 38593, 17466, 2766, 1418, 310, 13113, 1665, 5131, 1274, 13, 51058], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 77, "seek": 33068, "start": 344.96000000000004, "end": 347.08, "text": " To zamienia intuicje w twarde dane.", "tokens": [51078, 1407, 19876, 18811, 560, 84, 299, 2884, 261, 683, 10866, 49206, 13, 51184], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 78, "seek": 33068, "start": 347.56, "end": 349.4, "text": " Genialne w swoje prostocie.", "tokens": [51208, 3632, 831, 716, 261, 29489, 10293, 905, 414, 13, 51300], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 79, "seek": 33068, "start": 350.16, "end": 356.68, "text": " Prze\u015bwda\u0107my wi\u0119c te kluczowe kroki i ich, jak si\u0119 okazuje, zaskakuj\u0105ce wyniki.", "tokens": [51338, 2114, 1381, 1788, 86, 2675, 2162, 2226, 16677, 535, 9671, 1311, 89, 6880, 45909, 2984, 741, 1893, 11, 4207, 3244, 3133, 43317, 11, 710, 3863, 514, 13263, 384, 31936, 9850, 13, 51664], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 80, "seek": 33068, "start": 357.44, "end": 358.52, "text": " Od czego zacz\u0119li?", "tokens": [51702, 12210, 36559, 34430, 11052, 2081, 30, 51756], "temperature": 0.0, "avg_logprob": -0.15722288502206047, "compression_ratio": 1.3786764705882353, "no_speech_prob": 0.00786679144948721}, {"id": 81, "seek": 35852, "start": 358.79999999999995, "end": 361.59999999999997, "text": " Od samej podstawy, ekstrakcji tekstu.", "tokens": [50378, 12210, 912, 73, 43443, 88, 11, 13359, 372, 11272, 19649, 16624, 372, 84, 13, 50518], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 82, "seek": 35852, "start": 362.15999999999997, "end": 364.88, "text": " Dane w Common Crawl s\u0105 dost\u0119pne w dw\u00f3ch formatach.", "tokens": [50546, 413, 1929, 261, 18235, 37877, 75, 9015, 48209, 716, 261, 27379, 812, 339, 7877, 608, 13, 50682], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 83, "seek": 35852, "start": 365.15999999999997, "end": 370.24, "text": " Surowych plik\u00f3w WARK, z ca\u0142ym kodem HTTML i ju\u017c przetworzonych plik\u00f3w WET.", "tokens": [50696, 6732, 19605, 499, 1035, 3901, 343, 36402, 11, 710, 35224, 4199, 350, 378, 443, 11751, 51, 12683, 741, 10678, 6541, 302, 28321, 44479, 339, 499, 1035, 3901, 343, 4850, 13, 50950], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 84, "seek": 35852, "start": 370.56, "end": 374.08, "text": " I wi\u0119kszo\u015b\u0107 projekt\u00f3w si\u0119ga po te WET, bo jest po prostu \u0142atwiej, tak?", "tokens": [50966, 286, 29968, 4765, 7753, 26261, 3901, 3244, 3680, 714, 535, 343, 4850, 11, 748, 3492, 714, 19518, 47759, 86, 7764, 11, 991, 30, 51142], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 85, "seek": 35852, "start": 374.24, "end": 379.59999999999997, "text": " No w\u0142a\u015bnie, ale badaczy odkryli, \u017ce u\u017cycie specjalistycznego narz\u0119dzia, trafilatura,", "tokens": [51150, 883, 14234, 11, 6775, 1578, 14691, 3611, 43298, 2081, 11, 3561, 34097, 4260, 46433, 468, 17466, 11858, 6714, 89, 6298, 40395, 11, 944, 19776, 19660, 11, 51418], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 86, "seek": 35852, "start": 379.96, "end": 385.0, "text": " do wyci\u0105gni\u0119cia tekstu prosto z surowych plik\u00f3w WET daje o wiele lepsze rezultaty.", "tokens": [51436, 360, 4628, 34381, 70, 35938, 2755, 16624, 372, 84, 10293, 78, 710, 1022, 19605, 499, 1035, 3901, 343, 4850, 1120, 2884, 277, 33137, 476, 1878, 1381, 48060, 723, 21398, 13, 51688], "temperature": 0.0, "avg_logprob": -0.16828635471319062, "compression_ratio": 1.3914473684210527, "no_speech_prob": 0.00887133926153183}, {"id": 87, "seek": 38500, "start": 385.76, "end": 391.32, "text": " Pozwala to starannie oddzieli\u0107, wiesz, tre\u015b\u0107 artyku\u0142u od ca\u0142ej reszty menu, stopek, reklam.", "tokens": [50402, 6165, 14406, 5159, 281, 3543, 43433, 7401, 42280, 12757, 11, 261, 15347, 11, 2192, 7753, 594, 874, 5279, 24066, 3611, 47631, 73, 725, 89, 874, 6510, 11, 1590, 916, 11, 33881, 4326, 13, 50680], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 88, "seek": 38500, "start": 391.64, "end": 395.76, "text": " Ju\u017c ten jeden wydawa\u0142oby si\u0119 techniczny krok, da\u0142 wyra\u017an\u0105 popraw\u0119.", "tokens": [50696, 13582, 1427, 2064, 12906, 25984, 10449, 1221, 13944, 3244, 1537, 17946, 1634, 350, 31621, 11, 1120, 1221, 4628, 424, 10659, 13113, 1665, 5131, 1274, 13, 50902], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 89, "seek": 38500, "start": 396.24, "end": 398.16, "text": " OK, mamy czystszy tekst.", "tokens": [50926, 2264, 11, 17335, 6430, 372, 7706, 16624, 372, 13, 51022], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 90, "seek": 38500, "start": 398.4, "end": 401.36, "text": " Nast\u0119pny logiczny krok to deduplikacja.", "tokens": [51034, 42185, 18085, 1634, 9952, 89, 1634, 350, 31621, 281, 4172, 44810, 1035, 23395, 13, 51182], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 91, "seek": 38500, "start": 401.84, "end": 402.88, "text": " Usuwanie powt\u00f3rze\u0144.", "tokens": [51206, 4958, 36824, 7155, 3388, 4547, 13503, 5248, 13, 51258], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 92, "seek": 38500, "start": 403.56, "end": 407.56, "text": " Moja intuicja podpowiada, \u017ce tu trzeba by\u0107 jak najbardziej agresywnym.", "tokens": [51292, 3335, 2938, 560, 84, 299, 2938, 2497, 14701, 39018, 11, 3561, 2604, 25860, 15069, 4207, 41857, 623, 495, 88, 895, 4199, 13, 51492], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 93, "seek": 38500, "start": 407.84, "end": 411.64, "text": " Znale\u017a\u0107 i usun\u0105\u0107 ka\u017cdy duplikat w ca\u0142ym archiwom internetu.", "tokens": [51506, 1176, 77, 1220, 10659, 2162, 741, 505, 409, 36374, 31615, 1581, 564, 36300, 261, 35224, 4199, 3912, 72, 86, 298, 4705, 84, 13, 51696], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 94, "seek": 38500, "start": 411.8, "end": 414.12, "text": " To jest dok\u0142adnie to, co podpowiada logika.", "tokens": [51704, 1407, 3492, 45864, 2766, 281, 11, 598, 2497, 14701, 39018, 3565, 5439, 13, 51820], "temperature": 0.0, "avg_logprob": -0.13954894135637982, "compression_ratio": 1.4121405750798721, "no_speech_prob": 0.0031399440485984087}, {"id": 95, "seek": 41500, "start": 415.24, "end": 418.04, "text": " I dok\u0142adnie to, co spr\u00f3bowali na pocz\u0105tku.", "tokens": [50376, 286, 45864, 2766, 281, 11, 598, 6103, 812, 8202, 5103, 1667, 43959, 13, 50516], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 96, "seek": 41500, "start": 418.56, "end": 422.68, "text": " Zastosowali strategi\u0119, kt\u00f3r\u0105 nazwali globaln\u0105 deduplikacj\u0105.", "tokens": [50542, 1176, 525, 329, 305, 5103, 5464, 5034, 11, 37415, 20151, 40054, 4338, 13113, 4172, 44810, 1035, 326, 8555, 13, 50748], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 97, "seek": 41500, "start": 423.2, "end": 427.96, "text": " Wzi\u0119li wszystkie 96 zrzut\u00f3w, potraktowali je jak jeden gigantyczny zbi\u00f3r", "tokens": [50774, 343, 16706, 2081, 31723, 24124, 710, 19390, 325, 3901, 11, 1847, 32249, 305, 5103, 1506, 4207, 12906, 8741, 394, 17466, 1634, 710, 5614, 15614, 51012], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 98, "seek": 41500, "start": 428.36, "end": 432.16, "text": " i wywalili ka\u017cdy dokument, kt\u00f3ry mia\u0142 sw\u00f3j duplikat, gdziekolwiek indziej.", "tokens": [51032, 741, 4628, 29530, 2312, 31615, 40858, 11, 9913, 27989, 1693, 18999, 1581, 564, 36300, 11, 18922, 36620, 44674, 1016, 19554, 13, 51222], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 99, "seek": 41500, "start": 432.32, "end": 433.48, "text": " I jaki by\u0142 efekt?", "tokens": [51230, 286, 24492, 16673, 31482, 8192, 30, 51288], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 100, "seek": 41500, "start": 433.84, "end": 436.48, "text": " To musia\u0142o da\u0107 ogromny skok jako\u015bci, prawda?", "tokens": [51306, 1407, 1038, 654, 5249, 1120, 2162, 34416, 298, 1634, 1110, 453, 17123, 6199, 11, 43607, 30, 51438], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 101, "seek": 41500, "start": 436.6, "end": 440.72, "text": " I tu dochodzimy do najbardziej zaskakuj\u0105cego odkrycia w ca\u0142ej tej pracy.", "tokens": [51444, 286, 2604, 9243, 378, 89, 13189, 360, 41857, 710, 3863, 514, 13263, 384, 1571, 3611, 43298, 2755, 261, 47631, 73, 12573, 35591, 13, 51650], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 102, "seek": 41500, "start": 440.96, "end": 441.48, "text": " No.", "tokens": [51662, 883, 13, 51688], "temperature": 0.0, "avg_logprob": -0.15848225606998928, "compression_ratio": 1.4027303754266212, "no_speech_prob": 0.0016165978740900755}, {"id": 103, "seek": 44148, "start": 442.48, "end": 444.84000000000003, "text": " Wynik by\u0142 szokuj\u0105cy.", "tokens": [50414, 343, 2534, 1035, 16673, 7870, 453, 13263, 1344, 13, 50532], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 104, "seek": 44148, "start": 445.24, "end": 447.24, "text": " Prawie \u017cadnej poprawy.", "tokens": [50552, 430, 5131, 414, 39628, 11794, 1665, 5131, 88, 13, 50652], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 105, "seek": 44148, "start": 447.40000000000003, "end": 448.16, "text": " \u017badnej?", "tokens": [50660, 29804, 345, 11794, 30, 50698], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 106, "seek": 44148, "start": 448.32, "end": 449.12, "text": " Prawie \u017cadnej.", "tokens": [50706, 430, 5131, 414, 39628, 11794, 13, 50746], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 107, "seek": 44148, "start": 449.76, "end": 453.44, "text": " A kiedy zacz\u0119li bada\u0107, dlaczego, odkryli co\u015b jeszcze dziwniejszego.", "tokens": [50778, 316, 18777, 34430, 11052, 2081, 272, 1538, 2162, 11, 37873, 39329, 11, 3611, 43298, 2081, 19241, 14168, 31981, 895, 7764, 15453, 6308, 13, 50962], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 108, "seek": 44148, "start": 454.04, "end": 459.20000000000005, "text": " W przypadku starszych zrzut\u00f3w internetu z lat 2013-2014", "tokens": [50992, 343, 41955, 6105, 28051, 710, 19390, 325, 3901, 4705, 84, 710, 4465, 9012, 12, 2009, 7271, 51250], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 109, "seek": 44148, "start": 459.6, "end": 462.64000000000004, "text": " ten proces zachowywa\u0142 dane o ni\u017cszej jako\u015bci.", "tokens": [51270, 2064, 17565, 29303, 10089, 44603, 49206, 277, 28502, 82, 16920, 17123, 6199, 13, 51422], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 110, "seek": 44148, "start": 462.84000000000003, "end": 466.72, "text": " Jakie\u015b porzucone strony, listy s\u0142\u00f3w kluczowych spam,", "tokens": [51432, 15029, 414, 1788, 1515, 89, 1311, 546, 32406, 11, 1329, 88, 15116, 3901, 9671, 1311, 89, 19605, 24028, 11, 51626], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 111, "seek": 44148, "start": 467.08000000000004, "end": 469.08000000000004, "text": " a odrzuca\u0142 te bardziej warto\u015bciowe.", "tokens": [51644, 257, 3611, 81, 11728, 496, 1221, 535, 27209, 31830, 6199, 6880, 13, 51744], "temperature": 0.0, "avg_logprob": -0.25500796951410426, "compression_ratio": 1.368, "no_speech_prob": 0.005509513430297375}, {"id": 112, "seek": 46908, "start": 470.08, "end": 471.35999999999996, "text": " Jak to w og\u00f3le mo\u017cliwe?", "tokens": [50414, 15029, 281, 261, 29229, 30854, 826, 30, 50478], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 113, "seek": 46908, "start": 471.71999999999997, "end": 473.47999999999996, "text": " To brzmi wbrew wszelkiej logice.", "tokens": [50496, 1407, 738, 89, 3057, 261, 65, 2236, 37647, 12971, 45145, 3565, 573, 13, 50584], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 114, "seek": 46908, "start": 473.56, "end": 475.52, "text": " Autorzy u\u017cywaj\u0105 \u015bwietnej analogii.", "tokens": [50588, 6049, 284, 1229, 34097, 86, 11133, 8299, 39083, 11794, 16660, 5597, 13, 50686], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 115, "seek": 46908, "start": 475.91999999999996, "end": 478.96, "text": " Wyobra\u017a sobie, \u017ce porz\u0105dkujemy ogromn\u0105 bibliotek\u0119.", "tokens": [50706, 14458, 24393, 10659, 13652, 11, 3561, 1515, 23876, 74, 21767, 34416, 298, 13113, 34344, 310, 916, 1274, 13, 50858], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 116, "seek": 46908, "start": 479.15999999999997, "end": 482.8, "text": " Ksi\u0105\u017cki z ca\u0142ego \u015bwiata i z r\u00f3\u017cnych epok i przyjmujemy zasad\u0119.", "tokens": [50868, 591, 7691, 27242, 2984, 710, 35224, 6308, 21485, 3274, 741, 710, 42602, 2388, 453, 741, 6501, 35195, 21767, 44585, 1274, 13, 51050], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 117, "seek": 46908, "start": 483.28, "end": 487.15999999999997, "text": " Wyrzucamy ka\u017cd\u0105 ksi\u0105\u017ck\u0119, kt\u00f3ra ma sw\u00f3j duplikat, gdziekolwiek indziej.", "tokens": [51074, 343, 6016, 89, 1311, 7804, 21912, 67, 1611, 39311, 15724, 11, 19456, 463, 1693, 18999, 1581, 564, 36300, 11, 18922, 36620, 44674, 1016, 19554, 13, 51268], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 118, "seek": 46908, "start": 488.47999999999996, "end": 489.32, "text": " Co by nam zosta\u0142o?", "tokens": [51334, 3066, 538, 8835, 23154, 5249, 30, 51376], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 119, "seek": 46908, "start": 489.44, "end": 495.32, "text": " No, pewnie pozbyliby\u015bmy si\u0119 wszystkich klasyk\u00f3w, bo s\u0105 powielane w milionach egzemplarzy,", "tokens": [51382, 883, 11, 520, 14215, 21281, 2322, 38270, 88, 10513, 3244, 34234, 9671, 5871, 23849, 11, 748, 9015, 3388, 1187, 1929, 261, 1962, 313, 608, 24263, 89, 5895, 289, 1229, 11, 51676], "temperature": 0.0, "avg_logprob": -0.15235303243001302, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.007141202222555876}, {"id": 120, "seek": 49532, "start": 495.76, "end": 500.24, "text": " a zostaliby\u015bmy z jakimi\u015b ma\u0142o znanymi broszurami, bo s\u0105 unikalne.", "tokens": [50386, 257, 31873, 304, 897, 88, 10513, 710, 4207, 10121, 1788, 463, 5249, 15397, 1325, 3057, 738, 329, 50210, 4526, 11, 748, 9015, 517, 41216, 716, 13, 50610], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 121, "seek": 49532, "start": 500.36, "end": 501.48, "text": " Winko, dok\u0142adnie.", "tokens": [50616, 343, 475, 78, 11, 45864, 2766, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 122, "seek": 49532, "start": 501.8, "end": 504.32, "text": " Warto\u015bciowe tre\u015bci s\u0105 cz\u0119\u015bciej powielane w internecie,", "tokens": [50688, 343, 15864, 6199, 6880, 2192, 6199, 9015, 18544, 9815, 73, 3388, 1187, 1929, 261, 728, 716, 4260, 11, 50814], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 123, "seek": 49532, "start": 504.4, "end": 507.88, "text": " a globalna deduplikacja omy\u0142kowo traktowa\u0142a jej jak \u015bmieci.", "tokens": [50818, 257, 4338, 629, 4172, 44810, 1035, 23395, 277, 2226, 1221, 74, 19941, 944, 2320, 5528, 5024, 28924, 4207, 8299, 25210, 537, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 124, "seek": 49532, "start": 508.04, "end": 508.68, "text": " Rozumiem.", "tokens": [51000, 43313, 449, 4907, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 125, "seek": 49532, "start": 509.68, "end": 510.52, "text": " Niesamowite.", "tokens": [51082, 426, 530, 335, 305, 642, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 126, "seek": 49532, "start": 510.92, "end": 512.8, "text": " Jakie wi\u0119c by\u0142o rozwi\u0105zanie?", "tokens": [51144, 15029, 414, 16677, 14811, 9544, 22620, 7155, 30, 51238], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 127, "seek": 49532, "start": 513.0, "end": 514.56, "text": " Zmienili perspektyw\u0119.", "tokens": [51248, 1176, 76, 1053, 2312, 868, 32659, 874, 86, 1274, 13, 51326], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 128, "seek": 49532, "start": 514.76, "end": 520.04, "text": " Zamiast traktowa\u0107 96 zrzut\u00f3w jako jeden gigantyczny zbi\u00f3r,", "tokens": [51336, 1176, 4526, 525, 944, 2320, 11445, 24124, 710, 19390, 325, 3901, 17123, 12906, 8741, 394, 17466, 1634, 710, 5614, 15614, 11, 51600], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 129, "seek": 49532, "start": 520.4399999999999, "end": 523.84, "text": " potraktowali ka\u017cdy zrzut jako osobn\u0105 bibliotek\u0119", "tokens": [51620, 1847, 32249, 305, 5103, 31615, 710, 19390, 325, 17123, 41518, 13113, 34344, 310, 916, 1274, 51790], "temperature": 0.0, "avg_logprob": -0.1645689550435768, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.01230828370898962}, {"id": 130, "seek": 52384, "start": 524.32, "end": 527.84, "text": " i wykonali deduplikacje tylko wezn\u0105\u0107 ka\u017cdego z nich.", "tokens": [50388, 741, 46702, 5103, 4172, 44810, 1035, 29293, 13219, 321, 89, 13113, 2162, 21912, 67, 6308, 710, 25570, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 131, "seek": 52384, "start": 528.12, "end": 529.08, "text": " Indywidualnie.", "tokens": [50578, 2333, 88, 17697, 901, 2766, 13, 50626], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 132, "seek": 52384, "start": 529.64, "end": 530.12, "text": " Aha.", "tokens": [50654, 27448, 13, 50678], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 133, "seek": 52384, "start": 530.48, "end": 536.72, "text": " U\u017cyli do tego algorytmu minhash i okaza\u0142o si\u0119, \u017ce takie lokalne podej\u015bcie to by\u0142 strza\u0142 w dziesi\u0105tk\u0119.", "tokens": [50696, 624, 7735, 2081, 360, 8627, 3501, 827, 83, 20140, 923, 71, 1299, 741, 3133, 12257, 5249, 3244, 11, 3561, 15963, 450, 19990, 716, 7468, 73, 9815, 281, 16673, 1056, 2394, 1221, 261, 9758, 530, 11404, 83, 15724, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 134, "seek": 52384, "start": 537.2, "end": 542.72, "text": " Ten jeden ruch pozwoli\u0142 im dogoni\u0107 wydajno\u015bci\u0105 czo\u0142owy wtedy publiczny zbi\u00f3r, Refined Web.", "tokens": [51032, 9380, 12906, 367, 625, 40557, 9384, 1221, 566, 3000, 266, 12757, 25984, 1805, 16438, 1611, 269, 4765, 1221, 10089, 26959, 1908, 89, 1634, 710, 5614, 15614, 11, 16957, 2001, 9573, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 135, "seek": 52384, "start": 542.96, "end": 543.84, "text": " Niesamowite.", "tokens": [51320, 426, 530, 335, 305, 642, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 136, "seek": 52384, "start": 544.36, "end": 549.2, "text": " Mniej agresywna, bardziej kontekstowa deduplikacja, a co z filtrowaniem tre\u015bci?", "tokens": [51390, 376, 10402, 623, 495, 27112, 629, 11, 27209, 14373, 916, 372, 5528, 4172, 44810, 1035, 23395, 11, 257, 598, 710, 29148, 1892, 282, 4907, 2192, 6199, 30, 51632], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 137, "seek": 52384, "start": 549.44, "end": 551.96, "text": " Wiem, \u017ce inspirowali si\u0119 klasycznym zbiorem C4.", "tokens": [51644, 343, 4907, 11, 3561, 17432, 305, 5103, 3244, 9671, 5871, 3689, 12996, 710, 5614, 37956, 383, 19, 13, 51770], "temperature": 0.0, "avg_logprob": -0.1825680500123559, "compression_ratio": 1.4, "no_speech_prob": 0.009525158442556858}, {"id": 138, "seek": 55196, "start": 552.24, "end": 553.96, "text": " Tak, to by\u0142 kolejny krok.", "tokens": [50378, 9118, 11, 281, 16673, 23749, 1634, 350, 31621, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 139, "seek": 55196, "start": 554.1600000000001, "end": 558.8000000000001, "text": " Zauwa\u017cyli, \u017ce modele trenowane na starym, ale dobrym zbiorze C4,", "tokens": [50474, 1176, 1459, 4151, 7735, 2081, 11, 3561, 4391, 306, 23136, 23066, 1667, 342, 822, 76, 11, 6775, 35884, 76, 710, 33362, 1381, 383, 19, 11, 50706], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 140, "seek": 55196, "start": 559.2, "end": 561.6800000000001, "text": " radz\u0105 sobie \u015bwietnie na niekt\u00f3rych benchmarkach.", "tokens": [50726, 2843, 8925, 13652, 8299, 39083, 2766, 1667, 2838, 43073, 627, 339, 18927, 608, 13, 50850], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 141, "seek": 55196, "start": 562.12, "end": 567.9200000000001, "text": " Postanowili wi\u0119c, \u017ce tak powiem, uczy\u0107 si\u0119 od mistrz\u00f3w i przeanalizowali filtry u\u017cyte w C4.", "tokens": [50872, 10223, 282, 305, 2312, 16677, 11, 3561, 991, 3388, 4907, 11, 344, 33967, 3244, 3611, 3544, 19390, 3901, 741, 8325, 29702, 590, 305, 5103, 29148, 627, 34097, 975, 261, 383, 19, 13, 51162], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 142, "seek": 55196, "start": 568.4000000000001, "end": 569.2, "text": " I co odkreli?", "tokens": [51186, 286, 598, 3611, 27885, 2081, 30, 51226], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 143, "seek": 55196, "start": 569.48, "end": 574.6800000000001, "text": " \u017be jeden z nich ten, kt\u00f3ry wymaga\u0142, aby ka\u017cda linia tekstu ko\u0144czy\u0142a si\u0119 znakiem interpunkcyjnym,", "tokens": [51240, 46864, 12906, 710, 25570, 2064, 11, 9913, 29764, 9286, 1221, 11, 24457, 21912, 2675, 22896, 654, 16624, 372, 84, 26470, 6522, 5024, 3244, 15397, 514, 4907, 728, 79, 3197, 42949, 12996, 11, 51500], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 144, "seek": 55196, "start": 575.08, "end": 580.6800000000001, "text": " by\u0142 bardzo skuteczny w usuwaniu \u015bmieci, ale by\u0142 te\u017c niezwykle agresywny.", "tokens": [51520, 16673, 9034, 1110, 1169, 3689, 1634, 261, 32247, 86, 25849, 8299, 25210, 537, 11, 6775, 16673, 9516, 33511, 9726, 14677, 623, 495, 88, 43682, 13, 51800], "temperature": 0.0, "avg_logprob": -0.12465577755334242, "compression_ratio": 1.422077922077922, "no_speech_prob": 0.0024580801837146282}, {"id": 145, "seek": 58068, "start": 580.92, "end": 583.3199999999999, "text": " Odrzuca\u0142 a\u017c 30 proc. danych.", "tokens": [50376, 12210, 81, 11728, 496, 1221, 48134, 2217, 9510, 13, 274, 34644, 13, 50496], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 146, "seek": 58068, "start": 583.4799999999999, "end": 589.3599999999999, "text": " 30 proc. to jest masakra, to mn\u00f3stwo potencjalnie warto\u015bciowych informacji.", "tokens": [50504, 2217, 9510, 13, 281, 3492, 2300, 34401, 11, 281, 275, 77, 45052, 6120, 1847, 22660, 22600, 2766, 31830, 6199, 19605, 1356, 13152, 13, 50798], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 147, "seek": 58068, "start": 589.52, "end": 590.68, "text": " Zdecydowanie za du\u017co.", "tokens": [50806, 1176, 1479, 1344, 67, 22028, 7949, 26673, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 148, "seek": 58068, "start": 591.12, "end": 595.0799999999999, "text": " Zdecydowali wi\u0119c, \u017ce zastosuj\u0105 pozosta\u0142e filtry z C4,", "tokens": [50886, 1176, 1479, 1344, 67, 305, 5103, 16677, 11, 3561, 36746, 329, 13263, 21281, 8638, 19827, 29148, 627, 710, 383, 19, 11, 51084], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 149, "seek": 58068, "start": 595.1999999999999, "end": 598.2399999999999, "text": " te mniej inwazyjne, ale ten jeden odpuszcz\u0105.", "tokens": [51090, 535, 39513, 294, 86, 33235, 73, 716, 11, 6775, 2064, 12906, 3611, 79, 22378, 3689, 1611, 13, 51242], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 150, "seek": 58068, "start": 598.68, "end": 601.68, "text": " Co wi\u0119cej, stworzyli w\u0142asne, ulepszone filtry.", "tokens": [51264, 3066, 26004, 11, 342, 28321, 1229, 2081, 43572, 716, 11, 344, 306, 1878, 16896, 29148, 627, 13, 51414], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 151, "seek": 58068, "start": 602.0, "end": 603.8399999999999, "text": " I to w bardzo przemy\u015blany spos\u00f3b.", "tokens": [51430, 286, 281, 261, 9034, 6541, 3633, 19212, 1325, 22904, 13, 51522], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 152, "seek": 58068, "start": 603.9599999999999, "end": 604.4399999999999, "text": " Jak?", "tokens": [51528, 15029, 30, 51552], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 153, "seek": 58068, "start": 604.56, "end": 610.28, "text": " Wykorzystali te dwa zbiory danych, kt\u00f3re powsta\u0142y podczas tego niefortunnego eksperymentu z globaln\u0105 deduplikacj\u0105.", "tokens": [51558, 14458, 19339, 36049, 5103, 535, 35045, 710, 5614, 827, 274, 34644, 11, 8864, 3388, 9140, 6825, 2497, 30989, 8627, 297, 2521, 1584, 11858, 30724, 610, 88, 518, 84, 710, 4338, 13113, 4172, 44810, 1035, 326, 8555, 13, 51844], "temperature": 0.0, "avg_logprob": -0.16764848674842697, "compression_ratio": 1.4230769230769231, "no_speech_prob": 0.006594801787286997}, {"id": 154, "seek": 61028, "start": 610.28, "end": 616.9599999999999, "text": " Ten dobry i ten z\u0142y i przeanalizowali je statystycznie, szukaj\u0105c cech, kt\u00f3re je odr\u00f3\u017cniaj\u0105.", "tokens": [50364, 9380, 35884, 741, 2064, 710, 6825, 741, 8325, 29702, 590, 305, 5103, 1506, 2219, 38593, 17466, 2766, 11, 7870, 2034, 38757, 1769, 339, 11, 8864, 1506, 3611, 11721, 1427, 12679, 8555, 13, 50698], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 155, "seek": 61028, "start": 617.0799999999999, "end": 622.9599999999999, "text": " Czyli zamiast zgadywa\u0107, co charakteryzuje tekst niskiej jako\u015bci, u\u017cyli danych, \u017ceby im to pokaza\u0142y.", "tokens": [50704, 37099, 710, 4526, 525, 40948, 880, 25234, 11, 598, 1290, 514, 12733, 11728, 2884, 16624, 372, 297, 7797, 7764, 17123, 6199, 11, 34097, 2081, 274, 34644, 11, 11316, 566, 281, 13010, 12257, 6825, 13, 50998], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 156, "seek": 61028, "start": 623.1999999999999, "end": 624.0799999999999, "text": " W\u0142a\u015bnie tak.", "tokens": [51010, 343, 5024, 12221, 991, 13, 51054], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 157, "seek": 61028, "start": 624.24, "end": 629.8399999999999, "text": " Zauwa\u017cyli na przyk\u0142ad, \u017ce w z\u0142ym zbiorze jest znacznie wi\u0119cej dokument\u00f3w,", "tokens": [51062, 1176, 1459, 4151, 7735, 2081, 1667, 23144, 11, 3561, 261, 31614, 4199, 710, 33362, 1381, 3492, 15397, 14875, 2766, 26004, 40858, 3901, 11, 51342], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 158, "seek": 61028, "start": 629.9599999999999, "end": 634.52, "text": " kt\u00f3rych bardzo ma\u0142y odsetek linii ko\u0144czy si\u0119 kropk\u0105 czy przecinkiem.", "tokens": [51348, 30382, 9034, 463, 6825, 3611, 3854, 916, 287, 3812, 72, 26470, 6522, 3244, 350, 1513, 26304, 6430, 8325, 66, 475, 4907, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 159, "seek": 61028, "start": 635.24, "end": 638.9599999999999, "text": " Na tej podstawie stworzyli nowy, inteligentny filtr.", "tokens": [51612, 6056, 12573, 43443, 414, 342, 28321, 1229, 2081, 586, 88, 11, 24777, 25002, 1634, 1387, 6903, 13, 51798], "temperature": 0.0, "avg_logprob": -0.14273018090903353, "compression_ratio": 1.4372881355932203, "no_speech_prob": 0.004284280352294445}, {"id": 160, "seek": 63896, "start": 639.32, "end": 645.8000000000001, "text": " Us\u00f3j dokument, je\u015bli mniej ni\u017c 12% jego linii ko\u0144czy si\u0119 znakiem interpunkcyjnym.", "tokens": [50382, 4958, 18999, 40858, 11, 25630, 39513, 28502, 2272, 4, 26542, 287, 3812, 72, 26470, 6522, 3244, 15397, 514, 4907, 728, 79, 409, 74, 42949, 12996, 13, 50706], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 161, "seek": 63896, "start": 646.0400000000001, "end": 646.8000000000001, "text": " Rozumiem.", "tokens": [50718, 43313, 449, 4907, 13, 50756], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 162, "seek": 63896, "start": 647.1600000000001, "end": 652.1600000000001, "text": " To pozwoli\u0142o im osi\u0105gn\u0105\u0107 podobny efekt, ale zachowuj\u0105c znacznie wi\u0119cej danych.", "tokens": [50774, 1407, 40557, 9384, 5249, 566, 3003, 11404, 4568, 36374, 43024, 1634, 31482, 8192, 11, 6775, 29303, 305, 44733, 15397, 14875, 2766, 26004, 274, 34644, 13, 51024], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 163, "seek": 63896, "start": 652.44, "end": 653.2, "text": " Dok\u0142adnie.", "tokens": [51038, 29768, 10358, 2766, 13, 51076], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 164, "seek": 63896, "start": 653.64, "end": 659.72, "text": " I to podej\u015bcie, oparte na danych, pozwoli\u0142o im ostatecznie przewy\u017cszy\u0107 jako\u015b\u0107 C4.", "tokens": [51098, 286, 281, 7468, 73, 9815, 11, 999, 11026, 1667, 274, 34644, 11, 40557, 9384, 5249, 566, 277, 15406, 19923, 39758, 88, 1427, 7706, 2162, 17123, 7753, 383, 19, 13, 51402], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 165, "seek": 63896, "start": 659.96, "end": 660.52, "text": " Ok.", "tokens": [51414, 3477, 13, 51442], "temperature": 0.0, "avg_logprob": -0.19518670668968788, "compression_ratio": 1.2780269058295963, "no_speech_prob": 0.0033096144907176495}, {"id": 166, "seek": 66052, "start": 660.8, "end": 664.76, "text": " Mamy wi\u0119c FineWeb, ogromny 15-billionowy zbi\u00f3r,", "tokens": [50378, 376, 7804, 16677, 12024, 4360, 65, 11, 34416, 298, 1634, 2119, 12, 65, 11836, 10089, 710, 5614, 15614, 11, 50576], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 167, "seek": 66052, "start": 665.04, "end": 669.28, "text": " kt\u00f3rego stworzenie by\u0142o seri\u0105 przemy\u015blanych, przetestowanych decyzji.", "tokens": [50590, 46951, 342, 28321, 16778, 14811, 816, 11404, 6541, 3633, 19212, 34644, 11, 6541, 302, 377, 23341, 339, 979, 37433, 4013, 13, 50802], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 168, "seek": 66052, "start": 669.64, "end": 674.28, "text": " Ale oni posznie okrok dalej, tworz\u0105c co\u015b, co nazywaj\u0105 per\u0142\u0105 w koronie.", "tokens": [50820, 9366, 36317, 1366, 89, 2766, 3133, 31621, 34257, 11, 46288, 8925, 66, 19241, 11, 598, 20151, 27112, 11133, 680, 15926, 261, 14784, 32242, 13, 51052], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 169, "seek": 66052, "start": 674.56, "end": 675.8, "text": " FineWeb Edu.", "tokens": [51066, 12024, 4360, 65, 31900, 13, 51128], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 170, "seek": 66052, "start": 676.12, "end": 676.96, "text": " Jaki by\u0142 cel?", "tokens": [51144, 508, 7421, 16673, 9277, 30, 51186], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 171, "seek": 66052, "start": 677.16, "end": 680.04, "text": " To jest chyba najbardziej innowacyjna cz\u0119\u015b\u0107 tej pracy.", "tokens": [51196, 1407, 3492, 31532, 41857, 294, 3785, 31285, 629, 47149, 12573, 35591, 13, 51340], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 172, "seek": 66052, "start": 680.4, "end": 685.12, "text": " Zainspirowali si\u0119, wiesz, sukcesem modeli jak Lama3.", "tokens": [51358, 1176, 2315, 9501, 305, 5103, 3244, 11, 261, 15347, 11, 46432, 887, 443, 2316, 72, 4207, 441, 2404, 18, 13, 51594], "temperature": 0.0, "avg_logprob": -0.21165727396480372, "compression_ratio": 1.313953488372093, "no_speech_prob": 0.32562947273254395}, {"id": 173, "seek": 68512, "start": 685.5600000000001, "end": 690.84, "text": " Wok\u00f3\u0142 kt\u00f3rych kr\u0105\u017c\u0105 spekulacje, \u017ce by\u0142y trenowane na specjalnie wyselekcjonowanych danych.", "tokens": [50386, 343, 453, 16181, 30382, 15913, 27242, 1611, 768, 74, 425, 29293, 11, 3561, 26366, 23136, 23066, 1667, 46433, 2766, 4628, 405, 29205, 45677, 23341, 339, 274, 34644, 13, 50650], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 174, "seek": 68512, "start": 691.04, "end": 693.64, "text": " Na danych syntetycznych, bardzo wysokiej jako\u015bci.", "tokens": [50660, 6056, 274, 34644, 23980, 2210, 3689, 9399, 11, 9034, 27062, 453, 7764, 17123, 6199, 13, 50790], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 175, "seek": 68512, "start": 693.84, "end": 694.36, "text": " W\u0142a\u015bnie.", "tokens": [50800, 343, 5024, 12221, 13, 50826], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 176, "seek": 68512, "start": 695.0, "end": 702.36, "text": " Postanowili wi\u0119c sprawdzi\u0107, czy da si\u0119 przefiltrowa\u0107 ich gigantyczny zbi\u00f3r FineWeb pod k\u0105tem warto\u015bci edukacyjnej.", "tokens": [50858, 10223, 282, 305, 2312, 16677, 46192, 28496, 11, 6430, 1120, 3244, 8325, 69, 2352, 1892, 43379, 1893, 8741, 394, 17466, 1634, 710, 5614, 15614, 12024, 4360, 65, 2497, 350, 1611, 18275, 31830, 6199, 1257, 2034, 31285, 11794, 13, 51226], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 177, "seek": 68512, "start": 702.6, "end": 705.92, "text": " To brzmi niezwykle subiektywnie.", "tokens": [51238, 1407, 738, 89, 3057, 33511, 9726, 14677, 1422, 19487, 874, 14215, 13, 51404], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 178, "seek": 68512, "start": 706.24, "end": 712.6, "text": " Jak w og\u00f3le mo\u017cna zdefiniowa\u0107 i zmierzy\u0107 co\u015b tak abstrakcyjnego na skal\u0119 bilion\u00f3w token\u00f3w?", "tokens": [51420, 15029, 261, 29229, 17790, 710, 20595, 3812, 11445, 741, 17020, 811, 27150, 19241, 991, 10823, 11272, 42949, 11858, 1667, 16890, 1274, 8588, 313, 3901, 14862, 3901, 30, 51738], "temperature": 0.0, "avg_logprob": -0.19161762016406958, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.10730484127998352}, {"id": 179, "seek": 71260, "start": 713.16, "end": 715.72, "text": " I tu metodologia jest absolutnie fascynuj\u0105ca.", "tokens": [50392, 286, 2604, 1131, 378, 24103, 3492, 18757, 2766, 30632, 1344, 77, 13263, 496, 13, 50520], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 180, "seek": 71260, "start": 716.2, "end": 721.4, "text": " Zrobili co\u015b, co mo\u017cna nazwa\u0107 u\u017cyciem jednej zaawansowanej AI do uczenia drugiej.", "tokens": [50544, 1176, 16614, 2312, 19241, 11, 598, 17790, 20151, 25234, 34097, 4260, 76, 5232, 11794, 7949, 1607, 599, 23066, 73, 7318, 360, 344, 38517, 47373, 13, 50804], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 181, "seek": 71260, "start": 722.08, "end": 726.6, "text": " Wzi\u0119li pot\u0119\u017cny ju\u017c istniej\u0105cy model Lama370B Instrakt.", "tokens": [50838, 343, 16706, 2081, 1847, 1274, 1427, 1634, 10678, 1418, 2766, 8555, 1344, 2316, 441, 2404, 18, 5867, 33, 2730, 32249, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 182, "seek": 71260, "start": 726.8000000000001, "end": 727.2, "text": " OK.", "tokens": [51074, 2264, 13, 51094], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 183, "seek": 71260, "start": 727.4, "end": 732.28, "text": " I poprosili go o ocen\u0119 prawie p\u00f3\u0142 miliona losowych stron internetowych z FineWeb.", "tokens": [51104, 286, 1665, 2635, 2312, 352, 277, 10409, 268, 1274, 3206, 8699, 47907, 1962, 21758, 1750, 19605, 45766, 4705, 19605, 710, 12024, 4360, 65, 13, 51348], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 184, "seek": 71260, "start": 732.8000000000001, "end": 736.6800000000001, "text": " Model mia\u0142 za zadanie oceni\u0107 ka\u017cd\u0105 stron\u0119 w skali od zera do pi\u0119ciu.", "tokens": [51374, 17105, 27989, 7949, 42788, 7155, 10409, 268, 12757, 21912, 67, 1611, 45766, 1274, 261, 1110, 5103, 3611, 710, 1663, 360, 32677, 30795, 13, 51568], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 185, "seek": 71260, "start": 737.0400000000001, "end": 738.6800000000001, "text": " Pod k\u0105tem warto\u015bci edukacyjnej.", "tokens": [51586, 12646, 350, 1611, 18275, 31830, 6199, 1257, 2034, 31285, 11794, 13, 51668], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 186, "seek": 71260, "start": 738.88, "end": 740.32, "text": " A jakiej konkretnie?", "tokens": [51678, 316, 4207, 7764, 36500, 2766, 30, 51750], "temperature": 0.0, "avg_logprob": -0.18135779433780247, "compression_ratio": 1.353135313531353, "no_speech_prob": 0.010812634602189064}, {"id": 187, "seek": 74032, "start": 740.72, "end": 747.24, "text": " Z naciskiem na wiedz\u0119 na poziomie szkolnego, \u017ceby unikn\u0105\u0107 faworyzowania bardzo niszowych technicznych artyku\u0142\u00f3w naukowych.", "tokens": [50384, 1176, 42071, 7797, 4907, 1667, 46894, 11052, 1667, 38503, 40120, 7870, 36620, 11858, 11, 11316, 517, 1035, 13113, 2162, 283, 1607, 827, 89, 21308, 9034, 297, 23848, 19605, 1537, 17946, 9399, 594, 874, 5279, 1221, 3901, 35616, 74, 19605, 13, 50710], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 188, "seek": 74032, "start": 747.44, "end": 754.32, "text": " Czyli de facto u\u017cyli jednego z najlepszych modeli, \u017ceby stworzy\u0142 im etykiety i nauczy\u0142 kolejny, mniejszy model.", "tokens": [50720, 37099, 368, 42225, 34097, 2081, 5232, 11858, 710, 41903, 1878, 28051, 2316, 72, 11, 11316, 342, 28321, 1229, 1221, 566, 1030, 46127, 4014, 741, 49103, 1229, 1221, 23749, 1634, 11, 39513, 7706, 2316, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 189, "seek": 74032, "start": 754.5200000000001, "end": 756.6400000000001, "text": " Jak rozpoznawa\u0107 warto\u015bciowe tre\u015bci?", "tokens": [51074, 15029, 9544, 2259, 35458, 25234, 31830, 6199, 6880, 2192, 6199, 30, 51180], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 190, "seek": 74032, "start": 756.84, "end": 757.84, "text": " Precyzyjnie.", "tokens": [51190, 6001, 1344, 1229, 73, 2766, 13, 51240], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 191, "seek": 74032, "start": 758.0400000000001, "end": 762.6400000000001, "text": " Te prawie p\u00f3\u0142 miliona ocen od Lama3 pos\u0142u\u017cy\u0142o jako zbi\u00f3r treningowy do", "tokens": [51250, 1989, 3206, 8699, 47907, 1962, 21758, 10409, 268, 3611, 441, 2404, 18, 1366, 24066, 7735, 5249, 17123, 710, 5614, 15614, 2192, 773, 10089, 360, 51480], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 192, "seek": 74032, "start": 762.84, "end": 768.6400000000001, "text": " wytrenowania znacznie mniejszego, ale bardzo wydajnego i szybkiego klasyfikatora.", "tokens": [51490, 261, 4328, 1095, 21308, 15397, 14875, 2766, 39513, 15453, 6308, 11, 6775, 9034, 25984, 1805, 11858, 741, 36456, 42349, 9671, 5871, 31230, 1639, 64, 13, 51780], "temperature": 0.0, "avg_logprob": -0.12395846379267705, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.0013929499546065927}, {"id": 193, "seek": 76864, "start": 768.84, "end": 773.36, "text": " I ten ma\u0142y klasyfikator przeanalizowa\u0142 ca\u0142y pi\u0119tna\u015bcie bilion\u00f3w token\u00f3w.", "tokens": [50374, 286, 2064, 463, 6825, 9671, 5871, 31230, 1639, 8325, 29702, 590, 30105, 35226, 32677, 83, 629, 9815, 8588, 313, 3901, 14862, 3901, 13, 50600], "temperature": 0.0, "avg_logprob": -0.148147705078125, "compression_ratio": 1.390625, "no_speech_prob": 0.0022383343894034624}, {"id": 194, "seek": 76864, "start": 773.56, "end": 782.1999999999999, "text": " Tak i wybra\u0142 z nich jeden trzy biliona tych najlepszych, tych z ocen\u0105 trzy lub wy\u017csz\u0105 i tak powsta\u0142 FineWeb edu.", "tokens": [50610, 9118, 741, 4628, 6198, 1221, 710, 25570, 12906, 34573, 8588, 21758, 15180, 41903, 1878, 28051, 11, 15180, 710, 10409, 268, 1611, 34573, 15980, 4628, 1427, 82, 8925, 741, 991, 3388, 9140, 1221, 12024, 4360, 65, 1257, 84, 13, 51042], "temperature": 0.0, "avg_logprob": -0.148147705078125, "compression_ratio": 1.390625, "no_speech_prob": 0.0022383343894034624}, {"id": 195, "seek": 76864, "start": 782.4, "end": 787.3199999999999, "text": " A wi\u0119c jaki by\u0142 efekt ko\u0144cowy? Czy ta ca\u0142a operacja by\u0142a warta w wysi\u0142ku?", "tokens": [51052, 316, 16677, 24492, 16673, 31482, 8192, 26470, 66, 10089, 30, 19832, 1846, 1335, 5024, 2208, 23395, 23936, 261, 19061, 261, 27062, 40622, 5279, 30, 51298], "temperature": 0.0, "avg_logprob": -0.148147705078125, "compression_ratio": 1.390625, "no_speech_prob": 0.0022383343894034624}, {"id": 196, "seek": 76864, "start": 787.52, "end": 789.1999999999999, "text": " Wyniki s\u0105 spektakularne.", "tokens": [51308, 343, 2534, 9850, 9015, 768, 2320, 514, 1040, 716, 13, 51392], "temperature": 0.0, "avg_logprob": -0.148147705078125, "compression_ratio": 1.390625, "no_speech_prob": 0.0022383343894034624}, {"id": 197, "seek": 76864, "start": 789.4, "end": 792.1999999999999, "text": " My\u015bl\u0119, \u017ce przeros\u0142y oczekiwania samych autor\u00f3w.", "tokens": [51402, 1222, 28749, 11, 3561, 582, 4527, 329, 6825, 277, 3689, 14753, 86, 5609, 3247, 16384, 19510, 3901, 13, 51542], "temperature": 0.0, "avg_logprob": -0.148147705078125, "compression_ratio": 1.390625, "no_speech_prob": 0.0022383343894034624}, {"id": 198, "seek": 79220, "start": 792.44, "end": 800.96, "text": " Modele trenowane na FineWeb edu dos\u0142ownie deklasuj\u0105 inne na benchmarkach mierz\u0105cych wiedz\u0119 i rozumowanie jak MMLu czy ARK.", "tokens": [50376, 20500, 306, 23136, 23066, 1667, 12024, 4360, 65, 1257, 84, 4491, 1221, 648, 414, 368, 74, 7743, 13263, 24170, 1667, 18927, 608, 275, 811, 8925, 31306, 46894, 11052, 741, 48797, 22028, 4207, 376, 12683, 84, 6430, 8943, 42, 13, 50802], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 199, "seek": 79220, "start": 801.1600000000001, "end": 802.36, "text": " Daj jaki\u015b przyk\u0142ad.", "tokens": [50812, 413, 1805, 34721, 23144, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 200, "seek": 79220, "start": 802.5600000000001, "end": 810.12, "text": " Prosz\u0119 bardzo. Na te\u015bcie MMLu model trenowany na FineWeb edu osi\u0105gn\u0105\u0142 wynik, na kt\u00f3ry konkurencyjny model", "tokens": [50882, 26024, 11052, 9034, 13, 6056, 535, 9815, 376, 12683, 84, 2316, 23136, 23341, 1667, 12024, 4360, 65, 1257, 84, 3003, 11404, 4568, 1611, 1221, 31936, 1035, 11, 1667, 9913, 21428, 9873, 42949, 1634, 2316, 51260], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 201, "seek": 79220, "start": 810.32, "end": 813.5200000000001, "text": " potrzebowa\u0142 prawie dziesi\u0119\u0107 razy wi\u0119cej danych treningowych.", "tokens": [51270, 37595, 30105, 3206, 8699, 9758, 530, 5034, 2162, 9639, 88, 26004, 274, 34644, 2192, 773, 19605, 13, 51430], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 202, "seek": 79220, "start": 813.72, "end": 818.2, "text": " Dziesi\u0119\u0107 razy mniej danych, \u017ceby osi\u0105gn\u0105\u0107 ten sam poziom wiedzy.", "tokens": [51440, 39448, 530, 5034, 2162, 9639, 88, 39513, 274, 34644, 11, 11316, 3003, 11404, 4568, 36374, 2064, 3247, 38503, 298, 46894, 1229, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 203, "seek": 79220, "start": 818.4000000000001, "end": 820.44, "text": " To jest gigantyczna r\u00f3\u017cnica.", "tokens": [51674, 1407, 3492, 8741, 394, 17466, 629, 19637, 32687, 13, 51776], "temperature": 0.0, "avg_logprob": -0.1553476197378976, "compression_ratio": 1.4826388888888888, "no_speech_prob": 0.04700159654021263}, {"id": 204, "seek": 82044, "start": 820.6, "end": 828.96, "text": " Ogromna to twardy dow\u00f3d na to, \u017ce precyzyjne kuratorstwo danych pod k\u0105tem okre\u015blonego rodzaju jako\u015bci, w tym przypadku edukacyjnej,", "tokens": [50372, 422, 861, 298, 629, 281, 683, 515, 88, 9459, 17081, 1667, 281, 11, 3561, 659, 1344, 1229, 73, 716, 10072, 1639, 372, 6120, 274, 34644, 2497, 350, 1611, 18275, 3133, 265, 19212, 546, 1571, 28607, 33166, 17123, 6199, 11, 261, 8107, 41955, 1257, 2034, 31285, 11794, 11, 50790], "temperature": 0.0, "avg_logprob": -0.11111293520246233, "compression_ratio": 1.4854014598540146, "no_speech_prob": 0.001199100399389863}, {"id": 205, "seek": 82044, "start": 829.1600000000001, "end": 831.5600000000001, "text": " przynosi niewsp\u00f3\u0142miernie du\u017ce korzy\u015bci.", "tokens": [50800, 6501, 16751, 72, 43622, 4952, 16181, 76, 811, 2766, 1581, 2875, 14784, 1229, 6199, 13, 50920], "temperature": 0.0, "avg_logprob": -0.11111293520246233, "compression_ratio": 1.4854014598540146, "no_speech_prob": 0.001199100399389863}, {"id": 206, "seek": 82044, "start": 831.7600000000001, "end": 837.36, "text": " Czyli to ju\u017c nie jest tylko kwestia usuwania \u015bmieci, ale aktywnego wybierania pere\u0142ek?", "tokens": [50930, 37099, 281, 10678, 2838, 3492, 13219, 42035, 654, 32247, 86, 5609, 8299, 25210, 537, 11, 6775, 9308, 874, 86, 11858, 45780, 811, 5609, 280, 323, 1221, 916, 30, 51210], "temperature": 0.0, "avg_logprob": -0.11111293520246233, "compression_ratio": 1.4854014598540146, "no_speech_prob": 0.001199100399389863}, {"id": 207, "seek": 82044, "start": 837.5600000000001, "end": 845.08, "text": " Dok\u0142adnie. To sugeruje, \u017ce takie dane nie tylko ucz\u0105 model fakt\u00f3w, ale mo\u017ce ucz\u0105 go lepszych wzorc\u00f3w, rozumowania i wnioskowania.", "tokens": [51220, 29768, 10358, 2766, 13, 1407, 459, 1321, 13008, 11, 3561, 15963, 49206, 2838, 13219, 35403, 1611, 2316, 21310, 3901, 11, 6775, 12034, 35403, 1611, 352, 476, 1878, 28051, 24809, 284, 29268, 11, 48797, 21308, 741, 45368, 2717, 74, 21308, 13, 51596], "temperature": 0.0, "avg_logprob": -0.11111293520246233, "compression_ratio": 1.4854014598540146, "no_speech_prob": 0.001199100399389863}, {"id": 208, "seek": 84508, "start": 845.32, "end": 850.2800000000001, "text": " I to filtrowanie, jak si\u0119 domy\u015blam, kompletnie zmienia sk\u0142ad tematyczny zbioru?", "tokens": [50376, 286, 281, 29148, 1892, 7155, 11, 4207, 3244, 3285, 88, 1788, 4326, 11, 5207, 14657, 2766, 17020, 18811, 1110, 10358, 32954, 17466, 1634, 710, 33362, 84, 30, 50624], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 209, "seek": 84508, "start": 850.48, "end": 853.4000000000001, "text": " Zdecydowanie. Analiza pokaza\u0142a, \u017ce FineWeb edu", "tokens": [50634, 1176, 1479, 1344, 67, 22028, 13, 16128, 13427, 13010, 12257, 5024, 11, 3561, 12024, 4360, 65, 1257, 84, 50780], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 210, "seek": 84508, "start": 853.6, "end": 858.76, "text": " faworyzuje tematy takie jak edukacja, nauka czy historia, kultura, polityka.", "tokens": [50790, 283, 1607, 827, 11728, 2884, 1383, 21398, 15963, 4207, 1257, 2034, 23395, 11, 35616, 2330, 6430, 18385, 11, 350, 49944, 11, 36066, 2330, 13, 51048], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 211, "seek": 84508, "start": 858.96, "end": 863.64, "text": " A jednocze\u015bnie marginalizuje kategorie typu biznes, finanse czy rozrywka.", "tokens": [51058, 316, 5232, 26694, 1381, 12221, 16885, 590, 13008, 350, 2968, 17473, 2125, 84, 7390, 4081, 11, 3682, 405, 6430, 9544, 47705, 2330, 13, 51292], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 212, "seek": 84508, "start": 863.84, "end": 866.0, "text": " Ciekawe. I co jeszcze ciekawsze?", "tokens": [51302, 383, 414, 2330, 826, 13, 286, 598, 14168, 46419, 28354, 30, 51410], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 213, "seek": 84508, "start": 866.2, "end": 874.0400000000001, "text": " Modele trenowane na tym zbiorze lepiej radz\u0105 sobie te\u017c z tekstami akademickimi i kodem programistycznym, mimo \u017ce to nie by\u0142 cel bezpo\u015bredni.", "tokens": [51420, 20500, 306, 23136, 23066, 1667, 8107, 710, 33362, 1381, 476, 39699, 2843, 8925, 13652, 9516, 710, 16624, 372, 4526, 9308, 49290, 618, 10121, 741, 350, 378, 443, 1461, 468, 17466, 12996, 11, 275, 6934, 3561, 281, 2838, 16673, 9277, 10782, 2259, 1788, 986, 3722, 13, 51812], "temperature": 0.0, "avg_logprob": -0.13025830115801024, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.05881033092737198}, {"id": 214, "seek": 87404, "start": 874.16, "end": 880.7199999999999, "text": " Brzmi jak ogromny krok na prz\u00f3d dla otwartej AI, ale jak zawsze s\u0105 jakie\u015b ograniczenia.", "tokens": [50370, 1603, 89, 3057, 4207, 34416, 298, 1634, 350, 31621, 1667, 6541, 17081, 12285, 4337, 86, 11026, 73, 7318, 11, 6775, 4207, 30964, 9015, 31163, 34416, 30732, 14320, 13, 50698], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 215, "seek": 87404, "start": 880.92, "end": 883.56, "text": " Jakie s\u0105 minusy? O czym musimy pami\u0119ta\u0107?", "tokens": [50708, 15029, 414, 9015, 923, 301, 88, 30, 422, 31466, 43449, 31088, 42931, 30, 50840], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 216, "seek": 87404, "start": 883.76, "end": 886.12, "text": " Autorzy s\u0105 bardzo transparentni w tej kwestii.", "tokens": [50850, 6049, 284, 1229, 9015, 9034, 12737, 3722, 261, 12573, 42035, 5597, 13, 50968], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 217, "seek": 87404, "start": 886.3199999999999, "end": 890.0, "text": " Po pierwsze podkre\u015blaj\u0105, \u017ce to w cia\u0142\u017c s\u0105 tylko dane z internetu.", "tokens": [50978, 6165, 45994, 2497, 27885, 1788, 875, 8555, 11, 3561, 281, 261, 269, 8908, 1427, 9015, 13219, 49206, 710, 4705, 84, 13, 51162], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 218, "seek": 87404, "start": 890.1999999999999, "end": 894.8, "text": " Zbi\u00f3r mo\u017cna by wzbogaci\u0107 o ksi\u0105\u017cki, transkrypcje artyku\u0142y naukowe.", "tokens": [51172, 1176, 5614, 15614, 17790, 538, 24809, 65, 664, 326, 12757, 277, 39311, 2984, 11, 1145, 43298, 79, 44261, 594, 874, 5279, 6825, 35616, 74, 6880, 13, 51402], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 219, "seek": 87404, "start": 895.0, "end": 897.0799999999999, "text": " I to pewnie przynios\u0142oby dalsz\u0105 popraw\u0119?", "tokens": [51412, 286, 281, 520, 14215, 6501, 77, 2717, 1221, 13944, 274, 1124, 8925, 1665, 5131, 1274, 30, 51516], "temperature": 0.0, "avg_logprob": -0.141376099219689, "compression_ratio": 1.3639705882352942, "no_speech_prob": 0.010308267548680305}, {"id": 220, "seek": 89708, "start": 897.24, "end": 904.44, "text": " Z pewno\u015bci\u0105. Po drugie, wszystkie ich eksperymenty typu Data Ablation by\u0142y prowadzone na stosunkowo ma\u0142ych modelach.", "tokens": [50372, 1176, 33002, 50227, 13, 6165, 4110, 414, 11, 31723, 1893, 30724, 610, 88, 518, 88, 2125, 84, 11888, 2847, 24278, 26366, 36590, 16896, 1667, 43581, 3197, 19941, 463, 47655, 2316, 608, 13, 50732], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 221, "seek": 89708, "start": 904.64, "end": 906.5200000000001, "text": " 1,7 miliarda parametr\u00f3w.", "tokens": [50742, 502, 11, 22, 1962, 72, 19218, 6220, 27965, 3901, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 222, "seek": 89708, "start": 906.72, "end": 908.1600000000001, "text": " Z oczywistych wzgl\u0119d\u00f3w kosztowych?", "tokens": [50846, 1176, 277, 6522, 86, 468, 16384, 48538, 6298, 3901, 19532, 2682, 19605, 30, 50918], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 223, "seek": 89708, "start": 908.36, "end": 915.24, "text": " No tak. I zaznaczaj\u0105, \u017ce efekty z gigantycznej skali na modelach z setkami miliard\u00f3w parametr\u00f3w mog\u0105 by\u0107 inne.", "tokens": [50928, 883, 991, 13, 286, 710, 921, 77, 14875, 11133, 11, 3561, 31482, 916, 874, 710, 8741, 394, 17466, 11794, 1110, 5103, 1667, 2316, 608, 710, 992, 48737, 1962, 72, 515, 3901, 6220, 27965, 3901, 34123, 15069, 24170, 13, 51272], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 224, "seek": 89708, "start": 915.44, "end": 920.12, "text": " Chocia\u017c wszystko wskazuje na to, \u017ce te wnioski powinny si\u0119 dobrze skalowa\u0107.", "tokens": [51282, 12366, 42673, 22607, 261, 5161, 43317, 1667, 281, 11, 3561, 535, 45368, 2717, 2984, 27310, 1634, 3244, 28335, 16890, 11445, 13, 51516], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 225, "seek": 89708, "start": 920.32, "end": 921.8000000000001, "text": " A to samo zawarto\u015bci\u0105.", "tokens": [51526, 316, 281, 36422, 28165, 15864, 50227, 13, 51600], "temperature": 0.0, "avg_logprob": -0.14112728260181567, "compression_ratio": 1.411149825783972, "no_speech_prob": 0.14840832352638245}, {"id": 226, "seek": 92180, "start": 922.04, "end": 923.7199999999999, "text": " Internet nie jest neutralny.", "tokens": [50376, 7703, 2838, 3492, 10598, 1634, 13, 50460], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 227, "seek": 92180, "start": 923.92, "end": 928.28, "text": " Czy przyjrzeli si\u0119, jak ten proces wp\u0142yn\u0105\u0142 na, no nie wiem, stereotypy w danych?", "tokens": [50470, 19832, 6501, 73, 19390, 10148, 3244, 11, 4207, 2064, 17565, 32444, 1221, 2534, 1611, 1221, 1667, 11, 572, 2838, 26522, 11, 41182, 8200, 261, 274, 34644, 30, 50688], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 228, "seek": 92180, "start": 928.4799999999999, "end": 930.0799999999999, "text": " Tak, to bardzo wa\u017cny punkt.", "tokens": [50698, 9118, 11, 281, 9034, 27777, 1634, 39561, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 229, "seek": 92180, "start": 930.28, "end": 932.12, "text": " I tak przeprowadzili tak\u0105 analiz\u0119.", "tokens": [50788, 286, 991, 30829, 1892, 345, 89, 2312, 31069, 2624, 590, 1274, 13, 50880], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 230, "seek": 92180, "start": 932.3199999999999, "end": 938.0, "text": " Otkryli, co nie jest z zaskoczeniem, \u017ce FineWeb odzwierciedla stereotypy z sieci.", "tokens": [50890, 12936, 43298, 2081, 11, 598, 2838, 3492, 710, 710, 3863, 905, 2904, 4907, 11, 3561, 12024, 4360, 65, 3611, 14406, 811, 537, 292, 875, 41182, 8200, 710, 2804, 537, 13, 51174], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 231, "seek": 92180, "start": 938.1999999999999, "end": 942.4399999999999, "text": " Nadreprezentowane s\u0105 terminy m\u0119\u017cczyzna czy chrze\u015bcijanin.", "tokens": [51184, 23269, 265, 3712, 14185, 23066, 9015, 1433, 3519, 275, 1274, 1427, 6522, 35458, 6430, 417, 13503, 6199, 14763, 259, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 232, "seek": 92180, "start": 942.64, "end": 943.16, "text": " OK.", "tokens": [51406, 2264, 13, 51432], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 233, "seek": 92180, "start": 943.3599999999999, "end": 951.04, "text": " Ale co ciekawe, filtrowanie pod k\u0105tem warto\u015bci edukacyjnej w FineWeb edu zmienia charakter tych skojarze\u0144.", "tokens": [51442, 9366, 598, 30596, 2330, 826, 11, 1387, 6903, 22028, 2497, 350, 1611, 18275, 31830, 6199, 1257, 2034, 31285, 11794, 261, 12024, 4360, 65, 1257, 84, 17020, 18811, 1290, 33557, 15180, 1110, 78, 10150, 49689, 13, 51826], "temperature": 0.0, "avg_logprob": -0.1656678235983547, "compression_ratio": 1.46, "no_speech_prob": 0.14013785123825073}, {"id": 234, "seek": 95104, "start": 951.24, "end": 956.7199999999999, "text": " Na przyk\u0142ad s\u0142owo kobieta w og\u00f3lnym zbiorze jest silnie kojarzone z randkowaniem.", "tokens": [50374, 6056, 23144, 15116, 19941, 43057, 1684, 64, 261, 5360, 15741, 12996, 710, 33362, 1381, 3492, 3425, 2766, 8384, 10150, 16896, 710, 367, 474, 74, 37345, 4907, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 235, "seek": 95104, "start": 956.92, "end": 957.8399999999999, "text": " A w edukacyjnym?", "tokens": [50658, 316, 261, 1257, 2034, 31285, 12996, 30, 50704], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 236, "seek": 95104, "start": 958.04, "end": 963.04, "text": " W edukacyjnym te skojarzenia przesuwaj\u0105 si\u0119 w kierunku ci\u0105\u017cy, matki i rodziny.", "tokens": [50714, 343, 1257, 2034, 31285, 12996, 535, 1110, 78, 10150, 14320, 6541, 279, 36824, 11133, 3244, 261, 38767, 49910, 42398, 7735, 11, 3803, 2984, 741, 28607, 3519, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 237, "seek": 95104, "start": 963.24, "end": 969.28, "text": " Czyli bajas nie znika, tylko zmienia sw\u00f3j charakter na powiedzmy bardziej biologiczny czy historyczny.", "tokens": [50974, 37099, 23589, 296, 2838, 15397, 5439, 11, 13219, 17020, 18811, 1693, 18999, 1290, 33557, 1667, 27617, 2226, 27209, 3228, 1132, 17946, 1634, 6430, 2503, 3689, 1634, 13, 51276], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 238, "seek": 95104, "start": 969.48, "end": 977.88, "text": " Dok\u0142adnie. To nie eliminuje problemu, ale pokazuje, jak proces kuracji danych kszta\u0142tuje osobowo\u015b\u0107 i \u015bwiatopogl\u0105d modelu.", "tokens": [51286, 29768, 10358, 2766, 13, 1407, 2838, 7892, 13008, 1154, 84, 11, 6775, 13010, 43317, 11, 4207, 17565, 10072, 13152, 274, 34644, 350, 15453, 46426, 9179, 2884, 19116, 8202, 78, 7753, 741, 36425, 404, 664, 75, 18962, 2316, 84, 13, 51706], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 239, "seek": 95104, "start": 978.0799999999999, "end": 980.28, "text": " To bardzo wa\u017cne odkrycie samo w sobie.", "tokens": [51716, 1407, 9034, 46110, 3611, 43298, 4260, 36422, 261, 13652, 13, 51826], "temperature": 0.0, "avg_logprob": -0.10778741647076133, "compression_ratio": 1.4476190476190476, "no_speech_prob": 0.005296202376484871}, {"id": 240, "seek": 98028, "start": 980.4399999999999, "end": 988.76, "text": " Podsumowuj\u0105c, mamy nowy, czo\u0142owy, otwarty zbi\u00f3r danych oraz, co chyba wa\u017cniejsze, publiczny, powtarzalny przepis na jego stworzenie.", "tokens": [50372, 12646, 82, 449, 305, 44733, 11, 17335, 586, 88, 11, 269, 4765, 1221, 10089, 11, 4337, 29587, 88, 710, 5614, 15614, 274, 34644, 28905, 11, 598, 31532, 27777, 44258, 11, 1908, 89, 1634, 11, 3388, 23480, 89, 304, 1634, 30829, 271, 1667, 26542, 342, 28321, 16778, 13, 50788], "temperature": 0.0, "avg_logprob": -0.11113786061604818, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.00867330003529787}, {"id": 241, "seek": 98028, "start": 988.9599999999999, "end": 991.28, "text": " Ogromny wk\u0142ad w spo\u0142eczno\u015b\u0107 Open Source.", "tokens": [50798, 422, 861, 298, 1634, 261, 15317, 261, 36851, 89, 23293, 7238, 29629, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11113786061604818, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.00867330003529787}, {"id": 242, "seek": 98028, "start": 991.48, "end": 999.92, "text": " Zdecydowanie. Ta praca przenosi akcent z podej\u015bcia wi\u0119cej danych za wszelk\u0105 cen\u0119 na m\u0105drzejsze, lepiej przygotowane dane.", "tokens": [50924, 1176, 1479, 1344, 67, 22028, 13, 6551, 582, 6628, 582, 2904, 21521, 9308, 2207, 710, 7468, 73, 1788, 2755, 26004, 274, 34644, 7949, 37647, 12971, 26304, 27900, 1274, 1667, 275, 18962, 13503, 25530, 1381, 11, 476, 39699, 35914, 23066, 49206, 13, 51346], "temperature": 0.0, "avg_logprob": -0.11113786061604818, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.00867330003529787}, {"id": 243, "seek": 98028, "start": 1000.12, "end": 1008.6, "text": " Pokazuje, \u017ce systematyczne, empiryczne podej\u015bcie jak Data Ablation i to jako\u015bciowe filtrowanie z pomoc\u0105 AI to kluczowe lekcje.", "tokens": [51356, 14958, 43317, 11, 3561, 1185, 267, 17466, 716, 11, 4012, 12781, 38491, 7468, 73, 9815, 4207, 11888, 2847, 24278, 741, 281, 17123, 6199, 6880, 1387, 6903, 22028, 710, 48962, 1611, 7318, 281, 9671, 1311, 89, 6880, 30863, 44261, 13, 51780], "temperature": 0.0, "avg_logprob": -0.11113786061604818, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.00867330003529787}, {"id": 244, "seek": 100860, "start": 1008.8000000000001, "end": 1015.32, "text": " Zanim sko\u0144czymy, nasuwa mi si\u0119 jedna taka troch\u0119 prowokuj\u0105ca my\u015bl. Jest tu pewien fascynuj\u0105cy paradoks.", "tokens": [50374, 1176, 17869, 1110, 78, 5248, 6522, 2226, 11, 5382, 84, 4151, 2752, 3244, 5232, 629, 28017, 24926, 45553, 453, 13263, 496, 452, 19212, 13, 24918, 2604, 25889, 1053, 30632, 1344, 77, 13263, 1344, 13480, 25500, 13, 50700], "temperature": 0.0, "avg_logprob": -0.12994510007191853, "compression_ratio": 1.3603603603603605, "no_speech_prob": 0.0036329212598502636}, {"id": 245, "seek": 100860, "start": 1015.52, "end": 1026.3600000000001, "text": " \u017beby stworzy\u0107 ten najlepszy w swojej klasie otwarty zbi\u00f3r danych, FineWebEdu, badacze musieli polega\u0107 na pot\u0119\u017cnym, ale zamkni\u0119tym i komercyjnym modelu Lama3.", "tokens": [50710, 46864, 2322, 342, 28321, 27150, 2064, 41903, 1878, 1229, 261, 29489, 73, 350, 7743, 414, 4337, 29587, 88, 710, 5614, 15614, 274, 34644, 11, 12024, 4360, 65, 36, 769, 11, 1578, 326, 1381, 1038, 23099, 13208, 3680, 2162, 1667, 1847, 1274, 1427, 12996, 11, 6775, 19876, 74, 35938, 874, 76, 741, 5207, 260, 42949, 12996, 2316, 84, 441, 2404, 18, 13, 51252], "temperature": 0.0, "avg_logprob": -0.12994510007191853, "compression_ratio": 1.3603603603603605, "no_speech_prob": 0.0036329212598502636}, {"id": 246, "seek": 100860, "start": 1026.56, "end": 1029.08, "text": " To on dostarczy\u0142 im etykiety.", "tokens": [51262, 1407, 322, 20568, 289, 6522, 1221, 566, 1030, 46127, 4014, 13, 51388], "temperature": 0.0, "avg_logprob": -0.12994510007191853, "compression_ratio": 1.3603603603603605, "no_speech_prob": 0.0036329212598502636}, {"id": 247, "seek": 100860, "start": 1029.28, "end": 1034.2, "text": " Czy to nie oznacza, \u017ce spo\u0142eczno\u015b\u0107 Open Source jest skazana na bycie okrok w tyle?", "tokens": [51398, 19832, 281, 2838, 277, 22672, 326, 2394, 11, 3561, 36851, 89, 23293, 7238, 29629, 3492, 1110, 921, 2095, 1667, 538, 4260, 3133, 31621, 261, 39293, 30, 51644], "temperature": 0.0, "avg_logprob": -0.12994510007191853, "compression_ratio": 1.3603603603603605, "no_speech_prob": 0.0036329212598502636}, {"id": 248, "seek": 100860, "start": 1034.4, "end": 1037.48, "text": " Zale\u017cna od narz\u0119dzi z wielkich zamkni\u0119tych laboratori\u00f3w?", "tokens": [51654, 1176, 45494, 629, 3611, 6714, 89, 6298, 3992, 710, 20570, 48349, 19876, 74, 35938, 874, 339, 5938, 39842, 3901, 30, 51808], "temperature": 0.0, "avg_logprob": -0.12994510007191853, "compression_ratio": 1.3603603603603605, "no_speech_prob": 0.0036329212598502636}, {"id": 249, "seek": 103748, "start": 1037.6, "end": 1045.88, "text": " To jest pytanie za milion dolar\u00f3w i to jest rdze\u0144 obecnej debaty, ale ta praca wskazuje te\u017c potencjaln\u0105 \u015bcie\u017ck\u0119 wyj\u015bcia z tej p\u0119tli.", "tokens": [50370, 1407, 3492, 36610, 7949, 1962, 313, 360, 2200, 3901, 741, 281, 3492, 367, 67, 49689, 49141, 11794, 3001, 21398, 11, 6775, 1846, 582, 6628, 261, 5161, 43317, 9516, 1847, 22660, 22600, 13113, 8299, 40082, 15724, 4628, 73, 1788, 2755, 710, 12573, 280, 46788, 2081, 13, 50784], "temperature": 0.0, "avg_logprob": -0.11506753354459195, "compression_ratio": 1.3551020408163266, "no_speech_prob": 0.00233853398822248}, {"id": 250, "seek": 103748, "start": 1046.08, "end": 1046.6, "text": " To znaczy?", "tokens": [50794, 1407, 36584, 30, 50820], "temperature": 0.0, "avg_logprob": -0.11506753354459195, "compression_ratio": 1.3551020408163266, "no_speech_prob": 0.00233853398822248}, {"id": 251, "seek": 103748, "start": 1046.8, "end": 1054.2, "text": " W miar\u0119 jak otwarte modele, trenowane na zbiorach takich jak FineWeb, staj\u0105 si\u0119 coraz lepsze?", "tokens": [50830, 343, 2752, 289, 1274, 4207, 4337, 86, 11026, 4391, 306, 11, 23136, 23066, 1667, 710, 33362, 608, 29607, 4207, 12024, 4360, 65, 11, 342, 11133, 3244, 25899, 476, 1878, 1381, 30, 51200], "temperature": 0.0, "avg_logprob": -0.11506753354459195, "compression_ratio": 1.3551020408163266, "no_speech_prob": 0.00233853398822248}, {"id": 252, "seek": 103748, "start": 1054.4, "end": 1059.64, "text": " Czy nie dojdziemy do punktu, w kt\u00f3rym b\u0119d\u0105 w stanie same nap\u0119dza\u0107 ten proces?", "tokens": [51210, 19832, 2838, 360, 73, 13096, 2226, 360, 39561, 84, 11, 261, 30120, 26239, 261, 40013, 912, 9296, 6298, 35873, 2064, 17565, 30, 51472], "temperature": 0.0, "avg_logprob": -0.11506753354459195, "compression_ratio": 1.3551020408163266, "no_speech_prob": 0.00233853398822248}, {"id": 253, "seek": 105964, "start": 1059.8400000000001, "end": 1070.0, "text": " Czy otwarty model przysz\u0142o\u015bci, nazwijmy go FineWeb model 2.0, b\u0119dzie na tyle dobry, by tworzy\u0107 etykiety dla danych treningowych nast\u0119pnej generacji?", "tokens": [50374, 19832, 4337, 29587, 88, 2316, 44018, 35059, 11, 20151, 36652, 2226, 352, 12024, 4360, 65, 2316, 568, 13, 15, 11, 10562, 1667, 39293, 35884, 11, 538, 46288, 27150, 1030, 46127, 4014, 12285, 274, 34644, 2192, 773, 19605, 39662, 11794, 1337, 13152, 30, 50882], "temperature": 0.0, "avg_logprob": -0.13367695727590787, "compression_ratio": 1.375, "no_speech_prob": 0.03697437420487404}, {"id": 254, "seek": 105964, "start": 1070.2, "end": 1080.1200000000001, "text": " Tworz\u0105c w ten spos\u00f3b samo nap\u0119dzaj\u0105ce si\u0119 ko\u0142o, kt\u00f3re pozwoli\u0142oby spo\u0142eczno\u015bci Open Source nie tylko goni\u0107, ale mo\u017ce nawet przegoni\u0107 systemy zamkni\u0119te?", "tokens": [50892, 2574, 284, 8925, 66, 261, 2064, 22904, 36422, 9296, 6298, 89, 11133, 384, 3244, 8384, 5249, 11, 8864, 40557, 9384, 1221, 13944, 36851, 89, 16438, 7238, 29629, 2838, 13219, 26307, 12757, 11, 6775, 12034, 22696, 6541, 1146, 266, 12757, 1185, 88, 19876, 74, 35938, 975, 30, 51388], "temperature": 0.0, "avg_logprob": -0.13367695727590787, "compression_ratio": 1.375, "no_speech_prob": 0.03697437420487404}, {"id": 255, "seek": 105964, "start": 1080.3200000000002, "end": 1085.44, "text": " W\u0142a\u015bnie. Mo\u017cemy by\u0107 \u015bwiadkami pierwszego obrotu tego ko\u0142a zamachowego.", "tokens": [51398, 343, 5024, 12221, 13, 44736, 3633, 15069, 21485, 345, 48737, 27623, 27725, 1111, 10536, 84, 8627, 8384, 5024, 19876, 608, 26576, 13, 51654], "temperature": 0.0, "avg_logprob": -0.13367695727590787, "compression_ratio": 1.375, "no_speech_prob": 0.03697437420487404}, {"id": 256, "seek": 108544, "start": 1085.6000000000001, "end": 1089.64, "text": " Ta praca dostarczy\u0142a spo\u0142eczno\u015bci przepis i sk\u0142adniki.", "tokens": [50372, 6551, 582, 6628, 20568, 289, 6522, 5024, 36851, 89, 16438, 30829, 271, 741, 1110, 10358, 77, 9850, 13, 50574], "temperature": 0.0, "avg_logprob": -0.11647542317708333, "compression_ratio": 1.3315217391304348, "no_speech_prob": 0.02468799613416195}, {"id": 257, "seek": 108544, "start": 1089.8400000000001, "end": 1098.6000000000001, "text": " Teraz gdy otwarte modele staj\u0105 si\u0119 coraz pot\u0119\u017cniejsze, by\u0107 mo\u017ce nied\u0142ugo b\u0119d\u0105 w stanie same zacz\u0105\u0107 pisa\u0107 nowe, jeszcze lepsze przepisy.", "tokens": [50584, 41810, 28405, 4337, 86, 11026, 4391, 306, 342, 11133, 3244, 25899, 1847, 1274, 1427, 44258, 11, 15069, 12034, 32488, 1221, 20746, 26239, 261, 40013, 912, 34430, 8925, 2162, 280, 3837, 2162, 586, 68, 11, 14168, 476, 1878, 1381, 30829, 14169, 13, 51022], "temperature": 0.0, "avg_logprob": -0.11647542317708333, "compression_ratio": 1.3315217391304348, "no_speech_prob": 0.02468799613416195}, {"id": 258, "seek": 108544, "start": 1098.8, "end": 1101.04, "text": " To naprawd\u0119 ekscytuj\u0105ca perspektywa.", "tokens": [51032, 1407, 20970, 30724, 1344, 83, 13263, 496, 868, 32659, 874, 4151, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11647542317708333, "compression_ratio": 1.3315217391304348, "no_speech_prob": 0.02468799613416195}], "language": "pl"}