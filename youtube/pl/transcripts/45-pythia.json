{"text": " Jak w\u0142a\u015bciwie du\u017cy model j\u0119zykowy uczy si\u0119, no, m\u00f3wi\u0107. Cz\u0119sto my\u015blimy o tym, jako takiej czarnej skrzynce, wrzucamy do niej ca\u0142y internet, kr\u0119cimy korbk\u0105 i wychodzi co\u015b, co pisze wiersze, ale co tak naprawd\u0119 dzieje si\u0119 w \u015brodku? To chyba jedna z najwi\u0119kszych zagadek w AI. I to zagadka, kt\u00f3rej wiesz, naukowcy do tej pory nie mogli tak na serio zbada\u0107, bo brakowa\u0142o im kluczowego narz\u0119dzia, laboratorium. Tak, wyobra\u017c sobie, \u017ce chcesz zbada\u0107, jak ro\u015bnie ro\u015blina, ale ka\u017cd\u0105 sadzonk\u0119 masz w innej ziemi i podlewasz j\u0105 inaczej. No, nigdy si\u0119 nie dowie\u017a, co tak naprawd\u0119 na ni\u0105 wp\u0142ywa. Dok\u0142adnie. I wygl\u0105da na to, \u017ce materia\u0142, kt\u00f3ry dzisiaj omawiamy, to w\u0142a\u015bnie opis budowy takiego pierwszego, prawdziwego laboratorium dla du\u017cych modeli j\u0119zykowych. Projekt nazywa si\u0119 Pitya. Zgadza si\u0119. Ale Pitya to nie jest, wiesz, jeden model. To ca\u0142a rodzina. Ca\u0142a rodzina. 16 modeli od malutkiego 70 milionowego po ca\u0142kiem spory 12 miliardowy. I tu jest kluk. Wszystkie co do jednego by\u0142y trenowane na tych samych danych, w tej samej kolejno\u015bci. Czyli wszystkie ro\u015blinki w ko\u0144cu dosta\u0142y t\u0119 sam\u0105 ziemi\u0119 i wod\u0119. W\u0142a\u015bnie. A co wi\u0119cej, badacze udost\u0119pnili nie tylko te gotowe modele, mamy dost\u0119p do 154 zdj\u0119\u0107 zrobionych w trakcie treningu, tak zwanych checkpoints\u00f3w. Dla ka\u017cdego z tych 16 modeli. Dla ka\u017cdego. To jest bezprecedensowe. W ko\u0144cu mo\u017cemy obejrze\u0107 ten proces w zwolnionym tempie. I w\u0142a\u015bnie dlatego dzisiejsza rozmowa b\u0119dzie tak fascynuj\u0105ca. Nie b\u0119dziemy m\u00f3wi\u0107 tylko o tym, jak to laboratorium zbudowano, ale co dzi\u0119ki niemu odkryto. Zgadza si\u0119. Artyku\u0142 prezentuje kilka niesamowitych studi\u00f3w w przypadku, kt\u00f3re no troch\u0119 podwa\u017caj\u0105 nasze intuicje. Dobrze, to rozpakujmy to. Ale zanim przejdziemy do tych odkry\u0107 musz\u0119 zapyta\u0107. Dlaczego to by\u0142o a\u017c tak potrzebne? Mieli\u015bmy przecie\u017c wcze\u015bniej otwarte modele. Jak gibitineo czy bloom. Czego im brakowa\u0142o? Mmm, naukowych dyscypliny. Dyscypliny? Tak. To by\u0142y \u015bwietne modele in\u017cynteryjne, ale nie narz\u0119dzia naukowe. Jeden by\u0142 tenowany na tym, inny na tamtym, inna kolejno\u015b\u0107 danych, a liczba publicznie dost\u0119pnych checkpoint\u00f3w by\u0142a powiedzmy minimalna. Cz\u0119sto tylko ten ostatni. Czyli nie da\u0142o si\u0119 wyci\u0105ga\u0107 powtarzalnych wniosk\u00f3w. Dok\u0142adnie. To by\u0142a seria anegdut, a nie kontrolowany eksperyment. Pitya to zmienia. Tutaj sp\u00f3jno\u015b\u0107 by\u0142a wa\u017cniejsza ni\u017c absolutna wydajno\u015b\u0107. To ciekawe, co m\u00f3wisz o tej sp\u00f3jno\u015bci ponad wydajno\u015bci\u0105. W artykule jest fragment, kt\u00f3ry mnie zaintrygowa\u0142. Autorzy \u015bwiadomie u\u017cyli tej samej architektury we wszystkich modelach. Nawet tych ma\u0142ych. Zastosowali co\u015b, co nazywaj\u0105 parallel attention. A przecie\u017c wszystkie poradniki m\u00f3wi\u0105, \u017ce to nie jest optymalne dla ma\u0142ych modeli. W\u0142a\u015bnie. Zrobili to dla tej naukowej czysto\u015bci. Chcieli mie\u0107 tylko jedn\u0105 zmienn\u0105. Skale. Rozmiar modelu. A nie dwie. Czyli skal\u0119 i architektur\u0119. Dok\u0142adnie. Gdyby zmienili architektur\u0119, nie byliby pewni, czy to, co widz\u0105 wynika ze skaly, czy z innej budowy. I tu dochodzimy do pierwszego ma\u0142ego zaskoczenia. No w\u0142a\u015bnie, bo spodziewa\u0142abym si\u0119, \u017ce te mniejsze modele Pity b\u0119d\u0105 przez to po prostu s\u0142absze od konkurencji. A okaza\u0142o si\u0119, \u017ce wcale nie. Naprawd\u0119? Tak. Mimo tej teoretycznie suboptymalnej decyzji, modele Pity osi\u0105gaj\u0105 wydajno\u015b\u0107 por\u00f3wnywaln\u0105 z modelami OPT o tej samej wielko\u015bci. A te by\u0142y budowane ju\u017c, wiesz, zgodnie ze sztuk\u0105 dla maksymalizacji wydajno\u015bci. Czyli ju\u017c na etapie budowy narz\u0119dzia dokonali pierwszego odkrycia. Mo\u017cna tak powiedzie\u0107. To pokazuje, \u017ce niekt\u00f3re z naszych najlepszych praktyk mog\u0105 nie by\u0107 tak kluczowe, jak nam si\u0119 wydawa\u0142o. Co z danymi? U\u017cyto zbioru Depile, ale tu te\u017c zrobili co\u015b ciekawego. Stworzyli dwie wersje ca\u0142ej rodziny modeli. Tak, to kolejna genialna zmienna kontrolna. Jeden zestaw, 16 modeli, wytrenowano na oryginalnym Depile. A drugi, r\u00f3wnoleg\u0142y, na tym samym zbiorze, ale po usuni\u0119ciu duplikat\u00f3w. \u017beby bezpo\u015brednio zbada\u0107, jaki jest wp\u0142yw duplikat\u00f3w. I znowu, wbrew powszechnemu przekonaniu, okaza\u0142o si\u0119, \u017ce w tym przypadku deduplikacja nie da\u0142a jakiej\u015b wiesz jednoznacznej poprawy wynik\u00f3w. Ok, czyli mamy to niesamowite, kontrolowane laboratorium, czas na eksperymenty. Pierwszy temat, za kt\u00f3ry si\u0119 zabrali, jest niezwykle wa\u017cny. Gender bias, tendencyjno\u015b\u0107 zwi\u0105zana z p\u0142ci\u0105. Wiemy, \u017ce modele j\u0105 przejmuj\u0105 z danych, ale. Czy da si\u0119 co\u015b z tym zrobi\u0107 ju\u017c na etapie pretreningu? No to jest w\u0142a\u015bnie pytanie za milion dolar\u00f3w. Zazwyczaj z bias walczy si\u0119 p\u00f3\u017aniej na etapie fine tuning. A tutaj badacze spr\u00f3bowali czego\u015b innego. Wzi\u0119li kilka modeli PTA, ale nie te finalne, tylko checkpoints z samego ko\u0144ca treningu. A potem wznowili ten trening na ostatnim, malutkim fragmencie danych. Ostatnich siedmiu procentach. Czekaj, czyli model trollowa\u0142 si\u0119, powiedzmy, przez 93% czasu na normalnych danych. A na sam koniec podmienili mu t\u0119 ko\u0144c\u00f3wk\u0119. Co w niej zmienili? Zrobili bardzo prost\u0105, ale sprytn\u0105 rzecz. W tym ostatnim fragmenciku zamienili wszystkie zajmki m\u0119skie na ich \u017ce\u0144skie odpowiedniki. Tyle. Tylko tyle. Tylko tyle. Pytanie brzmia\u0142o. Czy taka interwencja na ostatniej prostej mo\u017ce wp\u0142yn\u0105\u0107 na bias ca\u0142ego modelu? I co zadzia\u0142a\u0142o? Na tak ma\u0142ego wycinka danych na samym ko\u0144cu mog\u0142a odwr\u00f3ci\u0107 efekt tysi\u0119cy godzin wcze\u015bniejszego treningu. To brzmi zbyt prosto, \u017ceby by\u0142o prawdziwe. A jednak efekt by\u0142 wyra\u017any i mierzalny. Na specjalistycznym benchmarku Winobayas, kt\u00f3ry w\u0142a\u015bnie mierzy stereotypowe skojarzenia. Modele po tej interwencji mia\u0142y znacznie mniejsz\u0105 tendencyjno\u015b\u0107. Znacznie mniejsz\u0105? Tak. A w przypadku najwi\u0119kszego testowanego modelu 6,9 miliarda parametr\u00f3w sta\u0142o si\u0119 co\u015b jeszcze bardziej niezwyk\u0142ego. Jego sk\u0142onno\u015b\u0107 do stereotyp\u00f3w nie tylko zmala\u0142a, ale wr\u0119cz si\u0119 odwr\u00f3ci\u0142a. Z modelu prostereotypowego sta\u0142 si\u0119 antystereotypowy. Niesamowite. To tak jakby kto\u015b przeczyta\u0142 wielk\u0105 ksi\u0105\u017ck\u0119, a my na sam koniec podmieniliby\u015bmy mu ostatni rozdzia\u0142. Na taki z innym mora\u0142em. I to ten ostatni rozdzia\u0142 zdefinowa\u0142by jego ostateczne wra\u017cenie. Dok\u0142adnie. To pokazuje, jak plastyczny jest model nawet pod sam koniec pre-trainingu. A czy to dzia\u0142a\u0142o tak samo dobrze dla wszystkich modeli? Co ciekawe, ta metoda by\u0142a tym skuteczniejsza, im wi\u0119kszy by\u0142 model. Czyli wi\u0119ksze modele s\u0105 bardziej wra\u017cliwe na te dane z ko\u0144ca. Wygl\u0105da na to, \u017ce tak. Z perspektywy praktycznej to jest ogromnie wa\u017cne odkrycie. Pokazuje, \u017ce mamy now\u0105 metod\u0119 walki z BIAS-em. Celowana interwencja w dane, kt\u00f3ra nie wymaga kosztownego fine tuningu. A tylko dzi\u0119ki Pityom mogli mie\u0107 pewne, \u017ce to zas\u0142uga tej zmiany, a nie czego\u015b innego. W\u0142a\u015bnie. Bo znali dok\u0142adn\u0105 kolejno\u015b\u0107 danych. To by\u0142a jedyna zmienna. To co powiedzia\u0142e\u015b o wp\u0142ywie danych z samego ko\u0144ca treningu, od razu rodzi inne pytanie. Intuicja podpowiada, \u017ce model powinien te dane nie tylko lepiej wykorzystywa\u0107, ale te\u017c lepiej pami\u0119ta\u0107. Jak wygl\u0105da kwestia zapami\u0119tywania, czyli memorization? To by\u0142a dok\u0142adnie hipoteza, kt\u00f3r\u0105 badacze postanowili sprawdzi\u0107. Teoretycznie ma to sens, prawda? Modele Transformer dzia\u0142aj\u0105 iteracyjnie, ci\u0105gle aktualizuj\u0105 swoj\u0105 wiedz\u0119. Informacje, kt\u00f3re napotykaj\u0105 p\u00f3\u017aniej, maj\u0105 jakby mniej czasu, \u017ceby si\u0119 rozp\u0142yn\u0105\u0107 w sieci, wi\u0119c powinny by\u0107 \u0142atwiejsze do odtworzenia s\u0142owu w s\u0142owu. Czyli id\u0105c z tym tropem, je\u015bli mam w danych jakie\u015b wra\u017cliwe informacje, to najbezpieczniej by\u0142oby umie\u015bcicie na samym pocz\u0105tku zbioru treningowego. \u017beby model zd\u0105\u017cy\u0142 je zapomnie\u0107, to by\u0142aby bardzo konkretna wskaz\u00f3wka. By\u0142aby. Gdyby by\u0142a prawdziwa. Jak to? I to jest chyba najbardziej szokuj\u0105ce odkrycie w ca\u0142ym tym artykule. Okaza\u0142o si\u0119, \u017ce ta hipoteza jest kompletnie b\u0142\u0119dna. Czekaj, chcesz powiedzie\u0107, \u017ce nie ma znaczenia, czy wra\u017cliwe dane damy na pocz\u0105tku, w \u015brodku czy na ko\u0144cu? \u017be szansa na ich zapami\u0119tanie jest zawsze taka sama? To brzmi jak herezja. Ale jednak dane nie k\u0142ami\u0105. Wykazali, \u017ce kolejno\u015b\u0107 danych ma znikomy wp\u0142yw na to, czy dana sekwencja zostanie zapami\u0119tana. Co wi\u0119cej, odkryli, \u017ce zjawisko memorization w czasie jest procesem losowym. Losowym? Tak. I idealnie opisuje go model matematyczny znany jako Poisson Point Process. Ok. A co to oznacza w praktyce? Dla kogo\u015b, kto nie jest statystykiem? Oznacza to, \u017ce zapami\u0119tywanie jest jak spadaj\u0105ce krople deszciu w czasie mrzawki. Uderzaj\u0105 losowo, ale ze sta\u0142\u0105, \u015bredni\u0105 cz\u0119stotliwo\u015bci\u0105. Aha. Nie przewidzisz, gdzie spadnie nast\u0119pna kropla, ale wiesz, \u017ce w ci\u0105gu minuty spadnie ich mniej wi\u0119cej tyle samo. I tak samo jest z memorization. W ka\u017cdej partii danych, oboj\u0119tnie czy na pocz\u0105tku czy na ko\u0144cu, model zapami\u0119ta \u015brednio tyle samo fragment\u00f3w. Ryzyko jest sta\u0142e przez ca\u0142y czas. Dok\u0142adnie. Ale czy to na pewno jest takie proste? Bo trudno mi w to uwierzy\u0107. Wykluczyli inne czynniki? W\u0142a\u015bnie w tym jest si\u0142a tego eksperymentu. Mieli dost\u0119p do setek check point\u00f3w, mogli precyzyjnie sprawdzi\u0107, kiedy co zosta\u0142o zapami\u0119tane. A dow\u00f3d jest wr\u0119cz namacalny. W artyku\u0142y jest taki wykres. QQ plot. Jak go zobaczy\u0142em, to musia\u0142em si\u0119 chwil\u0119 przyjrze\u0107, bo wydawa\u0142 si\u0119 zbyt idealny. Co na nim wida\u0107? Punkty, kt\u00f3re reprezentuj\u0105 rzeczywiste dane, uk\u0142adaj\u0105 si\u0119 na idealnie prostej linii, kt\u00f3ra reprezentuje ten teoretyczny rozk\u0142ad P\u0142asona. To pot\u0119\u017cny dow\u00f3d. A implikacja jest brutalnie prosta. Tak. Nie da si\u0119 schowa\u0107 wra\u017aliwych danych na pocz\u0105tku treningu. Strategia ukryj i zapomnij po prostu nie dzia\u0142a. Dobrze, to by\u0142o naprawd\u0119 mocne. Musk mi paruje. Przejd\u017amy do ostatniego studium przypadku, kt\u00f3re jest r\u00f3wnie fascynuj\u0105ce. Memorization to jedno, a faktyczne uczenie si\u0119 to drugie. Wiemy, \u017ce modele lepiej radz\u0105 sobie z faktami, kt\u00f3re cz\u0119sto pojawiaj\u0105 si\u0119 w danych. Ale kiedy model za\u0142apuje t\u0119 zale\u017cno\u015b\u0107? To jest w\u0142a\u015bnie pytanie o tzw. zdolno\u015bci emergentne. Te, kt\u00f3re pojawiaj\u0105 si\u0119 nagle po osi\u0105gni\u0119ciu pewnej skali. I zn\u00f3w dost\u0119p do ca\u0142ej osi czasu treningu by\u0142 tu kluczowy. Wzi\u0119li modele i testowali je na zadaniach wymagaj\u0105cych wiedz\u0119 arytmetyce i kwizach typu trivia QA. I \u015bledzili, jak zmienia si\u0119 jedna konkretna rzecz. Dok\u0142adnie. Korelacja mi\u0119dzy tym, jak cz\u0119sto w danych pojawia si\u0119 jaki\u015b termin, a tym, czy model odpowiada poprawnie. Czyli obserwowali ten proces nauki, klatka po klatce i co zobaczyli, czy ta zdolno\u015b\u0107 pojawia\u0142a si\u0119 stopniowo? W\u0142a\u015bnie nie. I to jest fascynuj\u0105ce. Zobaczyli co\u015b, co nazwali znacz\u0105c\u0105 zmian\u0105 fazow\u0105. Zmian\u0105 fazow\u0105? Tak. To nie by\u0142 p\u0142ynny proces. Przez d\u0142ugi czas, przez prawie po\u0142ow\u0119 treningu tej korelacji praktycznie nie by\u0142o. A\u017c tu nagle, po oko\u0142o 65 tys. krok\u00f3w, czyli w 45% ca\u0142ego procesu, nast\u0119powa\u0142 klik. Klik. Tak. W modelach od 2,8 miliarda parametr\u00f3w w g\u00f3r\u0119 nagle pojawia\u0142a si\u0119 silna, pozytywna korelacja. Model zaczyna urozumie\u0107, \u017ce cz\u0119stotliwo\u015b\u0107 ma znaczenie. Wow, czyli to jest ten moment AHA. Jak ucze\u0144, kt\u00f3ry przez p\u00f3\u0142 roku wkuwa na pami\u0119\u0107 daty, a potem nagle wszystko zaskakuje i zaczyna rozumie\u0107 histori\u0119. To niesamowite, \u017ce mo\u017cna wskaza\u0107 ten konkretny punkt na osi czasu. Dok\u0142adnie. A co wa\u017cne, w mniejszych modelach ten moment AHA nigdy nie nast\u0119powa\u0142. Po prostu nie mia\u0142y wystarczaj\u0105cej mocy, \u017ceby dokona\u0107 tego przeskoku. W\u0142a\u015bnie. To pokazuje, \u017ce zdolno\u015bci emergentne to nie tylko kwestia ostatecznego rozmiaru modelu, ale te\u017c tego krytycznego punktu w czasie treningu. To wiedza o dynamice, a nie tylko o ko\u0144cowym rezultacie. OK, to spr\u00f3bujmy zebra\u0107 te wszystkie rewolucyjne odkrycia. Co to wszystko oznacza? My\u015bl\u0119, \u017ce mo\u017cna to zebra\u0107 w kilka kluczowych punkt\u00f3w. Po pierwsze, mamy wreszcie publiczne otwarty laboratorium do badania LLMS, kt\u00f3re pozwala na prawdziw\u0105 nauk\u0119, a nie tylko in\u017cynieri\u0119. Po drugie. Odkryli\u015bmy, \u017ce niekt\u00f3re z naszych \u015bwi\u0119tych kr\u00f3w, jak optymalna architektura czy absolutna konieczno\u015b\u0107 deduplikacji, mog\u0105 by\u0107 mniej istotne ni\u017c s\u0105dzili\u015bmy. Po trzecie, i to jest bardzo praktyczne, dowiedzieli\u015bmy si\u0119, \u017ce mo\u017cemy aktywnie kszta\u0142towa\u0107 zachowanie modelu, np. redukowa\u0107 bias przez bardzo precyzyjne interwencje. I po czwarte, chyba najbardziej kontrintuicyjne, \u017ce memorization jest procesem losowym w czasie. Ta wiedza o rozk\u0142adzie p\u0142asona sama w sobie zmieni to, jak my\u015bli si\u0119 o bezpiecze\u0144stwie danych. I na koniec po pi\u0105te. Solno\u015bci, kt\u00f3re podziwiamy w du\u017cych modelach, nie pojawiaj\u0105 si\u0119 liniowo. Maj\u0105 swoje momenty na rodzin, gwa\u0142towne, zmiany fazowe. To wszystko sprawia wra\u017cenie, \u017ce naprawd\u0119 przechodzimy od etapu budowania coraz wi\u0119kszych czarnych skrzynek do pr\u00f3by zrozumienia, jaka jest w \u015brodku instalacja elektryczna. A Pitya to jak dostarczenie ca\u0142ej spo\u0142eczno\u015bci naukowej schematu w tej instalacji. Zdecydowanie. I nasuwa mi si\u0119 taka my\u015bl na koniec, kt\u00f3ra wykracza troch\u0119 poza sam artyku\u0142. Pokazano tu, \u017ce mo\u017cna zmniejszy\u0107 bajas modyfikuj\u0105c zajmki. Ale to otwiera ca\u0142\u0105 puszk\u0119 pandory z pytaniami, jakie inne, bardziej subtelne w\u0142a\u015bciwo\u015bci statystyczne danych mo\u017cna by w ten spos\u00f3b modyfikowa\u0107. Co masz na my\u015bli? No, czy mogliby\u015bmy na przyk\u0142ad w ostatnich 10% treningu delikatnie zwi\u0119kszy\u0107 cz\u0119stotliwo\u015b\u0107 wyst\u0119powania pewnych wzorc\u00f3w logicznego rozumowania? Albo metafor. \u017beby zaszczepi\u0107 w modelu konkretne zdolno\u015bci bez pe\u0142nego fine tuning? W\u0142a\u015bnie. To rodzi fundamentalne tykrynie. Czy granica mi\u0119dzy pretreningiem a fajnym tuningiem jest tak ostra, jak nam si\u0119 wydaje? A mo\u017ce istnieje ca\u0142e nieodkryte jeszcze spektrum interwencji treningowych, kt\u00f3re pozwol\u0105 nam precyzyjnie rze\u017abi\u0107 umys\u0142y tych maszyn? My\u015bl\u0119, \u017ce dopiero zaczynamy to odkrywa\u0107.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.88, "text": " Jak w\u0142a\u015bciwie du\u017cy model j\u0119zykowy uczy si\u0119, no, m\u00f3wi\u0107.", "tokens": [50364, 15029, 50108, 1581, 7735, 2316, 49055, 74, 10089, 344, 6522, 3244, 11, 572, 11, 13489, 12757, 13, 50658], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 1, "seek": 0, "start": 5.88, "end": 9.6, "text": " Cz\u0119sto my\u015blimy o tym, jako takiej czarnej skrzynce,", "tokens": [50658, 383, 11052, 20875, 48633, 4197, 88, 277, 8107, 11, 17123, 38941, 6472, 289, 11794, 1110, 13047, 77, 384, 11, 50844], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 2, "seek": 0, "start": 9.6, "end": 15.8, "text": " wrzucamy do niej ca\u0142y internet, kr\u0119cimy korbk\u0105 i wychodzi co\u015b, co pisze wiersze,", "tokens": [50844, 928, 89, 1311, 7804, 360, 2838, 73, 35226, 4705, 11, 15913, 1274, 66, 13189, 14784, 65, 26304, 741, 4628, 34616, 19241, 11, 598, 26584, 1381, 261, 4890, 1381, 11, 51154], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 3, "seek": 0, "start": 15.8, "end": 18.56, "text": " ale co tak naprawd\u0119 dzieje si\u0119 w \u015brodku?", "tokens": [51154, 6775, 598, 991, 20970, 17953, 2884, 3244, 261, 28580, 5279, 30, 51292], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 4, "seek": 0, "start": 18.56, "end": 21.400000000000002, "text": " To chyba jedna z najwi\u0119kszych zagadek w AI.", "tokens": [51292, 1407, 31532, 5232, 629, 710, 48636, 1694, 28051, 27001, 762, 74, 261, 7318, 13, 51434], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 5, "seek": 0, "start": 21.400000000000002, "end": 26.12, "text": " I to zagadka, kt\u00f3rej wiesz, naukowcy do tej pory nie mogli tak na serio zbada\u0107,", "tokens": [51434, 286, 281, 27001, 345, 2330, 11, 36023, 261, 15347, 11, 35616, 74, 305, 1344, 360, 12573, 280, 827, 2838, 13172, 2081, 991, 1667, 49531, 710, 65, 1538, 2162, 11, 51670], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 6, "seek": 0, "start": 26.12, "end": 29.76, "text": " bo brakowa\u0142o im kluczowego narz\u0119dzia, laboratorium.", "tokens": [51670, 748, 1548, 74, 5528, 5249, 566, 9671, 1311, 89, 26576, 6714, 89, 6298, 40395, 11, 5938, 41679, 13, 51852], "temperature": 0.0, "avg_logprob": -0.15435946844761667, "compression_ratio": 1.4026402640264026, "no_speech_prob": 0.002795608015730977}, {"id": 7, "seek": 2976, "start": 29.76, "end": 34.480000000000004, "text": " Tak, wyobra\u017c sobie, \u017ce chcesz zbada\u0107, jak ro\u015bnie ro\u015blina,", "tokens": [50364, 9118, 11, 4628, 24393, 1427, 13652, 11, 3561, 417, 887, 89, 710, 65, 1538, 2162, 11, 4207, 744, 12221, 744, 19212, 1426, 11, 50600], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 8, "seek": 2976, "start": 34.480000000000004, "end": 39.36, "text": " ale ka\u017cd\u0105 sadzonk\u0119 masz w innej ziemi i podlewasz j\u0105 inaczej.", "tokens": [50600, 6775, 21912, 67, 1611, 4227, 35296, 15724, 2300, 89, 261, 294, 11794, 16503, 3057, 741, 2497, 306, 6569, 89, 35692, 33230, 16920, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 9, "seek": 2976, "start": 39.36, "end": 42.36, "text": " No, nigdy si\u0119 nie dowie\u017a, co tak naprawd\u0119 na ni\u0105 wp\u0142ywa.", "tokens": [50844, 883, 11, 26996, 3173, 3244, 2838, 9459, 414, 10659, 11, 598, 991, 20970, 1667, 3867, 1611, 32444, 6825, 4151, 13, 50994], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 10, "seek": 2976, "start": 42.36, "end": 46.96, "text": " Dok\u0142adnie. I wygl\u0105da na to, \u017ce materia\u0142, kt\u00f3ry dzisiaj omawiamy,", "tokens": [50994, 29768, 10358, 2766, 13, 286, 32015, 1667, 281, 11, 3561, 2389, 8908, 11, 9913, 25772, 3406, 1607, 2918, 88, 11, 51224], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 11, "seek": 2976, "start": 46.96, "end": 54.08, "text": " to w\u0142a\u015bnie opis budowy takiego pierwszego, prawdziwego laboratorium dla du\u017cych modeli j\u0119zykowych.", "tokens": [51224, 281, 14234, 45477, 3265, 10089, 32296, 27623, 27725, 11, 41175, 3992, 826, 1571, 5938, 41679, 12285, 1581, 7735, 339, 2316, 72, 49055, 74, 19605, 13, 51580], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 12, "seek": 2976, "start": 54.08, "end": 55.84, "text": " Projekt nazywa si\u0119 Pitya.", "tokens": [51580, 34804, 20151, 88, 4151, 3244, 430, 507, 64, 13, 51668], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 13, "seek": 2976, "start": 55.84, "end": 59.36, "text": " Zgadza si\u0119. Ale Pitya to nie jest, wiesz, jeden model.", "tokens": [51668, 1176, 70, 345, 2394, 3244, 13, 9366, 430, 507, 64, 281, 2838, 3492, 11, 261, 15347, 11, 12906, 2316, 13, 51844], "temperature": 0.0, "avg_logprob": -0.13925590270604843, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0047385781072080135}, {"id": 14, "seek": 5936, "start": 59.36, "end": 61.36, "text": " To ca\u0142a rodzina. Ca\u0142a rodzina.", "tokens": [50364, 1407, 1335, 5024, 28607, 1426, 13, 7544, 5024, 28607, 1426, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12546737988789877, "compression_ratio": 1.434959349593496, "no_speech_prob": 0.012767438776791096}, {"id": 15, "seek": 5936, "start": 61.36, "end": 68.32, "text": " 16 modeli od malutkiego 70 milionowego po ca\u0142kiem spory 12 miliardowy.", "tokens": [50464, 3165, 2316, 72, 3611, 2806, 325, 42349, 5285, 1962, 313, 26576, 714, 35224, 26116, 637, 827, 2272, 1962, 72, 515, 10089, 13, 50812], "temperature": 0.0, "avg_logprob": -0.12546737988789877, "compression_ratio": 1.434959349593496, "no_speech_prob": 0.012767438776791096}, {"id": 16, "seek": 5936, "start": 68.32, "end": 74.72, "text": " I tu jest kluk. Wszystkie co do jednego by\u0142y trenowane na tych samych danych, w tej samej kolejno\u015bci.", "tokens": [50812, 286, 2604, 3492, 9671, 2034, 13, 343, 10424, 22872, 598, 360, 5232, 11858, 26366, 23136, 23066, 1667, 15180, 3247, 16384, 274, 34644, 11, 261, 12573, 912, 73, 23749, 16438, 13, 51132], "temperature": 0.0, "avg_logprob": -0.12546737988789877, "compression_ratio": 1.434959349593496, "no_speech_prob": 0.012767438776791096}, {"id": 17, "seek": 5936, "start": 74.72, "end": 79.12, "text": " Czyli wszystkie ro\u015blinki w ko\u0144cu dosta\u0142y t\u0119 sam\u0105 ziemi\u0119 i wod\u0119.", "tokens": [51132, 37099, 31723, 744, 19212, 41917, 261, 26470, 12032, 274, 8638, 6825, 32489, 3247, 1611, 16503, 3057, 1274, 741, 47751, 1274, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12546737988789877, "compression_ratio": 1.434959349593496, "no_speech_prob": 0.012767438776791096}, {"id": 18, "seek": 5936, "start": 79.12, "end": 83.76, "text": " W\u0142a\u015bnie. A co wi\u0119cej, badacze udost\u0119pnili nie tylko te gotowe modele,", "tokens": [51352, 343, 5024, 12221, 13, 316, 598, 26004, 11, 1578, 326, 1381, 11727, 555, 18085, 77, 2312, 2838, 13219, 535, 658, 6880, 4391, 306, 11, 51584], "temperature": 0.0, "avg_logprob": -0.12546737988789877, "compression_ratio": 1.434959349593496, "no_speech_prob": 0.012767438776791096}, {"id": 19, "seek": 8376, "start": 83.76, "end": 89.76, "text": " mamy dost\u0119p do 154 zdj\u0119\u0107 zrobionych w trakcie treningu, tak zwanych checkpoints\u00f3w.", "tokens": [50364, 17335, 48209, 360, 2119, 19, 49026, 2162, 44399, 313, 16384, 261, 944, 74, 4260, 2192, 773, 84, 11, 991, 11873, 34644, 1520, 20552, 3901, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 20, "seek": 8376, "start": 89.76, "end": 91.76, "text": " Dla ka\u017cdego z tych 16 modeli.", "tokens": [50664, 413, 875, 21912, 67, 6308, 710, 15180, 3165, 2316, 72, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 21, "seek": 8376, "start": 91.76, "end": 94.76, "text": " Dla ka\u017cdego. To jest bezprecedensowe.", "tokens": [50764, 413, 875, 21912, 67, 6308, 13, 1407, 3492, 10782, 3712, 1232, 694, 6880, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 22, "seek": 8376, "start": 94.76, "end": 98.76, "text": " W ko\u0144cu mo\u017cemy obejrze\u0107 ten proces w zwolnionym tempie.", "tokens": [50914, 343, 26470, 12032, 26500, 36346, 73, 13503, 2162, 2064, 17565, 261, 11873, 14110, 313, 4199, 1383, 9144, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 23, "seek": 8376, "start": 98.76, "end": 102.56, "text": " I w\u0142a\u015bnie dlatego dzisiejsza rozmowa b\u0119dzie tak fascynuj\u0105ca.", "tokens": [51114, 286, 14234, 32205, 9758, 50117, 82, 2394, 35234, 5528, 10562, 991, 30632, 1344, 77, 13263, 496, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 24, "seek": 8376, "start": 102.56, "end": 108.76, "text": " Nie b\u0119dziemy m\u00f3wi\u0107 tylko o tym, jak to laboratorium zbudowano, ale co dzi\u0119ki niemu odkryto.", "tokens": [51304, 12016, 31966, 13489, 12757, 13219, 277, 8107, 11, 4207, 281, 5938, 41679, 710, 18281, 305, 3730, 11, 6775, 598, 45003, 2838, 20140, 3611, 43298, 1353, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 25, "seek": 8376, "start": 108.76, "end": 109.76, "text": " Zgadza si\u0119.", "tokens": [51614, 1176, 70, 345, 2394, 3244, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1337017260099712, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.011984141543507576}, {"id": 26, "seek": 10976, "start": 109.76, "end": 115.76, "text": " Artyku\u0142 prezentuje kilka niesamowitych studi\u00f3w w przypadku, kt\u00f3re no troch\u0119 podwa\u017caj\u0105 nasze intuicje.", "tokens": [50364, 1587, 874, 5279, 1221, 659, 14185, 13008, 36466, 48100, 335, 305, 507, 339, 972, 72, 3901, 261, 41955, 11, 8864, 572, 24926, 2497, 27111, 11133, 43394, 560, 84, 299, 2884, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 27, "seek": 10976, "start": 115.76, "end": 117.76, "text": " Dobrze, to rozpakujmy to.", "tokens": [50664, 29679, 13503, 11, 281, 9544, 45944, 4579, 2226, 281, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 28, "seek": 10976, "start": 117.76, "end": 121.76, "text": " Ale zanim przejdziemy do tych odkry\u0107 musz\u0119 zapyta\u0107.", "tokens": [50764, 9366, 710, 17869, 8325, 73, 13096, 2226, 360, 15180, 3611, 43298, 2162, 1038, 11052, 14223, 88, 42931, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 29, "seek": 10976, "start": 121.76, "end": 123.76, "text": " Dlaczego to by\u0142o a\u017c tak potrzebne?", "tokens": [50964, 413, 75, 39329, 281, 14811, 48134, 991, 37595, 716, 30, 51064], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 30, "seek": 10976, "start": 123.76, "end": 126.76, "text": " Mieli\u015bmy przecie\u017c wcze\u015bniej otwarte modele.", "tokens": [51064, 376, 23099, 10513, 8325, 40082, 40785, 4337, 86, 11026, 4391, 306, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 31, "seek": 10976, "start": 126.76, "end": 130.76, "text": " Jak gibitineo czy bloom. Czego im brakowa\u0142o?", "tokens": [51214, 15029, 4553, 270, 533, 78, 6430, 26899, 13, 383, 27725, 566, 1548, 74, 5528, 5249, 30, 51414], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 32, "seek": 10976, "start": 130.76, "end": 132.76, "text": " Mmm, naukowych dyscypliny.", "tokens": [51414, 12146, 11, 35616, 74, 19605, 15243, 1344, 564, 3519, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 33, "seek": 10976, "start": 132.76, "end": 133.76, "text": " Dyscypliny?", "tokens": [51514, 413, 749, 1344, 564, 3519, 30, 51564], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 34, "seek": 10976, "start": 133.76, "end": 137.76, "text": " Tak. To by\u0142y \u015bwietne modele in\u017cynteryjne, ale nie narz\u0119dzia naukowe.", "tokens": [51564, 9118, 13, 1407, 26366, 8299, 39083, 716, 4391, 306, 294, 1427, 2534, 12733, 73, 716, 11, 6775, 2838, 6714, 89, 6298, 40395, 35616, 74, 6880, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1071748193704857, "compression_ratio": 1.4191419141914192, "no_speech_prob": 0.06262829899787903}, {"id": 35, "seek": 13776, "start": 137.76, "end": 141.76, "text": " Jeden by\u0142 tenowany na tym, inny na tamtym, inna kolejno\u015b\u0107 danych,", "tokens": [50364, 508, 6876, 16673, 2064, 23341, 1667, 8107, 11, 294, 1634, 1667, 7677, 874, 76, 11, 294, 629, 23749, 23293, 274, 34644, 11, 50564], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 36, "seek": 13776, "start": 141.76, "end": 145.76, "text": " a liczba publicznie dost\u0119pnych checkpoint\u00f3w by\u0142a powiedzmy minimalna.", "tokens": [50564, 257, 6169, 89, 4231, 1908, 89, 2766, 48209, 9399, 42269, 3901, 23936, 27617, 2226, 13206, 629, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 37, "seek": 13776, "start": 145.76, "end": 147.76, "text": " Cz\u0119sto tylko ten ostatni.", "tokens": [50764, 383, 11052, 20875, 13219, 2064, 32686, 3722, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 38, "seek": 13776, "start": 147.76, "end": 150.76, "text": " Czyli nie da\u0142o si\u0119 wyci\u0105ga\u0107 powtarzalnych wniosk\u00f3w.", "tokens": [50864, 37099, 2838, 1120, 5249, 3244, 4628, 34381, 3680, 2162, 3388, 23480, 89, 304, 9399, 45368, 2717, 23849, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 39, "seek": 13776, "start": 150.76, "end": 154.76, "text": " Dok\u0142adnie. To by\u0142a seria anegdut, a nie kontrolowany eksperyment.", "tokens": [51014, 29768, 10358, 2766, 13, 1407, 23936, 20809, 364, 1146, 67, 325, 11, 257, 2838, 14373, 6623, 23341, 30724, 610, 88, 518, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 40, "seek": 13776, "start": 154.76, "end": 155.76, "text": " Pitya to zmienia.", "tokens": [51214, 430, 507, 64, 281, 17020, 18811, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 41, "seek": 13776, "start": 155.76, "end": 159.76, "text": " Tutaj sp\u00f3jno\u015b\u0107 by\u0142a wa\u017cniejsza ni\u017c absolutna wydajno\u015b\u0107.", "tokens": [51264, 41819, 637, 18999, 23293, 23936, 27777, 30295, 2394, 28502, 18757, 629, 25984, 1805, 23293, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 42, "seek": 13776, "start": 159.76, "end": 164.76, "text": " To ciekawe, co m\u00f3wisz o tej sp\u00f3jno\u015bci ponad wydajno\u015bci\u0105.", "tokens": [51464, 1407, 30596, 2330, 826, 11, 598, 13489, 23848, 277, 12573, 637, 18999, 16438, 9224, 345, 25984, 1805, 16438, 1611, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07523886362711589, "compression_ratio": 1.5226480836236933, "no_speech_prob": 0.006747060921043158}, {"id": 43, "seek": 16476, "start": 164.76, "end": 167.76, "text": " W artykule jest fragment, kt\u00f3ry mnie zaintrygowa\u0142.", "tokens": [50364, 343, 594, 874, 74, 2271, 3492, 26424, 11, 9913, 17661, 710, 5114, 627, 70, 30105, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 44, "seek": 16476, "start": 167.76, "end": 172.76, "text": " Autorzy \u015bwiadomie u\u017cyli tej samej architektury we wszystkich modelach.", "tokens": [50514, 6049, 284, 1229, 21485, 345, 40120, 34097, 2081, 12573, 912, 73, 3912, 642, 2320, 2598, 321, 34234, 2316, 608, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 45, "seek": 16476, "start": 172.76, "end": 173.76, "text": " Nawet tych ma\u0142ych.", "tokens": [50764, 40315, 302, 15180, 463, 47655, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 46, "seek": 16476, "start": 173.76, "end": 177.76, "text": " Zastosowali co\u015b, co nazywaj\u0105 parallel attention.", "tokens": [50814, 1176, 525, 329, 305, 5103, 19241, 11, 598, 20151, 27112, 11133, 8952, 3202, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 47, "seek": 16476, "start": 177.76, "end": 182.76, "text": " A przecie\u017c wszystkie poradniki m\u00f3wi\u0105, \u017ce to nie jest optymalne dla ma\u0142ych modeli.", "tokens": [51014, 316, 8325, 40082, 31723, 1515, 345, 77, 9850, 46591, 11, 3561, 281, 2838, 3492, 2427, 4199, 304, 716, 12285, 463, 47655, 2316, 72, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 48, "seek": 16476, "start": 182.76, "end": 186.76, "text": " W\u0142a\u015bnie. Zrobili to dla tej naukowej czysto\u015bci.", "tokens": [51264, 343, 5024, 12221, 13, 1176, 16614, 2312, 281, 12285, 12573, 35616, 74, 21091, 6430, 20875, 6199, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 49, "seek": 16476, "start": 186.76, "end": 188.76, "text": " Chcieli mie\u0107 tylko jedn\u0105 zmienn\u0105.", "tokens": [51464, 761, 537, 10148, 35612, 13219, 5232, 13113, 17020, 1053, 13113, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 50, "seek": 16476, "start": 188.76, "end": 190.76, "text": " Skale. Rozmiar modelu.", "tokens": [51564, 7324, 1220, 13, 43313, 3057, 289, 2316, 84, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 51, "seek": 16476, "start": 190.76, "end": 193.76, "text": " A nie dwie. Czyli skal\u0119 i architektur\u0119.", "tokens": [51664, 316, 2838, 274, 8699, 13, 37099, 16890, 1274, 741, 3912, 642, 2320, 374, 1274, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0648846187089619, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.03197244182229042}, {"id": 52, "seek": 19376, "start": 193.76, "end": 197.76, "text": " Dok\u0142adnie. Gdyby zmienili architektur\u0119, nie byliby pewni,", "tokens": [50364, 29768, 10358, 2766, 13, 460, 3173, 2322, 17020, 1053, 2312, 3912, 642, 2320, 374, 1274, 11, 2838, 538, 38270, 88, 520, 895, 72, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 53, "seek": 19376, "start": 197.76, "end": 201.76, "text": " czy to, co widz\u0105 wynika ze skaly, czy z innej budowy.", "tokens": [50564, 6430, 281, 11, 598, 5274, 8925, 31936, 5439, 5277, 1110, 5222, 11, 6430, 710, 294, 11794, 3265, 10089, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 54, "seek": 19376, "start": 201.76, "end": 204.76, "text": " I tu dochodzimy do pierwszego ma\u0142ego zaskoczenia.", "tokens": [50764, 286, 2604, 9243, 378, 89, 13189, 360, 27623, 27725, 463, 1221, 6308, 710, 3863, 905, 14320, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 55, "seek": 19376, "start": 204.76, "end": 210.76, "text": " No w\u0142a\u015bnie, bo spodziewa\u0142abym si\u0119, \u017ce te mniejsze modele Pity b\u0119d\u0105 przez to po prostu s\u0142absze od konkurencji.", "tokens": [50914, 883, 14234, 11, 748, 637, 378, 89, 1093, 64, 1221, 2509, 76, 3244, 11, 3561, 535, 275, 44258, 4391, 306, 430, 507, 26239, 14064, 281, 714, 19518, 15116, 17243, 1381, 3611, 21428, 9873, 19649, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 56, "seek": 19376, "start": 210.76, "end": 212.76, "text": " A okaza\u0142o si\u0119, \u017ce wcale nie.", "tokens": [51214, 316, 3133, 12257, 5249, 3244, 11, 3561, 261, 37088, 2838, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 57, "seek": 19376, "start": 212.76, "end": 213.76, "text": " Naprawd\u0119?", "tokens": [51314, 18287, 20098, 30, 51364], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 58, "seek": 19376, "start": 213.76, "end": 218.76, "text": " Tak. Mimo tej teoretycznie suboptymalnej decyzji,", "tokens": [51364, 9118, 13, 376, 6934, 12573, 535, 418, 45586, 1422, 5747, 4199, 304, 11794, 979, 37433, 4013, 11, 51614], "temperature": 0.0, "avg_logprob": -0.08805004979523134, "compression_ratio": 1.3977695167286246, "no_speech_prob": 0.015276161953806877}, {"id": 59, "seek": 21876, "start": 218.76, "end": 224.76, "text": " modele Pity osi\u0105gaj\u0105 wydajno\u015b\u0107 por\u00f3wnywaln\u0105 z modelami OPT o tej samej wielko\u015bci.", "tokens": [50364, 4391, 306, 430, 507, 3003, 11404, 70, 11133, 25984, 1805, 23293, 1515, 812, 895, 27112, 304, 13113, 710, 2316, 4526, 23324, 51, 277, 12573, 912, 73, 20570, 4093, 6199, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07138296961784363, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03539727255702019}, {"id": 60, "seek": 21876, "start": 224.76, "end": 230.76, "text": " A te by\u0142y budowane ju\u017c, wiesz, zgodnie ze sztuk\u0105 dla maksymalizacji wydajno\u015bci.", "tokens": [50664, 316, 535, 26366, 3265, 23066, 10678, 11, 261, 15347, 11, 710, 21787, 2766, 5277, 262, 2682, 2034, 1611, 12285, 963, 3187, 5579, 590, 13152, 25984, 1805, 16438, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07138296961784363, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03539727255702019}, {"id": 61, "seek": 21876, "start": 230.76, "end": 234.76, "text": " Czyli ju\u017c na etapie budowy narz\u0119dzia dokonali pierwszego odkrycia.", "tokens": [50964, 37099, 10678, 1667, 47634, 414, 3265, 10089, 6714, 89, 6298, 40395, 360, 18295, 5103, 27623, 27725, 3611, 43298, 2755, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07138296961784363, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03539727255702019}, {"id": 62, "seek": 21876, "start": 234.76, "end": 235.76, "text": " Mo\u017cna tak powiedzie\u0107.", "tokens": [51164, 44736, 629, 991, 27886, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07138296961784363, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03539727255702019}, {"id": 63, "seek": 21876, "start": 235.76, "end": 242.76, "text": " To pokazuje, \u017ce niekt\u00f3re z naszych najlepszych praktyk mog\u0105 nie by\u0107 tak kluczowe, jak nam si\u0119 wydawa\u0142o.", "tokens": [51214, 1407, 13010, 43317, 11, 3561, 2838, 43073, 265, 710, 45002, 41903, 1878, 28051, 3206, 74, 874, 74, 34123, 2838, 15069, 991, 9671, 1311, 89, 6880, 11, 4207, 8835, 3244, 25984, 10449, 5249, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07138296961784363, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03539727255702019}, {"id": 64, "seek": 24276, "start": 242.76, "end": 244.76, "text": " Co z danymi?", "tokens": [50364, 3066, 710, 274, 1325, 3057, 30, 50464], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 65, "seek": 24276, "start": 244.76, "end": 248.76, "text": " U\u017cyto zbioru Depile, ale tu te\u017c zrobili co\u015b ciekawego.", "tokens": [50464, 624, 7735, 1353, 710, 33362, 84, 4056, 794, 11, 6775, 2604, 9516, 44399, 2312, 19241, 30596, 2330, 826, 1571, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 66, "seek": 24276, "start": 248.76, "end": 251.76, "text": " Stworzyli dwie wersje ca\u0142ej rodziny modeli.", "tokens": [50664, 745, 28321, 1229, 2081, 274, 8699, 261, 433, 2884, 47631, 73, 28607, 3519, 2316, 72, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 67, "seek": 24276, "start": 251.76, "end": 254.76, "text": " Tak, to kolejna genialna zmienna kontrolna.", "tokens": [50814, 9118, 11, 281, 23749, 629, 48228, 629, 17020, 26143, 14373, 6623, 629, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 68, "seek": 24276, "start": 254.76, "end": 259.76, "text": " Jeden zestaw, 16 modeli, wytrenowano na oryginalnym Depile.", "tokens": [50964, 508, 6876, 37889, 1607, 11, 3165, 2316, 72, 11, 261, 4328, 1095, 305, 3730, 1667, 420, 88, 1494, 304, 12996, 4056, 794, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 69, "seek": 24276, "start": 259.76, "end": 265.76, "text": " A drugi, r\u00f3wnoleg\u0142y, na tym samym zbiorze, ale po usuni\u0119ciu duplikat\u00f3w.", "tokens": [51214, 316, 4110, 72, 11, 11416, 895, 4812, 70, 6825, 11, 1667, 8107, 3247, 4199, 710, 33362, 1381, 11, 6775, 714, 505, 409, 5034, 30795, 1581, 564, 36300, 3901, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 70, "seek": 24276, "start": 265.76, "end": 269.76, "text": " \u017beby bezpo\u015brednio zbada\u0107, jaki jest wp\u0142yw duplikat\u00f3w.", "tokens": [51514, 46864, 2322, 10782, 2259, 1788, 986, 41084, 710, 65, 1538, 2162, 11, 24492, 3492, 32444, 6825, 86, 1581, 564, 36300, 3901, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08380398585878569, "compression_ratio": 1.388235294117647, "no_speech_prob": 0.777299165725708}, {"id": 71, "seek": 26976, "start": 270.76, "end": 278.76, "text": " I znowu, wbrew powszechnemu przekonaniu, okaza\u0142o si\u0119, \u017ce w tym przypadku deduplikacja nie da\u0142a jakiej\u015b wiesz jednoznacznej poprawy wynik\u00f3w.", "tokens": [50414, 286, 710, 3785, 84, 11, 261, 65, 2236, 280, 1509, 1381, 1377, 37552, 29785, 266, 25849, 11, 3133, 12257, 5249, 3244, 11, 3561, 261, 8107, 41955, 4172, 44810, 1035, 23395, 2838, 1120, 5024, 4207, 7764, 1788, 261, 15347, 5232, 1771, 22672, 14875, 11794, 1665, 5131, 88, 31936, 1035, 3901, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 72, "seek": 26976, "start": 278.76, "end": 284.76, "text": " Ok, czyli mamy to niesamowite, kontrolowane laboratorium, czas na eksperymenty.", "tokens": [50814, 3477, 11, 16591, 17335, 281, 48100, 335, 305, 642, 11, 14373, 6623, 23066, 5938, 41679, 11, 13190, 1667, 30724, 610, 88, 518, 88, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 73, "seek": 26976, "start": 284.76, "end": 287.76, "text": " Pierwszy temat, za kt\u00f3ry si\u0119 zabrali, jest niezwykle wa\u017cny.", "tokens": [51114, 16676, 30012, 32954, 11, 7949, 9913, 3244, 24838, 2155, 72, 11, 3492, 33511, 9726, 14677, 27777, 1634, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 74, "seek": 26976, "start": 287.76, "end": 291.76, "text": " Gender bias, tendencyjno\u015b\u0107 zwi\u0105zana z p\u0142ci\u0105.", "tokens": [51264, 48039, 12577, 11, 3928, 3020, 73, 23293, 27741, 2095, 710, 28695, 537, 1611, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 75, "seek": 26976, "start": 291.76, "end": 294.76, "text": " Wiemy, \u017ce modele j\u0105 przejmuj\u0105 z danych, ale.", "tokens": [51464, 9233, 2226, 11, 3561, 4391, 306, 35692, 8325, 35195, 13263, 710, 274, 34644, 11, 6775, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 76, "seek": 26976, "start": 294.76, "end": 298.76, "text": " Czy da si\u0119 co\u015b z tym zrobi\u0107 ju\u017c na etapie pretreningu?", "tokens": [51614, 19832, 1120, 3244, 19241, 710, 8107, 31785, 10678, 1667, 47634, 414, 1162, 1095, 7050, 30, 51814], "temperature": 0.0, "avg_logprob": -0.10185133068766815, "compression_ratio": 1.4217252396166133, "no_speech_prob": 0.2699528932571411}, {"id": 77, "seek": 29876, "start": 298.76, "end": 301.76, "text": " No to jest w\u0142a\u015bnie pytanie za milion dolar\u00f3w.", "tokens": [50364, 883, 281, 3492, 14234, 36610, 7949, 1962, 313, 360, 2200, 3901, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 78, "seek": 29876, "start": 301.76, "end": 305.76, "text": " Zazwyczaj z bias walczy si\u0119 p\u00f3\u017aniej na etapie fine tuning.", "tokens": [50514, 1176, 921, 9726, 3689, 1805, 710, 12577, 21346, 6522, 3244, 36968, 1667, 47634, 414, 2489, 15164, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 79, "seek": 29876, "start": 305.76, "end": 308.76, "text": " A tutaj badacze spr\u00f3bowali czego\u015b innego.", "tokens": [50714, 316, 12749, 1578, 326, 1381, 6103, 812, 8202, 5103, 36559, 1788, 294, 11858, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 80, "seek": 29876, "start": 308.76, "end": 314.76, "text": " Wzi\u0119li kilka modeli PTA, ale nie te finalne, tylko checkpoints z samego ko\u0144ca treningu.", "tokens": [50864, 343, 16706, 2081, 36466, 2316, 72, 430, 8241, 11, 6775, 2838, 535, 2572, 716, 11, 13219, 1520, 20552, 710, 912, 1571, 26470, 496, 2192, 773, 84, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 81, "seek": 29876, "start": 314.76, "end": 319.76, "text": " A potem wznowili ten trening na ostatnim, malutkim fragmencie danych.", "tokens": [51164, 316, 36513, 24809, 3785, 2312, 2064, 2192, 773, 1667, 32686, 39223, 11, 2806, 325, 25112, 9241, 2558, 4260, 274, 34644, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 82, "seek": 29876, "start": 319.76, "end": 321.76, "text": " Ostatnich siedmiu procentach.", "tokens": [51414, 422, 19435, 77, 480, 262, 1091, 3057, 84, 38826, 608, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 83, "seek": 29876, "start": 321.76, "end": 326.76, "text": " Czekaj, czyli model trollowa\u0142 si\u0119, powiedzmy, przez 93% czasu na normalnych danych.", "tokens": [51514, 383, 19878, 1805, 11, 16591, 2316, 20680, 30105, 3244, 11, 27617, 2226, 11, 14064, 28876, 4, 40860, 1667, 2710, 9399, 274, 34644, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09423061803723058, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004850031342357397}, {"id": 84, "seek": 32676, "start": 326.76, "end": 329.76, "text": " A na sam koniec podmienili mu t\u0119 ko\u0144c\u00f3wk\u0119.", "tokens": [50364, 316, 1667, 3247, 5897, 35733, 2497, 76, 1053, 2312, 2992, 32489, 26470, 29268, 15724, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 85, "seek": 32676, "start": 329.76, "end": 330.76, "text": " Co w niej zmienili?", "tokens": [50514, 3066, 261, 2838, 73, 17020, 1053, 2312, 30, 50564], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 86, "seek": 32676, "start": 330.76, "end": 333.76, "text": " Zrobili bardzo prost\u0105, ale sprytn\u0105 rzecz.", "tokens": [50564, 1176, 16614, 2312, 9034, 10293, 1611, 11, 6775, 637, 627, 83, 13113, 36833, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 87, "seek": 32676, "start": 333.76, "end": 339.76, "text": " W tym ostatnim fragmenciku zamienili wszystkie zajmki m\u0119skie na ich \u017ce\u0144skie odpowiedniki.", "tokens": [50714, 343, 8107, 32686, 39223, 9241, 2558, 537, 5279, 19876, 1053, 2312, 31723, 33729, 76, 2984, 275, 1274, 5161, 414, 1667, 1893, 3561, 27125, 414, 36574, 77, 9850, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 88, "seek": 32676, "start": 339.76, "end": 340.76, "text": " Tyle.", "tokens": [51014, 314, 2072, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 89, "seek": 32676, "start": 340.76, "end": 341.76, "text": " Tylko tyle.", "tokens": [51064, 49286, 4093, 39293, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 90, "seek": 32676, "start": 341.76, "end": 342.76, "text": " Tylko tyle.", "tokens": [51114, 49286, 4093, 39293, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 91, "seek": 32676, "start": 342.76, "end": 343.76, "text": " Pytanie brzmia\u0142o.", "tokens": [51164, 430, 4328, 7155, 738, 89, 29958, 5249, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 92, "seek": 32676, "start": 343.76, "end": 348.76, "text": " Czy taka interwencja na ostatniej prostej mo\u017ce wp\u0142yn\u0105\u0107 na bias ca\u0142ego modelu?", "tokens": [51214, 19832, 28017, 728, 15615, 34056, 1667, 32686, 10402, 10293, 40779, 12034, 32444, 1221, 2534, 36374, 1667, 12577, 35224, 6308, 2316, 84, 30, 51464], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 93, "seek": 32676, "start": 348.76, "end": 350.76, "text": " I co zadzia\u0142a\u0142o?", "tokens": [51464, 286, 598, 42788, 89, 25605, 5249, 30, 51564], "temperature": 0.0, "avg_logprob": -0.07680091857910157, "compression_ratio": 1.416, "no_speech_prob": 0.05055427923798561}, {"id": 94, "seek": 35076, "start": 350.76, "end": 358.76, "text": " Na tak ma\u0142ego wycinka danych na samym ko\u0144cu mog\u0142a odwr\u00f3ci\u0107 efekt tysi\u0119cy godzin wcze\u015bniejszego treningu.", "tokens": [50364, 6056, 991, 463, 1221, 6308, 4628, 66, 38989, 274, 34644, 1667, 3247, 4199, 26470, 12032, 13172, 5024, 3611, 7449, 812, 39162, 31482, 8192, 38156, 47303, 3044, 23584, 40785, 15453, 6308, 2192, 773, 84, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 95, "seek": 35076, "start": 358.76, "end": 362.76, "text": " To brzmi zbyt prosto, \u017ceby by\u0142o prawdziwe.", "tokens": [50764, 1407, 738, 89, 3057, 710, 2322, 83, 10293, 78, 11, 11316, 14811, 41175, 3992, 826, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 96, "seek": 35076, "start": 362.76, "end": 366.76, "text": " A jednak efekt by\u0142 wyra\u017any i mierzalny.", "tokens": [50964, 316, 25897, 31482, 8192, 16673, 4628, 424, 10659, 1634, 741, 275, 34602, 304, 1634, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 97, "seek": 35076, "start": 366.76, "end": 372.76, "text": " Na specjalistycznym benchmarku Winobayas, kt\u00f3ry w\u0142a\u015bnie mierzy stereotypowe skojarzenia.", "tokens": [51164, 6056, 46433, 468, 17466, 12996, 18927, 84, 10427, 996, 320, 296, 11, 9913, 14234, 47448, 1229, 41182, 79, 6880, 1110, 78, 10150, 14320, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 98, "seek": 35076, "start": 372.76, "end": 376.76, "text": " Modele po tej interwencji mia\u0142y znacznie mniejsz\u0105 tendencyjno\u015b\u0107.", "tokens": [51464, 20500, 306, 714, 12573, 728, 15615, 19649, 21290, 6825, 15397, 14875, 2766, 275, 30295, 8925, 3928, 3020, 73, 23293, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 99, "seek": 35076, "start": 376.76, "end": 377.76, "text": " Znacznie mniejsz\u0105?", "tokens": [51664, 1176, 77, 14875, 2766, 275, 30295, 8925, 30, 51714], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 100, "seek": 35076, "start": 377.76, "end": 378.76, "text": " Tak.", "tokens": [51714, 9118, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09234607131392868, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.15692554414272308}, {"id": 101, "seek": 37876, "start": 378.76, "end": 386.76, "text": " A w przypadku najwi\u0119kszego testowanego modelu 6,9 miliarda parametr\u00f3w sta\u0142o si\u0119 co\u015b jeszcze bardziej niezwyk\u0142ego.", "tokens": [50364, 316, 261, 41955, 48636, 1694, 27725, 1500, 37345, 6308, 2316, 84, 1386, 11, 24, 1962, 72, 19218, 6220, 27965, 3901, 11135, 5249, 3244, 19241, 14168, 27209, 33511, 9726, 74, 1221, 6308, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 102, "seek": 37876, "start": 386.76, "end": 392.76, "text": " Jego sk\u0142onno\u015b\u0107 do stereotyp\u00f3w nie tylko zmala\u0142a, ale wr\u0119cz si\u0119 odwr\u00f3ci\u0142a.", "tokens": [50764, 508, 6308, 1110, 1221, 266, 23293, 360, 41182, 79, 3901, 2838, 13219, 17020, 5159, 5024, 11, 6775, 928, 1274, 3689, 3244, 3611, 7449, 812, 537, 5024, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 103, "seek": 37876, "start": 392.76, "end": 396.76, "text": " Z modelu prostereotypowego sta\u0142 si\u0119 antystereotypowy.", "tokens": [51064, 1176, 2316, 84, 10293, 323, 6737, 79, 26576, 11135, 1221, 3244, 364, 874, 372, 323, 6737, 79, 10089, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 104, "seek": 37876, "start": 396.76, "end": 397.76, "text": " Niesamowite.", "tokens": [51264, 426, 530, 335, 305, 642, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 105, "seek": 37876, "start": 397.76, "end": 405.76, "text": " To tak jakby kto\u015b przeczyta\u0142 wielk\u0105 ksi\u0105\u017ck\u0119, a my na sam koniec podmieniliby\u015bmy mu ostatni rozdzia\u0142.", "tokens": [51314, 1407, 991, 28976, 32982, 8325, 6522, 46426, 20570, 26304, 39311, 15724, 11, 257, 452, 1667, 3247, 5897, 35733, 2497, 76, 1053, 12722, 88, 10513, 2992, 32686, 3722, 9544, 28168, 8908, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 106, "seek": 37876, "start": 405.76, "end": 407.76, "text": " Na taki z innym mora\u0142em.", "tokens": [51714, 6056, 20065, 710, 294, 12996, 1896, 64, 11126, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07115630827088287, "compression_ratio": 1.45, "no_speech_prob": 0.0015045949257910252}, {"id": 107, "seek": 40776, "start": 407.76, "end": 411.76, "text": " I to ten ostatni rozdzia\u0142 zdefinowa\u0142by jego ostateczne wra\u017cenie.", "tokens": [50364, 286, 281, 2064, 32686, 3722, 9544, 28168, 8908, 710, 20595, 259, 30105, 2322, 26542, 277, 15406, 38491, 7843, 41118, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 108, "seek": 40776, "start": 411.76, "end": 412.76, "text": " Dok\u0142adnie.", "tokens": [50564, 29768, 10358, 2766, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 109, "seek": 40776, "start": 412.76, "end": 417.76, "text": " To pokazuje, jak plastyczny jest model nawet pod sam koniec pre-trainingu.", "tokens": [50614, 1407, 13010, 43317, 11, 4207, 499, 9820, 3689, 1634, 3492, 2316, 22696, 2497, 3247, 5897, 35733, 659, 12, 17227, 1760, 84, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 110, "seek": 40776, "start": 417.76, "end": 420.76, "text": " A czy to dzia\u0142a\u0142o tak samo dobrze dla wszystkich modeli?", "tokens": [50864, 316, 6430, 281, 37903, 5249, 991, 36422, 28335, 12285, 34234, 2316, 72, 30, 51014], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 111, "seek": 40776, "start": 420.76, "end": 424.76, "text": " Co ciekawe, ta metoda by\u0142a tym skuteczniejsza, im wi\u0119kszy by\u0142 model.", "tokens": [51014, 3066, 30596, 2330, 826, 11, 1846, 1131, 13449, 23936, 8107, 1110, 1169, 3689, 30295, 2394, 11, 566, 29968, 1229, 16673, 2316, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 112, "seek": 40776, "start": 424.76, "end": 427.76, "text": " Czyli wi\u0119ksze modele s\u0105 bardziej wra\u017cliwe na te dane z ko\u0144ca.", "tokens": [51214, 37099, 29968, 1381, 4391, 306, 9015, 27209, 7843, 1427, 2081, 826, 1667, 535, 49206, 710, 26470, 496, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 113, "seek": 40776, "start": 427.76, "end": 429.76, "text": " Wygl\u0105da na to, \u017ce tak.", "tokens": [51364, 14458, 7191, 26398, 1667, 281, 11, 3561, 991, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 114, "seek": 40776, "start": 429.76, "end": 432.76, "text": " Z perspektywy praktycznej to jest ogromnie wa\u017cne odkrycie.", "tokens": [51464, 1176, 868, 32659, 874, 9726, 3206, 74, 874, 3689, 11794, 281, 3492, 34416, 298, 2766, 46110, 3611, 43298, 4260, 13, 51614], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 115, "seek": 40776, "start": 432.76, "end": 435.76, "text": " Pokazuje, \u017ce mamy now\u0105 metod\u0119 walki z BIAS-em.", "tokens": [51614, 14958, 43317, 11, 3561, 17335, 586, 1611, 1131, 378, 1274, 1792, 72, 710, 23524, 3160, 12, 443, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05093629676175405, "compression_ratio": 1.5, "no_speech_prob": 0.008471815846860409}, {"id": 116, "seek": 43576, "start": 435.76, "end": 439.76, "text": " Celowana interwencja w dane, kt\u00f3ra nie wymaga kosztownego fine tuningu.", "tokens": [50364, 19967, 40458, 728, 15615, 34056, 261, 49206, 11, 19456, 2838, 29764, 9286, 19532, 2682, 648, 6308, 2489, 15164, 84, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 117, "seek": 43576, "start": 439.76, "end": 444.76, "text": " A tylko dzi\u0119ki Pityom mogli mie\u0107 pewne, \u017ce to zas\u0142uga tej zmiany, a nie czego\u015b innego.", "tokens": [50564, 316, 13219, 45003, 430, 507, 298, 13172, 2081, 35612, 25889, 716, 11, 3561, 281, 26530, 1221, 19364, 12573, 43591, 88, 11, 257, 2838, 36559, 1788, 294, 11858, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 118, "seek": 43576, "start": 444.76, "end": 445.76, "text": " W\u0142a\u015bnie.", "tokens": [50814, 343, 5024, 12221, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 119, "seek": 43576, "start": 445.76, "end": 447.76, "text": " Bo znali dok\u0142adn\u0105 kolejno\u015b\u0107 danych.", "tokens": [50864, 3286, 710, 4660, 72, 45864, 13113, 23749, 23293, 274, 34644, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 120, "seek": 43576, "start": 447.76, "end": 448.76, "text": " To by\u0142a jedyna zmienna.", "tokens": [50964, 1407, 23936, 5232, 88, 629, 17020, 26143, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 121, "seek": 43576, "start": 448.76, "end": 453.76, "text": " To co powiedzia\u0142e\u015b o wp\u0142ywie danych z samego ko\u0144ca treningu, od razu rodzi inne pytanie.", "tokens": [51014, 1407, 598, 48539, 68, 1788, 277, 32444, 6825, 8699, 274, 34644, 710, 912, 1571, 26470, 496, 2192, 773, 84, 11, 3611, 367, 8813, 8685, 3992, 24170, 36610, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 122, "seek": 43576, "start": 453.76, "end": 461.76, "text": " Intuicja podpowiada, \u017ce model powinien te dane nie tylko lepiej wykorzystywa\u0107, ale te\u017c lepiej pami\u0119ta\u0107.", "tokens": [51264, 5681, 84, 299, 2938, 2497, 14701, 39018, 11, 3561, 2316, 27310, 1053, 535, 49206, 2838, 13219, 476, 39699, 43606, 1229, 25134, 25234, 11, 6775, 9516, 476, 39699, 31088, 42931, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 123, "seek": 43576, "start": 461.76, "end": 464.76, "text": " Jak wygl\u0105da kwestia zapami\u0119tywania, czyli memorization?", "tokens": [51664, 15029, 32015, 42035, 654, 14223, 23806, 874, 86, 5609, 11, 16591, 10560, 2144, 30, 51814], "temperature": 0.0, "avg_logprob": -0.09040958285331727, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.000764621829148382}, {"id": 124, "seek": 46576, "start": 465.76, "end": 470.76, "text": " To by\u0142a dok\u0142adnie hipoteza, kt\u00f3r\u0105 badacze postanowili sprawdzi\u0107.", "tokens": [50364, 1407, 23936, 45864, 2766, 8103, 1370, 2394, 11, 37415, 1578, 326, 1381, 2183, 282, 305, 2312, 46192, 28496, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 125, "seek": 46576, "start": 470.76, "end": 473.76, "text": " Teoretycznie ma to sens, prawda?", "tokens": [50614, 1989, 418, 45586, 463, 281, 2923, 11, 43607, 30, 50764], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 126, "seek": 46576, "start": 473.76, "end": 478.76, "text": " Modele Transformer dzia\u0142aj\u0105 iteracyjnie, ci\u0105gle aktualizuj\u0105 swoj\u0105 wiedz\u0119.", "tokens": [50764, 20500, 306, 27938, 260, 27121, 11133, 17138, 31285, 2766, 11, 42398, 22631, 13680, 901, 590, 13263, 49194, 46894, 11052, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 127, "seek": 46576, "start": 478.76, "end": 484.76, "text": " Informacje, kt\u00f3re napotykaj\u0105 p\u00f3\u017aniej, maj\u0105 jakby mniej czasu, \u017ceby si\u0119 rozp\u0142yn\u0105\u0107 w sieci,", "tokens": [51014, 34301, 29293, 11, 8864, 9296, 6737, 74, 11133, 36968, 11, 26064, 28976, 39513, 40860, 11, 11316, 3244, 47576, 1221, 2534, 36374, 261, 2804, 537, 11, 51314], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 128, "seek": 46576, "start": 484.76, "end": 487.76, "text": " wi\u0119c powinny by\u0107 \u0142atwiejsze do odtworzenia s\u0142owu w s\u0142owu.", "tokens": [51314, 16677, 27310, 1634, 15069, 47759, 86, 7764, 82, 1381, 360, 3611, 20270, 284, 14320, 15116, 305, 84, 261, 15116, 305, 84, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 129, "seek": 46576, "start": 487.76, "end": 492.76, "text": " Czyli id\u0105c z tym tropem, je\u015bli mam w danych jakie\u015b wra\u017cliwe informacje,", "tokens": [51464, 37099, 4496, 1611, 66, 710, 8107, 9006, 443, 11, 25630, 13524, 261, 274, 34644, 31163, 7843, 1427, 2081, 826, 1356, 29293, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08204005146754607, "compression_ratio": 1.4175084175084176, "no_speech_prob": 0.00882058683782816}, {"id": 130, "seek": 49276, "start": 492.76, "end": 496.76, "text": " to najbezpieczniej by\u0142oby umie\u015bcicie na samym pocz\u0105tku zbioru treningowego.", "tokens": [50364, 281, 11212, 650, 89, 9144, 3689, 10402, 16673, 13944, 1105, 414, 1788, 66, 28434, 1667, 3247, 4199, 43959, 710, 33362, 84, 2192, 773, 26576, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 131, "seek": 49276, "start": 496.76, "end": 501.76, "text": " \u017beby model zd\u0105\u017cy\u0142 je zapomnie\u0107, to by\u0142aby bardzo konkretna wskaz\u00f3wka.", "tokens": [50564, 46864, 2322, 2316, 16221, 1611, 7735, 1221, 1506, 14223, 298, 2766, 2162, 11, 281, 16673, 2509, 9034, 36500, 629, 261, 5161, 921, 3901, 2330, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 132, "seek": 49276, "start": 501.76, "end": 503.76, "text": " By\u0142aby. Gdyby by\u0142a prawdziwa.", "tokens": [50814, 3146, 1221, 2509, 13, 460, 3173, 2322, 23936, 41175, 3992, 4151, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 133, "seek": 49276, "start": 503.76, "end": 504.76, "text": " Jak to?", "tokens": [50914, 15029, 281, 30, 50964], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 134, "seek": 49276, "start": 504.76, "end": 508.76, "text": " I to jest chyba najbardziej szokuj\u0105ce odkrycie w ca\u0142ym tym artykule.", "tokens": [50964, 286, 281, 3492, 31532, 41857, 7870, 453, 13263, 384, 3611, 43298, 4260, 261, 35224, 4199, 8107, 594, 874, 74, 2271, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 135, "seek": 49276, "start": 508.76, "end": 512.76, "text": " Okaza\u0142o si\u0119, \u017ce ta hipoteza jest kompletnie b\u0142\u0119dna.", "tokens": [51164, 3477, 12257, 5249, 3244, 11, 3561, 1846, 8103, 1370, 2394, 3492, 5207, 14657, 2766, 272, 1221, 6298, 629, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 136, "seek": 49276, "start": 512.76, "end": 519.76, "text": " Czekaj, chcesz powiedzie\u0107, \u017ce nie ma znaczenia, czy wra\u017cliwe dane damy na pocz\u0105tku, w \u015brodku czy na ko\u0144cu?", "tokens": [51364, 383, 19878, 1805, 11, 417, 887, 89, 27886, 11, 3561, 2838, 463, 15397, 326, 14320, 11, 6430, 7843, 1427, 2081, 826, 49206, 2422, 88, 1667, 43959, 11, 261, 28580, 5279, 6430, 1667, 26470, 12032, 30, 51714], "temperature": 0.0, "avg_logprob": -0.06236839905763284, "compression_ratio": 1.4342105263157894, "no_speech_prob": 0.1283431053161621}, {"id": 137, "seek": 51976, "start": 519.76, "end": 522.76, "text": " \u017be szansa na ich zapami\u0119tanie jest zawsze taka sama?", "tokens": [50364, 46864, 7870, 38734, 1667, 1893, 14223, 23806, 83, 7155, 3492, 30964, 28017, 17768, 30, 50514], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 138, "seek": 51976, "start": 522.76, "end": 523.76, "text": " To brzmi jak herezja.", "tokens": [50514, 1407, 738, 89, 3057, 4207, 720, 4371, 2938, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 139, "seek": 51976, "start": 523.76, "end": 525.76, "text": " Ale jednak dane nie k\u0142ami\u0105.", "tokens": [50564, 9366, 25897, 49206, 2838, 350, 20177, 11404, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 140, "seek": 51976, "start": 525.76, "end": 531.76, "text": " Wykazali, \u017ce kolejno\u015b\u0107 danych ma znikomy wp\u0142yw na to, czy dana sekwencja zostanie zapami\u0119tana.", "tokens": [50664, 14458, 74, 921, 5103, 11, 3561, 23749, 23293, 274, 34644, 463, 710, 13123, 8488, 32444, 6825, 86, 1667, 281, 11, 6430, 274, 2095, 17215, 15615, 34056, 31873, 7155, 14223, 23806, 83, 2095, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 141, "seek": 51976, "start": 531.76, "end": 538.76, "text": " Co wi\u0119cej, odkryli, \u017ce zjawisko memorization w czasie jest procesem losowym.", "tokens": [50964, 3066, 26004, 11, 3611, 43298, 2081, 11, 3561, 710, 22199, 43442, 10560, 2144, 261, 42667, 3492, 17565, 443, 1750, 31691, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 142, "seek": 51976, "start": 538.76, "end": 539.76, "text": " Losowym?", "tokens": [51314, 7632, 31691, 30, 51364], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 143, "seek": 51976, "start": 539.76, "end": 545.76, "text": " Tak. I idealnie opisuje go model matematyczny znany jako Poisson Point Process.", "tokens": [51364, 9118, 13, 286, 7157, 2766, 45477, 13008, 352, 2316, 3803, 8615, 17466, 1634, 15397, 1325, 17123, 6165, 30472, 12387, 31093, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 144, "seek": 51976, "start": 545.76, "end": 548.76, "text": " Ok. A co to oznacza w praktyce?", "tokens": [51664, 3477, 13, 316, 598, 281, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 30, 51814], "temperature": 0.0, "avg_logprob": -0.08201698518135178, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03437964245676994}, {"id": 145, "seek": 54876, "start": 548.76, "end": 550.76, "text": " Dla kogo\u015b, kto nie jest statystykiem?", "tokens": [50364, 413, 875, 350, 23515, 1788, 11, 23780, 2838, 3492, 2219, 88, 25134, 26116, 30, 50464], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 146, "seek": 54876, "start": 550.76, "end": 556.76, "text": " Oznacza to, \u017ce zapami\u0119tywanie jest jak spadaj\u0105ce krople deszciu w czasie mrzawki.", "tokens": [50464, 422, 22672, 326, 2394, 281, 11, 3561, 14223, 23806, 874, 86, 7155, 3492, 4207, 637, 1538, 8555, 384, 45909, 781, 730, 89, 30795, 261, 42667, 275, 19390, 1607, 2984, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 147, "seek": 54876, "start": 556.76, "end": 560.76, "text": " Uderzaj\u0105 losowo, ale ze sta\u0142\u0105, \u015bredni\u0105 cz\u0119stotliwo\u015bci\u0105.", "tokens": [50764, 624, 1068, 89, 11133, 1750, 19941, 11, 6775, 5277, 11135, 15926, 11, 8299, 986, 3722, 1611, 18544, 372, 310, 2081, 36476, 1611, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 148, "seek": 54876, "start": 560.76, "end": 561.76, "text": " Aha.", "tokens": [50964, 27448, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 149, "seek": 54876, "start": 561.76, "end": 568.76, "text": " Nie przewidzisz, gdzie spadnie nast\u0119pna kropla, ale wiesz, \u017ce w ci\u0105gu minuty spadnie ich mniej wi\u0119cej tyle samo.", "tokens": [51014, 12016, 39758, 327, 89, 23848, 11, 18922, 637, 345, 2766, 39662, 629, 45909, 29684, 11, 6775, 261, 15347, 11, 3561, 261, 42398, 2794, 923, 6432, 637, 345, 2766, 1893, 39513, 26004, 39293, 36422, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 150, "seek": 54876, "start": 568.76, "end": 570.76, "text": " I tak samo jest z memorization.", "tokens": [51364, 286, 991, 36422, 3492, 710, 10560, 2144, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 151, "seek": 54876, "start": 570.76, "end": 577.76, "text": " W ka\u017cdej partii danych, oboj\u0119tnie czy na pocz\u0105tku czy na ko\u0144cu, model zapami\u0119ta \u015brednio tyle samo fragment\u00f3w.", "tokens": [51464, 343, 21912, 1479, 73, 644, 5597, 274, 34644, 11, 1111, 78, 11115, 83, 2766, 6430, 1667, 43959, 6430, 1667, 26470, 12032, 11, 2316, 14223, 23806, 1328, 8299, 986, 41084, 39293, 36422, 26424, 3901, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07722058503524117, "compression_ratio": 1.5165562913907285, "no_speech_prob": 0.013009527698159218}, {"id": 152, "seek": 57776, "start": 578.76, "end": 580.76, "text": " Ryzyko jest sta\u0142e przez ca\u0142y czas.", "tokens": [50414, 13654, 1229, 4093, 3492, 11135, 19827, 14064, 35226, 13190, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 153, "seek": 57776, "start": 580.76, "end": 581.76, "text": " Dok\u0142adnie.", "tokens": [50514, 29768, 10358, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 154, "seek": 57776, "start": 581.76, "end": 584.76, "text": " Ale czy to na pewno jest takie proste?", "tokens": [50564, 9366, 6430, 281, 1667, 33002, 3492, 15963, 10293, 68, 30, 50714], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 155, "seek": 57776, "start": 584.76, "end": 586.76, "text": " Bo trudno mi w to uwierzy\u0107.", "tokens": [50714, 3286, 32007, 1771, 2752, 261, 281, 23147, 811, 27150, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 156, "seek": 57776, "start": 586.76, "end": 588.76, "text": " Wykluczyli inne czynniki?", "tokens": [50814, 14458, 7837, 1311, 1229, 2081, 24170, 6430, 26384, 9850, 30, 50914], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 157, "seek": 57776, "start": 588.76, "end": 590.76, "text": " W\u0142a\u015bnie w tym jest si\u0142a tego eksperymentu.", "tokens": [50914, 343, 5024, 12221, 261, 8107, 3492, 1511, 5024, 8627, 30724, 610, 88, 518, 84, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 158, "seek": 57776, "start": 590.76, "end": 598.76, "text": " Mieli dost\u0119p do setek check point\u00f3w, mogli precyzyjnie sprawdzi\u0107, kiedy co zosta\u0142o zapami\u0119tane.", "tokens": [51014, 376, 23099, 48209, 360, 992, 916, 1520, 935, 3901, 11, 13172, 2081, 659, 1344, 1229, 73, 2766, 46192, 28496, 11, 18777, 598, 23154, 5249, 14223, 23806, 83, 1929, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 159, "seek": 57776, "start": 598.76, "end": 600.76, "text": " A dow\u00f3d jest wr\u0119cz namacalny.", "tokens": [51414, 316, 9459, 17081, 3492, 928, 1274, 3689, 8835, 326, 304, 1634, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 160, "seek": 57776, "start": 600.76, "end": 602.76, "text": " W artyku\u0142y jest taki wykres.", "tokens": [51514, 343, 594, 874, 5279, 6825, 3492, 20065, 39287, 495, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 161, "seek": 57776, "start": 602.76, "end": 604.76, "text": " QQ plot.", "tokens": [51614, 1249, 48, 7542, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1003731138565961, "compression_ratio": 1.40625, "no_speech_prob": 0.009936735965311527}, {"id": 162, "seek": 60476, "start": 604.76, "end": 608.76, "text": " Jak go zobaczy\u0142em, to musia\u0142em si\u0119 chwil\u0119 przyjrze\u0107, bo wydawa\u0142 si\u0119 zbyt idealny.", "tokens": [50364, 15029, 352, 37273, 11126, 11, 281, 1038, 36368, 3244, 41941, 1274, 6501, 73, 13503, 2162, 11, 748, 25984, 10449, 1221, 3244, 710, 2322, 83, 7157, 1634, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 163, "seek": 60476, "start": 608.76, "end": 610.76, "text": " Co na nim wida\u0107?", "tokens": [50564, 3066, 1667, 24887, 261, 46898, 30, 50664], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 164, "seek": 60476, "start": 610.76, "end": 618.76, "text": " Punkty, kt\u00f3re reprezentuj\u0105 rzeczywiste dane, uk\u0142adaj\u0105 si\u0119 na idealnie prostej linii, kt\u00f3ra reprezentuje ten teoretyczny rozk\u0142ad P\u0142asona.", "tokens": [50664, 25487, 88, 11, 8864, 1085, 265, 14185, 13263, 26297, 86, 8375, 49206, 11, 26769, 46217, 8555, 3244, 1667, 7157, 2766, 10293, 40779, 287, 3812, 72, 11, 19456, 1085, 265, 14185, 13008, 2064, 535, 418, 874, 3689, 1634, 9544, 15317, 430, 1221, 1258, 64, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 165, "seek": 60476, "start": 618.76, "end": 620.76, "text": " To pot\u0119\u017cny dow\u00f3d.", "tokens": [51064, 1407, 1847, 1274, 1427, 1634, 9459, 17081, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 166, "seek": 60476, "start": 620.76, "end": 623.76, "text": " A implikacja jest brutalnie prosta.", "tokens": [51164, 316, 8484, 1035, 23395, 3492, 17878, 2766, 582, 8638, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 167, "seek": 60476, "start": 623.76, "end": 624.76, "text": " Tak.", "tokens": [51314, 9118, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 168, "seek": 60476, "start": 624.76, "end": 627.76, "text": " Nie da si\u0119 schowa\u0107 wra\u017aliwych danych na pocz\u0105tku treningu.", "tokens": [51364, 12016, 1120, 3244, 956, 11445, 7843, 10659, 2081, 9726, 339, 274, 34644, 1667, 43959, 2192, 773, 84, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 169, "seek": 60476, "start": 627.76, "end": 631.76, "text": " Strategia ukryj i zapomnij po prostu nie dzia\u0142a.", "tokens": [51514, 30064, 654, 26769, 627, 73, 741, 14223, 38131, 1718, 714, 19518, 2838, 37903, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 170, "seek": 60476, "start": 631.76, "end": 633.76, "text": " Dobrze, to by\u0142o naprawd\u0119 mocne.", "tokens": [51714, 29679, 13503, 11, 281, 14811, 20970, 34962, 716, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07828570015822785, "compression_ratio": 1.4743589743589745, "no_speech_prob": 0.13025331497192383}, {"id": 171, "seek": 63376, "start": 633.76, "end": 635.76, "text": " Musk mi paruje.", "tokens": [50364, 3569, 74, 2752, 971, 13008, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 172, "seek": 63376, "start": 635.76, "end": 639.76, "text": " Przejd\u017amy do ostatniego studium przypadku, kt\u00f3re jest r\u00f3wnie fascynuj\u0105ce.", "tokens": [50464, 2114, 16920, 67, 10659, 2226, 360, 32686, 2766, 1571, 972, 2197, 41955, 11, 8864, 3492, 11416, 14215, 30632, 1344, 77, 13263, 384, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 173, "seek": 63376, "start": 639.76, "end": 643.76, "text": " Memorization to jedno, a faktyczne uczenie si\u0119 to drugie.", "tokens": [50664, 8731, 284, 2144, 281, 5232, 1771, 11, 257, 33647, 874, 38491, 344, 39043, 3244, 281, 4110, 414, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 174, "seek": 63376, "start": 643.76, "end": 648.76, "text": " Wiemy, \u017ce modele lepiej radz\u0105 sobie z faktami, kt\u00f3re cz\u0119sto pojawiaj\u0105 si\u0119 w danych.", "tokens": [50864, 9233, 2226, 11, 3561, 4391, 306, 476, 39699, 2843, 8925, 13652, 710, 21310, 4526, 11, 8864, 34369, 30655, 48125, 3244, 261, 274, 34644, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 175, "seek": 63376, "start": 648.76, "end": 652.76, "text": " Ale kiedy model za\u0142apuje t\u0119 zale\u017cno\u015b\u0107?", "tokens": [51114, 9366, 18777, 2316, 7949, 1221, 569, 13008, 32489, 710, 45494, 23293, 30, 51314], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 176, "seek": 63376, "start": 652.76, "end": 655.76, "text": " To jest w\u0142a\u015bnie pytanie o tzw. zdolno\u015bci emergentne.", "tokens": [51314, 1407, 3492, 14234, 36610, 277, 256, 14406, 13, 16221, 401, 16438, 4345, 70, 317, 716, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 177, "seek": 63376, "start": 655.76, "end": 659.76, "text": " Te, kt\u00f3re pojawiaj\u0105 si\u0119 nagle po osi\u0105gni\u0119ciu pewnej skali.", "tokens": [51464, 1989, 11, 8864, 30655, 48125, 3244, 297, 15088, 714, 3003, 11404, 70, 35938, 30795, 25889, 11794, 1110, 5103, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07365468722670826, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.009239086881279945}, {"id": 178, "seek": 65976, "start": 659.76, "end": 663.76, "text": " I zn\u00f3w dost\u0119p do ca\u0142ej osi czasu treningu by\u0142 tu kluczowy.", "tokens": [50364, 286, 15397, 3901, 48209, 360, 47631, 73, 3003, 72, 40860, 2192, 773, 84, 16673, 2604, 9671, 1311, 89, 10089, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 179, "seek": 65976, "start": 663.76, "end": 669.76, "text": " Wzi\u0119li modele i testowali je na zadaniach wymagaj\u0105cych wiedz\u0119 arytmetyce i kwizach typu trivia QA.", "tokens": [50564, 343, 16706, 2081, 4391, 306, 741, 1500, 305, 5103, 1506, 1667, 42788, 3782, 608, 29764, 559, 11133, 31306, 46894, 11052, 594, 4328, 76, 2210, 384, 741, 350, 6253, 89, 608, 2125, 84, 48770, 1249, 32, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 180, "seek": 65976, "start": 669.76, "end": 673.76, "text": " I \u015bledzili, jak zmienia si\u0119 jedna konkretna rzecz.", "tokens": [50864, 286, 8299, 1493, 89, 2312, 11, 4207, 17020, 18811, 3244, 5232, 629, 36500, 629, 36833, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 181, "seek": 65976, "start": 673.76, "end": 674.76, "text": " Dok\u0142adnie.", "tokens": [51064, 29768, 10358, 2766, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 182, "seek": 65976, "start": 674.76, "end": 680.76, "text": " Korelacja mi\u0119dzy tym, jak cz\u0119sto w danych pojawia si\u0119 jaki\u015b termin, a tym, czy model odpowiada poprawnie.", "tokens": [51114, 591, 418, 75, 23395, 33964, 8107, 11, 4207, 34369, 261, 274, 34644, 30655, 654, 3244, 34721, 10761, 11, 257, 8107, 11, 6430, 2316, 24314, 39018, 1665, 424, 14215, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 183, "seek": 65976, "start": 680.76, "end": 687.76, "text": " Czyli obserwowali ten proces nauki, klatka po klatce i co zobaczyli, czy ta zdolno\u015b\u0107 pojawia\u0142a si\u0119 stopniowo?", "tokens": [51414, 37099, 12887, 34354, 5103, 2064, 17565, 35616, 2984, 11, 9671, 267, 2330, 714, 9671, 267, 384, 741, 598, 37273, 2081, 11, 6430, 1846, 16221, 401, 23293, 30655, 25605, 3244, 1590, 3722, 19941, 30, 51764], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 184, "seek": 65976, "start": 687.76, "end": 688.76, "text": " W\u0142a\u015bnie nie.", "tokens": [51764, 343, 5024, 12221, 2838, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09474006388922157, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.026302427053451538}, {"id": 185, "seek": 68876, "start": 688.76, "end": 693.76, "text": " I to jest fascynuj\u0105ce. Zobaczyli co\u015b, co nazwali znacz\u0105c\u0105 zmian\u0105 fazow\u0105.", "tokens": [50364, 286, 281, 3492, 30632, 1344, 77, 13263, 384, 13, 1176, 996, 14691, 2081, 19241, 11, 598, 20151, 40054, 15397, 326, 8925, 32557, 43591, 1611, 4375, 30297, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 186, "seek": 68876, "start": 693.76, "end": 694.76, "text": " Zmian\u0105 fazow\u0105?", "tokens": [50614, 1176, 76, 952, 1611, 4375, 30297, 30, 50664], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 187, "seek": 68876, "start": 694.76, "end": 701.76, "text": " Tak. To nie by\u0142 p\u0142ynny proces. Przez d\u0142ugi czas, przez prawie po\u0142ow\u0119 treningu tej korelacji praktycznie nie by\u0142o.", "tokens": [50664, 9118, 13, 1407, 2838, 16673, 28695, 2534, 1634, 17565, 13, 2114, 1381, 89, 44042, 24780, 13190, 11, 14064, 3206, 8699, 714, 1221, 305, 1274, 2192, 773, 84, 12573, 350, 418, 75, 13152, 3206, 74, 45586, 2838, 14811, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 188, "seek": 68876, "start": 701.76, "end": 709.76, "text": " A\u017c tu nagle, po oko\u0142o 65 tys. krok\u00f3w, czyli w 45% ca\u0142ego procesu, nast\u0119powa\u0142 klik.", "tokens": [51014, 316, 1427, 2604, 297, 15088, 11, 714, 45730, 5249, 11624, 38156, 13, 45909, 23849, 11, 16591, 261, 6905, 4, 35224, 6308, 17565, 84, 11, 39662, 30105, 9671, 1035, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 189, "seek": 68876, "start": 709.76, "end": 710.76, "text": " Klik.", "tokens": [51414, 16053, 1035, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 190, "seek": 68876, "start": 710.76, "end": 717.76, "text": " Tak. W modelach od 2,8 miliarda parametr\u00f3w w g\u00f3r\u0119 nagle pojawia\u0142a si\u0119 silna, pozytywna korelacja.", "tokens": [51464, 9118, 13, 343, 2316, 608, 3611, 568, 11, 23, 1962, 72, 19218, 6220, 27965, 3901, 261, 290, 15614, 1274, 297, 15088, 30655, 25605, 3244, 3425, 629, 11, 49358, 874, 86, 629, 350, 418, 75, 23395, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06285896548977146, "compression_ratio": 1.4290657439446366, "no_speech_prob": 0.003540137317031622}, {"id": 191, "seek": 71776, "start": 717.76, "end": 721.76, "text": " Model zaczyna urozumie\u0107, \u017ce cz\u0119stotliwo\u015b\u0107 ma znaczenie.", "tokens": [50364, 17105, 43811, 629, 344, 27857, 449, 414, 2162, 11, 3561, 18544, 372, 310, 2081, 48847, 463, 15397, 326, 16778, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07481644948323568, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.013707204721868038}, {"id": 192, "seek": 71776, "start": 721.76, "end": 733.76, "text": " Wow, czyli to jest ten moment AHA. Jak ucze\u0144, kt\u00f3ry przez p\u00f3\u0142 roku wkuwa na pami\u0119\u0107 daty, a potem nagle wszystko zaskakuje i zaczyna rozumie\u0107 histori\u0119.", "tokens": [50564, 3153, 11, 16591, 281, 3492, 2064, 1623, 316, 4983, 13, 15029, 344, 9680, 5248, 11, 9913, 14064, 47907, 19451, 261, 5279, 4151, 1667, 31088, 2162, 1137, 88, 11, 257, 36513, 297, 15088, 22607, 710, 3863, 514, 13008, 741, 43811, 629, 48797, 414, 2162, 4058, 5034, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07481644948323568, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.013707204721868038}, {"id": 193, "seek": 71776, "start": 733.76, "end": 737.76, "text": " To niesamowite, \u017ce mo\u017cna wskaza\u0107 ten konkretny punkt na osi czasu.", "tokens": [51164, 1407, 48100, 335, 305, 642, 11, 3561, 17790, 261, 5161, 12257, 2162, 2064, 36500, 1634, 39561, 1667, 3003, 72, 40860, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07481644948323568, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.013707204721868038}, {"id": 194, "seek": 71776, "start": 737.76, "end": 743.76, "text": " Dok\u0142adnie. A co wa\u017cne, w mniejszych modelach ten moment AHA nigdy nie nast\u0119powa\u0142.", "tokens": [51364, 29768, 10358, 2766, 13, 316, 598, 46110, 11, 261, 39513, 45021, 2316, 608, 2064, 1623, 316, 4983, 26996, 3173, 2838, 39662, 30105, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07481644948323568, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.013707204721868038}, {"id": 195, "seek": 74376, "start": 744.76, "end": 748.76, "text": " Po prostu nie mia\u0142y wystarczaj\u0105cej mocy, \u017ceby dokona\u0107 tego przeskoku.", "tokens": [50414, 6165, 19518, 2838, 21290, 6825, 4628, 9710, 3689, 11133, 20811, 705, 1344, 11, 11316, 25037, 4037, 2162, 8627, 6541, 279, 74, 13275, 13, 50614], "temperature": 0.0, "avg_logprob": -0.041096617778142296, "compression_ratio": 1.4691780821917808, "no_speech_prob": 0.41564124822616577}, {"id": 196, "seek": 74376, "start": 748.76, "end": 758.76, "text": " W\u0142a\u015bnie. To pokazuje, \u017ce zdolno\u015bci emergentne to nie tylko kwestia ostatecznego rozmiaru modelu, ale te\u017c tego krytycznego punktu w czasie treningu.", "tokens": [50614, 343, 5024, 12221, 13, 1407, 13010, 43317, 11, 3561, 16221, 401, 16438, 4345, 6930, 716, 281, 2838, 13219, 42035, 654, 277, 15406, 3689, 11858, 9544, 3057, 16870, 2316, 84, 11, 6775, 9516, 8627, 34847, 874, 3689, 11858, 39561, 84, 261, 42667, 2192, 773, 84, 13, 51114], "temperature": 0.0, "avg_logprob": -0.041096617778142296, "compression_ratio": 1.4691780821917808, "no_speech_prob": 0.41564124822616577}, {"id": 197, "seek": 74376, "start": 758.76, "end": 762.76, "text": " To wiedza o dynamice, a nie tylko o ko\u0144cowym rezultacie.", "tokens": [51114, 1407, 46894, 2394, 277, 5999, 573, 11, 257, 2838, 13219, 277, 26470, 66, 31691, 48060, 723, 30805, 13, 51314], "temperature": 0.0, "avg_logprob": -0.041096617778142296, "compression_ratio": 1.4691780821917808, "no_speech_prob": 0.41564124822616577}, {"id": 198, "seek": 74376, "start": 762.76, "end": 767.76, "text": " OK, to spr\u00f3bujmy zebra\u0107 te wszystkie rewolucyjne odkrycia. Co to wszystko oznacza?", "tokens": [51314, 2264, 11, 281, 6103, 14216, 4579, 2226, 47060, 2162, 535, 31723, 319, 48481, 1311, 88, 73, 716, 3611, 43298, 2755, 13, 3066, 281, 22607, 277, 22672, 326, 2394, 30, 51564], "temperature": 0.0, "avg_logprob": -0.041096617778142296, "compression_ratio": 1.4691780821917808, "no_speech_prob": 0.41564124822616577}, {"id": 199, "seek": 74376, "start": 767.76, "end": 771.76, "text": " My\u015bl\u0119, \u017ce mo\u017cna to zebra\u0107 w kilka kluczowych punkt\u00f3w.", "tokens": [51564, 1222, 28749, 11, 3561, 17790, 281, 47060, 2162, 261, 36466, 9671, 1311, 89, 19605, 39561, 3901, 13, 51764], "temperature": 0.0, "avg_logprob": -0.041096617778142296, "compression_ratio": 1.4691780821917808, "no_speech_prob": 0.41564124822616577}, {"id": 200, "seek": 77176, "start": 771.76, "end": 780.76, "text": " Po pierwsze, mamy wreszcie publiczne otwarty laboratorium do badania LLMS, kt\u00f3re pozwala na prawdziw\u0105 nauk\u0119, a nie tylko in\u017cynieri\u0119.", "tokens": [50364, 6165, 45994, 11, 17335, 261, 495, 89, 4260, 1908, 43077, 4337, 29587, 88, 5938, 41679, 360, 1578, 5609, 441, 43, 10288, 11, 8864, 40557, 5159, 1667, 41175, 3992, 86, 1611, 35616, 15724, 11, 257, 2838, 13219, 294, 1427, 2534, 811, 5034, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07382125298953751, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00167070550378412}, {"id": 201, "seek": 77176, "start": 780.76, "end": 781.76, "text": " Po drugie.", "tokens": [50814, 6165, 4110, 414, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07382125298953751, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00167070550378412}, {"id": 202, "seek": 77176, "start": 781.76, "end": 791.76, "text": " Odkryli\u015bmy, \u017ce niekt\u00f3re z naszych \u015bwi\u0119tych kr\u00f3w, jak optymalna architektura czy absolutna konieczno\u015b\u0107 deduplikacji, mog\u0105 by\u0107 mniej istotne ni\u017c s\u0105dzili\u015bmy.", "tokens": [50864, 12210, 43298, 38452, 11, 3561, 2838, 43073, 265, 710, 45002, 8299, 22423, 874, 339, 15913, 3901, 11, 4207, 2427, 4199, 304, 629, 3912, 642, 2320, 2991, 6430, 18757, 629, 5897, 414, 3689, 23293, 4172, 44810, 1035, 13152, 11, 34123, 15069, 39513, 1418, 310, 716, 28502, 9015, 28168, 43912, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07382125298953751, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.00167070550378412}, {"id": 203, "seek": 79176, "start": 791.76, "end": 802.76, "text": " Po trzecie, i to jest bardzo praktyczne, dowiedzieli\u015bmy si\u0119, \u017ce mo\u017cemy aktywnie kszta\u0142towa\u0107 zachowanie modelu, np. redukowa\u0107 bias przez bardzo precyzyjne interwencje.", "tokens": [50364, 6165, 22266, 4260, 11, 741, 281, 3492, 9034, 3206, 74, 874, 38491, 11, 9459, 15338, 23099, 10513, 3244, 11, 3561, 26500, 9308, 874, 14215, 350, 15453, 46426, 83, 11445, 29303, 22028, 2316, 84, 11, 33808, 13, 2783, 74, 11445, 272, 4609, 14064, 9034, 659, 1344, 1229, 73, 716, 728, 15615, 44261, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08421707153320312, "compression_ratio": 1.481203007518797, "no_speech_prob": 0.05511023849248886}, {"id": 204, "seek": 79176, "start": 802.76, "end": 809.76, "text": " I po czwarte, chyba najbardziej kontrintuicyjne, \u017ce memorization jest procesem losowym w czasie.", "tokens": [50914, 286, 714, 6472, 86, 11026, 11, 31532, 41857, 14373, 81, 686, 84, 2632, 73, 716, 11, 3561, 10560, 2144, 3492, 17565, 443, 1750, 31691, 261, 42667, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08421707153320312, "compression_ratio": 1.481203007518797, "no_speech_prob": 0.05511023849248886}, {"id": 205, "seek": 79176, "start": 809.76, "end": 815.76, "text": " Ta wiedza o rozk\u0142adzie p\u0142asona sama w sobie zmieni to, jak my\u015bli si\u0119 o bezpiecze\u0144stwie danych.", "tokens": [51264, 6551, 46894, 2394, 277, 9544, 15317, 3283, 28695, 296, 4037, 17768, 261, 13652, 17020, 35462, 281, 11, 4207, 452, 15350, 3244, 277, 47153, 9680, 12229, 8699, 274, 34644, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08421707153320312, "compression_ratio": 1.481203007518797, "no_speech_prob": 0.05511023849248886}, {"id": 206, "seek": 79176, "start": 815.76, "end": 817.76, "text": " I na koniec po pi\u0105te.", "tokens": [51564, 286, 1667, 5897, 35733, 714, 3895, 1611, 975, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08421707153320312, "compression_ratio": 1.481203007518797, "no_speech_prob": 0.05511023849248886}, {"id": 207, "seek": 81776, "start": 817.76, "end": 824.76, "text": " Solno\u015bci, kt\u00f3re podziwiamy w du\u017cych modelach, nie pojawiaj\u0105 si\u0119 liniowo. Maj\u0105 swoje momenty na rodzin, gwa\u0142towne, zmiany fazowe.", "tokens": [50364, 7026, 16438, 11, 8864, 2497, 3992, 86, 2918, 88, 261, 1581, 7735, 339, 2316, 608, 11, 2838, 30655, 48125, 3244, 287, 3812, 19941, 13, 7048, 1611, 29489, 1623, 88, 1667, 8685, 23584, 11, 290, 44603, 30401, 68, 11, 43591, 88, 4375, 6880, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11270316954581969, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.191104918718338}, {"id": 208, "seek": 81776, "start": 824.76, "end": 835.76, "text": " To wszystko sprawia wra\u017cenie, \u017ce naprawd\u0119 przechodzimy od etapu budowania coraz wi\u0119kszych czarnych skrzynek do pr\u00f3by zrozumienia, jaka jest w \u015brodku instalacja elektryczna.", "tokens": [50714, 1407, 22607, 22734, 654, 7843, 41118, 11, 3561, 20970, 8325, 29914, 89, 13189, 3611, 47634, 84, 3265, 21308, 25899, 29968, 28051, 6472, 1083, 16384, 1110, 13047, 23255, 360, 8565, 2322, 710, 27857, 449, 18811, 11, 4207, 64, 3492, 261, 28580, 5279, 34059, 23395, 26991, 627, 3689, 629, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11270316954581969, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.191104918718338}, {"id": 209, "seek": 81776, "start": 835.76, "end": 841.76, "text": " A Pitya to jak dostarczenie ca\u0142ej spo\u0142eczno\u015bci naukowej schematu w tej instalacji.", "tokens": [51264, 316, 430, 507, 64, 281, 4207, 20568, 289, 39043, 47631, 73, 36851, 89, 16438, 35616, 74, 21091, 956, 8615, 84, 261, 12573, 34059, 13152, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11270316954581969, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.191104918718338}, {"id": 210, "seek": 84176, "start": 841.76, "end": 846.76, "text": " Zdecydowanie. I nasuwa mi si\u0119 taka my\u015bl na koniec, kt\u00f3ra wykracza troch\u0119 poza sam artyku\u0142.", "tokens": [50364, 1176, 1479, 1344, 67, 22028, 13, 286, 5382, 84, 4151, 2752, 3244, 28017, 452, 19212, 1667, 5897, 35733, 11, 19456, 39287, 12080, 2394, 24926, 714, 2394, 3247, 594, 874, 5279, 1221, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09260692766734532, "compression_ratio": 1.3400809716599191, "no_speech_prob": 0.7290207147598267}, {"id": 211, "seek": 84176, "start": 846.76, "end": 851.76, "text": " Pokazano tu, \u017ce mo\u017cna zmniejszy\u0107 bajas modyfikuj\u0105c zajmki.", "tokens": [50614, 14958, 921, 3730, 2604, 11, 3561, 17790, 17020, 10402, 7706, 2162, 23589, 296, 275, 843, 31230, 44733, 33729, 76, 2984, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09260692766734532, "compression_ratio": 1.3400809716599191, "no_speech_prob": 0.7290207147598267}, {"id": 212, "seek": 84176, "start": 851.76, "end": 860.76, "text": " Ale to otwiera ca\u0142\u0105 puszk\u0119 pandory z pytaniami, jakie inne, bardziej subtelne w\u0142a\u015bciwo\u015bci statystyczne danych mo\u017cna by w ten spos\u00f3b modyfikowa\u0107.", "tokens": [50864, 9366, 281, 4337, 86, 10609, 1335, 15926, 280, 22378, 15724, 4565, 827, 710, 25878, 282, 15568, 11, 22124, 24170, 11, 27209, 7257, 338, 716, 40112, 36476, 2219, 38593, 17466, 716, 274, 34644, 17790, 538, 261, 2064, 22904, 275, 843, 31230, 11445, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09260692766734532, "compression_ratio": 1.3400809716599191, "no_speech_prob": 0.7290207147598267}, {"id": 213, "seek": 84176, "start": 860.76, "end": 862.76, "text": " Co masz na my\u015bli?", "tokens": [51314, 3066, 2300, 89, 1667, 452, 15350, 30, 51414], "temperature": 0.0, "avg_logprob": -0.09260692766734532, "compression_ratio": 1.3400809716599191, "no_speech_prob": 0.7290207147598267}, {"id": 214, "seek": 86276, "start": 862.76, "end": 871.76, "text": " No, czy mogliby\u015bmy na przyk\u0142ad w ostatnich 10% treningu delikatnie zwi\u0119kszy\u0107 cz\u0119stotliwo\u015b\u0107 wyst\u0119powania pewnych wzorc\u00f3w logicznego rozumowania?", "tokens": [50364, 883, 11, 6430, 13172, 38270, 88, 10513, 1667, 23144, 261, 32686, 77, 480, 1266, 4, 2192, 773, 84, 1103, 36300, 2766, 11873, 5034, 1694, 27150, 18544, 372, 310, 2081, 48847, 48255, 1274, 14701, 5609, 47160, 16384, 24809, 284, 29268, 9952, 89, 11858, 48797, 21308, 30, 50814], "temperature": 0.0, "avg_logprob": -0.10086039702097575, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.06562615931034088}, {"id": 215, "seek": 86276, "start": 871.76, "end": 872.76, "text": " Albo metafor.", "tokens": [50814, 967, 1763, 1131, 2792, 284, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10086039702097575, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.06562615931034088}, {"id": 216, "seek": 86276, "start": 872.76, "end": 876.76, "text": " \u017beby zaszczepi\u0107 w modelu konkretne zdolno\u015bci bez pe\u0142nego fine tuning?", "tokens": [50864, 46864, 2322, 710, 19601, 3689, 595, 12757, 261, 2316, 84, 36500, 716, 16221, 401, 16438, 10782, 43205, 11858, 2489, 15164, 30, 51064], "temperature": 0.0, "avg_logprob": -0.10086039702097575, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.06562615931034088}, {"id": 217, "seek": 86276, "start": 876.76, "end": 880.76, "text": " W\u0142a\u015bnie. To rodzi fundamentalne tykrynie.", "tokens": [51064, 343, 5024, 12221, 13, 1407, 8685, 3992, 8088, 716, 1104, 43298, 2766, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10086039702097575, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.06562615931034088}, {"id": 218, "seek": 86276, "start": 880.76, "end": 887.76, "text": " Czy granica mi\u0119dzy pretreningiem a fajnym tuningiem jest tak ostra, jak nam si\u0119 wydaje?", "tokens": [51264, 19832, 9370, 2262, 33964, 1162, 1095, 278, 4907, 257, 34001, 12996, 15164, 4907, 3492, 991, 277, 19639, 11, 4207, 8835, 3244, 49165, 30, 51614], "temperature": 0.0, "avg_logprob": -0.10086039702097575, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.06562615931034088}, {"id": 219, "seek": 88776, "start": 887.76, "end": 897.76, "text": " A mo\u017ce istnieje ca\u0142e nieodkryte jeszcze spektrum interwencji treningowych, kt\u00f3re pozwol\u0105 nam precyzyjnie rze\u017abi\u0107 umys\u0142y tych maszyn?", "tokens": [50364, 316, 12034, 1418, 2766, 2884, 47631, 2838, 378, 43298, 975, 14168, 768, 2320, 6247, 728, 15615, 19649, 2192, 773, 19605, 11, 8864, 40557, 401, 1611, 8835, 659, 1344, 1229, 73, 2766, 16081, 10659, 5614, 2162, 1105, 749, 6825, 15180, 2300, 1229, 77, 30, 50864], "temperature": 0.0, "avg_logprob": -0.05689519836056617, "compression_ratio": 1.1572327044025157, "no_speech_prob": 0.16464795172214508}, {"id": 220, "seek": 88776, "start": 897.76, "end": 900.76, "text": " My\u015bl\u0119, \u017ce dopiero zaczynamy to odkrywa\u0107.", "tokens": [50864, 1222, 28749, 11, 3561, 21900, 12030, 43811, 5378, 88, 281, 3611, 43298, 25234, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05689519836056617, "compression_ratio": 1.1572327044025157, "no_speech_prob": 0.16464795172214508}], "language": "pl"}