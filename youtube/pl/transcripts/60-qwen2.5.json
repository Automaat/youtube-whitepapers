{"text": " Co by by\u0142o, gdyby istnia\u0142 model sztucznej inteligencji, kt\u00f3ry ma wydajno\u015b\u0107, no wiesz, absolutnego topu, ale jest pi\u0119\u0107 razy mniejszy? Brzmi troch\u0119 jak zagadka, prawda? Ale to nie jest \u017cadna teoria, a rzeczywisto\u015b\u0107 opisana w raporcie technicznym dotycz\u0105cym Quen 2.5. Dzisiaj przyjrzymy si\u0119, jak jego tw\u00f3rcom uda\u0142o si\u0119 dokona\u0107 czego\u015b, co wydaje si\u0119 przeczy\u0107 praw\u0105 skali w \u015bwiecie AI. Nasza misja to zbada\u0107 ich przepis na sukces, bo wygl\u0105da na to, \u017ce nie wystarczy\u0142o po prostu rzuci\u0107 na problem wi\u0119cej mocy obliczeniowej. Oni dzia\u0142ali jak mistrzowie kuchni, analitycy danych i, no nie wiem, psychologowie w jednym. W\u0142a\u015bnie, ten raport to jest naprawd\u0119 fascynuj\u0105ca lektura, bo on odzwierciedla tak\u0105 zmian\u0119 paradygmat\u00f3w ca\u0142ej bran\u017cy. Przez lata mantra brzmia\u0142a wi\u0119kszy znaczy lepszy, wi\u0119cej danych, wi\u0119cej parametr\u00f3w, wi\u0119ksze serwerownie. A Quen 2.5 pokazuje, \u017ce na pierwszy plan wysuwa si\u0119 inteligencja projektu. To, jak m\u0105drze dobierasz sk\u0142adniki i jak finezyjnie prowadzisz ca\u0142y proces, staje si\u0119 wa\u017cniejsze ni\u017c sama, no wiesz, wielko\u015b\u0107. Dobrze, to rozpakujmy ten temat. Czym dok\u0142adnie jest ta nowa rodzina modeli Quen 2.5? Bo z raportu wynika, \u017ce to nie jest jeden monolit, tylko, no, ca\u0142a paleta narz\u0119dzi. Tak, i to jest kluczowe dla zrozumienia ich strategii. Quen 2.5 to ca\u0142a seria modeli j\u0119zykowych, czyli LLMs, zaprojektowana z my\u015bl\u0105 o bardzo r\u00f3\u017cnych zastosowaniach. Mamy tu modele naprawd\u0119 ma\u0142e z zaledwie p\u00f3\u0142 miliarda parametr\u00f3w, kt\u00f3re mog\u0105 dzia\u0142a\u0107 na urz\u0105dzeniach brzegowych, na przyk\u0142ad smartfonach. A z drugiej strony s\u0105 bardzo du\u017ce i pot\u0119\u017cne modele, z siedemdziesi\u0105cioma dwoma miliardami parametr\u00f3w. Co wa\u017cne, seria dzieli si\u0119 na dwie g\u0142\u00f3wne kategorie. Pierwsza to modele OpenWade. Ich m\u00f3zgi s\u0105 publicznie dost\u0119pne dla badaczy i developer\u00f3w, co, wiesz, nap\u0119dza innowacje w ca\u0142ej spo\u0142eczno\u015bci. A druga kategoria to modele w\u0142asno\u015bciowe oferowane komercyjnie przez API, czyli Quen 2.5 Turbo i Quen 2.5 Plus. Czekaj, wspominasz, \u017ce te komercyjne modele u\u017cywaj\u0105 archipektury Mixture of Experts, czyli MOH. To poj\u0119cie cz\u0119sto si\u0119 pojawia, ale rzadko jest tak prosto wyt\u0142umaczone. Co to w\u0142a\u015bciwie oznacza w praktyce? To jest \u015bwietne pytanie. Zamiast my\u015ble\u0107 o modelu jako o jednym, gigantycznym m\u00f3zgu, kt\u00f3ry musi wiedzie\u0107 wszystko, MOH i dzia\u0142a bardziej jak komitet specjalist\u00f3w. Wyobra\u017a sobie, \u017ce masz pytanie dotycz\u0105ce fizyki kwantowej, historii renesansu i pisania kod\u00f3w Pythonie. Zamiast pyta\u0107 jednego, wszechwiedz\u0105cego m\u0119drca, system inteligentnie kieruje ka\u017cde zapytanie do odpowiedniego eksperta w swojej dziedzinie. W danym momencie aktywna jest tylko ma\u0142a cz\u0119\u015b\u0107 ca\u0142ego modelu. To sprawia, \u017ce jest on niewiarygodnie wydajny i szybki, zw\u0142aszcza przy tych bardzo du\u017cych modelach. Rozumiem, czyli to specjalizacja zamiast generalizacji. To ma sens. Ale wr\u00f3czmy do tej niesamowitej tezy z raportu, kt\u00f3ra przyci\u0105gn\u0119\u0142a moj\u0105 uwag\u0119. M\u00f3wimy o tym, \u017ce flagowy model OpenWade, czyli Quen2572B-instrakt, osi\u0105ga wydajno\u015b\u0107 por\u00f3wnywaln\u0105 z modelem Lama345B-instrakt. A ten drugi jest oko\u0142o 5 razy wi\u0119kszy. To brzmi prawie niewiarygodnie. A jednak wyniki to potwierdzaj\u0105. To troch\u0119 tak jakby kto\u015b zbudowa\u0142 silnik do samochodu wy\u015bcigowego, kt\u00f3ry ma osi\u0105gi bolidu Formu\u0142y 1. Ale zu\u017cywa tyle paliwa, co ma\u0142y miejski samoch\u00f3d. I w\u0142a\u015bnie dlatego ten raport jest tak istotny. Pokazuje, \u017ce kluczem nie jest ju\u017c tylko surowa moc, ale przede wszystkim efektywno\u015b\u0107. Jak najwi\u0119cej wydajno\u015bci z jak najmniejszej liczby parametr\u00f3w. To imponuj\u0105ce. No dobrze, ale jak oni to zrobili? Jaki jest ten sekretny sk\u0142adnik? Raport zag\u0142\u0119bia si\u0119 w szczeg\u00f3\u0142y procesu treningowego, kt\u00f3ry wydaje si\u0119 by\u0107 sercem tej innowacji. Zgadza si\u0119. Ca\u0142y proces mo\u017cna podzieli\u0107 na dwa kluczowe etapy. Pre-training, czyli trening wst\u0119pny i post-training, czyli dostrajanie. Fundamentem wszystkiego jest to, co wydarzy\u0142o si\u0119 na pierwszym etapie. W pre-trainingu zwi\u0119kszyli ilo\u015b\u0107 danych treningowych z 7 bilion\u00f3w token\u00f3w do a\u017c 18 bilion\u00f3w. 18 bilion\u00f3w? Ta liczba jest tak abstrakcyjna, \u017ce w zasadzie nic mi nie m\u00f3wi. Mo\u017cesz to jako\u015b zobrazowa\u0107? Biblioteka Kongresu USA. Najwi\u0119ksza biblioteka na \u015bwiecie to oko\u0142o 10 bilion\u00f3w s\u0142\u00f3w. Czyli m\u00f3wimy o danych tekstowych o obj\u0119to\u015bci niemal dw\u00f3ch takich bibliotek. Ale co tu jest naprawd\u0119 fascynuj\u0105ce, to nie sama ilo\u015b\u0107, a inteligentne podej\u015bcie do tego, co wchodzi w sk\u0142ad tych danych. Zauwa\u017cyli, \u017ce dane z internetu s\u0105 zdominowane przez pewne domeny, jak media spo\u0142eczno\u015bciowe czy e-commerce, kt\u00f3re cz\u0119sto zawieraj\u0105 du\u017co szumu. Zmniejszyli wi\u0119c ich udzia\u0142, a zwi\u0119kszyli porcj\u0119 danych wysokiej jako\u015bci z nauki, technologii, kodowania i matematyki. Czyli zamiast karmi\u0107 model wszystkim, co znajd\u0105 w internecie, zrobili mu diet\u0119 bogat\u0105 z najbardziej po\u017cywne sk\u0142adniki. Ale wspominaj\u0105 te\u017c, \u017ce do filtrowania tych danych u\u017cyli swoich poprzednich modelik Juven. Czekaj, czy to nie jest ryzykowne? U\u017cywanie starych modeli do selekcji danych dla nowego nie brzmi jak przepis na, no wiesz, echo chamber, utrwalanie starych b\u0142\u0119d\u00f3w? To jest bardzo trafna uwaga i jedno z kluczowych wyzwa\u0144. Oni pode\u015bli do tego w przemy\u015blany spos\u00f3b. Nie chodzi\u0142o o to, \u017ceby stary model decydowa\u0142, co jest prawd\u0105, ale \u017ceby dzia\u0142a\u0142 jako taki filtr jako\u015bciowy na masow\u0105 skal\u0119. Potrafi\u0142 np. odsia\u0107 zduplikowane tre\u015bci, tekst niskiej jako\u015bci czy spam. To jest zadanie, kt\u00f3re cz\u0142owiekowi zaj\u0119\u0142oby tysi\u0105ce lat. R\u00f3wnocze\u015bnie, jak wspomnia\u0142em, zr\u00f3wnowa\u017cyli to r\u0119cznie zwi\u0119kszaj\u0105c udzia\u0142 danych z zaufanych, wysokiej jako\u015bci \u017ar\u00f3de\u0142. Dodatkowo w\u0142\u0105czyli do diety dane ze swoich modeli wyspecjalizowanych w matematyce i kodowaniu oraz wygenerowali nowe dane syntetyczne. To wszystko razem stworzy\u0142o niezwykle solidny fundament. OK, to ma sens. Czyli po tym etapie mamy model, kt\u00f3ry jest jak gigantyczna, \u015bwietnie zredagowana encyklopedia, ma ogromn\u0105 wiedz\u0119. Ale jak nauczy\u0107 go, \u017ceby by\u0142 faktycznie pomocny? \u017beby nie tylko recytowa\u0142 fakty, ale rozumia\u0142 polecenia i potrafi\u0142 prowadzi\u0107 rozmow\u0119. Czyli tu w\u0142a\u015bnie przechodzimy do drugiego etapu, czyli post-trainingu, gdzie dzieje si\u0119 prawdziwa magia. Surowa wiedza to jedno, ale u\u017cyteczno\u015b\u0107 to zupe\u0142nie inna historia. Tutaj zastosowali bardzo przemy\u015blane dwustopniowe szkolenie z ludzkich preferencji. Najpierw jest Supervised Fine Tuning w skr\u00f3cie SFT. To jak danie modelowi ogromnego podr\u0119cznika z ponad milionem przyk\u0142ad\u00f3w w formacie Pytanie Idealna Odpowied\u017a. Celem by\u0142o wyeliminowanie s\u0142abo\u015bci poprzednich wersji. Na przyk\u0142ad w generowaniu d\u0142ugich, sp\u00f3jnych tekst\u00f3w czy rozumieniu danych w tabelach. Czyli to s\u0105 te ksi\u0105\u017ckowe m\u0105dro\u015bci, ale co z inteligencj\u0105 praktyczn\u0105? Jak nauczy\u0107 go niuans\u00f3w? Dok\u0142adnie. I do tego s\u0142u\u017cy Reinforcement Learning, czyli uczenie przez wzmacnianie. I tu znowu podzielili to na dwa inteligentne kroki. Pierwszy, wykorzystuj\u0105cy technik\u0119 DPO, czyli Direct Preference Optimization, jest jak przej\u015bcie od podr\u0119cznika do pracy z bardzo wymagaj\u0105cym nauczycielem, kt\u00f3ry ma twardy klucz odpowiedzi. Modelowi pokazuje si\u0119 dwie odpowiedzi na to samo pytanie. Jedn\u0105 oznaczon\u0105 jako dobra, drug\u0105 jako z\u0142a. I uczy si\u0119 go, by zawsze preferowa\u0142 t\u0105 lepsz\u0105. To \u015bwietnie dzia\u0142a w zadaniach, gdzie jest jasna odpowied\u017a, jak w rozumowaniu logicznym czy zadaniach matematycznych. Ale przecie\u017c wi\u0119kszo\u015b\u0107 naszych interakcji z AI nie opiera si\u0119 na prostym, dobrze, \u017ale. Oczekujemy, \u017ce odpowied\u017a b\u0119dzie pomocna, zwi\u0119z\u0142a, a czasem nawet kreatywna. Jak to wytrenowa\u0107? I to jest w\u0142a\u015bnie ten ostatni genialny szlif. Druga faza, wykorzystuj\u0105ca nowsz\u0105 technik\u0119 GRPO, czyli Group Relative Policy Optimization, przypomina uko\u0144czenie szko\u0142y i do\u0142\u0105czenie do klubu dyskusyjnego. Tu ju\u017c nie ma jednego prostego klucza odpowiedzi. Model generuje kilka r\u00f3\u017cnych odpowiedzi, a bardzo zaawansowany s\u0119dzia, inny model AI, nazywany reward model, ocenia je i szereguje. Bierze pod uwag\u0119 nie tylko poprawno\u015b\u0107, ale te\u017c styl, pomocno\u015b\u0107, bezpieczne\u0144stwo i zwi\u0119z\u0142o\u015b\u0107. To ju\u017c nie jest nauka fakt\u00f3w, to jest nauka sztuki konwersacji. OK, ten proces treningowy brzmi naprawd\u0119 ukompleksowo, ale czy ca\u0142a ta ci\u0119\u017cka praca prze\u0142o\u017cy\u0142a si\u0119 na wyniki? Sp\u00f3jrzmy na \u015bwiadectwo Q&A 5. Czy w tym raporcie by\u0142 jaki\u015b konkretny wynik, kt\u00f3ry sprawi\u0142, \u017ce pomy\u015bla\u0142a\u015b sobie, wow, to naprawd\u0119 dzia\u0142a? Zdecydowanie. Poza og\u00f3lnymi benchmarkami, gdzie Q&A 5.72B INSTRACT faktycznie pokonuje znacznie wi\u0119kszego Lama 4.5B INSTRACT w zadaniach na kodowanie MBPP czy matematyk\u0119 MAF dla mnie najbardziej uderzaj\u0105cy by\u0142 wynik w te\u015bcie Arena Hard. To jest benchmark, gdzie ostateczn\u0105 ocen\u0119 wydaj\u0105 ludzie, por\u00f3wnuj\u0105c odpowiedzi dw\u00f3ch anonimowych modeli. I tutaj mniejszy Kfen zdeklasowa\u0142 wi\u0119kszego konkurenta. To pokazuje, \u017ce ta ca\u0142a finezja w post-treningu naprawd\u0119 sprawi\u0142a, \u017ce model jest bardziej pomocny i preferowany przez prawdziwych u\u017cytkownik\u00f3w. Ale jest jeszcze jeden test, kt\u00f3ry pokazuje zupe\u0142nie now\u0105 jako\u015b\u0107. Domy\u015blam si\u0119, \u017ce m\u00f3wisz o zdolno\u015bci do pracy z d\u0142ugim kontekstem. S\u0142ynny test i g\u0142\u00f3w z Togusiana. Dok\u0142adnie. Test nazywa si\u0119 PASKY RETRIVAL. Wyja\u015bnimy, na czym polega. Model otrzymuje ekstremalnie d\u0142ugi dokument, powiedzmy na milion token\u00f3w, kt\u00f3ry jest wype\u0142niony losowymi, nieistotnymi informacjami. Gdzie\u015b g\u0142\u0119boko w tym tek\u015bcie ukryta jest jedna kr\u00f3tka informacja. Na przyk\u0142ad zdanie tajny klucz to 1234. Zadaniem modelu jest odnalezienie tego jednego zdania na podstawie prostego pytania. To jest ostateczny test na zdolno\u015b\u0107 do utrzymania uwagi i rozumienia na ogromn\u0105 skal\u0119. I jak sobie z tym poradzi\u0142? Model QN-25 Turbo osi\u0105gn\u0105\u0142 100% skuteczno\u015bci. Znalaz\u0142 klucz za ka\u017cdym razem w tek\u015bcie o d\u0142ugo\u015bci miliona token\u00f3w. \u017beby da\u0107 skal\u0119 to tak, jakby przeczyta\u0107 wojn\u0119 i pok\u00f3j dwa razy i by\u0107 w stanie wskaza\u0107 jedno konkretne losowe zdanie ukryte gdzie\u015b w \u015brodku. To jest dow\u00f3d na niezwyk\u0142\u0105 zdolno\u015b\u0107 do przetwarzania informacji. Niesamowite. Ale czy to jest w og\u00f3le praktyczne przetworzenie miliona token\u00f3w musi trwa\u0107 w wieki? Czy u\u017cytkownik nie umr\u00f3b z nud\u00f3w czekaj\u0105c na odpowied\u017a? I to jest w\u0142a\u015bnie kolejna wisienka na torcie. Dzi\u0119ki technikom optymalizacyjnym takim jak Dual Chunk Attention, DCA i Yarn modele nie tylko radz\u0105 sobie z d\u0142ugim kontekstem, ale robi\u0105 to znacznie szybciej. Wykresy z raportu pokazuj\u0105 od 3x do 4x przyspieszenia w uzyskaniu pierwszej cz\u0119\u015bci odpowiedzi. W metryce Time to First Token, czyli TTFT, QIWEN jest jednym z najszybszych modeli na rynku. To oznacza, \u017ce nie czekasz w niesko\u0144czono\u015b\u0107 na rozpocz\u0119cie generowania odpowiedzi, nawet przy bardzo d\u0142ugich dokumentach. W porz\u0105dku. A wi\u0119c co to wszystko oznacza dla nas developer\u00f3w, badaczy, a nawet no zwyk\u0142ych u\u017cytkownik\u00f3w? Jakie s\u0105 praktyczne implikacje tych osi\u0105gni\u0119\u0107? My\u015bl\u0119, \u017ce s\u0105 co najmniej trzy. Po pierwsze, to dalsza demokratyzacja dost\u0119pu do zaawansowanej AI. Dzi\u0119ki modelom Open Weight, kt\u00f3re s\u0105 tak wydajne, jaki\u015b startup w Warszawie, czy laboratorium uniwersyteckie w Bangalor, mog\u0105 eksperymentowa\u0107 z narz\u0119dziem, kt\u00f3re do niedawna by\u0142o dost\u0119pne tylko dla garstki gigant\u00f3w z Doliny Kszemowej. To obni\u017ca bariery wej\u015bcia i mo\u017ce uwolni\u0107 fale innowacji. A co z nowymi zastosowaniami, kt\u00f3re staj\u0105 si\u0119 mo\u017cliwe dzi\u0119ki tej technologii? Tutaj kluczowa jest w o\u017cgiel zdolno\u015b\u0107 do pracy z d\u0142ugim kontekstem. Otwiera to drzwi do zastosowa\u0144, kt\u00f3re do tej pory by\u0142y, no, w sferze science fiction. Wyobra\u017a sobie lekarza, kt\u00f3ry mo\u017ce wgra\u0107 do AI ostatnie 10 lat dokumentacji medycznej pacjenta. Wszystkie wyniki bada\u0144, wizyty, opisy i zapyta\u0107. Jakich wzorc\u00f3w lub korelacji tutaj nie dostrzegam? Albo analityka finansowego, kt\u00f3ry w kilka minut przetwarza raporty kwartalne, transkrypcj\u0119 rozm\u00f3w z inwestorami i wewn\u0119trzne maile firmy, \u017ceby uzyska\u0107 pe\u0142ny obraz sytuacji. To staje si\u0119 teraz realne. I jest jeszcze trzecia implikacja zapewne zwi\u0105zana z biznesem. Eport jasno pokazuje, \u017ce modele takie jak QN 2.5 Turbo oferuj\u0105 wydajno\u015b\u0107 na poziomie GPT-4O mini, ale przy potencjalnie ni\u017cszych kosztach operacyjnych. Dla firm, kt\u00f3re wdra\u017caj\u0105 AI na du\u017c\u0105 skal\u0119, ka\u017cdy u\u0142amek centa zaprzetworzony token ma znaczenie. Lepsza wydajno\u015b\u0107 przy mniejszym rozmiarze modelu bezpo\u015brednio przek\u0142ada si\u0119 na oszcz\u0119dno\u015bci i zmienia rachunek ekonomiczny dla ca\u0142ych kategorii produkt\u00f3w. Brzmi jak lista samych sukces\u00f3w. Ale przecie\u017c nie wszystko mo\u017ce by\u0107 idealne. Czy w raporcie wspomniano o jakich\u015b ograniczeniach, o drobnym druku? S\u0105 w tej kwestii do\u015b\u0107 transparentni. Wskazuj\u0105 na przyk\u0142ad, \u017ce chocia\u017c model jest bardzo dobry w zadaniach wieloj\u0119zycznych, to wci\u0105\u017c jest pole do poprawy w rozumieniu subtelnych niuans\u00f3w kulturowych w r\u00f3\u017cnych j\u0119zykach. To pokazuje, \u017ce samo t\u0142umaczenie danych nie wystarczy, aby model w pe\u0142ni zrozumia\u0142 kultur\u0119. Ale poruszaj\u0105 te\u017c ciekawszy problem badawczy. To znaczy? Zauwa\u017caj\u0105, \u017ce obecne metody oceny reward models, tych s\u0119dzi\u00f3w w procesie reinforcement learning, nie zawsze idealnie przek\u0142adaj\u0105 si\u0119 na ostateczn\u0105 jako\u015b\u0107 modelu. Innymi s\u0142owy, nawet je\u015bli masz \u015bwietnego s\u0119dziego, nie gwarantuje to, \u017ce tw\u00f3j zawodnik w klubie dyskusyjnym b\u0119dzie najlepszy na \u015bwiecie. To rodzi fundamentalne pytanie. Je\u015bli nie do ko\u0144ca wiemy, jak mierzy\u0107 jako\u015b\u0107 nauczyciela, to jak mo\u017cemy by\u0107 pewni, \u017ce ucze\u0144 jest szkolony w optymalny spos\u00f3b? Dok\u0142adnie. To jest jedno z kluczowych wyzwa\u0144, przed kt\u00f3rymi stoi obecnie ca\u0142a bran\u017ca AI. To, \u017ce autorze raportu otwarcie o tym m\u00f3wi\u0105, pokazuje dojrza\u0142o\u015b\u0107 ich podej\u015bcia i wskazuje kierunki dla przysz\u0142ych bada\u0144. Uje\u017cd\u017c\u0119, \u017ce mamy do czynienia z prawdziwym prze\u0142omem w efektywno\u015bci modeli j\u0119zykowych. Usi\u0105gni\u0119to go nie przez bezmy\u015blne skalowanie, ale przez inteligentne podej\u015bcie do danych i zaawansowany wieloetapowy proces dostrajania, kt\u00f3ry zamienia encyklopedyczn\u0105 wiedz\u0119 w praktyczn\u0105 m\u0105dro\u015b\u0107. My\u015bl\u0119, \u017ce to jest kluczowy wniosek. Era, w kt\u00f3rej wi\u0119kszy automatycznie znaczy\u0142o lepszy, powoli dobiega ko\u0144ca. Teraz na pierwszy plan wysuwa si\u0119 m\u0105drzejszy. M\u0105drzejszy w doborze danych, m\u0105drzejszy w architekturze i m\u0105drzejszy w procesie treningu. Kuwen 2.5 jest tego doskona\u0142ym dowodem. Zostawmy naszych s\u0142uchaczy z jedn\u0105 my\u015bl\u0105. W podsumowaniu raportu autorzy zapowiadaj\u0105 dalsze prace nad modelami multimodalnymi, kt\u00f3re b\u0119d\u0105 w stanie przetwarza\u0107 i \u0142\u0105czy\u0107 tekst, obraz i d\u017awi\u0119k w jednym systemie. Skoro modele staj\u0105 si\u0119 nie tylko wydajniejsze, ale te\u017c bardziej wielozmys\u0142owe, fundamentalne pytanie brzmi. Co nowego mo\u017ce stworzy\u0107 maszyna, kt\u00f3ra b\u0119dzie przetwarza\u0107 \u015bwiat w spos\u00f3b bardziej zbli\u017cony do ludzkiego? Jakie zupe\u0142nie nowe formy kreatywno\u015bci czy naukowe odkrycia mog\u0105 z tego wynikn\u0105\u0107?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.9, "text": " Co by by\u0142o, gdyby istnia\u0142 model sztucznej inteligencji,", "tokens": [50364, 3066, 538, 14811, 11, 28405, 2322, 1418, 77, 8908, 2316, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 11, 50559], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 1, "seek": 0, "start": 3.9, "end": 7.6000000000000005, "text": " kt\u00f3ry ma wydajno\u015b\u0107, no wiesz, absolutnego topu,", "tokens": [50559, 9913, 463, 25984, 1805, 23293, 11, 572, 261, 15347, 11, 18757, 11858, 1192, 84, 11, 50744], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 2, "seek": 0, "start": 7.6000000000000005, "end": 9.5, "text": " ale jest pi\u0119\u0107 razy mniejszy?", "tokens": [50744, 6775, 3492, 32677, 2162, 9639, 88, 39513, 7706, 30, 50839], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 3, "seek": 0, "start": 9.5, "end": 11.4, "text": " Brzmi troch\u0119 jak zagadka, prawda?", "tokens": [50839, 1603, 89, 3057, 24926, 4207, 27001, 345, 2330, 11, 43607, 30, 50934], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 4, "seek": 0, "start": 11.4, "end": 18.6, "text": " Ale to nie jest \u017cadna teoria, a rzeczywisto\u015b\u0107 opisana w raporcie technicznym dotycz\u0105cym Quen 2.5.", "tokens": [50934, 9366, 281, 2838, 3492, 39628, 629, 535, 8172, 11, 257, 26297, 86, 9334, 7753, 45477, 2095, 261, 5099, 284, 4260, 1537, 17946, 12996, 5893, 17466, 1611, 1344, 76, 2326, 268, 568, 13, 20, 13, 51294], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 5, "seek": 0, "start": 18.6, "end": 23.6, "text": " Dzisiaj przyjrzymy si\u0119, jak jego tw\u00f3rcom uda\u0142o si\u0119 dokona\u0107 czego\u015b,", "tokens": [51294, 39448, 22356, 6501, 73, 13047, 2226, 3244, 11, 4207, 26542, 683, 15614, 1112, 44544, 5249, 3244, 25037, 4037, 2162, 36559, 1788, 11, 51544], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 6, "seek": 0, "start": 23.6, "end": 27.6, "text": " co wydaje si\u0119 przeczy\u0107 praw\u0105 skali w \u015bwiecie AI.", "tokens": [51544, 598, 49165, 3244, 8325, 33967, 22508, 1611, 1110, 5103, 261, 40078, 4260, 7318, 13, 51744], "temperature": 0.0, "avg_logprob": -0.16495304107666015, "compression_ratio": 1.4006968641114983, "no_speech_prob": 0.025596491992473602}, {"id": 7, "seek": 2760, "start": 27.6, "end": 30.700000000000003, "text": " Nasza misja to zbada\u0107 ich przepis na sukces,", "tokens": [50364, 16151, 2394, 3346, 2938, 281, 710, 65, 1538, 2162, 1893, 30829, 271, 1667, 46432, 887, 11, 50519], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 8, "seek": 2760, "start": 30.700000000000003, "end": 35.5, "text": " bo wygl\u0105da na to, \u017ce nie wystarczy\u0142o po prostu rzuci\u0107 na problem wi\u0119cej mocy obliczeniowej.", "tokens": [50519, 748, 32015, 1667, 281, 11, 3561, 2838, 4628, 9710, 6522, 5249, 714, 19518, 367, 11728, 39162, 1667, 1154, 26004, 705, 1344, 1111, 1050, 42124, 21091, 13, 50759], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 9, "seek": 2760, "start": 35.5, "end": 41.1, "text": " Oni dzia\u0142ali jak mistrzowie kuchni, analitycy danych i, no nie wiem, psychologowie w jednym.", "tokens": [50759, 1282, 72, 27121, 5103, 4207, 3544, 19390, 13998, 350, 625, 3722, 11, 364, 1860, 1344, 274, 34644, 741, 11, 572, 2838, 26522, 11, 4681, 1132, 13998, 261, 5232, 12996, 13, 51039], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 10, "seek": 2760, "start": 41.1, "end": 45.3, "text": " W\u0142a\u015bnie, ten raport to jest naprawd\u0119 fascynuj\u0105ca lektura,", "tokens": [51039, 343, 5024, 12221, 11, 2064, 5099, 477, 281, 3492, 20970, 30632, 1344, 77, 13263, 496, 476, 2320, 2991, 11, 51249], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 11, "seek": 2760, "start": 45.3, "end": 50.1, "text": " bo on odzwierciedla tak\u0105 zmian\u0119 paradygmat\u00f3w ca\u0142ej bran\u017cy.", "tokens": [51249, 748, 322, 3611, 14406, 811, 537, 292, 875, 31069, 17020, 952, 1274, 13480, 18103, 15677, 3901, 47631, 73, 12029, 7735, 13, 51489], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 12, "seek": 2760, "start": 50.1, "end": 53.3, "text": " Przez lata mantra brzmia\u0142a wi\u0119kszy znaczy lepszy,", "tokens": [51489, 2114, 1381, 89, 46722, 32094, 738, 89, 29958, 5024, 29968, 1229, 36584, 476, 1878, 1229, 11, 51649], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 13, "seek": 2760, "start": 53.3, "end": 57.0, "text": " wi\u0119cej danych, wi\u0119cej parametr\u00f3w, wi\u0119ksze serwerownie.", "tokens": [51649, 26004, 274, 34644, 11, 26004, 6220, 27965, 3901, 11, 29968, 1381, 816, 1554, 648, 414, 13, 51834], "temperature": 0.0, "avg_logprob": -0.09288652539253235, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.035029634833335876}, {"id": 14, "seek": 5700, "start": 57.0, "end": 62.0, "text": " A Quen 2.5 pokazuje, \u017ce na pierwszy plan wysuwa si\u0119 inteligencja projektu.", "tokens": [50364, 316, 2326, 268, 568, 13, 20, 13010, 43317, 11, 3561, 1667, 34016, 1393, 27062, 84, 4151, 3244, 24777, 3213, 34056, 26261, 84, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 15, "seek": 5700, "start": 62.0, "end": 67.1, "text": " To, jak m\u0105drze dobierasz sk\u0142adniki i jak finezyjnie prowadzisz ca\u0142y proces,", "tokens": [50614, 1407, 11, 4207, 275, 18962, 13503, 27082, 811, 19601, 1110, 10358, 77, 9850, 741, 4207, 2489, 1229, 73, 2766, 36590, 89, 23848, 35226, 17565, 11, 50869], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 16, "seek": 5700, "start": 67.1, "end": 70.3, "text": " staje si\u0119 wa\u017cniejsze ni\u017c sama, no wiesz, wielko\u015b\u0107.", "tokens": [50869, 342, 11153, 3244, 27777, 44258, 28502, 17768, 11, 572, 261, 15347, 11, 20570, 4093, 7753, 13, 51029], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 17, "seek": 5700, "start": 70.3, "end": 72.0, "text": " Dobrze, to rozpakujmy ten temat.", "tokens": [51029, 29679, 13503, 11, 281, 9544, 45944, 4579, 2226, 2064, 32954, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 18, "seek": 5700, "start": 72.0, "end": 75.6, "text": " Czym dok\u0142adnie jest ta nowa rodzina modeli Quen 2.5?", "tokens": [51114, 19832, 76, 45864, 2766, 3492, 1846, 586, 64, 28607, 1426, 2316, 72, 2326, 268, 568, 13, 20, 30, 51294], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 19, "seek": 5700, "start": 75.6, "end": 81.8, "text": " Bo z raportu wynika, \u017ce to nie jest jeden monolit, tylko, no, ca\u0142a paleta narz\u0119dzi.", "tokens": [51294, 3286, 710, 5099, 477, 84, 31936, 5439, 11, 3561, 281, 2838, 3492, 12906, 1108, 33704, 11, 13219, 11, 572, 11, 1335, 5024, 3984, 7664, 6714, 89, 6298, 3992, 13, 51604], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 20, "seek": 5700, "start": 81.8, "end": 85.3, "text": " Tak, i to jest kluczowe dla zrozumienia ich strategii.", "tokens": [51604, 9118, 11, 741, 281, 3492, 9671, 1311, 89, 6880, 12285, 710, 27857, 449, 18811, 1893, 5464, 5597, 13, 51779], "temperature": 0.0, "avg_logprob": -0.08886234576885517, "compression_ratio": 1.4569536423841059, "no_speech_prob": 0.0003654928004834801}, {"id": 21, "seek": 8530, "start": 85.39999999999999, "end": 89.89999999999999, "text": " Quen 2.5 to ca\u0142a seria modeli j\u0119zykowych, czyli LLMs,", "tokens": [50369, 2326, 268, 568, 13, 20, 281, 1335, 5024, 20809, 2316, 72, 49055, 74, 19605, 11, 16591, 441, 43, 26386, 11, 50594], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 22, "seek": 8530, "start": 89.89999999999999, "end": 93.5, "text": " zaprojektowana z my\u015bl\u0105 o bardzo r\u00f3\u017cnych zastosowaniach.", "tokens": [50594, 14223, 340, 14930, 40458, 710, 452, 19212, 1611, 277, 9034, 42602, 36746, 329, 305, 3782, 608, 13, 50774], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 23, "seek": 8530, "start": 93.5, "end": 98.1, "text": " Mamy tu modele naprawd\u0119 ma\u0142e z zaledwie p\u00f3\u0142 miliarda parametr\u00f3w,", "tokens": [50774, 376, 7804, 2604, 4391, 306, 20970, 463, 19827, 710, 710, 5573, 8699, 47907, 1962, 72, 19218, 6220, 27965, 3901, 11, 51004], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 24, "seek": 8530, "start": 98.1, "end": 102.1, "text": " kt\u00f3re mog\u0105 dzia\u0142a\u0107 na urz\u0105dzeniach brzegowych, na przyk\u0142ad smartfonach.", "tokens": [51004, 8864, 34123, 37903, 2162, 1667, 4038, 23876, 42124, 608, 738, 89, 1146, 19605, 11, 1667, 23144, 4069, 14338, 608, 13, 51204], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 25, "seek": 8530, "start": 102.1, "end": 105.8, "text": " A z drugiej strony s\u0105 bardzo du\u017ce i pot\u0119\u017cne modele,", "tokens": [51204, 316, 710, 47373, 32406, 9015, 9034, 1581, 2875, 741, 1847, 1274, 1427, 716, 4391, 306, 11, 51389], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 26, "seek": 8530, "start": 105.8, "end": 109.1, "text": " z siedemdziesi\u0105cioma dwoma miliardami parametr\u00f3w.", "tokens": [51389, 710, 262, 1091, 443, 28168, 530, 11404, 537, 6440, 27379, 6440, 1962, 72, 515, 4526, 6220, 27965, 3901, 13, 51554], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 27, "seek": 8530, "start": 109.1, "end": 112.7, "text": " Co wa\u017cne, seria dzieli si\u0119 na dwie g\u0142\u00f3wne kategorie.", "tokens": [51554, 3066, 46110, 11, 20809, 9758, 23099, 3244, 1667, 274, 8699, 18117, 3901, 716, 350, 2968, 17473, 13, 51734], "temperature": 0.0, "avg_logprob": -0.07216569308576913, "compression_ratio": 1.4657534246575343, "no_speech_prob": 0.0038404730148613453}, {"id": 28, "seek": 11270, "start": 112.7, "end": 115.5, "text": " Pierwsza to modele OpenWade.", "tokens": [50364, 16676, 14358, 2394, 281, 4391, 306, 7238, 54, 762, 13, 50504], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 29, "seek": 11270, "start": 115.5, "end": 119.0, "text": " Ich m\u00f3zgi s\u0105 publicznie dost\u0119pne dla badaczy i developer\u00f3w,", "tokens": [50504, 3141, 32515, 89, 7834, 9015, 1908, 89, 2766, 48209, 716, 12285, 1578, 14691, 741, 10754, 3901, 11, 50679], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 30, "seek": 11270, "start": 119.0, "end": 122.5, "text": " co, wiesz, nap\u0119dza innowacje w ca\u0142ej spo\u0142eczno\u015bci.", "tokens": [50679, 598, 11, 261, 15347, 11, 9296, 6298, 2394, 294, 3785, 29293, 261, 47631, 73, 36851, 89, 16438, 13, 50854], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 31, "seek": 11270, "start": 122.5, "end": 127.0, "text": " A druga kategoria to modele w\u0142asno\u015bciowe oferowane komercyjnie przez API,", "tokens": [50854, 316, 4110, 64, 350, 2968, 8172, 281, 4391, 306, 43572, 16438, 6880, 295, 260, 23066, 5207, 260, 42949, 2766, 14064, 9362, 11, 51079], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 32, "seek": 11270, "start": 127.0, "end": 130.9, "text": " czyli Quen 2.5 Turbo i Quen 2.5 Plus.", "tokens": [51079, 16591, 2326, 268, 568, 13, 20, 35848, 741, 2326, 268, 568, 13, 20, 7721, 13, 51274], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 33, "seek": 11270, "start": 130.9, "end": 138.0, "text": " Czekaj, wspominasz, \u017ce te komercyjne modele u\u017cywaj\u0105 archipektury Mixture of Experts, czyli MOH.", "tokens": [51274, 383, 19878, 1805, 11, 17757, 6981, 19601, 11, 3561, 535, 5207, 260, 42949, 716, 4391, 306, 34097, 86, 11133, 3912, 647, 8192, 2598, 10204, 8890, 295, 12522, 1373, 11, 16591, 19290, 39, 13, 51629], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 34, "seek": 11270, "start": 138.0, "end": 142.1, "text": " To poj\u0119cie cz\u0119sto si\u0119 pojawia, ale rzadko jest tak prosto wyt\u0142umaczone.", "tokens": [51629, 1407, 714, 11115, 4260, 34369, 3244, 30655, 654, 11, 6775, 367, 89, 345, 4093, 3492, 991, 10293, 78, 261, 4328, 49166, 14875, 546, 13, 51834], "temperature": 0.0, "avg_logprob": -0.12125944322155367, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.005652648862451315}, {"id": 35, "seek": 14210, "start": 142.1, "end": 144.2, "text": " Co to w\u0142a\u015bciwie oznacza w praktyce?", "tokens": [50364, 3066, 281, 50108, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 30, 50469], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 36, "seek": 14210, "start": 144.2, "end": 145.9, "text": " To jest \u015bwietne pytanie.", "tokens": [50469, 1407, 3492, 8299, 39083, 716, 36610, 13, 50554], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 37, "seek": 14210, "start": 145.9, "end": 152.1, "text": " Zamiast my\u015ble\u0107 o modelu jako o jednym, gigantycznym m\u00f3zgu, kt\u00f3ry musi wiedzie\u0107 wszystko,", "tokens": [50554, 1176, 4526, 525, 48633, 306, 2162, 277, 2316, 84, 17123, 277, 5232, 12996, 11, 8741, 394, 17466, 12996, 32515, 89, 2794, 11, 9913, 37587, 261, 22078, 22607, 11, 50864], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 38, "seek": 14210, "start": 152.1, "end": 155.7, "text": " MOH i dzia\u0142a bardziej jak komitet specjalist\u00f3w.", "tokens": [50864, 19290, 39, 741, 37903, 27209, 4207, 5207, 16341, 46433, 468, 3901, 13, 51044], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 39, "seek": 14210, "start": 155.7, "end": 162.7, "text": " Wyobra\u017a sobie, \u017ce masz pytanie dotycz\u0105ce fizyki kwantowej, historii renesansu i pisania kod\u00f3w Pythonie.", "tokens": [51044, 14458, 24393, 10659, 13652, 11, 3561, 2300, 89, 36610, 5893, 17466, 1611, 384, 21000, 88, 2984, 23846, 394, 21091, 11, 4058, 5597, 319, 4081, 599, 84, 741, 26584, 5609, 350, 378, 3901, 15329, 414, 13, 51394], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 40, "seek": 14210, "start": 162.7, "end": 166.2, "text": " Zamiast pyta\u0107 jednego, wszechwiedz\u0105cego m\u0119drca,", "tokens": [51394, 1176, 4526, 525, 10664, 42931, 5232, 11858, 11, 37647, 19439, 86, 1091, 8925, 384, 1571, 275, 6298, 81, 496, 11, 51569], "temperature": 0.0, "avg_logprob": -0.0915058786554854, "compression_ratio": 1.3707865168539326, "no_speech_prob": 0.006903261411935091}, {"id": 41, "seek": 16620, "start": 166.2, "end": 172.2, "text": " system inteligentnie kieruje ka\u017cde zapytanie do odpowiedniego eksperta w swojej dziedzinie.", "tokens": [50364, 1185, 24777, 25002, 2766, 38767, 13008, 21912, 1479, 14223, 4328, 7155, 360, 36574, 2766, 1571, 30724, 610, 1328, 261, 29489, 73, 9758, 15338, 259, 414, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 42, "seek": 16620, "start": 172.2, "end": 176.5, "text": " W danym momencie aktywna jest tylko ma\u0142a cz\u0119\u015b\u0107 ca\u0142ego modelu.", "tokens": [50664, 343, 274, 1325, 76, 40883, 9308, 874, 86, 629, 3492, 13219, 463, 5024, 47149, 35224, 6308, 2316, 84, 13, 50879], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 43, "seek": 16620, "start": 176.5, "end": 182.7, "text": " To sprawia, \u017ce jest on niewiarygodnie wydajny i szybki, zw\u0142aszcza przy tych bardzo du\u017cych modelach.", "tokens": [50879, 1407, 22734, 654, 11, 3561, 3492, 322, 43622, 29104, 21787, 2766, 25984, 1805, 1634, 741, 36456, 2984, 11, 11873, 1221, 19601, 41524, 6501, 15180, 9034, 1581, 7735, 339, 2316, 608, 13, 51189], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 44, "seek": 16620, "start": 182.7, "end": 186.89999999999998, "text": " Rozumiem, czyli to specjalizacja zamiast generalizacji.", "tokens": [51189, 43313, 449, 4907, 11, 16591, 281, 46433, 590, 23395, 710, 4526, 525, 2674, 590, 13152, 13, 51399], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 45, "seek": 16620, "start": 186.89999999999998, "end": 188.2, "text": " To ma sens.", "tokens": [51399, 1407, 463, 2923, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 46, "seek": 16620, "start": 188.2, "end": 193.29999999999998, "text": " Ale wr\u00f3czmy do tej niesamowitej tezy z raportu, kt\u00f3ra przyci\u0105gn\u0119\u0142a moj\u0105 uwag\u0119.", "tokens": [51464, 9366, 928, 812, 3689, 2226, 360, 12573, 48100, 335, 305, 642, 73, 535, 1229, 710, 5099, 477, 84, 11, 19456, 6501, 34381, 4568, 1274, 5024, 705, 8555, 43696, 13, 51719], "temperature": 0.0, "avg_logprob": -0.05178614829083998, "compression_ratio": 1.4344827586206896, "no_speech_prob": 0.005767569877207279}, {"id": 47, "seek": 19330, "start": 193.4, "end": 200.70000000000002, "text": " M\u00f3wimy o tym, \u017ce flagowy model OpenWade, czyli Quen2572B-instrakt,", "tokens": [50369, 376, 3901, 13189, 277, 8107, 11, 3561, 7166, 10089, 2316, 7238, 54, 762, 11, 16591, 2326, 268, 6074, 28890, 33, 12, 13911, 32249, 11, 50734], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 48, "seek": 19330, "start": 200.70000000000002, "end": 206.10000000000002, "text": " osi\u0105ga wydajno\u015b\u0107 por\u00f3wnywaln\u0105 z modelem Lama345B-instrakt.", "tokens": [50734, 3003, 11404, 3680, 25984, 1805, 23293, 1515, 812, 895, 27112, 304, 13113, 710, 4391, 10386, 441, 2404, 18, 8465, 33, 12, 13911, 32249, 13, 51004], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 49, "seek": 19330, "start": 206.10000000000002, "end": 210.3, "text": " A ten drugi jest oko\u0142o 5 razy wi\u0119kszy.", "tokens": [51004, 316, 2064, 4110, 72, 3492, 45730, 5249, 1025, 9639, 88, 29968, 1229, 13, 51214], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 50, "seek": 19330, "start": 210.3, "end": 212.20000000000002, "text": " To brzmi prawie niewiarygodnie.", "tokens": [51214, 1407, 738, 89, 3057, 3206, 8699, 43622, 29104, 21787, 2766, 13, 51309], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 51, "seek": 19330, "start": 212.20000000000002, "end": 214.70000000000002, "text": " A jednak wyniki to potwierdzaj\u0105.", "tokens": [51309, 316, 25897, 31936, 9850, 281, 1847, 40717, 28168, 11133, 13, 51434], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 52, "seek": 19330, "start": 214.70000000000002, "end": 219.5, "text": " To troch\u0119 tak jakby kto\u015b zbudowa\u0142 silnik do samochodu wy\u015bcigowego,", "tokens": [51434, 1407, 24926, 991, 28976, 32982, 710, 18281, 30105, 3425, 13123, 360, 3247, 8997, 34873, 4628, 1788, 66, 328, 26576, 11, 51674], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 53, "seek": 19330, "start": 219.5, "end": 222.20000000000002, "text": " kt\u00f3ry ma osi\u0105gi bolidu Formu\u0142y 1.", "tokens": [51674, 9913, 463, 3003, 11404, 7834, 8986, 327, 84, 10126, 84, 6825, 502, 13, 51809], "temperature": 0.0, "avg_logprob": -0.14823304969845838, "compression_ratio": 1.294776119402985, "no_speech_prob": 0.0026602379512041807}, {"id": 54, "seek": 22220, "start": 222.2, "end": 225.89999999999998, "text": " Ale zu\u017cywa tyle paliwa, co ma\u0142y miejski samoch\u00f3d.", "tokens": [50364, 9366, 2164, 7735, 4151, 39293, 3984, 72, 4151, 11, 598, 463, 6825, 18522, 18020, 3247, 8997, 17081, 13, 50549], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 55, "seek": 22220, "start": 225.89999999999998, "end": 228.89999999999998, "text": " I w\u0142a\u015bnie dlatego ten raport jest tak istotny.", "tokens": [50549, 286, 14234, 32205, 2064, 5099, 477, 3492, 991, 1418, 310, 1634, 13, 50699], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 56, "seek": 22220, "start": 228.89999999999998, "end": 234.5, "text": " Pokazuje, \u017ce kluczem nie jest ju\u017c tylko surowa moc, ale przede wszystkim efektywno\u015b\u0107.", "tokens": [50699, 14958, 43317, 11, 3561, 9671, 1311, 24313, 2838, 3492, 10678, 13219, 1022, 5528, 34962, 11, 6775, 44786, 30481, 31482, 916, 874, 20944, 7753, 13, 50979], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 57, "seek": 22220, "start": 234.5, "end": 239.1, "text": " Jak najwi\u0119cej wydajno\u015bci z jak najmniejszej liczby parametr\u00f3w.", "tokens": [50979, 15029, 48636, 20811, 25984, 1805, 16438, 710, 4207, 11212, 47658, 82, 16920, 6169, 89, 2322, 6220, 27965, 3901, 13, 51209], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 58, "seek": 22220, "start": 239.1, "end": 240.39999999999998, "text": " To imponuj\u0105ce.", "tokens": [51209, 1407, 704, 266, 13263, 384, 13, 51274], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 59, "seek": 22220, "start": 240.39999999999998, "end": 242.89999999999998, "text": " No dobrze, ale jak oni to zrobili?", "tokens": [51274, 883, 28335, 11, 6775, 4207, 36317, 281, 44399, 2312, 30, 51399], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 60, "seek": 22220, "start": 242.89999999999998, "end": 245.6, "text": " Jaki jest ten sekretny sk\u0142adnik?", "tokens": [51399, 508, 7421, 3492, 2064, 17215, 1505, 1634, 1110, 10358, 13123, 30, 51534], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 61, "seek": 22220, "start": 245.6, "end": 249.1, "text": " Raport zag\u0142\u0119bia si\u0119 w szczeg\u00f3\u0142y procesu treningowego,", "tokens": [51534, 16184, 477, 27001, 46564, 26975, 3244, 261, 22090, 1146, 812, 6825, 17565, 84, 2192, 773, 26576, 11, 51709], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 62, "seek": 22220, "start": 249.1, "end": 251.6, "text": " kt\u00f3ry wydaje si\u0119 by\u0107 sercem tej innowacji.", "tokens": [51709, 9913, 49165, 3244, 15069, 816, 26422, 12573, 294, 3785, 13152, 13, 51834], "temperature": 0.0, "avg_logprob": -0.09079697325422957, "compression_ratio": 1.4235668789808917, "no_speech_prob": 0.0012250627623870969}, {"id": 63, "seek": 25160, "start": 251.7, "end": 252.7, "text": " Zgadza si\u0119.", "tokens": [50369, 1176, 70, 345, 2394, 3244, 13, 50419], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 64, "seek": 25160, "start": 252.7, "end": 255.79999999999998, "text": " Ca\u0142y proces mo\u017cna podzieli\u0107 na dwa kluczowe etapy.", "tokens": [50419, 7544, 6825, 17565, 17790, 2497, 42280, 12757, 1667, 35045, 9671, 1311, 89, 6880, 47634, 88, 13, 50574], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 65, "seek": 25160, "start": 255.79999999999998, "end": 260.9, "text": " Pre-training, czyli trening wst\u0119pny i post-training, czyli dostrajanie.", "tokens": [50574, 6001, 12, 17227, 1760, 11, 16591, 2192, 773, 261, 372, 18085, 1634, 741, 2183, 12, 17227, 1760, 11, 16591, 20568, 48690, 7155, 13, 50829], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 66, "seek": 25160, "start": 260.9, "end": 264.9, "text": " Fundamentem wszystkiego jest to, co wydarzy\u0142o si\u0119 na pierwszym etapie.", "tokens": [50829, 13493, 2466, 443, 14615, 12200, 3492, 281, 11, 598, 4628, 20327, 1229, 5249, 3244, 1667, 34016, 76, 47634, 414, 13, 51029], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 67, "seek": 25160, "start": 264.9, "end": 271.4, "text": " W pre-trainingu zwi\u0119kszyli ilo\u015b\u0107 danych treningowych z 7 bilion\u00f3w token\u00f3w do a\u017c 18 bilion\u00f3w.", "tokens": [51029, 343, 659, 12, 17227, 1760, 84, 11873, 5034, 1694, 1229, 2081, 1930, 78, 7753, 274, 34644, 2192, 773, 19605, 710, 1614, 8588, 313, 3901, 14862, 3901, 360, 48134, 2443, 8588, 313, 3901, 13, 51354], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 68, "seek": 25160, "start": 271.4, "end": 273.6, "text": " 18 bilion\u00f3w?", "tokens": [51354, 2443, 8588, 313, 3901, 30, 51464], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 69, "seek": 25160, "start": 273.6, "end": 277.8, "text": " Ta liczba jest tak abstrakcyjna, \u017ce w zasadzie nic mi nie m\u00f3wi.", "tokens": [51464, 6551, 6169, 89, 4231, 3492, 991, 10823, 11272, 42949, 629, 11, 3561, 261, 44585, 3283, 6201, 2752, 2838, 24592, 13, 51674], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 70, "seek": 25160, "start": 277.8, "end": 279.7, "text": " Mo\u017cesz to jako\u015b zobrazowa\u0107?", "tokens": [51674, 44736, 10430, 281, 17123, 1788, 710, 24393, 89, 11445, 30, 51769], "temperature": 0.0, "avg_logprob": -0.09925114082184848, "compression_ratio": 1.4894366197183098, "no_speech_prob": 0.013994467444717884}, {"id": 71, "seek": 27970, "start": 280.7, "end": 282.9, "text": " Biblioteka Kongresu USA.", "tokens": [50414, 31520, 2081, 310, 36361, 9832, 495, 84, 10827, 13, 50524], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 72, "seek": 27970, "start": 282.9, "end": 287.7, "text": " Najwi\u0119ksza biblioteka na \u015bwiecie to oko\u0142o 10 bilion\u00f3w s\u0142\u00f3w.", "tokens": [50524, 31576, 22423, 1694, 2394, 34344, 310, 36361, 1667, 40078, 4260, 281, 45730, 5249, 1266, 8588, 313, 3901, 15116, 3901, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 73, "seek": 27970, "start": 287.7, "end": 292.2, "text": " Czyli m\u00f3wimy o danych tekstowych o obj\u0119to\u015bci niemal dw\u00f3ch takich bibliotek.", "tokens": [50764, 37099, 13489, 13189, 277, 274, 34644, 16624, 372, 19605, 277, 1111, 11115, 1353, 6199, 2838, 5579, 27379, 812, 339, 29607, 34344, 310, 916, 13, 50989], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 74, "seek": 27970, "start": 292.2, "end": 295.8, "text": " Ale co tu jest naprawd\u0119 fascynuj\u0105ce, to nie sama ilo\u015b\u0107,", "tokens": [50989, 9366, 598, 2604, 3492, 20970, 30632, 1344, 77, 13263, 384, 11, 281, 2838, 17768, 1930, 78, 7753, 11, 51169], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 75, "seek": 27970, "start": 295.8, "end": 299.7, "text": " a inteligentne podej\u015bcie do tego, co wchodzi w sk\u0142ad tych danych.", "tokens": [51169, 257, 24777, 25002, 716, 7468, 73, 9815, 360, 8627, 11, 598, 261, 34616, 261, 1110, 10358, 15180, 274, 34644, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 76, "seek": 27970, "start": 299.7, "end": 304.5, "text": " Zauwa\u017cyli, \u017ce dane z internetu s\u0105 zdominowane przez pewne domeny,", "tokens": [51364, 1176, 1459, 4151, 7735, 2081, 11, 3561, 49206, 710, 4705, 84, 9015, 710, 4121, 259, 23066, 14064, 25889, 716, 3285, 43100, 11, 51604], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 77, "seek": 27970, "start": 304.5, "end": 309.59999999999997, "text": " jak media spo\u0142eczno\u015bciowe czy e-commerce, kt\u00f3re cz\u0119sto zawieraj\u0105 du\u017co szumu.", "tokens": [51604, 4207, 3021, 36851, 89, 16438, 6880, 6430, 308, 12, 26926, 11, 8864, 34369, 28165, 811, 11133, 26673, 7870, 30034, 13, 51859], "temperature": 0.0, "avg_logprob": -0.08569942064733313, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.05768971890211105}, {"id": 78, "seek": 30960, "start": 309.6, "end": 316.90000000000003, "text": " Zmniejszyli wi\u0119c ich udzia\u0142, a zwi\u0119kszyli porcj\u0119 danych wysokiej jako\u015bci z nauki, technologii, kodowania i matematyki.", "tokens": [50364, 1176, 76, 10402, 7706, 2081, 16677, 1893, 11727, 43070, 11, 257, 11873, 5034, 1694, 1229, 2081, 1515, 41960, 274, 34644, 27062, 453, 7764, 17123, 6199, 710, 35616, 2984, 11, 1537, 1132, 5597, 11, 350, 378, 21308, 741, 3803, 8615, 88, 2984, 13, 50729], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 79, "seek": 30960, "start": 316.90000000000003, "end": 321.0, "text": " Czyli zamiast karmi\u0107 model wszystkim, co znajd\u0105 w internecie,", "tokens": [50729, 37099, 710, 4526, 525, 350, 4452, 12757, 2316, 30481, 11, 598, 27318, 67, 1611, 261, 728, 716, 4260, 11, 50934], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 80, "seek": 30960, "start": 321.0, "end": 324.6, "text": " zrobili mu diet\u0119 bogat\u0105 z najbardziej po\u017cywne sk\u0142adniki.", "tokens": [50934, 44399, 2312, 2992, 6339, 1274, 26132, 267, 1611, 710, 41857, 714, 7735, 86, 716, 1110, 10358, 77, 9850, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 81, "seek": 30960, "start": 324.6, "end": 330.6, "text": " Ale wspominaj\u0105 te\u017c, \u017ce do filtrowania tych danych u\u017cyli swoich poprzednich modelik Juven.", "tokens": [51114, 9366, 17757, 49217, 8555, 9516, 11, 3561, 360, 29148, 1892, 5609, 15180, 274, 34644, 34097, 2081, 13291, 480, 1665, 81, 11312, 77, 480, 2316, 1035, 13582, 553, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 82, "seek": 30960, "start": 330.6, "end": 332.6, "text": " Czekaj, czy to nie jest ryzykowne?", "tokens": [51414, 383, 19878, 1805, 11, 6430, 281, 2838, 3492, 20791, 1229, 74, 648, 68, 30, 51514], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 83, "seek": 30960, "start": 332.6, "end": 337.20000000000005, "text": " U\u017cywanie starych modeli do selekcji danych dla nowego nie brzmi jak przepis na,", "tokens": [51514, 624, 7735, 86, 7155, 342, 822, 339, 2316, 72, 360, 23264, 74, 19649, 274, 34644, 12285, 586, 6308, 2838, 738, 89, 3057, 4207, 30829, 271, 1667, 11, 51744], "temperature": 0.0, "avg_logprob": -0.09469623214628067, "compression_ratio": 1.49185667752443, "no_speech_prob": 0.00403751153498888}, {"id": 84, "seek": 33720, "start": 337.2, "end": 340.3, "text": " no wiesz, echo chamber, utrwalanie starych b\u0142\u0119d\u00f3w?", "tokens": [50364, 572, 261, 15347, 11, 14300, 13610, 11, 2839, 81, 29530, 7155, 342, 822, 339, 272, 1221, 6298, 3901, 30, 50519], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 85, "seek": 33720, "start": 340.3, "end": 344.59999999999997, "text": " To jest bardzo trafna uwaga i jedno z kluczowych wyzwa\u0144.", "tokens": [50519, 1407, 3492, 9034, 944, 69, 629, 23147, 9286, 741, 5232, 1771, 710, 9671, 1311, 89, 19605, 4628, 89, 4151, 5248, 13, 50734], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 86, "seek": 33720, "start": 344.59999999999997, "end": 346.9, "text": " Oni pode\u015bli do tego w przemy\u015blany spos\u00f3b.", "tokens": [50734, 1282, 72, 7468, 15350, 360, 8627, 261, 6541, 3633, 19212, 1325, 22904, 13, 50849], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 87, "seek": 33720, "start": 346.9, "end": 350.5, "text": " Nie chodzi\u0142o o to, \u017ceby stary model decydowa\u0142, co jest prawd\u0105,", "tokens": [50849, 12016, 23998, 5249, 277, 281, 11, 11316, 342, 822, 2316, 979, 6655, 30105, 11, 598, 3492, 41175, 1611, 11, 51029], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 88, "seek": 33720, "start": 350.5, "end": 354.8, "text": " ale \u017ceby dzia\u0142a\u0142 jako taki filtr jako\u015bciowy na masow\u0105 skal\u0119.", "tokens": [51029, 6775, 11316, 37903, 1221, 17123, 20065, 1387, 6903, 17123, 6199, 10089, 1667, 2300, 30297, 16890, 1274, 13, 51244], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 89, "seek": 33720, "start": 354.8, "end": 360.09999999999997, "text": " Potrafi\u0142 np. odsia\u0107 zduplikowane tre\u015bci, tekst niskiej jako\u015bci czy spam.", "tokens": [51244, 9145, 10437, 40622, 33808, 13, 3611, 82, 654, 2162, 710, 769, 564, 1035, 23066, 2192, 6199, 11, 16624, 372, 297, 7797, 7764, 17123, 6199, 6430, 24028, 13, 51509], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 90, "seek": 33720, "start": 360.09999999999997, "end": 363.9, "text": " To jest zadanie, kt\u00f3re cz\u0142owiekowi zaj\u0119\u0142oby tysi\u0105ce lat.", "tokens": [51509, 1407, 3492, 42788, 7155, 11, 8864, 36282, 74, 24503, 33729, 1274, 1221, 13944, 38156, 11404, 384, 4465, 13, 51699], "temperature": 0.0, "avg_logprob": -0.08792657216389974, "compression_ratio": 1.43, "no_speech_prob": 0.012392711825668812}, {"id": 91, "seek": 36390, "start": 363.9, "end": 371.4, "text": " R\u00f3wnocze\u015bnie, jak wspomnia\u0142em, zr\u00f3wnowa\u017cyli to r\u0119cznie zwi\u0119kszaj\u0105c udzia\u0142 danych z zaufanych, wysokiej jako\u015bci \u017ar\u00f3de\u0142.", "tokens": [50364, 497, 812, 895, 905, 1381, 12221, 11, 4207, 17757, 38131, 36368, 11, 710, 11721, 895, 5528, 7735, 2081, 281, 41197, 19923, 11873, 5034, 1694, 89, 38757, 11727, 43070, 274, 34644, 710, 710, 9507, 34644, 11, 27062, 453, 7764, 17123, 6199, 50212, 11721, 1479, 1221, 13, 50739], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 92, "seek": 36390, "start": 371.4, "end": 377.09999999999997, "text": " Dodatkowo w\u0142\u0105czyli do diety dane ze swoich modeli wyspecjalizowanych w matematyce i kodowaniu", "tokens": [50739, 26904, 33525, 19941, 261, 15926, 6522, 2081, 360, 1026, 2210, 49206, 5277, 13291, 480, 2316, 72, 27062, 494, 66, 22600, 590, 23341, 339, 261, 3803, 8615, 88, 384, 741, 350, 378, 305, 25849, 51024], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 93, "seek": 36390, "start": 377.09999999999997, "end": 379.7, "text": " oraz wygenerowali nowe dane syntetyczne.", "tokens": [51024, 28905, 4628, 21848, 305, 5103, 586, 68, 49206, 23980, 2210, 38491, 13, 51154], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 94, "seek": 36390, "start": 379.7, "end": 383.29999999999995, "text": " To wszystko razem stworzy\u0142o niezwykle solidny fundament.", "tokens": [51154, 1407, 22607, 40225, 342, 28321, 1229, 5249, 33511, 9726, 14677, 5100, 1634, 6073, 13, 51334], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 95, "seek": 36390, "start": 383.29999999999995, "end": 384.9, "text": " OK, to ma sens.", "tokens": [51334, 2264, 11, 281, 463, 2923, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 96, "seek": 36390, "start": 384.9, "end": 392.2, "text": " Czyli po tym etapie mamy model, kt\u00f3ry jest jak gigantyczna, \u015bwietnie zredagowana encyklopedia, ma ogromn\u0105 wiedz\u0119.", "tokens": [51414, 37099, 714, 8107, 47634, 414, 17335, 2316, 11, 9913, 3492, 4207, 8741, 394, 17466, 629, 11, 8299, 39083, 2766, 710, 986, 559, 40458, 465, 1344, 7837, 27277, 654, 11, 463, 34416, 298, 13113, 46894, 11052, 13, 51779], "temperature": 0.0, "avg_logprob": -0.07908556461334229, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.005226675420999527}, {"id": 97, "seek": 39220, "start": 392.2, "end": 395.5, "text": " Ale jak nauczy\u0107 go, \u017ceby by\u0142 faktycznie pomocny?", "tokens": [50364, 9366, 4207, 49103, 27150, 352, 11, 11316, 16673, 33647, 45586, 48962, 1634, 30, 50529], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 98, "seek": 39220, "start": 395.5, "end": 400.7, "text": " \u017beby nie tylko recytowa\u0142 fakty, ale rozumia\u0142 polecenia i potrafi\u0142 prowadzi\u0107 rozmow\u0119.", "tokens": [50529, 46864, 2322, 2838, 13219, 850, 4328, 30105, 33647, 874, 11, 6775, 48797, 8908, 13208, 13037, 654, 741, 1847, 10437, 40622, 36590, 28496, 35234, 305, 1274, 13, 50789], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 99, "seek": 39220, "start": 400.7, "end": 407.59999999999997, "text": " Czyli tu w\u0142a\u015bnie przechodzimy do drugiego etapu, czyli post-trainingu, gdzie dzieje si\u0119 prawdziwa magia.", "tokens": [50789, 37099, 2604, 14234, 8325, 29914, 89, 13189, 360, 4110, 12200, 47634, 84, 11, 16591, 2183, 12, 17227, 1760, 84, 11, 18922, 17953, 2884, 3244, 41175, 3992, 4151, 2258, 654, 13, 51134], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 100, "seek": 39220, "start": 407.59999999999997, "end": 411.7, "text": " Surowa wiedza to jedno, ale u\u017cyteczno\u015b\u0107 to zupe\u0142nie inna historia.", "tokens": [51134, 6732, 5528, 46894, 2394, 281, 5232, 1771, 11, 6775, 34097, 975, 3689, 23293, 281, 49922, 294, 629, 18385, 13, 51339], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 101, "seek": 39220, "start": 411.7, "end": 417.0, "text": " Tutaj zastosowali bardzo przemy\u015blane dwustopniowe szkolenie z ludzkich preferencji.", "tokens": [51339, 41819, 36746, 329, 305, 5103, 9034, 6541, 3633, 19212, 1929, 27379, 381, 404, 3722, 6880, 7870, 74, 11940, 414, 710, 15946, 30154, 480, 4382, 268, 19649, 13, 51604], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 102, "seek": 39220, "start": 417.0, "end": 421.4, "text": " Najpierw jest Supervised Fine Tuning w skr\u00f3cie SFT.", "tokens": [51604, 31576, 45119, 86, 3492, 4548, 24420, 12024, 21363, 278, 261, 1110, 11721, 4260, 318, 25469, 13, 51824], "temperature": 0.0, "avg_logprob": -0.07711811723380253, "compression_ratio": 1.434375, "no_speech_prob": 0.003958107437938452}, {"id": 103, "seek": 42140, "start": 421.4, "end": 428.59999999999997, "text": " To jak danie modelowi ogromnego podr\u0119cznika z ponad milionem przyk\u0142ad\u00f3w w formacie Pytanie Idealna Odpowied\u017a.", "tokens": [50364, 1407, 4207, 3277, 414, 2316, 24503, 34416, 298, 11858, 15305, 1274, 3689, 77, 5439, 710, 9224, 345, 1962, 313, 443, 23144, 3901, 261, 1254, 30805, 430, 4328, 7155, 13090, 304, 629, 12210, 14701, 1091, 10659, 13, 50724], "temperature": 0.0, "avg_logprob": -0.09778660062759642, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.003783478634431958}, {"id": 104, "seek": 42140, "start": 428.59999999999997, "end": 432.0, "text": " Celem by\u0142o wyeliminowanie s\u0142abo\u015bci poprzednich wersji.", "tokens": [50724, 8257, 10386, 14811, 4628, 338, 4395, 22028, 15116, 41265, 6199, 1665, 81, 11312, 77, 480, 261, 433, 4013, 13, 50894], "temperature": 0.0, "avg_logprob": -0.09778660062759642, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.003783478634431958}, {"id": 105, "seek": 42140, "start": 432.0, "end": 436.9, "text": " Na przyk\u0142ad w generowaniu d\u0142ugich, sp\u00f3jnych tekst\u00f3w czy rozumieniu danych w tabelach.", "tokens": [50894, 6056, 23144, 261, 1337, 305, 25849, 274, 34077, 480, 11, 637, 18999, 9399, 16624, 372, 3901, 6430, 48797, 1053, 5951, 274, 34644, 261, 4421, 338, 608, 13, 51139], "temperature": 0.0, "avg_logprob": -0.09778660062759642, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.003783478634431958}, {"id": 106, "seek": 42140, "start": 436.9, "end": 444.29999999999995, "text": " Czyli to s\u0105 te ksi\u0105\u017ckowe m\u0105dro\u015bci, ale co z inteligencj\u0105 praktyczn\u0105? Jak nauczy\u0107 go niuans\u00f3w?", "tokens": [51139, 37099, 281, 9015, 535, 39311, 74, 6880, 275, 18962, 340, 6199, 11, 6775, 598, 710, 24777, 3213, 66, 8555, 3206, 74, 874, 3689, 13113, 30, 15029, 49103, 27150, 352, 3867, 84, 599, 3901, 30, 51509], "temperature": 0.0, "avg_logprob": -0.09778660062759642, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.003783478634431958}, {"id": 107, "seek": 44430, "start": 444.3, "end": 451.6, "text": " Dok\u0142adnie. I do tego s\u0142u\u017cy Reinforcement Learning, czyli uczenie przez wzmacnianie.", "tokens": [50364, 29768, 10358, 2766, 13, 286, 360, 8627, 48459, 7735, 42116, 9382, 15205, 11, 16591, 344, 39043, 14064, 24809, 37065, 77, 952, 414, 13, 50729], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 108, "seek": 44430, "start": 451.6, "end": 455.3, "text": " I tu znowu podzielili to na dwa inteligentne kroki.", "tokens": [50729, 286, 2604, 710, 3785, 84, 2497, 42280, 2312, 281, 1667, 35045, 24777, 25002, 716, 45909, 2984, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 109, "seek": 44430, "start": 455.3, "end": 461.2, "text": " Pierwszy, wykorzystuj\u0105cy technik\u0119 DPO, czyli Direct Preference Optimization,", "tokens": [50914, 16676, 30012, 11, 43606, 36049, 13263, 1344, 1537, 1035, 1274, 413, 34885, 11, 16591, 18308, 6001, 5158, 35013, 2144, 11, 51209], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 110, "seek": 44430, "start": 461.2, "end": 466.2, "text": " jest jak przej\u015bcie od podr\u0119cznika do pracy z bardzo wymagaj\u0105cym nauczycielem,", "tokens": [51209, 3492, 4207, 8325, 73, 9815, 3611, 15305, 1274, 3689, 77, 5439, 360, 35591, 710, 9034, 29764, 559, 11133, 1344, 76, 49103, 1229, 4260, 10386, 11, 51459], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 111, "seek": 44430, "start": 466.2, "end": 468.7, "text": " kt\u00f3ry ma twardy klucz odpowiedzi.", "tokens": [51459, 9913, 463, 683, 515, 88, 9671, 1311, 89, 36574, 3992, 13, 51584], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 112, "seek": 44430, "start": 468.7, "end": 472.40000000000003, "text": " Modelowi pokazuje si\u0119 dwie odpowiedzi na to samo pytanie.", "tokens": [51584, 17105, 24503, 13010, 43317, 3244, 274, 8699, 36574, 3992, 1667, 281, 36422, 36610, 13, 51769], "temperature": 0.0, "avg_logprob": -0.08316363057782573, "compression_ratio": 1.410071942446043, "no_speech_prob": 0.1290946900844574}, {"id": 113, "seek": 47240, "start": 472.4, "end": 476.4, "text": " Jedn\u0105 oznaczon\u0105 jako dobra, drug\u0105 jako z\u0142a.", "tokens": [50364, 27076, 13113, 277, 22672, 14875, 266, 1611, 17123, 360, 6198, 11, 4110, 1611, 17123, 710, 5024, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08717238990059734, "compression_ratio": 1.4340277777777777, "no_speech_prob": 0.006089941132813692}, {"id": 114, "seek": 47240, "start": 476.4, "end": 479.9, "text": " I uczy si\u0119 go, by zawsze preferowa\u0142 t\u0105 lepsz\u0105.", "tokens": [50564, 286, 344, 6522, 3244, 352, 11, 538, 30964, 4382, 30105, 32294, 476, 1878, 8925, 13, 50739], "temperature": 0.0, "avg_logprob": -0.08717238990059734, "compression_ratio": 1.4340277777777777, "no_speech_prob": 0.006089941132813692}, {"id": 115, "seek": 47240, "start": 479.9, "end": 485.9, "text": " To \u015bwietnie dzia\u0142a w zadaniach, gdzie jest jasna odpowied\u017a, jak w rozumowaniu logicznym czy zadaniach matematycznych.", "tokens": [50739, 1407, 8299, 39083, 2766, 37903, 261, 42788, 3782, 608, 11, 18922, 3492, 361, 296, 629, 36574, 10659, 11, 4207, 261, 48797, 305, 25849, 9952, 89, 12996, 6430, 42788, 3782, 608, 3803, 8615, 17466, 9399, 13, 51039], "temperature": 0.0, "avg_logprob": -0.08717238990059734, "compression_ratio": 1.4340277777777777, "no_speech_prob": 0.006089941132813692}, {"id": 116, "seek": 47240, "start": 485.9, "end": 491.9, "text": " Ale przecie\u017c wi\u0119kszo\u015b\u0107 naszych interakcji z AI nie opiera si\u0119 na prostym, dobrze, \u017ale.", "tokens": [51039, 9366, 8325, 40082, 29968, 4765, 7753, 45002, 728, 514, 19649, 710, 7318, 2838, 999, 10609, 3244, 1667, 10293, 4199, 11, 28335, 11, 50212, 306, 13, 51339], "temperature": 0.0, "avg_logprob": -0.08717238990059734, "compression_ratio": 1.4340277777777777, "no_speech_prob": 0.006089941132813692}, {"id": 117, "seek": 47240, "start": 491.9, "end": 498.5, "text": " Oczekujemy, \u017ce odpowied\u017a b\u0119dzie pomocna, zwi\u0119z\u0142a, a czasem nawet kreatywna. Jak to wytrenowa\u0107?", "tokens": [51339, 422, 3689, 916, 21767, 11, 3561, 36574, 10659, 10562, 48962, 629, 11, 11873, 5034, 89, 5024, 11, 257, 13190, 443, 22696, 350, 620, 27112, 629, 13, 15029, 281, 261, 4328, 1095, 11445, 30, 51669], "temperature": 0.0, "avg_logprob": -0.08717238990059734, "compression_ratio": 1.4340277777777777, "no_speech_prob": 0.006089941132813692}, {"id": 118, "seek": 49850, "start": 498.5, "end": 502.5, "text": " I to jest w\u0142a\u015bnie ten ostatni genialny szlif.", "tokens": [50364, 286, 281, 3492, 14234, 2064, 32686, 3722, 48228, 1634, 7870, 75, 351, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 119, "seek": 49850, "start": 502.5, "end": 510.6, "text": " Druga faza, wykorzystuj\u0105ca nowsz\u0105 technik\u0119 GRPO, czyli Group Relative Policy Optimization,", "tokens": [50564, 2491, 19364, 4375, 64, 11, 43606, 36049, 13263, 496, 586, 82, 8925, 1537, 1035, 1274, 10903, 34885, 11, 16591, 10500, 8738, 1166, 21708, 35013, 2144, 11, 50969], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 120, "seek": 49850, "start": 510.6, "end": 515.0, "text": " przypomina uko\u0144czenie szko\u0142y i do\u0142\u0105czenie do klubu dyskusyjnego.", "tokens": [50969, 41780, 49217, 344, 4093, 5248, 39043, 7870, 4093, 6825, 741, 360, 15926, 39043, 360, 9671, 836, 84, 15243, 35080, 88, 73, 11858, 13, 51189], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 121, "seek": 49850, "start": 515.0, "end": 518.3, "text": " Tu ju\u017c nie ma jednego prostego klucza odpowiedzi.", "tokens": [51189, 7836, 10678, 2838, 463, 5232, 11858, 10293, 6308, 9671, 1311, 2394, 36574, 3992, 13, 51354], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 122, "seek": 49850, "start": 518.3, "end": 524.4, "text": " Model generuje kilka r\u00f3\u017cnych odpowiedzi, a bardzo zaawansowany s\u0119dzia, inny model AI,", "tokens": [51354, 17105, 1337, 13008, 36466, 42602, 36574, 3992, 11, 257, 9034, 7949, 1607, 599, 23341, 262, 6298, 40395, 11, 294, 1634, 2316, 7318, 11, 51659], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 123, "seek": 49850, "start": 524.4, "end": 528.2, "text": " nazywany reward model, ocenia je i szereguje.", "tokens": [51659, 20151, 27112, 1325, 7782, 2316, 11, 10409, 268, 654, 1506, 741, 7870, 323, 2794, 2884, 13, 51849], "temperature": 0.0, "avg_logprob": -0.08940256103988765, "compression_ratio": 1.3797909407665505, "no_speech_prob": 0.019487841054797173}, {"id": 124, "seek": 52820, "start": 528.2, "end": 534.9000000000001, "text": " Bierze pod uwag\u0119 nie tylko poprawno\u015b\u0107, ale te\u017c styl, pomocno\u015b\u0107, bezpieczne\u0144stwo i zwi\u0119z\u0142o\u015b\u0107.", "tokens": [50364, 363, 811, 1381, 2497, 43696, 2838, 13219, 1665, 424, 20944, 7753, 11, 6775, 9516, 23736, 11, 48962, 23293, 11, 47153, 3689, 716, 12229, 6120, 741, 11873, 5034, 89, 44742, 13, 50699], "temperature": 0.0, "avg_logprob": -0.11210772726270887, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.0031807583291083574}, {"id": 125, "seek": 52820, "start": 534.9000000000001, "end": 539.0, "text": " To ju\u017c nie jest nauka fakt\u00f3w, to jest nauka sztuki konwersacji.", "tokens": [50699, 1407, 10678, 2838, 3492, 35616, 2330, 21310, 3901, 11, 281, 3492, 35616, 2330, 262, 2682, 11788, 5897, 5364, 13152, 13, 50904], "temperature": 0.0, "avg_logprob": -0.11210772726270887, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.0031807583291083574}, {"id": 126, "seek": 52820, "start": 539.0, "end": 547.9000000000001, "text": " OK, ten proces treningowy brzmi naprawd\u0119 ukompleksowo, ale czy ca\u0142a ta ci\u0119\u017cka praca prze\u0142o\u017cy\u0142a si\u0119 na wyniki?", "tokens": [50904, 2264, 11, 2064, 17565, 2192, 773, 10089, 738, 89, 3057, 20970, 344, 20557, 781, 1694, 19941, 11, 6775, 6430, 1335, 5024, 1846, 35484, 1427, 2330, 582, 6628, 8325, 5249, 7735, 5024, 3244, 1667, 31936, 9850, 30, 51349], "temperature": 0.0, "avg_logprob": -0.11210772726270887, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.0031807583291083574}, {"id": 127, "seek": 52820, "start": 547.9000000000001, "end": 550.9000000000001, "text": " Sp\u00f3jrzmy na \u015bwiadectwo Q&A 5.", "tokens": [51349, 1738, 18999, 19390, 2226, 1667, 21485, 345, 557, 6120, 1249, 5, 32, 1025, 13, 51499], "temperature": 0.0, "avg_logprob": -0.11210772726270887, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.0031807583291083574}, {"id": 128, "seek": 52820, "start": 550.9000000000001, "end": 557.8000000000001, "text": " Czy w tym raporcie by\u0142 jaki\u015b konkretny wynik, kt\u00f3ry sprawi\u0142, \u017ce pomy\u015bla\u0142a\u015b sobie, wow, to naprawd\u0119 dzia\u0142a?", "tokens": [51499, 19832, 261, 8107, 5099, 284, 4260, 16673, 34721, 36500, 1634, 31936, 1035, 11, 9913, 22734, 40622, 11, 3561, 280, 8488, 1788, 875, 5024, 1788, 13652, 11, 6076, 11, 281, 20970, 37903, 30, 51844], "temperature": 0.0, "avg_logprob": -0.11210772726270887, "compression_ratio": 1.4581939799331103, "no_speech_prob": 0.0031807583291083574}, {"id": 129, "seek": 55780, "start": 557.8, "end": 559.4, "text": " Zdecydowanie.", "tokens": [50364, 1176, 1479, 1344, 67, 22028, 13, 50444], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 130, "seek": 55780, "start": 559.4, "end": 564.6999999999999, "text": " Poza og\u00f3lnymi benchmarkami, gdzie Q&A 5.72B INSTRACT", "tokens": [50444, 6165, 2394, 5360, 15741, 31813, 18927, 4526, 11, 18922, 1249, 5, 32, 1025, 13, 28890, 33, 6892, 49440, 42936, 50709], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 131, "seek": 55780, "start": 564.6999999999999, "end": 568.9, "text": " faktycznie pokonuje znacznie wi\u0119kszego Lama 4.5B INSTRACT", "tokens": [50709, 33647, 45586, 13010, 266, 13008, 15397, 14875, 2766, 29968, 27725, 441, 2404, 1017, 13, 20, 33, 6892, 49440, 42936, 50919], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 132, "seek": 55780, "start": 568.9, "end": 572.6999999999999, "text": " w zadaniach na kodowanie MBPP czy matematyk\u0119 MAF", "tokens": [50919, 261, 42788, 3782, 608, 1667, 350, 378, 22028, 28866, 17755, 6430, 3803, 8615, 88, 15724, 12191, 37, 51109], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 133, "seek": 55780, "start": 572.6999999999999, "end": 577.1999999999999, "text": " dla mnie najbardziej uderzaj\u0105cy by\u0142 wynik w te\u015bcie Arena Hard.", "tokens": [51109, 12285, 17661, 41857, 344, 1068, 89, 11133, 1344, 16673, 31936, 1035, 261, 535, 9815, 34290, 11817, 13, 51334], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 134, "seek": 55780, "start": 577.1999999999999, "end": 584.0, "text": " To jest benchmark, gdzie ostateczn\u0105 ocen\u0119 wydaj\u0105 ludzie, por\u00f3wnuj\u0105c odpowiedzi dw\u00f3ch anonimowych modeli.", "tokens": [51334, 1407, 3492, 18927, 11, 18922, 277, 15406, 3689, 13113, 10409, 268, 1274, 25984, 11133, 37025, 11, 1515, 812, 895, 44733, 36574, 3992, 27379, 812, 339, 364, 266, 332, 19605, 2316, 72, 13, 51674], "temperature": 0.0, "avg_logprob": -0.15774599198372133, "compression_ratio": 1.3270676691729324, "no_speech_prob": 0.013936050236225128}, {"id": 135, "seek": 58400, "start": 584.1, "end": 588.6, "text": " I tutaj mniejszy Kfen zdeklasowa\u0142 wi\u0119kszego konkurenta.", "tokens": [50369, 286, 12749, 39513, 7706, 591, 6570, 710, 67, 916, 7743, 30105, 29968, 27725, 21428, 540, 580, 64, 13, 50594], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 136, "seek": 58400, "start": 588.6, "end": 594.8, "text": " To pokazuje, \u017ce ta ca\u0142a finezja w post-treningu naprawd\u0119 sprawi\u0142a, \u017ce model jest bardziej pomocny", "tokens": [50594, 1407, 13010, 43317, 11, 3561, 1846, 1335, 5024, 2489, 89, 2938, 261, 2183, 12, 3599, 773, 84, 20970, 22734, 72, 5024, 11, 3561, 2316, 3492, 27209, 48962, 1634, 50904], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 137, "seek": 58400, "start": 594.8, "end": 598.0, "text": " i preferowany przez prawdziwych u\u017cytkownik\u00f3w.", "tokens": [50904, 741, 4382, 23341, 14064, 41175, 3992, 9726, 339, 344, 1427, 4328, 74, 44895, 3901, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 138, "seek": 58400, "start": 598.0, "end": 601.8, "text": " Ale jest jeszcze jeden test, kt\u00f3ry pokazuje zupe\u0142nie now\u0105 jako\u015b\u0107.", "tokens": [51064, 9366, 3492, 14168, 12906, 1500, 11, 9913, 13010, 43317, 49922, 586, 1611, 17123, 7753, 13, 51254], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 139, "seek": 58400, "start": 601.8, "end": 605.8, "text": " Domy\u015blam si\u0119, \u017ce m\u00f3wisz o zdolno\u015bci do pracy z d\u0142ugim kontekstem.", "tokens": [51254, 413, 8488, 1788, 4326, 3244, 11, 3561, 13489, 23848, 277, 16221, 401, 16438, 360, 35591, 710, 274, 34077, 332, 14373, 916, 1099, 13, 51454], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 140, "seek": 58400, "start": 605.8, "end": 608.0, "text": " S\u0142ynny test i g\u0142\u00f3w z Togusiana.", "tokens": [51454, 318, 1221, 2534, 1634, 1500, 741, 18117, 3901, 710, 314, 664, 301, 8497, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 141, "seek": 58400, "start": 608.0, "end": 609.3, "text": " Dok\u0142adnie.", "tokens": [51564, 29768, 10358, 2766, 13, 51629], "temperature": 0.0, "avg_logprob": -0.12393472427712347, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.005153968930244446}, {"id": 142, "seek": 60930, "start": 609.3, "end": 612.4, "text": " Test nazywa si\u0119 PASKY RETRIVAL.", "tokens": [50364, 9279, 20151, 88, 4151, 3244, 430, 3160, 42, 56, 497, 4850, 5577, 53, 3427, 13, 50519], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 143, "seek": 60930, "start": 612.4, "end": 615.0999999999999, "text": " Wyja\u015bnimy, na czym polega.", "tokens": [50519, 14458, 2938, 1788, 77, 13189, 11, 1667, 31466, 13208, 3680, 13, 50654], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 144, "seek": 60930, "start": 615.0999999999999, "end": 621.0999999999999, "text": " Model otrzymuje ekstremalnie d\u0142ugi dokument, powiedzmy na milion token\u00f3w,", "tokens": [50654, 17105, 4337, 13047, 76, 13008, 13359, 372, 2579, 304, 2766, 44042, 24780, 40858, 11, 27617, 2226, 1667, 1962, 313, 14862, 3901, 11, 50954], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 145, "seek": 60930, "start": 621.0999999999999, "end": 625.4, "text": " kt\u00f3ry jest wype\u0142niony losowymi, nieistotnymi informacjami.", "tokens": [50954, 9913, 3492, 4628, 31457, 77, 46184, 1750, 10089, 3057, 11, 2838, 468, 310, 31813, 1356, 326, 73, 4526, 13, 51169], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 146, "seek": 60930, "start": 625.4, "end": 629.5, "text": " Gdzie\u015b g\u0142\u0119boko w tym tek\u015bcie ukryta jest jedna kr\u00f3tka informacja.", "tokens": [51169, 460, 13096, 1788, 18117, 1274, 65, 13704, 261, 8107, 16624, 9815, 26769, 627, 1328, 3492, 5232, 629, 42366, 83, 2330, 1356, 23395, 13, 51374], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 147, "seek": 60930, "start": 629.5, "end": 634.4, "text": " Na przyk\u0142ad zdanie tajny klucz to 1234.", "tokens": [51374, 6056, 23144, 16221, 7155, 256, 1805, 1634, 9671, 1311, 89, 281, 2272, 12249, 13, 51619], "temperature": 0.0, "avg_logprob": -0.12436178175069518, "compression_ratio": 1.2560975609756098, "no_speech_prob": 0.006754620932042599}, {"id": 148, "seek": 63440, "start": 634.4, "end": 639.3, "text": " Zadaniem modelu jest odnalezienie tego jednego zdania na podstawie prostego pytania.", "tokens": [50364, 1176, 11338, 4907, 2316, 84, 3492, 3611, 77, 37646, 27385, 8627, 5232, 11858, 16221, 5609, 1667, 43443, 414, 10293, 6308, 25878, 5609, 13, 50609], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 149, "seek": 63440, "start": 639.3, "end": 646.3, "text": " To jest ostateczny test na zdolno\u015b\u0107 do utrzymania uwagi i rozumienia na ogromn\u0105 skal\u0119.", "tokens": [50609, 1407, 3492, 277, 15406, 3689, 1634, 1500, 1667, 16221, 401, 23293, 360, 2839, 13047, 37268, 23147, 20291, 741, 48797, 18811, 1667, 34416, 298, 13113, 16890, 1274, 13, 50959], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 150, "seek": 63440, "start": 646.3, "end": 647.6999999999999, "text": " I jak sobie z tym poradzi\u0142?", "tokens": [50959, 286, 4207, 13652, 710, 8107, 1515, 345, 3992, 1221, 30, 51029], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 151, "seek": 63440, "start": 647.6999999999999, "end": 653.1, "text": " Model QN-25 Turbo osi\u0105gn\u0105\u0142 100% skuteczno\u015bci.", "tokens": [51029, 17105, 1249, 45, 12, 6074, 35848, 3003, 11404, 4568, 1611, 1221, 2319, 4, 1110, 1169, 3689, 16438, 13, 51299], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 152, "seek": 63440, "start": 653.1, "end": 658.0, "text": " Znalaz\u0142 klucz za ka\u017cdym razem w tek\u015bcie o d\u0142ugo\u015bci miliona token\u00f3w.", "tokens": [51299, 1176, 4660, 921, 1221, 9671, 1311, 89, 7949, 31615, 76, 40225, 261, 16624, 9815, 277, 44042, 20746, 6199, 1962, 21758, 14862, 3901, 13, 51544], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 153, "seek": 63440, "start": 658.0, "end": 661.9, "text": " \u017beby da\u0107 skal\u0119 to tak, jakby przeczyta\u0107 wojn\u0119 i pok\u00f3j dwa razy", "tokens": [51544, 46864, 2322, 1120, 2162, 16890, 1274, 281, 991, 11, 28976, 8325, 6522, 42931, 40758, 77, 1274, 741, 13010, 18999, 35045, 9639, 88, 51739], "temperature": 0.0, "avg_logprob": -0.10981863258528883, "compression_ratio": 1.397887323943662, "no_speech_prob": 0.022031955420970917}, {"id": 154, "seek": 66190, "start": 661.9, "end": 667.3, "text": " i by\u0107 w stanie wskaza\u0107 jedno konkretne losowe zdanie ukryte gdzie\u015b w \u015brodku.", "tokens": [50364, 741, 15069, 261, 40013, 261, 5161, 12257, 2162, 5232, 1771, 36500, 716, 1750, 6880, 16221, 7155, 26769, 627, 975, 41359, 261, 28580, 5279, 13, 50634], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 155, "seek": 66190, "start": 667.3, "end": 671.5, "text": " To jest dow\u00f3d na niezwyk\u0142\u0105 zdolno\u015b\u0107 do przetwarzania informacji.", "tokens": [50634, 1407, 3492, 9459, 17081, 1667, 33511, 9726, 74, 15926, 16221, 401, 23293, 360, 6541, 302, 31991, 5609, 1356, 13152, 13, 50844], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 156, "seek": 66190, "start": 671.5, "end": 673.1999999999999, "text": " Niesamowite.", "tokens": [50844, 426, 530, 335, 305, 642, 13, 50929], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 157, "seek": 66190, "start": 673.1999999999999, "end": 678.4, "text": " Ale czy to jest w og\u00f3le praktyczne przetworzenie miliona token\u00f3w musi trwa\u0107 w wieki?", "tokens": [50929, 9366, 6430, 281, 3492, 261, 29229, 3206, 74, 874, 38491, 6541, 302, 28321, 16778, 1962, 21758, 14862, 3901, 37587, 504, 25234, 261, 3355, 2984, 30, 51189], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 158, "seek": 66190, "start": 678.4, "end": 682.1999999999999, "text": " Czy u\u017cytkownik nie umr\u00f3b z nud\u00f3w czekaj\u0105c na odpowied\u017a?", "tokens": [51189, 19832, 344, 1427, 4328, 74, 44895, 2838, 1105, 11721, 65, 710, 40045, 3901, 6472, 916, 38757, 1667, 36574, 10659, 30, 51379], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 159, "seek": 66190, "start": 682.1999999999999, "end": 685.0, "text": " I to jest w\u0142a\u015bnie kolejna wisienka na torcie.", "tokens": [51379, 286, 281, 3492, 14234, 23749, 629, 9074, 1053, 2330, 1667, 3930, 4260, 13, 51519], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 160, "seek": 66190, "start": 685.0, "end": 691.1999999999999, "text": " Dzi\u0119ki technikom optymalizacyjnym takim jak Dual Chunk Attention, DCA i Yarn", "tokens": [51519, 413, 34546, 1537, 1035, 298, 2427, 4199, 304, 590, 31285, 12996, 31732, 4207, 37625, 761, 3197, 31858, 11, 9114, 32, 741, 398, 1083, 51829], "temperature": 0.0, "avg_logprob": -0.09940209031915989, "compression_ratio": 1.4038461538461537, "no_speech_prob": 0.004274748731404543}, {"id": 161, "seek": 69120, "start": 691.2, "end": 695.5, "text": " modele nie tylko radz\u0105 sobie z d\u0142ugim kontekstem, ale robi\u0105 to znacznie szybciej.", "tokens": [50364, 4391, 306, 2838, 13219, 2843, 8925, 13652, 710, 274, 34077, 332, 14373, 916, 1099, 11, 6775, 3870, 11404, 281, 15397, 14875, 2766, 36456, 4260, 73, 13, 50579], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 162, "seek": 69120, "start": 695.5, "end": 702.4000000000001, "text": " Wykresy z raportu pokazuj\u0105 od 3x do 4x przyspieszenia w uzyskaniu pierwszej cz\u0119\u015bci odpowiedzi.", "tokens": [50579, 14458, 74, 495, 88, 710, 5099, 477, 84, 13010, 921, 13263, 3611, 805, 87, 360, 1017, 87, 6541, 749, 79, 530, 14320, 261, 16851, 749, 74, 25849, 27623, 16920, 41314, 36574, 3992, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 163, "seek": 69120, "start": 702.4000000000001, "end": 709.4000000000001, "text": " W metryce Time to First Token, czyli TTFT, QIWEN jest jednym z najszybszych modeli na rynku.", "tokens": [50924, 343, 1131, 627, 384, 6161, 281, 2386, 314, 8406, 11, 16591, 32576, 25469, 11, 1249, 40, 54, 2195, 3492, 5232, 12996, 710, 11212, 7706, 929, 28051, 2316, 72, 1667, 367, 2534, 5279, 13, 51274], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 164, "seek": 69120, "start": 709.4000000000001, "end": 714.1, "text": " To oznacza, \u017ce nie czekasz w niesko\u0144czono\u015b\u0107 na rozpocz\u0119cie generowania odpowiedzi,", "tokens": [51274, 1407, 277, 22672, 326, 2394, 11, 3561, 2838, 6472, 916, 19601, 261, 48100, 4093, 5248, 3689, 8957, 7753, 1667, 47576, 905, 11052, 4260, 1337, 21308, 36574, 3992, 11, 51509], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 165, "seek": 69120, "start": 714.1, "end": 716.4000000000001, "text": " nawet przy bardzo d\u0142ugich dokumentach.", "tokens": [51509, 22696, 6501, 9034, 274, 34077, 480, 40858, 608, 13, 51624], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 166, "seek": 69120, "start": 716.4000000000001, "end": 717.2, "text": " W porz\u0105dku.", "tokens": [51624, 343, 1515, 23876, 5279, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11307422534839527, "compression_ratio": 1.4197952218430034, "no_speech_prob": 0.0790168046951294}, {"id": 167, "seek": 71720, "start": 717.2, "end": 724.2, "text": " A wi\u0119c co to wszystko oznacza dla nas developer\u00f3w, badaczy, a nawet no zwyk\u0142ych u\u017cytkownik\u00f3w?", "tokens": [50364, 316, 16677, 598, 281, 22607, 277, 22672, 326, 2394, 12285, 5382, 10754, 3901, 11, 1578, 14691, 11, 257, 22696, 572, 43436, 74, 47655, 344, 1427, 4328, 74, 44895, 3901, 30, 50714], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 168, "seek": 71720, "start": 724.2, "end": 727.2, "text": " Jakie s\u0105 praktyczne implikacje tych osi\u0105gni\u0119\u0107?", "tokens": [50714, 15029, 414, 9015, 3206, 74, 874, 38491, 8484, 1035, 29293, 15180, 3003, 11404, 70, 35938, 2162, 30, 50864], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 169, "seek": 71720, "start": 727.2, "end": 729.7, "text": " My\u015bl\u0119, \u017ce s\u0105 co najmniej trzy.", "tokens": [50864, 1222, 28749, 11, 3561, 9015, 598, 11212, 47658, 34573, 13, 50989], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 170, "seek": 71720, "start": 729.7, "end": 734.7, "text": " Po pierwsze, to dalsza demokratyzacja dost\u0119pu do zaawansowanej AI.", "tokens": [50989, 6165, 45994, 11, 281, 274, 1124, 2394, 49432, 37433, 23395, 48209, 84, 360, 7949, 1607, 599, 23066, 73, 7318, 13, 51239], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 171, "seek": 71720, "start": 734.7, "end": 740.2, "text": " Dzi\u0119ki modelom Open Weight, kt\u00f3re s\u0105 tak wydajne, jaki\u015b startup w Warszawie,", "tokens": [51239, 413, 34546, 2316, 298, 7238, 44464, 11, 8864, 9015, 991, 25984, 1805, 716, 11, 34721, 18578, 261, 48479, 1607, 414, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 172, "seek": 71720, "start": 740.2, "end": 745.0, "text": " czy laboratorium uniwersyteckie w Bangalor, mog\u0105 eksperymentowa\u0107 z narz\u0119dziem,", "tokens": [51514, 6430, 5938, 41679, 36435, 5364, 88, 975, 547, 414, 261, 11538, 304, 284, 11, 34123, 30724, 610, 88, 518, 11445, 710, 6714, 89, 42643, 76, 11, 51754], "temperature": 0.0, "avg_logprob": -0.1563405990600586, "compression_ratio": 1.360655737704918, "no_speech_prob": 0.03646606579422951}, {"id": 173, "seek": 74500, "start": 745.0, "end": 749.5, "text": " kt\u00f3re do niedawna by\u0142o dost\u0119pne tylko dla garstki gigant\u00f3w z Doliny Kszemowej.", "tokens": [50364, 8864, 360, 32488, 1607, 629, 14811, 48209, 716, 13219, 12285, 3691, 372, 2984, 8741, 394, 3901, 710, 18786, 3519, 591, 15453, 443, 21091, 13, 50589], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 174, "seek": 74500, "start": 749.5, "end": 753.5, "text": " To obni\u017ca bariery wej\u015bcia i mo\u017ce uwolni\u0107 fale innowacji.", "tokens": [50589, 1407, 1111, 3722, 35075, 2159, 811, 88, 321, 73, 1788, 2755, 741, 12034, 23147, 401, 3722, 2162, 26772, 294, 3785, 13152, 13, 50789], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 175, "seek": 74500, "start": 753.5, "end": 758.0, "text": " A co z nowymi zastosowaniami, kt\u00f3re staj\u0105 si\u0119 mo\u017cliwe dzi\u0119ki tej technologii?", "tokens": [50789, 316, 598, 710, 586, 88, 3057, 36746, 329, 37345, 15568, 11, 8864, 342, 11133, 3244, 30854, 826, 45003, 12573, 1537, 1132, 5597, 30, 51014], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 176, "seek": 74500, "start": 758.0, "end": 762.0, "text": " Tutaj kluczowa jest w o\u017cgiel zdolno\u015b\u0107 do pracy z d\u0142ugim kontekstem.", "tokens": [51014, 41819, 9671, 1311, 89, 5528, 3492, 261, 277, 1427, 70, 1187, 16221, 401, 23293, 360, 35591, 710, 274, 34077, 332, 14373, 916, 1099, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 177, "seek": 74500, "start": 762.0, "end": 767.5, "text": " Otwiera to drzwi do zastosowa\u0144, kt\u00f3re do tej pory by\u0142y, no, w sferze science fiction.", "tokens": [51214, 12936, 86, 10609, 281, 1224, 89, 6253, 360, 36746, 329, 5528, 5248, 11, 8864, 360, 12573, 280, 827, 26366, 11, 572, 11, 261, 262, 612, 1381, 3497, 13266, 13, 51489], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 178, "seek": 74500, "start": 767.5, "end": 773.5, "text": " Wyobra\u017a sobie lekarza, kt\u00f3ry mo\u017ce wgra\u0107 do AI ostatnie 10 lat dokumentacji medycznej pacjenta.", "tokens": [51489, 14458, 24393, 10659, 13652, 476, 12303, 2394, 11, 9913, 12034, 261, 20735, 2162, 360, 7318, 32686, 2766, 1266, 4465, 40858, 13152, 1205, 17466, 11794, 15165, 73, 8938, 13, 51789], "temperature": 0.0, "avg_logprob": -0.08607465464894365, "compression_ratio": 1.4421364985163205, "no_speech_prob": 0.0465516559779644}, {"id": 179, "seek": 77350, "start": 773.5, "end": 777.5, "text": " Wszystkie wyniki bada\u0144, wizyty, opisy i zapyta\u0107.", "tokens": [50364, 343, 10424, 22872, 31936, 9850, 272, 1538, 5248, 11, 40808, 41944, 11, 999, 14169, 741, 14223, 88, 42931, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 180, "seek": 77350, "start": 777.5, "end": 781.5, "text": " Jakich wzorc\u00f3w lub korelacji tutaj nie dostrzegam?", "tokens": [50564, 15029, 480, 24809, 284, 29268, 15980, 350, 418, 75, 13152, 12749, 2838, 20568, 19390, 1146, 335, 30, 50764], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 181, "seek": 77350, "start": 781.5, "end": 785.5, "text": " Albo analityka finansowego, kt\u00f3ry w kilka minut przetwarza raporty kwartalne,", "tokens": [50764, 967, 1763, 364, 1860, 2330, 38843, 26576, 11, 9913, 261, 36466, 13951, 6541, 302, 6925, 2394, 5099, 477, 88, 23846, 446, 304, 716, 11, 50964], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 182, "seek": 77350, "start": 785.5, "end": 791.5, "text": " transkrypcj\u0119 rozm\u00f3w z inwestorami i wewn\u0119trzne maile firmy, \u017ceby uzyska\u0107 pe\u0142ny obraz sytuacji.", "tokens": [50964, 1145, 43298, 79, 41960, 35234, 3901, 710, 294, 8750, 284, 4526, 741, 321, 895, 1274, 6903, 43077, 463, 794, 12159, 2226, 11, 11316, 16851, 749, 2330, 2162, 43205, 1634, 22798, 89, 28275, 13152, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 183, "seek": 77350, "start": 791.5, "end": 793.5, "text": " To staje si\u0119 teraz realne.", "tokens": [51264, 1407, 342, 11153, 3244, 16854, 957, 716, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 184, "seek": 77350, "start": 793.5, "end": 797.5, "text": " I jest jeszcze trzecia implikacja zapewne zwi\u0105zana z biznesem.", "tokens": [51364, 286, 3492, 14168, 22266, 2755, 8484, 1035, 23395, 7949, 494, 86, 716, 27741, 2095, 710, 7390, 4081, 443, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08852774302164713, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0404294952750206}, {"id": 185, "seek": 79750, "start": 797.5, "end": 804.5, "text": " Eport jasno pokazuje, \u017ce modele takie jak QN 2.5 Turbo oferuj\u0105 wydajno\u015b\u0107 na poziomie GPT-4O mini,", "tokens": [50364, 9970, 477, 361, 296, 1771, 13010, 43317, 11, 3561, 4391, 306, 15963, 4207, 1249, 45, 568, 13, 20, 35848, 295, 260, 13263, 25984, 1805, 23293, 1667, 38503, 40120, 26039, 51, 12, 19, 46, 8382, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 186, "seek": 79750, "start": 804.5, "end": 807.5, "text": " ale przy potencjalnie ni\u017cszych kosztach operacyjnych.", "tokens": [50714, 6775, 6501, 1847, 22660, 22600, 2766, 28502, 45021, 19532, 2682, 608, 2208, 31285, 9399, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 187, "seek": 79750, "start": 807.5, "end": 813.5, "text": " Dla firm, kt\u00f3re wdra\u017caj\u0105 AI na du\u017c\u0105 skal\u0119, ka\u017cdy u\u0142amek centa zaprzetworzony token ma znaczenie.", "tokens": [50864, 413, 875, 6174, 11, 8864, 261, 67, 424, 1427, 11133, 7318, 1667, 21783, 1611, 16890, 1274, 11, 31615, 344, 1221, 529, 74, 1489, 64, 14223, 19390, 302, 28321, 44479, 14862, 463, 15397, 326, 16778, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 188, "seek": 79750, "start": 813.5, "end": 818.5, "text": " Lepsza wydajno\u015b\u0107 przy mniejszym rozmiarze modelu bezpo\u015brednio przek\u0142ada si\u0119 na oszcz\u0119dno\u015bci", "tokens": [51164, 441, 10653, 2394, 25984, 1805, 23293, 6501, 39513, 7706, 76, 9544, 3057, 289, 1381, 2316, 84, 10782, 2259, 1788, 986, 41084, 29785, 46217, 3244, 1667, 3003, 43771, 6298, 16438, 51414], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 189, "seek": 79750, "start": 818.5, "end": 821.5, "text": " i zmienia rachunek ekonomiczny dla ca\u0142ych kategorii produkt\u00f3w.", "tokens": [51414, 741, 17020, 18811, 367, 608, 409, 916, 13359, 12481, 17946, 1634, 12285, 35226, 339, 350, 2968, 284, 5597, 42816, 3901, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 190, "seek": 79750, "start": 821.5, "end": 824.5, "text": " Brzmi jak lista samych sukces\u00f3w.", "tokens": [51564, 1603, 89, 3057, 4207, 27764, 3247, 16384, 46432, 887, 3901, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10164755582809448, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.06762408465147018}, {"id": 191, "seek": 82450, "start": 824.5, "end": 826.5, "text": " Ale przecie\u017c nie wszystko mo\u017ce by\u0107 idealne.", "tokens": [50364, 9366, 8325, 40082, 2838, 22607, 12034, 15069, 7157, 716, 13, 50464], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 192, "seek": 82450, "start": 826.5, "end": 832.5, "text": " Czy w raporcie wspomniano o jakich\u015b ograniczeniach, o drobnym druku?", "tokens": [50464, 19832, 261, 5099, 284, 4260, 17757, 38131, 6254, 277, 4207, 480, 1788, 34416, 30732, 42124, 608, 11, 277, 3789, 65, 12996, 38864, 5279, 30, 50764], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 193, "seek": 82450, "start": 832.5, "end": 834.5, "text": " S\u0105 w tej kwestii do\u015b\u0107 transparentni.", "tokens": [50764, 318, 1611, 261, 12573, 42035, 5597, 49333, 12737, 3722, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 194, "seek": 82450, "start": 834.5, "end": 838.5, "text": " Wskazuj\u0105 na przyk\u0142ad, \u017ce chocia\u017c model jest bardzo dobry w zadaniach wieloj\u0119zycznych,", "tokens": [50864, 343, 5161, 921, 13263, 1667, 23144, 11, 3561, 48929, 2316, 3492, 9034, 35884, 261, 42788, 3782, 608, 20570, 78, 11115, 1229, 3689, 9399, 11, 51064], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 195, "seek": 82450, "start": 838.5, "end": 843.5, "text": " to wci\u0105\u017c jest pole do poprawy w rozumieniu subtelnych niuans\u00f3w kulturowych w r\u00f3\u017cnych j\u0119zykach.", "tokens": [51064, 281, 261, 537, 27242, 3492, 13208, 360, 1665, 5131, 88, 261, 48797, 1053, 5951, 7257, 338, 9399, 3867, 84, 599, 3901, 350, 26099, 19605, 261, 42602, 49055, 41326, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 196, "seek": 82450, "start": 843.5, "end": 848.5, "text": " To pokazuje, \u017ce samo t\u0142umaczenie danych nie wystarczy, aby model w pe\u0142ni zrozumia\u0142 kultur\u0119.", "tokens": [51314, 1407, 13010, 43317, 11, 3561, 36422, 256, 49166, 326, 16778, 274, 34644, 2838, 4628, 9710, 6522, 11, 24457, 2316, 261, 43205, 3722, 710, 27857, 449, 8908, 350, 26099, 1274, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 197, "seek": 82450, "start": 848.5, "end": 850.5, "text": " Ale poruszaj\u0105 te\u017c ciekawszy problem badawczy.", "tokens": [51564, 9366, 1515, 22378, 11133, 9516, 46419, 1607, 7706, 1154, 272, 1538, 86, 6522, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 198, "seek": 82450, "start": 850.5, "end": 851.5, "text": " To znaczy?", "tokens": [51664, 1407, 36584, 30, 51714], "temperature": 0.0, "avg_logprob": -0.05332624176402151, "compression_ratio": 1.5, "no_speech_prob": 0.008878379128873348}, {"id": 199, "seek": 85150, "start": 851.5, "end": 858.5, "text": " Zauwa\u017caj\u0105, \u017ce obecne metody oceny reward models, tych s\u0119dzi\u00f3w w procesie reinforcement learning,", "tokens": [50364, 1176, 1459, 27111, 11133, 11, 3561, 49141, 716, 1131, 843, 10409, 43100, 7782, 5245, 11, 15180, 262, 6298, 3992, 3901, 261, 17565, 414, 29280, 2539, 11, 50714], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 200, "seek": 85150, "start": 858.5, "end": 862.5, "text": " nie zawsze idealnie przek\u0142adaj\u0105 si\u0119 na ostateczn\u0105 jako\u015b\u0107 modelu.", "tokens": [50714, 2838, 30964, 7157, 2766, 29785, 46217, 8555, 3244, 1667, 277, 15406, 3689, 13113, 17123, 7753, 2316, 84, 13, 50914], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 201, "seek": 85150, "start": 862.5, "end": 866.5, "text": " Innymi s\u0142owy, nawet je\u015bli masz \u015bwietnego s\u0119dziego, nie gwarantuje to,", "tokens": [50914, 682, 31813, 15116, 10089, 11, 22696, 25630, 2300, 89, 8299, 39083, 11858, 262, 42643, 1571, 11, 2838, 290, 6925, 394, 13008, 281, 11, 51114], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 202, "seek": 85150, "start": 866.5, "end": 870.5, "text": " \u017ce tw\u00f3j zawodnik w klubie dyskusyjnym b\u0119dzie najlepszy na \u015bwiecie.", "tokens": [51114, 3561, 683, 18999, 28165, 378, 13123, 261, 9671, 836, 414, 15243, 35080, 88, 73, 12996, 10562, 41903, 1878, 1229, 1667, 40078, 4260, 13, 51314], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 203, "seek": 85150, "start": 870.5, "end": 872.5, "text": " To rodzi fundamentalne pytanie.", "tokens": [51314, 1407, 8685, 3992, 8088, 716, 36610, 13, 51414], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 204, "seek": 85150, "start": 872.5, "end": 876.5, "text": " Je\u015bli nie do ko\u0144ca wiemy, jak mierzy\u0107 jako\u015b\u0107 nauczyciela,", "tokens": [51414, 37086, 2838, 360, 26470, 496, 3355, 2226, 11, 4207, 47448, 27150, 17123, 7753, 49103, 1229, 537, 4053, 11, 51614], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 205, "seek": 85150, "start": 876.5, "end": 880.5, "text": " to jak mo\u017cemy by\u0107 pewni, \u017ce ucze\u0144 jest szkolony w optymalny spos\u00f3b?", "tokens": [51614, 281, 4207, 26500, 15069, 47160, 72, 11, 3561, 344, 9680, 5248, 3492, 7870, 36620, 2526, 261, 2427, 4199, 304, 1634, 22904, 30, 51814], "temperature": 0.0, "avg_logprob": -0.054509823618371506, "compression_ratio": 1.4969135802469136, "no_speech_prob": 0.04735827073454857}, {"id": 206, "seek": 88050, "start": 880.5, "end": 885.5, "text": " Dok\u0142adnie. To jest jedno z kluczowych wyzwa\u0144, przed kt\u00f3rymi stoi obecnie ca\u0142a bran\u017ca AI.", "tokens": [50364, 29768, 10358, 2766, 13, 1407, 3492, 5232, 1771, 710, 9671, 1311, 89, 19605, 4628, 89, 4151, 5248, 11, 18334, 9913, 3057, 342, 4869, 49141, 2766, 1335, 5024, 12029, 35075, 7318, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05457666660177297, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.0019682375714182854}, {"id": 207, "seek": 88050, "start": 885.5, "end": 889.5, "text": " To, \u017ce autorze raportu otwarcie o tym m\u00f3wi\u0105, pokazuje dojrza\u0142o\u015b\u0107 ich podej\u015bcia", "tokens": [50614, 1407, 11, 3561, 19510, 1381, 5099, 477, 84, 4337, 6925, 4260, 277, 8107, 46591, 11, 13010, 43317, 360, 73, 81, 2394, 44742, 1893, 7468, 73, 1788, 2755, 50814], "temperature": 0.0, "avg_logprob": -0.05457666660177297, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.0019682375714182854}, {"id": 208, "seek": 88050, "start": 889.5, "end": 891.5, "text": " i wskazuje kierunki dla przysz\u0142ych bada\u0144.", "tokens": [50814, 741, 261, 5161, 43317, 38767, 409, 2984, 12285, 44018, 47655, 272, 1538, 5248, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05457666660177297, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.0019682375714182854}, {"id": 209, "seek": 88050, "start": 891.5, "end": 896.5, "text": " Uje\u017cd\u017c\u0119, \u017ce mamy do czynienia z prawdziwym prze\u0142omem w efektywno\u015bci modeli j\u0119zykowych.", "tokens": [50914, 624, 2884, 1427, 67, 1427, 1274, 11, 3561, 17335, 360, 6430, 77, 18811, 710, 41175, 3992, 86, 4199, 8325, 1221, 423, 76, 261, 31482, 916, 874, 20944, 6199, 2316, 72, 49055, 74, 19605, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05457666660177297, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.0019682375714182854}, {"id": 210, "seek": 88050, "start": 896.5, "end": 903.5, "text": " Usi\u0105gni\u0119to go nie przez bezmy\u015blne skalowanie, ale przez inteligentne podej\u015bcie do danych", "tokens": [51164, 624, 7691, 1611, 70, 35938, 1353, 352, 2838, 14064, 10782, 2226, 19212, 716, 16890, 22028, 11, 6775, 14064, 24777, 25002, 716, 7468, 73, 9815, 360, 274, 34644, 51514], "temperature": 0.0, "avg_logprob": -0.05457666660177297, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.0019682375714182854}, {"id": 211, "seek": 90350, "start": 903.5, "end": 911.5, "text": " i zaawansowany wieloetapowy proces dostrajania, kt\u00f3ry zamienia encyklopedyczn\u0105 wiedz\u0119 w praktyczn\u0105 m\u0105dro\u015b\u0107.", "tokens": [50364, 741, 7949, 1607, 599, 23341, 20570, 78, 302, 569, 10089, 17565, 20568, 48690, 5609, 11, 9913, 19876, 18811, 465, 1344, 7837, 404, 6038, 3689, 13113, 46894, 11052, 261, 3206, 74, 874, 3689, 13113, 275, 18962, 340, 7753, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 212, "seek": 90350, "start": 911.5, "end": 913.5, "text": " My\u015bl\u0119, \u017ce to jest kluczowy wniosek.", "tokens": [50764, 1222, 28749, 11, 3561, 281, 3492, 9671, 1311, 89, 10089, 261, 3722, 541, 74, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 213, "seek": 90350, "start": 913.5, "end": 918.5, "text": " Era, w kt\u00f3rej wi\u0119kszy automatycznie znaczy\u0142o lepszy, powoli dobiega ko\u0144ca.", "tokens": [50864, 23071, 11, 261, 36023, 29968, 1229, 28034, 17466, 2766, 36584, 5249, 476, 1878, 1229, 11, 3388, 9384, 360, 7392, 3680, 26470, 496, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 214, "seek": 90350, "start": 918.5, "end": 921.5, "text": " Teraz na pierwszy plan wysuwa si\u0119 m\u0105drzejszy.", "tokens": [51114, 41810, 1667, 34016, 1393, 27062, 84, 4151, 3244, 275, 18962, 13503, 73, 7706, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 215, "seek": 90350, "start": 921.5, "end": 927.5, "text": " M\u0105drzejszy w doborze danych, m\u0105drzejszy w architekturze i m\u0105drzejszy w procesie treningu.", "tokens": [51264, 376, 18962, 13503, 73, 7706, 261, 360, 3918, 1381, 274, 34644, 11, 275, 18962, 13503, 73, 7706, 261, 3912, 642, 2320, 374, 1381, 741, 275, 18962, 13503, 73, 7706, 261, 17565, 414, 2192, 773, 84, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 216, "seek": 90350, "start": 927.5, "end": 930.5, "text": " Kuwen 2.5 jest tego doskona\u0142ym dowodem.", "tokens": [51564, 20311, 15615, 568, 13, 20, 3492, 8627, 4491, 74, 4037, 1221, 4199, 9459, 378, 443, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06918886991647574, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.34665361046791077}, {"id": 217, "seek": 93050, "start": 930.5, "end": 933.5, "text": " Zostawmy naszych s\u0142uchaczy z jedn\u0105 my\u015bl\u0105.", "tokens": [50364, 1176, 555, 1607, 2226, 45002, 15116, 625, 14691, 710, 5232, 13113, 452, 19212, 1611, 13, 50514], "temperature": 0.0, "avg_logprob": -0.042698515222427694, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.26070019602775574}, {"id": 218, "seek": 93050, "start": 933.5, "end": 938.5, "text": " W podsumowaniu raportu autorzy zapowiadaj\u0105 dalsze prace nad modelami multimodalnymi,", "tokens": [50514, 343, 31925, 449, 305, 25849, 5099, 477, 84, 19510, 1229, 14223, 24503, 1538, 8555, 274, 1124, 1381, 582, 617, 12617, 2316, 4526, 32972, 378, 304, 31813, 11, 50764], "temperature": 0.0, "avg_logprob": -0.042698515222427694, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.26070019602775574}, {"id": 219, "seek": 93050, "start": 938.5, "end": 943.5, "text": " kt\u00f3re b\u0119d\u0105 w stanie przetwarza\u0107 i \u0142\u0105czy\u0107 tekst, obraz i d\u017awi\u0119k w jednym systemie.", "tokens": [50764, 8864, 26239, 261, 40013, 6541, 302, 6925, 35873, 741, 220, 15926, 33967, 16624, 372, 11, 22798, 89, 741, 274, 10659, 22423, 74, 261, 5232, 12996, 1185, 414, 13, 51014], "temperature": 0.0, "avg_logprob": -0.042698515222427694, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.26070019602775574}, {"id": 220, "seek": 93050, "start": 943.5, "end": 949.5, "text": " Skoro modele staj\u0105 si\u0119 nie tylko wydajniejsze, ale te\u017c bardziej wielozmys\u0142owe, fundamentalne pytanie brzmi.", "tokens": [51014, 7324, 10780, 4391, 306, 342, 11133, 3244, 2838, 13219, 25984, 1805, 44258, 11, 6775, 9516, 27209, 20570, 15151, 76, 39508, 6880, 11, 8088, 716, 36610, 738, 89, 3057, 13, 51314], "temperature": 0.0, "avg_logprob": -0.042698515222427694, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.26070019602775574}, {"id": 221, "seek": 93050, "start": 949.5, "end": 956.5, "text": " Co nowego mo\u017ce stworzy\u0107 maszyna, kt\u00f3ra b\u0119dzie przetwarza\u0107 \u015bwiat w spos\u00f3b bardziej zbli\u017cony do ludzkiego?", "tokens": [51314, 3066, 586, 6308, 12034, 342, 28321, 27150, 2300, 1229, 629, 11, 19456, 10562, 6541, 302, 6925, 35873, 36425, 261, 22904, 27209, 710, 32117, 1427, 2526, 360, 15946, 30154, 12200, 30, 51664], "temperature": 0.0, "avg_logprob": -0.042698515222427694, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.26070019602775574}, {"id": 222, "seek": 95650, "start": 956.5, "end": 962.5, "text": " Jakie zupe\u0142nie nowe formy kreatywno\u015bci czy naukowe odkrycia mog\u0105 z tego wynikn\u0105\u0107?", "tokens": [50364, 15029, 414, 49922, 586, 68, 1254, 88, 350, 620, 88, 20944, 6199, 6430, 35616, 74, 6880, 3611, 43298, 2755, 34123, 710, 8627, 31936, 1035, 13113, 2162, 30, 50664], "temperature": 0.0, "avg_logprob": -0.02982756495475769, "compression_ratio": 0.9772727272727273, "no_speech_prob": 0.08906959742307663}], "language": "pl"}