{"text": " Wyobra\u017amy sobie tak\u0105 sytuacj\u0119. Nie mamy jednego genialnego specjalisty od wszystkiego, ale mamy genialnego mened\u017cera projektu. Kogo\u015b kto sam nie musi by\u0107 programist\u0105, grafikiem i copyrighterem, ale potrafi wierszwirtuozersko zarz\u0105dza\u0107 ca\u0142ym zespo\u0142em ekspert\u00f3w i spi\u0105\u0107 ich prac\u0119 w jeden sp\u00f3jny genialny produkt. Dobra analogia. A teraz pomy\u015blimy, \u017ce takim mened\u017cerem jest model j\u0119zykowy. I to jest, no, dok\u0142adnie sedno pracy, kt\u00f3r\u0105 dzisiaj bierzemy na warsztat. Artyku\u0142 z Microsoft Research, zatytu\u0142owany Language Models are General Purpose Interfaces, rzuca w\u0142a\u015bnie tak\u0105 tez\u0119. A tym metaforycznym mened\u017cerem jest architektura o nazwie Metal LM. W\u0142a\u015bnie. Naszym celem dzisiaj jest rozebranie naczynniki pierwsze. Jak oni w og\u00f3le pr\u00f3buj\u0105 po\u0142\u0105czy\u0107 dwa? Do tej pory powiedzia\u0142abym niemal wrogie sobie \u015bwiaty modeli AI. Tak, to dobre okre\u015blenie. Chodzi o stworzenie czego\u015b na kszta\u0142t uniwersalnego interfejsu, kt\u00f3ry bierze to, co najlepsze z obu tych podej\u015b\u0107 i to bez wi\u0119kszych kompromis\u00f3w. Co do tej pory by\u0142o, no, w zasadzie niemo\u017cliwe. Zawsze by\u0142 jaki\u015b wyb\u00f3r, co\u015b za co\u015b. No w\u0142a\u015bnie. Ustalmy mo\u017ce scen\u0119, bo to jest kluczowe. W \u015bwiecie AI mamy w du\u017cym uproszczeniu dwa obozy. Dwie filozofie budowania d\u0142u\u017cych modeli j\u0119zykowych. Z jednej strony kreatorzy z drugiej analitycy. Dlaczego tak trudno by\u0142o ich pogodzi\u0107? To jest fundamentalny problem, kt\u00f3ry troch\u0119 hamowa\u0142 post\u0119p w kierunku takiej prawdziwie uniwersalnej AI. Z jednej strony mamy modele, kt\u00f3re nazywamy Cozel Models. Rodzina GPT. Tak, ca\u0142a rodzina GPT. One dzia\u0142aj\u0105 jednokierunkowo. Czytaj\u0105 tekst od lewej do prawej i ich jedynym zadaniem jest przewidzenie nast\u0119pnego s\u0142owa. To sprawia, \u017ce s\u0105 absolutnymi mistrzami w otwartym generowaniu tekstu. To s\u0105 nasi kreatywni autorzy, improwizatorzy. To one potrafi\u0105 pisa\u0107 wiersze, scenariusze, no i prowadzi\u0107 w miar\u0119 swobodn\u0105 rozmow\u0119. W nich te\u017c dzia\u0142a ta ca\u0142a magia in-context learning, czyli uczenia si\u0119 w locie z kilku przyk\u0142ad\u00f3w. Dok\u0142adnie. Ale ta jednokierunkowo\u015b\u0107 jest te\u017c ich pewn\u0105 s\u0142abo\u015bci\u0105. Kiedy musz\u0105 naprawd\u0119 g\u0142\u0119boko zrozumie\u0107 kontekst ca\u0142ego zdania, przeanalizowa\u0107 niuanse, brakuje im takiego spojrzenia zlotu ptaka. I wtedy na scen\u0119 wchodz\u0105 ci drudzy. I tu na scen\u0119 wchodz\u0105 modele z drugiego obozu. Non-cozel models, kt\u00f3rych kr\u00f3lem jest Bert. One s\u0105 dwukierunkowe. Czyli analizuj\u0105 zdanie patrz\u0105c jednocze\u015bnie w prz\u00f3d i w ty\u0142. Maj\u0105 pe\u0142en obraz. Pe\u0142en obraz. I dzi\u0119ki temu deklasuj\u0105 modele kausalne w zadaniach, kt\u00f3re wymagaj\u0105 g\u0142\u0119bokiego rozumienia kontekstu, jak analiza sentymentu, czy odpowiadanie na pytania na podstawie jakiego\u015b tekstu. To nasi skrupulatni analitycy. W\u0142a\u015bnie. A ich pot\u0119ga ujawnia si\u0119 po procesie, kt\u00f3ry znamy jako find tuning. Czyli precyzyjnym do strojeniu do jednego konkretnego zadania. Staj\u0105 si\u0119 wtedy powiedzmy w\u0105skimi specjalistami o niemal nadludzkiej precyzji. Czyli stajemy przed wyborem. Albo elastyczny i kreatywny generator, kt\u00f3ry uczy si\u0119 w locie, ale bywa powierzchnowny. Tak. Albo pot\u0119\u017cny, precyzyjny analityk, kt\u00f3rego trzeba d\u0142ugo i kosztownie szkoli\u0107 do ka\u017cdej nowej roli i kt\u00f3ry, co wa\u017cne, nie potrafi generowa\u0107 otwartego tekstu. Albo jedno albo drugie. I tu w\u0142a\u015bnie Tkwi powiedzia\u0142bym rewolucyjno\u015b\u0107 tezy z tej pracy. Autorzy m\u00f3wi\u0105, stop, nie musimy wybiera\u0107. Model metalen ma by\u0107 tym mostem. Ma by\u0107 jednocze\u015bnie analitykiem i kreatorem. Okej, na papierze taka hybryda wygl\u0105da genialnie. Ale w \u015bwiecie AI pe\u0142no jest pi\u0119knych idei, kt\u00f3re rozbijaj\u0105 si\u0119 o tward\u0105 rzeczywisto\u015b\u0107. Jak to jest w og\u00f3le zbudowane? Co oni zrobili pod mask\u0105, \u017ceby po\u0142\u0105czy\u0107 ten ogie\u0144 z wod\u0105? Kluczem jest architektura modu\u0142owa. Zamiast budowa\u0107 jeden monolityczny model, stworzyli co\u015b na kszta\u0142t systemu. Metan sk\u0142ada si\u0119 z wielu wyspecjalizowanych dwukierunkowych enkoder\u00f3w. To s\u0105 w\u0142a\u015bnie nasi analitycy. Ka\u017cdy od czego\u015b innego. Tak, ka\u017cdy mo\u017ce by\u0107 ekspertem od czego\u015b innego. Jeden od analizy tekstu, drugi od rozpoznawania obraz\u00f3w, a w przysz\u0142o\u015bci kto wie mo\u017ce i trzeci od przetwarzania d\u017awi\u0119ku. Okej, czyli mamy zesp\u00f3\u0142 specjalist\u00f3w, kt\u00f3rzy potrafi\u0105 dog\u0142\u0119bnie przeanalizowa\u0107 r\u00f3\u017cne typy danych. A gdzie jest ten mened\u017cer, kt\u00f3ry tym wszystkim zarz\u0105dza? Tym mened\u017cerem, a jednocze\u015bnie tym uniwersalnym interfejsem, jest jeden centralny, jednokierunkowy dekoder. To jest nasz kreatywny autor, podobny w dzia\u0142aniu do GPT. I te wszystkie specjalistyczne enkodery jakby dokuj\u0105 do niego. Przekazuj\u0105 mu swoje g\u0142\u0119bokie, przeanalizowane wnioski, a on na tej podstawie generuje ostateczn\u0105, sp\u00f3jn\u0105 odpowied\u017a w j\u0119zyku naturalnym. Czyli enkodery robi\u0105 taki g\u0142\u0119boki research, a dekoder pisze na jego podstawie finalny raport. Ciekawe, ale jak zmusi\u0107 te dwie tak r\u00f3\u017cne od siebie cz\u0119\u015bci, \u017ceby ze sob\u0105 wsp\u00f3\u0142pracowa\u0142y? To pewnie wymaga\u0142o jakie\u015b zupe\u0142nie nowej metody treningu. I to jest druga du\u017ca innowacja. Stworzyli now\u0105 technik\u0119, kt\u00f3r\u0105 nazwali Semicosal Language Modeling. Wiesz, w du\u017cym uproszczeniu w trakcie treningu model najpierw przetwarza dane wej\u015bciowe za pomow\u0105 tych dwukierunkowych enkoder\u00f3w, Pozwala im na pe\u0142n\u0105 analiz\u0119. Dok\u0142adnie. Pozwala im na pe\u0142n\u0105, g\u0142\u0119bok\u0105 analiz\u0119. I dopiero ich przemy\u015blenia, czyli takie skompresowane, wektorowe reprezentacje, s\u0105 przekazywane do jednokierunkowego dekodera. A on uczy si\u0119 generowa\u0107 na ich podstawie sekwencyjn\u0105 odpowied\u017a, s\u0142owo po s\u0142owie. To jest fascynuj\u0105ce. Czyta\u0142am, \u017ce autorzy pracy u\u017cywaj\u0105 tu bardzo trafnej analogii do ludzkiego my\u015blenia, do tej koncepcji spopularyzowanej przez Daniela Kanchemana. Tak, tak. Por\u00f3wnuj\u0105 to do systemu 1 i systemu 2. Te wyspecjalizowane dwukierunkowe enkodeny dzia\u0142aj\u0105 jak ten szybki, intuicyjny i, co wa\u017cne, r\u00f3wnoleg\u0142y system 1. B\u0142yskawicznie przetwarzaj\u0105 percepcj\u0119, czyli to, co model widzi lub czyta. A dekoder? Natomiast ten centralny jednokierunkowe dekoder dzia\u0142a jak ten wolniejszy, bardziej metodyczny i powiedzmy \u015bwiadomy system 2. Odpowiedzialny za rozumowanie, planowanie i generowanie przymy\u015blanej sekwencyjnej odpowiedzi. Uwielbiam t\u0119 analogi\u0119, ale musz\u0119 zapyta\u0107, czy to tylko chwytliwy marketing, czy ta architektura faktycznie odzwierciedla te dwa tryby my\u015blenia, bo system 1 to nie tylko szybko\u015b\u0107, to te\u017c b\u0142\u0119dy poznawcze. Czy te enkodery te\u017c je wykazuj\u0105? To jest \u015bwietne pytanie, kt\u00f3rego praca bezpo\u015brednio nie adresuje, ale wskazuje na kluczow\u0105 r\u00f3\u017cnic\u0119. W przeciwie\u0144stwie do ludzkiego systemu 1 te enkodery s\u0105 precyzyjnie dostrajane do swoich zada\u0144, wi\u0119c ich intuicje s\u0105 oparte na, no, na twardych danych. Ale analogia trzyma si\u0119 o tyle, \u017ce mamy do czynienia z szybkim, holistycznym przetwarzaniem, po kt\u00f3rym nast\u0119puje wolniejsze sekwencyjne rozumowanie. W porz\u0105dku teoria jest niezwykle elegancka, ale przejd\u017amy do dowod\u00f3w. Pytanie brzmi, czy ten mened\u017cer projektu faktycznie dowi\u00f3z\u0142 w nitki, czy to tylko \u0142adna koncepcja? Zacznijmy od jego podstawowej kompetencji, czyli od j\u0119zyka. Tutaj, no c\u00f3\u017c, liczby m\u00f3wi\u0105 same za siebie. Wzi\u0119li 34 r\u00f3\u017cne zadania z dziedziny przetwarzania j\u0119zyka naturalnego i przeprowadzili test, kt\u00f3ry nazywa si\u0119 multitask fine tuning. Meta\u0142 by\u0142 por\u00f3wnywany z modelem typu GPT o podobnej wielko\u015bci. I co si\u0119 okaza\u0142o? W zadaniach wymagaj\u0105cych g\u0142\u0119bokiego rozumienia j\u0119zyka, czyli natural language understanding, po prostu go zdeklasowa\u0142. Zdeklasowa\u0142, czyli o ile by\u0142 lepszy? M\u00f3wimy o jaki\u015b konkretnych liczwach? Tak. W zadaniach z Grupy Natural Language Influence, kt\u00f3re sprawdzaj\u0105 zdolno\u015b\u0107 do logicznego wnioskowania, r\u00f3\u017cnica wynosi\u0142a ponad 14 punkt\u00f3w procentowych na korzy\u015b\u0107 metalm. 14 punkt\u00f3w? Tak. To nie jest b\u0142\u0105d statystyczny, to jest przepa\u015b\u0107. To ogromna przewaga. A to je\u015bli chcemy go wyspecjalizowa\u0107 tylko w jednej konkretnej dziedzinie? Jak sobie radzi w takim klasycznym fine tuningu do jednego zadania? Sprawdzili to na standardowym te\u015bcie MNLE, czyli Multigener Natural Language Influence, to jest taka, wiesz, olimpiada zrozumienia tekstu. I tutaj sta\u0142o si\u0119 co\u015b bardzo, bardzo ciekawego. No. Ta, kt\u00f3re s\u0105 stworzone w\u0142a\u015bnie do tego typu zada\u0144. Ale najlepszy jest to, jak to osi\u0105gn\u0119li. S\u0142ucham, dostroili fine tuned jedynie odpowiedni encoder, tego analityka od j\u0119zyka. A ca\u0142a reszta modelu, w tym ca\u0142y generatywny dekoder, pozosta\u0142a zamro\u017cona, nietkni\u0119ta. Chwila chwila, to jest absolutnie kluczowe. Czyli oni udowodniaj\u0105, \u017ce mo\u017cna wyspecjalizowa\u0107 tylko jeden ma\u0142y modu\u0142 tego analityka, a ca\u0142y kreatywny mened\u017cer pozostaje nietkni\u0119ty i uniwersalny. To brzmi jak \u015bwi\u0119ty gra modu\u0142owej I.I. Dok\u0142adnie tak. To pokazuje niesamowit\u0105 elastyczno\u015b\u0107 tej architektury. Interfejs pozostaje uniwersalny, a my podmieniamy lub doszkalamy tylko ten jeden modu\u0142, kt\u00f3ry jest w danym momencie potrzebny. Ok, czyli udowodnili, \u017ce ma t\u0119 analityczn\u0105 dusz\u0119 modeli typu BERT. Ale czy w tym procesie nie po\u015bwi\u0119cili tego, co jest magi\u0105 w GPT? Czy ten model nadal potrafi improwizowa\u0107? Uczy\u0107 si\u0119 w locie? Co z in-context learning? I to jest w\u0142a\u015bnie to po\u0142\u0105czenie ognia z wod\u0105. Okazuje si\u0119, \u017ce nie stracili tych zdolno\u015bci. Po dodatkowym treningu na zadaniach z instrukcjami, czyli instruction tuning, model nie tylko zachowa\u0142 zdolno\u015b\u0107 do in-context learning na poziomie por\u00f3wnywalnym z bazowym GPT, ale te\u017c wykaza\u0142 znacznie lepsz\u0105 zdolno\u015b\u0107 do generalizacji zero shot na zupe\u0142nie nowe zadania, takie, kt\u00f3rych nigdy wcze\u015bniej nie widzia\u0142. Czyli mamy model, kt\u00f3ry po pracyzyjnym fine tuningi, w tym treningu jest ekspertem w jednej dziedzinie, ale jednocze\u015bnie zachowuje elastyczno\u015b\u0107, \u017ceby nauczy\u0107 si\u0119 czego\u015b nowego z kilku przyk\u0142ad\u00f3w podanych w pr\u0105cie. Dok\u0142adnie. To, co opisujesz, to mistrzostwo w rozumieniu j\u0119zyka. Ale obietnica uniwersalnego interfejsu si\u0119ga przecie\u017c dalej. Prawdziwy menad\u017cer nie tylko czyta raporty, ale te\u017c patrzy na wykresy i prototypy. Czy ten model potrafi patrze\u0107? I tu w\u0142a\u015bnie zarna\u017a\u0107 si\u0119 prawdziwa magia i pokaz si\u0142y tej architektury. Do\u0142\u0105czyli do systemu enkoder wizualny i sprawdzili, jak sobie radzi w zadaniach multimodalnych. I w trybie zero shot, czyli bez \u017cadnych wcze\u015bniejszych przyk\u0142ad\u00f3w, model potrafi\u0142 generowa\u0107 opisy obraz\u00f3w z popularnych zestaw\u00f3w danych, jak Koko czy Flicker 30K. I jak mu posz\u0142o? Ze znacznie lepszymi wynikami ni\u017c poprzednie modele o podobnej filozofii. Opisywanie tego, co jest na obrazku, to jedno. Ale co z pytaniami, kt\u00f3re wymagaj\u0105 czego\u015b wi\u0119cej? Takimi, kt\u00f3re \u0142\u0105cz\u0105 obraz z wiedz\u0105 o \u015bwiecie? Prawdziwi to. U\u017cyli bardzo wymagaj\u0105cego zestawu danych OKVQA, gdzie pytania wymagaj\u0105 wiedzy zewn\u0119trznej. Na przyk\u0142ad model widzi zdj\u0119cie samolotu i dostaje pytanie, kto go wynalaz\u0142? I co? Odpowiada? I potrafi na nie odpowiedzie\u0107. A to pokazuje co\u015b fundamentalnego. Enkoder wizualny m\u00f3wi, widz\u0119 samolot. A dekoder, kt\u00f3ry jest modelem j\u0119zykowym, si\u0119ga do swojej ogromnej wbudowanej bazy wiedzy o \u015bwiecie i generuje odpowied\u017a. Bracia Wright. Czyli bodziec wizualny aktywuje abstrakcyjn\u0105 wiedz\u0119 zapisan\u0105 w cz\u0119\u015bci j\u0119zykowej. To robi ogromne wra\u017cenie. A jak wypada w klasycznym finetuningu w zadaniach VQA, czyli Visual Question Answering? Czy mo\u017ce konkurowa\u0107 z modelami, kt\u00f3re by\u0142y budowane od zera tylko do tego celu? To jest dobre pytanie, bo mo\u017cna by pomy\u015ble\u0107, \u017ce jest na straconej pozycji. No w\u0142a\u015bnie. Te wyspecjalizowane modele VQA cz\u0119sto maj\u0105 z g\u00f3ry okre\u015blony zamkni\u0119ty zestaw mo\u017cliwych odpowiedzi. Generowanie otwartej odpowiedzi jest orz\u0105d wielko\u015bci trudniejsze. I on daje sobie rad\u0119 w\u0142a\u015bnie dzi\u0119ki temu, \u017ce generuje otwarte odpowiedzi. Przewy\u017csza inne modele generatywne, jest bardzo konkurencyjny wobec tych wyspecjalizowanych. A w testach, gdzie poprawna odpowied\u017a na pytanie nie znajduje si\u0119 w predefiniowanym zbiorze, po prostu je wyprzedza. Bo ma elastyczno\u015b\u0107. Bo jego elastyczno\u015b\u0107 pozwala mu sformu\u0142owa\u0107 odpowied\u017a, na kt\u00f3r\u0105 inne modele nie by\u0142y przygotowane. Ale jest jeszcze jeden eksperyment, kt\u00f3ry uwa\u017cam za najbardziej fascynuj\u0105cy. Bond dotyka czego\u015b, co przypomina zal\u0105\u017cek, samo\u015bwiadomo\u015bci w procesie rozumowania. Opowiedz o tym. U\u017cyto zestawu danych SNLE VIVI. Zadanie jest wieloetapowe. Model patrzy na obrazek, czyta zdanie, a nast\u0119pnie ma oceni\u0107, czy zdanie logicznie wynika z obrazka. Ok. Ale to nie wszystko. Musi nie tylko wyda\u0107 werdykt np. wnioskowanie jest poprawne, ale r\u00f3wnie\u017c wygenerowa\u0107 wyja\u015bnienie w j\u0119zyku naturalnym np. Poniewa\u017c zwierz\u0119 na zdj\u0119ciu to pies patrz\u0105cy w stron\u0119 kamery. I jak sobie z tym poradzi\u0142? Nie tylko \u015bwietnie generowa\u0142 te wyja\u015bnienia osi\u0105gaj\u0105c wyniki lepsze ni\u017c poprzednie modele. Sta\u0142o si\u0119 co\u015b znacznie ciekawszego. Okaza\u0142o si\u0119, \u017ce sam fakt, \u017ce model musi wygenerowa\u0107 wyja\u015bnienie, poprawia jego dok\u0142adno\u015b\u0107 w g\u0142\u00f3wnym zadaniu. Zaraz, zaraz. Czyli zmuszenie modelu do my\u015blenia na g\u0142os, do verbalizacji swojego rozumowania czy niego m\u0105drzejszym? Na to wygl\u0105da. To jest fascynuj\u0105co kontrintuicyjne. Zawsze my\u015bla\u0142y\u015bmy o tym wewn\u0119trznym monologu AI jako o czym\u015b, co spowalnia proces. A tu si\u0119 okazuje, \u017ce ta verbalizacja pomaga. To tak jakby proces uk\u0142adania my\u015bli w s\u0142owa zmusza\u0142 model do pod\u0105\u017cania bardziej logiczn\u0105 \u015bcie\u017ck\u0105 neuronow\u0105. Co wi\u0119cej, gdy badacze usun\u0119li z polecenia pro\u015bb\u0119 o generowanie wyja\u015bnienia, dok\u0142adno\u015b\u0107 w zadaniu klasyfikacji nieznacznie spad\u0142a. To troch\u0119 jak w \u017cyciu. Czasem dopieno, gdy pr\u00f3bujemy komo\u015b co\u015b wyt\u0142umaczy\u0107, to sami to do ko\u0144ca rozumiemy. W\u0142a\u015bnie. I okazuje si\u0119, \u017ce ta zasada mo\u017ce dotyczy\u0107 te\u017c krzemu. To niesamowite. Mamy wi\u0119c architektur\u0119, kt\u00f3ra dzia\u0142a i przynosi imponuj\u0105ce, a czasem zaskakuj\u0105ce rezultaty. Podsumujmy mo\u017ce jaki jest szerszy kontekst, jaki realny, du\u017cy problem to rozwi\u0105zuje. Poza tym, \u017ce jest to eleganckie in\u017cynieryjnie. To jest, my\u015bl\u0119, milowy krok w kierunku stworzenia prawdziwie zunifikowanego modelu AI. Modelu, kt\u00f3ry nie tylko jest wielozadaniowy, ale fundamentalnie \u0142\u0105czy r\u00f3\u017cne paradygmaty dzia\u0142ania. Ta praca pokazuje, \u017ce mo\u017cna mie\u0107 ciastko i zje\u015b\u0107 ciastko. Mo\u017cna mie\u0107 precyzj\u0119 analityka i elastyczno\u015b\u0107 kreatora w jednym. Tak. A co to oznacza w praktyce dla kogo\u015b, kto buduje aplikacje oparte na AI? To tworzy co\u015b, co autorzy nazywaj\u0105 Universal Task Layer, czyli uniwersaln\u0105 warstw\u0119 zadaniow\u0105. W tym podej\u015bciu j\u0119zyk naturalny staje si\u0119 prawdziwym interfejsem do interakcji, a nawet do programowania r\u00f3\u017cnych wyspecjalizowanych modeli. Czyli zamiast pisa\u0107 skomplikowany kod, \u017ceby u\u017cy\u0107 modelu do rozpoznawania obraz\u00f3w? Po prostu piszemy mu polecenie w j\u0119zyku angielskim. To odblokowuje te\u017c zupe\u0142nie nowe scenariusze, kt\u00f3re do tej pory by\u0142y, no, poza zasi\u0119giem. Zdecydowanie. Wyobra\u017cmy sobie tak\u0105 sytuacj\u0119. Bierzemy model, kt\u00f3ry zosta\u0142 precyzyjnie dostrojony, fine-tuned i jest \u015bwiatowej klasy ekspertem w analizie obraz\u00f3w medycznych. Powiedzmy, zdj\u0119\u0107 rentgenowskich p\u0142uc. A teraz za pomoc\u0105 in-context learning. Maj\u0105c mu w pr\u0105cie zaledwie kilka przyk\u0142ad\u00f3w w j\u0119zyku naturalnym, uczymy go szuka\u0107 na tych zdj\u0119ciach zupe\u0142nie nowej, rzadkiej anomali. Bez potrzeby ponownego, kosztownego treningu ca\u0142ego modelu. To jest po\u0142\u0105czenie specjalizacji i adaptacji, kt\u00f3re do tej pory by\u0142o niemo\u017cliwe. W\u0142a\u015bnie. Czyli to jest \u015bcie\u017cka do budowy bardziej elastycznych, modu\u0142owych i, co za tym, idzie bardziej wydajnych system\u00f3w AI. System\u00f3w, kt\u00f3re mog\u0105 postrzega\u0107 \u015bwiat za pomoc\u0105 wyspecjalizowanych modu\u0142\u00f3w percepcyjnych, naszych enkoder\u00f3w, a rozumowa\u0107, planowa\u0107 i wchodzi\u0107 w interakcj\u0119 za pomoc\u0105 centralnego, pot\u0119\u017cnego modu\u0142u j\u0119zykowego, czyli dekodera. To architektura, kt\u00f3ra znacznie lepiej na\u015bladuje spos\u00f3b, w jaki my ludzie, integrujemy informacje z r\u00f3\u017cnych zmys\u0142\u00f3w i u\u017cywamy j\u0119zyka jako narz\u0119dzie do my\u015blenia. Rozumowuj\u0105c, g\u0142\u00f3wna idea metalem to stworzenie modelu, kt\u00f3ry jest jak szwajcarski scyzoryk w \u015bwiecie AI, ale taki, w kt\u00f3rym ka\u017cde narz\u0119dzie jest najwy\u017cszej klasy. Tak, to dobre por\u00f3wnianie. \u0141\u0105czy w sobie analityczn\u0105 g\u0142\u0119bie modeli dwukierunkowych z kreatywn\u0105 elastyczno\u015bci\u0105 modeli kausalnych. Jest jednocze\u015bnie analitykiem i kreatorem. Idealne podsumowanie. To jest pr\u00f3ba stworzenia modelu, kt\u00f3ry nie jest tylko do\u015b\u0107 dobry we wszystkim, ale jest naprawd\u0119 wybitny w wielu kluczowych zdolno\u015bciach jednocze\u015bnie, dzi\u0119ki inteligentnej wsp\u00f3\u0142pracy wyspecjalizowanych komponent\u00f3w. Na koniec zostawmy mo\u017ce naszych s\u0142uchaczy z prowokuj\u0105c\u0105 mysi\u0105. Autorzy pracy pisz\u0105 wprost, \u017ce planuj\u0105 skalowa\u0107 ten model i dodawa\u0107 kolejne modalno\u015bci, takie jak d\u017awi\u0119k. Je\u015bli jeden model j\u0119zykowy mo\u017ce sta\u0107 si\u0119 uniwersalnym interfejsem dla ca\u0142ego zestawu wyspecjalizowanych modu\u0142\u00f3w AI, to czy my w\u0142a\u015bnie jeste\u015bmy \u015bwiadkami narodze\u0144 zupe\u0142nie nowego rodzaju systemu operacyjnego? To jest bardzo trafne pytanie. Systemu, kt\u00f3rym nie steruje si\u0119 za pomoc\u0105 klikni\u0119\u0107, menu i linijek kodu, ale poprzez rozmow\u0119. Co si\u0119 stanie, gdy b\u0119dziemy mogli po prostu rozmawia\u0107 z systemem, kt\u00f3ry widzi, s\u0142yszy, czyta i ma dost\u0119p do ogromnej wyspecjalizowanej wiedzy? A wszystko to za po\u015brednictwem jednego, sp\u00f3jnego, j\u0119zykowego interfejsu? Czy to nie jest ostateczna definicja tego, co autorzy nazwali General Purpose Interface?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " Wyobra\u017amy sobie tak\u0105 sytuacj\u0119. Nie mamy jednego genialnego specjalisty od wszystkiego, ale mamy genialnego mened\u017cera projektu.", "tokens": [50364, 14458, 24393, 10659, 2226, 13652, 31069, 28275, 29924, 13, 12016, 17335, 5232, 11858, 48228, 11858, 46433, 38618, 3611, 14615, 12200, 11, 6775, 17335, 48228, 11858, 1706, 292, 1427, 1663, 26261, 84, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1478591343713185, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.020353160798549652}, {"id": 1, "seek": 0, "start": 11.0, "end": 23.0, "text": " Kogo\u015b kto sam nie musi by\u0107 programist\u0105, grafikiem i copyrighterem, ale potrafi wierszwirtuozersko zarz\u0105dza\u0107 ca\u0142ym zespo\u0142em ekspert\u00f3w i spi\u0105\u0107 ich prac\u0119 w jeden sp\u00f3jny genialny produkt.", "tokens": [50914, 591, 23515, 1788, 23780, 3247, 2838, 37587, 15069, 1461, 468, 1611, 11, 1295, 31230, 4907, 741, 17996, 7333, 11, 6775, 1847, 10437, 72, 261, 4890, 14406, 347, 9179, 15151, 433, 4093, 22675, 23876, 35873, 35224, 4199, 710, 279, 2259, 11126, 30724, 15346, 3901, 741, 637, 11404, 2162, 1893, 22404, 1274, 261, 12906, 637, 18999, 1634, 48228, 1634, 42816, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1478591343713185, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.020353160798549652}, {"id": 2, "seek": 0, "start": 23.0, "end": 24.0, "text": " Dobra analogia.", "tokens": [51514, 413, 24393, 16660, 654, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1478591343713185, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.020353160798549652}, {"id": 3, "seek": 0, "start": 24.0, "end": 28.0, "text": " A teraz pomy\u015blimy, \u017ce takim mened\u017cerem jest model j\u0119zykowy.", "tokens": [51564, 316, 16854, 280, 8488, 1788, 4197, 88, 11, 3561, 31732, 1706, 292, 1427, 7333, 3492, 2316, 49055, 74, 10089, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1478591343713185, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.020353160798549652}, {"id": 4, "seek": 2800, "start": 28.0, "end": 41.0, "text": " I to jest, no, dok\u0142adnie sedno pracy, kt\u00f3r\u0105 dzisiaj bierzemy na warsztat. Artyku\u0142 z Microsoft Research, zatytu\u0142owany Language Models are General Purpose Interfaces, rzuca w\u0142a\u015bnie tak\u0105 tez\u0119.", "tokens": [50364, 286, 281, 3492, 11, 572, 11, 45864, 2766, 9643, 1771, 35591, 11, 37415, 25772, 272, 34602, 3633, 1667, 13718, 2682, 267, 13, 1587, 874, 5279, 1221, 710, 8116, 10303, 11, 35802, 4328, 84, 1221, 23341, 24445, 6583, 1625, 366, 6996, 14682, 43501, 5751, 69, 2116, 11, 367, 11728, 496, 14234, 31069, 535, 11052, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1322255716091249, "compression_ratio": 1.2654028436018958, "no_speech_prob": 0.01677795499563217}, {"id": 5, "seek": 2800, "start": 41.0, "end": 46.0, "text": " A tym metaforycznym mened\u017cerem jest architektura o nazwie Metal LM.", "tokens": [51014, 316, 8107, 1131, 2792, 827, 3689, 12996, 1706, 292, 1427, 7333, 3492, 3912, 642, 2320, 2991, 277, 20151, 8699, 23488, 46529, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1322255716091249, "compression_ratio": 1.2654028436018958, "no_speech_prob": 0.01677795499563217}, {"id": 6, "seek": 4600, "start": 46.0, "end": 58.0, "text": " W\u0142a\u015bnie. Naszym celem dzisiaj jest rozebranie naczynniki pierwsze. Jak oni w og\u00f3le pr\u00f3buj\u0105 po\u0142\u0105czy\u0107 dwa? Do tej pory powiedzia\u0142abym niemal wrogie sobie \u015bwiaty modeli AI.", "tokens": [50364, 343, 5024, 12221, 13, 16151, 26681, 1769, 10386, 25772, 3492, 744, 1381, 1443, 7155, 297, 14691, 26384, 9850, 45994, 13, 15029, 36317, 261, 29229, 8565, 65, 13263, 714, 15926, 33967, 35045, 30, 1144, 12573, 280, 827, 48539, 2509, 76, 2838, 5579, 261, 6675, 414, 13652, 21485, 21398, 2316, 72, 7318, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05646188194687302, "compression_ratio": 1.4208860759493671, "no_speech_prob": 0.7664547562599182}, {"id": 7, "seek": 4600, "start": 58.0, "end": 59.0, "text": " Tak, to dobre okre\u015blenie.", "tokens": [50964, 9118, 11, 281, 41959, 3133, 265, 1788, 6698, 414, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05646188194687302, "compression_ratio": 1.4208860759493671, "no_speech_prob": 0.7664547562599182}, {"id": 8, "seek": 4600, "start": 59.0, "end": 69.0, "text": " Chodzi o stworzenie czego\u015b na kszta\u0142t uniwersalnego interfejsu, kt\u00f3ry bierze to, co najlepsze z obu tych podej\u015b\u0107 i to bez wi\u0119kszych kompromis\u00f3w.", "tokens": [51014, 761, 14543, 277, 342, 28321, 16778, 36559, 1788, 1667, 350, 15453, 46426, 83, 36435, 5364, 304, 11858, 728, 2106, 73, 15091, 11, 9913, 272, 811, 1381, 281, 11, 598, 41903, 1878, 1381, 710, 1111, 84, 15180, 7468, 44536, 741, 281, 10782, 29968, 28051, 5207, 28722, 271, 3901, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05646188194687302, "compression_ratio": 1.4208860759493671, "no_speech_prob": 0.7664547562599182}, {"id": 9, "seek": 4600, "start": 69.0, "end": 75.0, "text": " Co do tej pory by\u0142o, no, w zasadzie niemo\u017cliwe. Zawsze by\u0142 jaki\u015b wyb\u00f3r, co\u015b za co\u015b.", "tokens": [51514, 3066, 360, 12573, 280, 827, 14811, 11, 572, 11, 261, 44585, 3283, 2838, 3280, 1427, 2081, 826, 13, 1176, 28354, 16673, 34721, 45780, 15614, 11, 19241, 7949, 19241, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05646188194687302, "compression_ratio": 1.4208860759493671, "no_speech_prob": 0.7664547562599182}, {"id": 10, "seek": 7500, "start": 75.0, "end": 84.0, "text": " No w\u0142a\u015bnie. Ustalmy mo\u017ce scen\u0119, bo to jest kluczowe. W \u015bwiecie AI mamy w du\u017cym uproszczeniu dwa obozy.", "tokens": [50364, 883, 14234, 13, 624, 9196, 2226, 12034, 4191, 1274, 11, 748, 281, 3492, 9671, 1311, 89, 6880, 13, 343, 40078, 4260, 7318, 17335, 261, 21783, 4199, 493, 2635, 89, 66, 39651, 35045, 1111, 78, 1229, 13, 50814], "temperature": 0.0, "avg_logprob": -0.060114530416635364, "compression_ratio": 1.4107744107744107, "no_speech_prob": 0.07859823852777481}, {"id": 11, "seek": 7500, "start": 84.0, "end": 93.0, "text": " Dwie filozofie budowania d\u0142u\u017cych modeli j\u0119zykowych. Z jednej strony kreatorzy z drugiej analitycy. Dlaczego tak trudno by\u0142o ich pogodzi\u0107?", "tokens": [50814, 413, 8699, 1387, 15151, 2670, 414, 3265, 21308, 274, 24066, 7735, 339, 2316, 72, 49055, 74, 19605, 13, 1176, 5232, 11794, 32406, 350, 620, 284, 1229, 710, 47373, 364, 1860, 1344, 13, 413, 75, 39329, 991, 32007, 1771, 14811, 1893, 32037, 14543, 2162, 30, 51264], "temperature": 0.0, "avg_logprob": -0.060114530416635364, "compression_ratio": 1.4107744107744107, "no_speech_prob": 0.07859823852777481}, {"id": 12, "seek": 7500, "start": 93.0, "end": 104.0, "text": " To jest fundamentalny problem, kt\u00f3ry troch\u0119 hamowa\u0142 post\u0119p w kierunku takiej prawdziwie uniwersalnej AI. Z jednej strony mamy modele, kt\u00f3re nazywamy Cozel Models.", "tokens": [51264, 1407, 3492, 8088, 1634, 1154, 11, 9913, 24926, 7852, 30105, 2183, 18085, 261, 38767, 49910, 38941, 41175, 3992, 8699, 36435, 5364, 304, 11794, 7318, 13, 1176, 5232, 11794, 32406, 17335, 4391, 306, 11, 8864, 20151, 27112, 7804, 3066, 12971, 6583, 1625, 13, 51814], "temperature": 0.0, "avg_logprob": -0.060114530416635364, "compression_ratio": 1.4107744107744107, "no_speech_prob": 0.07859823852777481}, {"id": 13, "seek": 10400, "start": 104.0, "end": 106.0, "text": " Rodzina GPT.", "tokens": [50364, 11097, 89, 1426, 26039, 51, 13, 50464], "temperature": 0.0, "avg_logprob": -0.083085272685591, "compression_ratio": 1.3409090909090908, "no_speech_prob": 0.1139090433716774}, {"id": 14, "seek": 10400, "start": 106.0, "end": 120.0, "text": " Tak, ca\u0142a rodzina GPT. One dzia\u0142aj\u0105 jednokierunkowo. Czytaj\u0105 tekst od lewej do prawej i ich jedynym zadaniem jest przewidzenie nast\u0119pnego s\u0142owa. To sprawia, \u017ce s\u0105 absolutnymi mistrzami w otwartym generowaniu tekstu.", "tokens": [50464, 9118, 11, 1335, 5024, 28607, 1426, 26039, 51, 13, 1485, 27121, 11133, 5232, 77, 453, 811, 3197, 19941, 13, 19832, 1328, 8555, 16624, 372, 3611, 476, 826, 73, 360, 3206, 826, 73, 741, 1893, 5232, 88, 12996, 710, 11338, 4907, 3492, 39758, 327, 16778, 39662, 11858, 15116, 5528, 13, 1407, 22734, 654, 11, 3561, 9015, 18757, 31813, 3544, 19390, 4526, 261, 4337, 29587, 4199, 1337, 305, 25849, 16624, 372, 84, 13, 51164], "temperature": 0.0, "avg_logprob": -0.083085272685591, "compression_ratio": 1.3409090909090908, "no_speech_prob": 0.1139090433716774}, {"id": 15, "seek": 12000, "start": 120.0, "end": 137.0, "text": " To s\u0105 nasi kreatywni autorzy, improwizatorzy. To one potrafi\u0105 pisa\u0107 wiersze, scenariusze, no i prowadzi\u0107 w miar\u0119 swobodn\u0105 rozmow\u0119. W nich te\u017c dzia\u0142a ta ca\u0142a magia in-context learning, czyli uczenia si\u0119 w locie z kilku przyk\u0142ad\u00f3w.", "tokens": [50364, 1407, 9015, 5382, 72, 350, 620, 88, 895, 72, 19510, 1229, 11, 704, 1892, 590, 1639, 1229, 13, 1407, 472, 1847, 10437, 11404, 280, 3837, 2162, 261, 4890, 1381, 11, 4191, 27440, 1381, 11, 572, 741, 36590, 28496, 261, 2752, 289, 1274, 1693, 996, 378, 13113, 35234, 305, 1274, 13, 343, 25570, 9516, 37903, 1846, 1335, 5024, 2258, 654, 294, 12, 9000, 3828, 2539, 11, 16591, 344, 38517, 3244, 261, 1628, 414, 710, 5128, 5279, 23144, 3901, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07268114206267566, "compression_ratio": 1.308108108108108, "no_speech_prob": 0.22592134773731232}, {"id": 16, "seek": 13700, "start": 137.0, "end": 152.0, "text": " Dok\u0142adnie. Ale ta jednokierunkowo\u015b\u0107 jest te\u017c ich pewn\u0105 s\u0142abo\u015bci\u0105. Kiedy musz\u0105 naprawd\u0119 g\u0142\u0119boko zrozumie\u0107 kontekst ca\u0142ego zdania, przeanalizowa\u0107 niuanse, brakuje im takiego spojrzenia zlotu ptaka.", "tokens": [50364, 29768, 10358, 2766, 13, 9366, 1846, 5232, 77, 453, 811, 3197, 19941, 7753, 3492, 9516, 1893, 47160, 1611, 15116, 41265, 50227, 13, 591, 16446, 1038, 8925, 20970, 18117, 1274, 65, 13704, 710, 27857, 449, 414, 2162, 14373, 916, 372, 35224, 6308, 16221, 5609, 11, 8325, 29702, 590, 11445, 3867, 6139, 405, 11, 1548, 5279, 2884, 566, 32296, 8243, 73, 81, 14320, 710, 43571, 84, 280, 83, 7849, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0944448955475338, "compression_ratio": 1.4131274131274132, "no_speech_prob": 0.8624212741851807}, {"id": 17, "seek": 13700, "start": 152.0, "end": 156.0, "text": " I wtedy na scen\u0119 wchodz\u0105 ci drudzy.", "tokens": [51114, 286, 26959, 1667, 4191, 1274, 261, 29914, 8925, 6983, 1224, 532, 1229, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0944448955475338, "compression_ratio": 1.4131274131274132, "no_speech_prob": 0.8624212741851807}, {"id": 18, "seek": 13700, "start": 156.0, "end": 165.0, "text": " I tu na scen\u0119 wchodz\u0105 modele z drugiego obozu. Non-cozel models, kt\u00f3rych kr\u00f3lem jest Bert. One s\u0105 dwukierunkowe.", "tokens": [51314, 286, 2604, 1667, 4191, 1274, 261, 29914, 8925, 4391, 306, 710, 4110, 12200, 1111, 78, 11728, 13, 8774, 12, 1291, 12971, 5245, 11, 30382, 42366, 10386, 3492, 29594, 13, 1485, 9015, 27379, 2034, 811, 3197, 6880, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0944448955475338, "compression_ratio": 1.4131274131274132, "no_speech_prob": 0.8624212741851807}, {"id": 19, "seek": 16500, "start": 165.0, "end": 171.0, "text": " Czyli analizuj\u0105 zdanie patrz\u0105c jednocze\u015bnie w prz\u00f3d i w ty\u0142. Maj\u0105 pe\u0142en obraz.", "tokens": [50364, 37099, 2624, 590, 13263, 16221, 7155, 1947, 81, 8925, 66, 5232, 26694, 1381, 12221, 261, 6541, 17081, 741, 261, 1104, 1221, 13, 7048, 1611, 43205, 268, 22798, 89, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07722944021224976, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.10556422173976898}, {"id": 20, "seek": 16500, "start": 171.0, "end": 183.0, "text": " Pe\u0142en obraz. I dzi\u0119ki temu deklasuj\u0105 modele kausalne w zadaniach, kt\u00f3re wymagaj\u0105 g\u0142\u0119bokiego rozumienia kontekstu, jak analiza sentymentu, czy odpowiadanie na pytania na podstawie jakiego\u015b tekstu.", "tokens": [50664, 2396, 1221, 268, 22798, 89, 13, 286, 45003, 33346, 368, 74, 7743, 13263, 4391, 306, 6799, 11765, 716, 261, 42788, 3782, 608, 11, 8864, 29764, 559, 11133, 18117, 1274, 21666, 12200, 48797, 18811, 14373, 916, 372, 84, 11, 4207, 2624, 13427, 2279, 88, 518, 84, 11, 6430, 24314, 38069, 7155, 1667, 25878, 5609, 1667, 43443, 414, 4207, 12200, 1788, 16624, 372, 84, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07722944021224976, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.10556422173976898}, {"id": 21, "seek": 16500, "start": 183.0, "end": 186.0, "text": " To nasi skrupulatni analitycy.", "tokens": [51264, 1407, 5382, 72, 1110, 11976, 425, 267, 3722, 2624, 507, 1344, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07722944021224976, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.10556422173976898}, {"id": 22, "seek": 18600, "start": 186.0, "end": 197.0, "text": " W\u0142a\u015bnie. A ich pot\u0119ga ujawnia si\u0119 po procesie, kt\u00f3ry znamy jako find tuning. Czyli precyzyjnym do strojeniu do jednego konkretnego zadania.", "tokens": [50364, 343, 5024, 12221, 13, 316, 1893, 1847, 1274, 3680, 344, 2938, 895, 654, 3244, 714, 17565, 414, 11, 9913, 710, 5378, 88, 17123, 915, 15164, 13, 37099, 659, 1344, 1229, 73, 12996, 360, 8959, 15378, 5951, 360, 5232, 11858, 36500, 11858, 42788, 5609, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08998574329023602, "compression_ratio": 1.417004048582996, "no_speech_prob": 0.6909340620040894}, {"id": 23, "seek": 18600, "start": 197.0, "end": 202.0, "text": " Staj\u0105 si\u0119 wtedy powiedzmy w\u0105skimi specjalistami o niemal nadludzkiej precyzji.", "tokens": [50914, 745, 11133, 3244, 26959, 27617, 2226, 261, 1611, 5161, 10121, 46433, 468, 4526, 277, 2838, 5579, 12617, 1471, 30154, 7764, 659, 1344, 89, 4013, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08998574329023602, "compression_ratio": 1.417004048582996, "no_speech_prob": 0.6909340620040894}, {"id": 24, "seek": 18600, "start": 202.0, "end": 210.0, "text": " Czyli stajemy przed wyborem. Albo elastyczny i kreatywny generator, kt\u00f3ry uczy si\u0119 w locie, ale bywa powierzchnowny.", "tokens": [51164, 37099, 342, 1805, 3633, 18334, 45780, 37956, 13, 967, 1763, 806, 9820, 3689, 1634, 741, 350, 620, 88, 43682, 19265, 11, 9913, 344, 6522, 3244, 261, 1628, 414, 11, 6775, 538, 4151, 3388, 34602, 1377, 648, 88, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08998574329023602, "compression_ratio": 1.417004048582996, "no_speech_prob": 0.6909340620040894}, {"id": 25, "seek": 18600, "start": 210.0, "end": 211.0, "text": " Tak.", "tokens": [51564, 9118, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08998574329023602, "compression_ratio": 1.417004048582996, "no_speech_prob": 0.6909340620040894}, {"id": 26, "seek": 21100, "start": 211.0, "end": 224.0, "text": " Albo pot\u0119\u017cny, precyzyjny analityk, kt\u00f3rego trzeba d\u0142ugo i kosztownie szkoli\u0107 do ka\u017cdej nowej roli i kt\u00f3ry, co wa\u017cne, nie potrafi generowa\u0107 otwartego tekstu. Albo jedno albo drugie.", "tokens": [50364, 967, 1763, 1847, 1274, 1427, 1634, 11, 659, 1344, 1229, 73, 1634, 364, 1860, 74, 11, 46951, 25860, 44042, 20746, 741, 19532, 2682, 648, 414, 7870, 74, 9384, 2162, 360, 21912, 1479, 73, 586, 40779, 744, 2081, 741, 9913, 11, 598, 46110, 11, 2838, 1847, 10437, 72, 1337, 11445, 4337, 29587, 6308, 16624, 372, 84, 13, 967, 1763, 5232, 1771, 22622, 4110, 414, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08971731681523361, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.03143221512436867}, {"id": 27, "seek": 21100, "start": 224.0, "end": 239.0, "text": " I tu w\u0142a\u015bnie Tkwi powiedzia\u0142bym rewolucyjno\u015b\u0107 tezy z tej pracy. Autorzy m\u00f3wi\u0105, stop, nie musimy wybiera\u0107. Model metalen ma by\u0107 tym mostem. Ma by\u0107 jednocze\u015bnie analitykiem i kreatorem.", "tokens": [51014, 286, 2604, 14234, 314, 74, 6253, 48539, 2322, 76, 319, 48481, 1311, 88, 73, 23293, 535, 1229, 710, 12573, 35591, 13, 6049, 284, 1229, 46591, 11, 1590, 11, 2838, 43449, 45780, 10609, 2162, 13, 17105, 1131, 21745, 463, 15069, 8107, 881, 443, 13, 4042, 15069, 5232, 26694, 1381, 12221, 364, 1860, 26116, 741, 350, 620, 37956, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08971731681523361, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.03143221512436867}, {"id": 28, "seek": 23900, "start": 239.0, "end": 252.0, "text": " Okej, na papierze taka hybryda wygl\u0105da genialnie. Ale w \u015bwiecie AI pe\u0142no jest pi\u0119knych idei, kt\u00f3re rozbijaj\u0105 si\u0119 o tward\u0105 rzeczywisto\u015b\u0107. Jak to jest w og\u00f3le zbudowane? Co oni zrobili pod mask\u0105, \u017ceby po\u0142\u0105czy\u0107 ten ogie\u0144 z wod\u0105?", "tokens": [50364, 29094, 73, 11, 1667, 37410, 1381, 28017, 2477, 65, 627, 2675, 32015, 48228, 2766, 13, 9366, 261, 40078, 4260, 7318, 43205, 1771, 3492, 48085, 9399, 1153, 72, 11, 8864, 9544, 30418, 11133, 3244, 277, 683, 515, 1611, 26297, 86, 9334, 7753, 13, 15029, 281, 3492, 261, 29229, 710, 18281, 23066, 30, 3066, 36317, 44399, 2312, 2497, 6094, 1611, 11, 11316, 714, 15926, 33967, 2064, 5360, 414, 5248, 710, 47751, 1611, 30, 51014], "temperature": 0.0, "avg_logprob": -0.06975885045608418, "compression_ratio": 1.3869047619047619, "no_speech_prob": 0.10692517459392548}, {"id": 29, "seek": 23900, "start": 252.0, "end": 268.0, "text": " Kluczem jest architektura modu\u0142owa. Zamiast budowa\u0107 jeden monolityczny model, stworzyli co\u015b na kszta\u0142t systemu. Metan sk\u0142ada si\u0119 z wielu wyspecjalizowanych dwukierunkowych enkoder\u00f3w. To s\u0105 w\u0142a\u015bnie nasi analitycy.", "tokens": [51014, 16053, 1311, 24313, 3492, 3912, 642, 2320, 2991, 1072, 84, 1221, 5528, 13, 1176, 4526, 525, 3265, 11445, 12906, 1108, 401, 507, 3689, 1634, 2316, 11, 342, 28321, 1229, 2081, 19241, 1667, 350, 15453, 46426, 83, 1185, 84, 13, 6377, 282, 1110, 46217, 3244, 710, 40437, 27062, 494, 66, 22600, 590, 23341, 339, 27379, 2034, 811, 3197, 19605, 465, 74, 19866, 3901, 13, 1407, 9015, 14234, 5382, 72, 364, 1860, 1344, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06975885045608418, "compression_ratio": 1.3869047619047619, "no_speech_prob": 0.10692517459392548}, {"id": 30, "seek": 26800, "start": 268.0, "end": 279.0, "text": " Ka\u017cdy od czego\u015b innego. Tak, ka\u017cdy mo\u017ce by\u0107 ekspertem od czego\u015b innego. Jeden od analizy tekstu, drugi od rozpoznawania obraz\u00f3w, a w przysz\u0142o\u015bci kto wie mo\u017ce i trzeci od przetwarzania d\u017awi\u0119ku.", "tokens": [50364, 10988, 1427, 3173, 3611, 36559, 1788, 294, 11858, 13, 9118, 11, 31615, 12034, 15069, 30724, 15346, 443, 3611, 36559, 1788, 294, 11858, 13, 508, 6876, 3611, 2624, 590, 88, 16624, 372, 84, 11, 4110, 72, 3611, 9544, 2259, 35458, 86, 5609, 22798, 89, 3901, 11, 257, 261, 44018, 35059, 23780, 3355, 12034, 741, 22266, 537, 3611, 6541, 302, 31991, 5609, 274, 10659, 22423, 5279, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06417585845686431, "compression_ratio": 1.4252873563218391, "no_speech_prob": 0.07129994034767151}, {"id": 31, "seek": 26800, "start": 279.0, "end": 288.0, "text": " Okej, czyli mamy zesp\u00f3\u0142 specjalist\u00f3w, kt\u00f3rzy potrafi\u0105 dog\u0142\u0119bnie przeanalizowa\u0107 r\u00f3\u017cne typy danych. A gdzie jest ten mened\u017cer, kt\u00f3ry tym wszystkim zarz\u0105dza?", "tokens": [50914, 29094, 73, 11, 16591, 17335, 710, 13361, 16181, 46433, 468, 3901, 11, 25382, 1847, 10437, 11404, 3000, 46564, 65, 2766, 8325, 29702, 590, 11445, 47760, 2125, 88, 274, 34644, 13, 316, 18922, 3492, 2064, 1706, 292, 1427, 260, 11, 9913, 8107, 30481, 22675, 23876, 2394, 30, 51364], "temperature": 0.0, "avg_logprob": -0.06417585845686431, "compression_ratio": 1.4252873563218391, "no_speech_prob": 0.07129994034767151}, {"id": 32, "seek": 28800, "start": 288.0, "end": 299.0, "text": " Tym mened\u017cerem, a jednocze\u015bnie tym uniwersalnym interfejsem, jest jeden centralny, jednokierunkowy dekoder. To jest nasz kreatywny autor, podobny w dzia\u0142aniu do GPT.", "tokens": [50364, 314, 4199, 1706, 292, 1427, 7333, 11, 257, 5232, 26694, 1381, 12221, 8107, 36435, 5364, 304, 12996, 728, 2106, 73, 19872, 11, 3492, 12906, 5777, 1634, 11, 5232, 77, 453, 811, 3197, 10089, 368, 74, 19866, 13, 1407, 3492, 5382, 89, 350, 620, 88, 43682, 19510, 11, 43024, 1634, 261, 27121, 25849, 360, 26039, 51, 13, 50914], "temperature": 0.0, "avg_logprob": -0.061658753723394674, "compression_ratio": 1.4242424242424243, "no_speech_prob": 0.501745343208313}, {"id": 33, "seek": 28800, "start": 299.0, "end": 310.0, "text": " I te wszystkie specjalistyczne enkodery jakby dokuj\u0105 do niego. Przekazuj\u0105 mu swoje g\u0142\u0119bokie, przeanalizowane wnioski, a on na tej podstawie generuje ostateczn\u0105, sp\u00f3jn\u0105 odpowied\u017a w j\u0119zyku naturalnym.", "tokens": [50914, 286, 535, 31723, 46433, 468, 17466, 716, 465, 74, 378, 2109, 28976, 25037, 13263, 360, 49615, 13, 2114, 19878, 921, 13263, 2992, 29489, 18117, 1274, 21666, 414, 11, 8325, 29702, 590, 23066, 45368, 2717, 2984, 11, 257, 322, 1667, 12573, 43443, 414, 1337, 13008, 277, 15406, 3689, 13113, 11, 637, 18999, 13113, 36574, 10659, 261, 49055, 5279, 3303, 12996, 13, 51464], "temperature": 0.0, "avg_logprob": -0.061658753723394674, "compression_ratio": 1.4242424242424243, "no_speech_prob": 0.501745343208313}, {"id": 34, "seek": 31000, "start": 310.0, "end": 326.0, "text": " Czyli enkodery robi\u0105 taki g\u0142\u0119boki research, a dekoder pisze na jego podstawie finalny raport. Ciekawe, ale jak zmusi\u0107 te dwie tak r\u00f3\u017cne od siebie cz\u0119\u015bci, \u017ceby ze sob\u0105 wsp\u00f3\u0142pracowa\u0142y? To pewnie wymaga\u0142o jakie\u015b zupe\u0142nie nowej metody treningu.", "tokens": [50364, 37099, 465, 74, 378, 2109, 3870, 11404, 20065, 18117, 1274, 21666, 72, 2132, 11, 257, 368, 74, 19866, 26584, 1381, 1667, 26542, 43443, 414, 2572, 1634, 5099, 477, 13, 383, 414, 2330, 826, 11, 6775, 4207, 17020, 301, 12757, 535, 274, 8699, 991, 47760, 3611, 39137, 41314, 11, 11316, 5277, 18253, 1611, 39069, 1424, 326, 5528, 6825, 30, 1407, 520, 14215, 29764, 9286, 5249, 31163, 49922, 586, 40779, 1131, 843, 2192, 773, 84, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09102863531846267, "compression_ratio": 1.2673267326732673, "no_speech_prob": 0.5259161591529846}, {"id": 35, "seek": 32600, "start": 327.0, "end": 342.0, "text": " I to jest druga du\u017ca innowacja. Stworzyli now\u0105 technik\u0119, kt\u00f3r\u0105 nazwali Semicosal Language Modeling. Wiesz, w du\u017cym uproszczeniu w trakcie treningu model najpierw przetwarza dane wej\u015bciowe za pomow\u0105 tych dwukierunkowych enkoder\u00f3w,", "tokens": [50414, 286, 281, 3492, 4110, 64, 21783, 64, 294, 3785, 23395, 13, 745, 28321, 1229, 2081, 586, 1611, 1537, 1035, 1274, 11, 37415, 20151, 40054, 318, 3438, 329, 304, 24445, 6583, 11031, 13, 343, 15347, 11, 261, 21783, 4199, 493, 2635, 89, 66, 39651, 261, 944, 74, 4260, 2192, 773, 84, 2316, 11212, 45119, 86, 6541, 302, 6925, 2394, 49206, 321, 73, 6199, 6880, 7949, 12991, 30297, 15180, 27379, 2034, 811, 3197, 19605, 465, 74, 19866, 3901, 11, 51164], "temperature": 0.0, "avg_logprob": -0.10367919780589917, "compression_ratio": 1.2659574468085106, "no_speech_prob": 0.8616390228271484}, {"id": 36, "seek": 34200, "start": 343.0, "end": 361.0, "text": " Pozwala im na pe\u0142n\u0105 analiz\u0119. Dok\u0142adnie. Pozwala im na pe\u0142n\u0105, g\u0142\u0119bok\u0105 analiz\u0119. I dopiero ich przemy\u015blenia, czyli takie skompresowane, wektorowe reprezentacje, s\u0105 przekazywane do jednokierunkowego dekodera. A on uczy si\u0119 generowa\u0107 na ich podstawie sekwencyjn\u0105 odpowied\u017a, s\u0142owo po s\u0142owie.", "tokens": [50414, 6165, 14406, 5159, 566, 1667, 43205, 13113, 2624, 590, 1274, 13, 29768, 10358, 2766, 13, 6165, 14406, 5159, 566, 1667, 43205, 13113, 11, 18117, 1274, 21666, 1611, 2624, 590, 1274, 13, 286, 21900, 12030, 1893, 6541, 3633, 1788, 6698, 654, 11, 16591, 15963, 1110, 8586, 495, 23066, 11, 321, 28359, 6880, 1085, 265, 14185, 29293, 11, 9015, 29785, 921, 27112, 1929, 360, 5232, 77, 453, 811, 3197, 26576, 368, 74, 378, 1663, 13, 316, 322, 344, 6522, 3244, 1337, 11445, 1667, 1893, 43443, 414, 17215, 86, 3020, 73, 13113, 36574, 10659, 11, 15116, 19941, 714, 15116, 13998, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09492306615792069, "compression_ratio": 1.429245283018868, "no_speech_prob": 0.4765189290046692}, {"id": 37, "seek": 36100, "start": 361.0, "end": 371.0, "text": " To jest fascynuj\u0105ce. Czyta\u0142am, \u017ce autorzy pracy u\u017cywaj\u0105 tu bardzo trafnej analogii do ludzkiego my\u015blenia, do tej koncepcji spopularyzowanej przez Daniela Kanchemana.", "tokens": [50364, 1407, 3492, 30632, 1344, 77, 13263, 384, 13, 19832, 1328, 20177, 11, 3561, 19510, 1229, 35591, 34097, 86, 11133, 2604, 9034, 944, 69, 11794, 16660, 5597, 360, 15946, 30154, 12200, 48633, 6698, 654, 11, 360, 12573, 5897, 27493, 19649, 637, 404, 425, 822, 89, 23066, 73, 14064, 8033, 64, 11120, 17345, 2095, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12393462867067571, "compression_ratio": 1.163265306122449, "no_speech_prob": 0.7047619223594666}, {"id": 38, "seek": 37100, "start": 372.0, "end": 390.0, "text": " Tak, tak. Por\u00f3wnuj\u0105 to do systemu 1 i systemu 2. Te wyspecjalizowane dwukierunkowe enkodeny dzia\u0142aj\u0105 jak ten szybki, intuicyjny i, co wa\u017cne, r\u00f3wnoleg\u0142y system 1. B\u0142yskawicznie przetwarzaj\u0105 percepcj\u0119, czyli to, co model widzi lub czyta.", "tokens": [50414, 9118, 11, 991, 13, 5269, 812, 895, 13263, 281, 360, 1185, 84, 502, 741, 1185, 84, 568, 13, 1989, 27062, 494, 66, 22600, 590, 23066, 27379, 2034, 811, 3197, 6880, 465, 74, 378, 43100, 27121, 11133, 4207, 2064, 36456, 2984, 11, 560, 84, 2632, 73, 1634, 741, 11, 598, 46110, 11, 11416, 895, 4812, 70, 6825, 1185, 502, 13, 363, 1221, 749, 74, 1607, 17946, 2766, 6541, 302, 31991, 11133, 9016, 79, 41960, 11, 16591, 281, 11, 598, 2316, 5274, 3992, 15980, 6430, 1328, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07783007353879093, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.6009523272514343}, {"id": 39, "seek": 39000, "start": 391.0, "end": 392.0, "text": " A dekoder?", "tokens": [50414, 316, 368, 74, 19866, 30, 50464], "temperature": 0.0, "avg_logprob": -0.10923761791653103, "compression_ratio": 1.4036144578313252, "no_speech_prob": 0.36142978072166443}, {"id": 40, "seek": 39000, "start": 392.0, "end": 407.0, "text": " Natomiast ten centralny jednokierunkowe dekoder dzia\u0142a jak ten wolniejszy, bardziej metodyczny i powiedzmy \u015bwiadomy system 2. Odpowiedzialny za rozumowanie, planowanie i generowanie przymy\u015blanej sekwencyjnej odpowiedzi.", "tokens": [50464, 36210, 2064, 5777, 1634, 5232, 77, 453, 811, 3197, 6880, 368, 74, 19866, 37903, 4207, 2064, 20960, 10402, 7706, 11, 27209, 1131, 843, 3689, 1634, 741, 27617, 2226, 21485, 345, 8488, 1185, 568, 13, 12210, 14701, 15338, 831, 1634, 7949, 48797, 22028, 11, 1393, 22028, 741, 1337, 22028, 6501, 2226, 19212, 1929, 73, 17215, 86, 3020, 73, 11794, 36574, 3992, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10923761791653103, "compression_ratio": 1.4036144578313252, "no_speech_prob": 0.36142978072166443}, {"id": 41, "seek": 40700, "start": 407.0, "end": 424.0, "text": " Uwielbiam t\u0119 analogi\u0119, ale musz\u0119 zapyta\u0107, czy to tylko chwytliwy marketing, czy ta architektura faktycznie odzwierciedla te dwa tryby my\u015blenia, bo system 1 to nie tylko szybko\u015b\u0107, to te\u017c b\u0142\u0119dy poznawcze. Czy te enkodery te\u017c je wykazuj\u0105?", "tokens": [50364, 624, 86, 1187, 65, 2918, 32489, 16660, 5034, 11, 6775, 1038, 11052, 14223, 88, 42931, 11, 6430, 281, 13219, 26237, 4328, 2081, 9726, 6370, 11, 6430, 1846, 3912, 642, 2320, 2991, 33647, 45586, 3611, 14406, 811, 537, 292, 875, 535, 35045, 853, 2322, 48633, 6698, 654, 11, 748, 1185, 502, 281, 2838, 13219, 36456, 4093, 7753, 11, 281, 9516, 272, 46564, 3173, 21281, 629, 86, 9680, 13, 19832, 535, 465, 74, 378, 2109, 9516, 1506, 39287, 921, 13263, 30, 51214], "temperature": 0.0, "avg_logprob": -0.07266230755541699, "compression_ratio": 1.2797927461139897, "no_speech_prob": 0.14535844326019287}, {"id": 42, "seek": 42400, "start": 424.0, "end": 441.0, "text": " To jest \u015bwietne pytanie, kt\u00f3rego praca bezpo\u015brednio nie adresuje, ale wskazuje na kluczow\u0105 r\u00f3\u017cnic\u0119. W przeciwie\u0144stwie do ludzkiego systemu 1 te enkodery s\u0105 precyzyjnie dostrajane do swoich zada\u0144, wi\u0119c ich intuicje s\u0105 oparte na, no, na twardych danych.", "tokens": [50364, 1407, 3492, 8299, 39083, 716, 36610, 11, 46951, 582, 6628, 10782, 2259, 1788, 986, 41084, 2838, 614, 495, 13008, 11, 6775, 261, 5161, 43317, 1667, 9671, 1311, 89, 30297, 19637, 7692, 1274, 13, 343, 39622, 8699, 12229, 8699, 360, 15946, 30154, 12200, 1185, 84, 502, 535, 465, 74, 378, 2109, 9015, 659, 1344, 1229, 73, 2766, 20568, 48690, 1929, 360, 13291, 480, 710, 1538, 5248, 11, 16677, 1893, 560, 84, 299, 2884, 9015, 999, 11026, 1667, 11, 572, 11, 1667, 683, 515, 16384, 274, 34644, 13, 51214], "temperature": 0.0, "avg_logprob": -0.04430249885276512, "compression_ratio": 1.439446366782007, "no_speech_prob": 0.031760457903146744}, {"id": 43, "seek": 42400, "start": 441.0, "end": 450.0, "text": " Ale analogia trzyma si\u0119 o tyle, \u017ce mamy do czynienia z szybkim, holistycznym przetwarzaniem, po kt\u00f3rym nast\u0119puje wolniejsze sekwencyjne rozumowanie.", "tokens": [51214, 9366, 16660, 654, 34573, 1696, 3244, 277, 39293, 11, 3561, 17335, 360, 6430, 77, 18811, 710, 36456, 25112, 11, 4091, 468, 17466, 12996, 6541, 302, 31991, 282, 4907, 11, 714, 30120, 39662, 13008, 20960, 44258, 17215, 86, 3020, 73, 716, 48797, 22028, 13, 51664], "temperature": 0.0, "avg_logprob": -0.04430249885276512, "compression_ratio": 1.439446366782007, "no_speech_prob": 0.031760457903146744}, {"id": 44, "seek": 45000, "start": 451.0, "end": 467.0, "text": " W porz\u0105dku teoria jest niezwykle elegancka, ale przejd\u017amy do dowod\u00f3w. Pytanie brzmi, czy ten mened\u017cer projektu faktycznie dowi\u00f3z\u0142 w nitki, czy to tylko \u0142adna koncepcja? Zacznijmy od jego podstawowej kompetencji, czyli od j\u0119zyka.", "tokens": [50414, 343, 1515, 23876, 5279, 535, 8172, 3492, 33511, 9726, 14677, 1118, 1275, 39342, 11, 6775, 8325, 37109, 10659, 2226, 360, 9459, 378, 3901, 13, 430, 4328, 7155, 738, 89, 3057, 11, 6430, 2064, 1706, 292, 1427, 260, 26261, 84, 33647, 45586, 9459, 7138, 89, 1221, 261, 10900, 2984, 11, 6430, 281, 13219, 47910, 629, 5897, 27493, 34056, 30, 1176, 14875, 77, 1718, 2226, 3611, 26542, 43443, 21091, 5207, 7275, 268, 19649, 11, 16591, 3611, 42309, 40940, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07880269745249807, "compression_ratio": 1.2826086956521738, "no_speech_prob": 0.05932764708995819}, {"id": 45, "seek": 46700, "start": 468.0, "end": 479.0, "text": " Tutaj, no c\u00f3\u017c, liczby m\u00f3wi\u0105 same za siebie. Wzi\u0119li 34 r\u00f3\u017cne zadania z dziedziny przetwarzania j\u0119zyka naturalnego i przeprowadzili test, kt\u00f3ry nazywa si\u0119 multitask fine tuning.", "tokens": [50414, 41819, 11, 572, 6333, 1427, 11, 6169, 89, 2322, 46591, 912, 7949, 39137, 13, 343, 16706, 2081, 12790, 47760, 42788, 5609, 710, 9758, 15338, 3519, 6541, 302, 31991, 5609, 42309, 40940, 3303, 11858, 741, 30829, 1892, 345, 89, 2312, 1500, 11, 9913, 20151, 88, 4151, 3244, 42338, 3863, 2489, 15164, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06896085426455638, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.27794358134269714}, {"id": 46, "seek": 46700, "start": 479.0, "end": 484.0, "text": " Meta\u0142 by\u0142 por\u00f3wnywany z modelem typu GPT o podobnej wielko\u015bci.", "tokens": [50964, 6377, 64, 1221, 16673, 1515, 812, 895, 27112, 1325, 710, 4391, 10386, 2125, 84, 26039, 51, 277, 43024, 11794, 20570, 4093, 6199, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06896085426455638, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.27794358134269714}, {"id": 47, "seek": 46700, "start": 484.0, "end": 485.0, "text": " I co si\u0119 okaza\u0142o?", "tokens": [51214, 286, 598, 3244, 3133, 12257, 5249, 30, 51264], "temperature": 0.0, "avg_logprob": -0.06896085426455638, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.27794358134269714}, {"id": 48, "seek": 46700, "start": 485.0, "end": 492.0, "text": " W zadaniach wymagaj\u0105cych g\u0142\u0119bokiego rozumienia j\u0119zyka, czyli natural language understanding, po prostu go zdeklasowa\u0142.", "tokens": [51264, 343, 42788, 3782, 608, 29764, 559, 11133, 31306, 18117, 1274, 21666, 12200, 48797, 18811, 42309, 40940, 11, 16591, 3303, 2856, 3701, 11, 714, 19518, 352, 710, 67, 916, 7743, 30105, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06896085426455638, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.27794358134269714}, {"id": 49, "seek": 49200, "start": 492.0, "end": 496.0, "text": " Zdeklasowa\u0142, czyli o ile by\u0142 lepszy? M\u00f3wimy o jaki\u015b konkretnych liczwach?", "tokens": [50364, 1176, 67, 916, 7743, 30105, 11, 16591, 277, 15465, 16673, 476, 1878, 1229, 30, 376, 3901, 13189, 277, 34721, 36500, 9399, 6169, 89, 50038, 30, 50564], "temperature": 0.0, "avg_logprob": -0.0713552643981161, "compression_ratio": 1.4364161849710984, "no_speech_prob": 0.06919113546609879}, {"id": 50, "seek": 49200, "start": 496.0, "end": 507.0, "text": " Tak. W zadaniach z Grupy Natural Language Influence, kt\u00f3re sprawdzaj\u0105 zdolno\u015b\u0107 do logicznego wnioskowania, r\u00f3\u017cnica wynosi\u0142a ponad 14 punkt\u00f3w procentowych na korzy\u015b\u0107 metalm.", "tokens": [50564, 9118, 13, 343, 42788, 3782, 608, 710, 10459, 8200, 20137, 24445, 11537, 40432, 11, 8864, 46192, 89, 11133, 16221, 401, 23293, 360, 9952, 89, 11858, 45368, 2717, 74, 21308, 11, 19637, 32687, 31936, 21521, 5024, 9224, 345, 3499, 39561, 3901, 38826, 19605, 1667, 14784, 1229, 7753, 5760, 76, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0713552643981161, "compression_ratio": 1.4364161849710984, "no_speech_prob": 0.06919113546609879}, {"id": 51, "seek": 49200, "start": 507.0, "end": 508.0, "text": " 14 punkt\u00f3w?", "tokens": [51114, 3499, 39561, 3901, 30, 51164], "temperature": 0.0, "avg_logprob": -0.0713552643981161, "compression_ratio": 1.4364161849710984, "no_speech_prob": 0.06919113546609879}, {"id": 52, "seek": 49200, "start": 508.0, "end": 511.0, "text": " Tak. To nie jest b\u0142\u0105d statystyczny, to jest przepa\u015b\u0107.", "tokens": [51164, 9118, 13, 1407, 2838, 3492, 272, 15926, 67, 2219, 38593, 17466, 1634, 11, 281, 3492, 30829, 64, 7753, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0713552643981161, "compression_ratio": 1.4364161849710984, "no_speech_prob": 0.06919113546609879}, {"id": 53, "seek": 49200, "start": 511.0, "end": 520.0, "text": " To ogromna przewaga. A to je\u015bli chcemy go wyspecjalizowa\u0107 tylko w jednej konkretnej dziedzinie? Jak sobie radzi w takim klasycznym fine tuningu do jednego zadania?", "tokens": [51314, 1407, 34416, 298, 629, 39758, 9286, 13, 316, 281, 25630, 28928, 2226, 352, 27062, 494, 66, 22600, 590, 11445, 13219, 261, 5232, 11794, 36500, 11794, 9758, 15338, 259, 414, 30, 15029, 13652, 2843, 3992, 261, 31732, 9671, 5871, 3689, 12996, 2489, 15164, 84, 360, 5232, 11858, 42788, 5609, 30, 51764], "temperature": 0.0, "avg_logprob": -0.0713552643981161, "compression_ratio": 1.4364161849710984, "no_speech_prob": 0.06919113546609879}, {"id": 54, "seek": 52000, "start": 520.0, "end": 529.0, "text": " Sprawdzili to na standardowym te\u015bcie MNLE, czyli Multigener Natural Language Influence, to jest taka, wiesz, olimpiada zrozumienia tekstu.", "tokens": [50364, 1738, 15889, 89, 2312, 281, 1667, 3832, 31691, 535, 9815, 376, 45, 2634, 11, 16591, 14665, 3213, 260, 20137, 24445, 11537, 40432, 11, 281, 3492, 28017, 11, 261, 15347, 11, 2545, 8814, 39018, 710, 27857, 449, 18811, 16624, 372, 84, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 55, "seek": 52000, "start": 529.0, "end": 532.0, "text": " I tutaj sta\u0142o si\u0119 co\u015b bardzo, bardzo ciekawego.", "tokens": [50814, 286, 12749, 11135, 5249, 3244, 19241, 9034, 11, 9034, 30596, 2330, 826, 1571, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 56, "seek": 52000, "start": 532.0, "end": 533.0, "text": " No.", "tokens": [50964, 883, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 57, "seek": 52000, "start": 533.0, "end": 536.0, "text": " Ta, kt\u00f3re s\u0105 stworzone w\u0142a\u015bnie do tego typu zada\u0144.", "tokens": [51014, 6551, 11, 8864, 9015, 342, 28321, 16896, 14234, 360, 8627, 2125, 84, 710, 1538, 5248, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 58, "seek": 52000, "start": 536.0, "end": 539.0, "text": " Ale najlepszy jest to, jak to osi\u0105gn\u0119li.", "tokens": [51164, 9366, 41903, 1878, 1229, 3492, 281, 11, 4207, 281, 3003, 11404, 4568, 1274, 2081, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 59, "seek": 52000, "start": 539.0, "end": 546.0, "text": " S\u0142ucham, dostroili fine tuned jedynie odpowiedni encoder, tego analityka od j\u0119zyka.", "tokens": [51314, 318, 1221, 625, 335, 11, 20568, 340, 2312, 2489, 10870, 5232, 2534, 414, 36574, 3722, 2058, 19866, 11, 8627, 2624, 507, 2330, 3611, 42309, 40940, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1177072674036026, "compression_ratio": 1.3633093525179856, "no_speech_prob": 0.04785758629441261}, {"id": 60, "seek": 54600, "start": 546.0, "end": 553.0, "text": " A ca\u0142a reszta modelu, w tym ca\u0142y generatywny dekoder, pozosta\u0142a zamro\u017cona, nietkni\u0119ta.", "tokens": [50364, 316, 1335, 5024, 725, 89, 1328, 2316, 84, 11, 261, 8107, 35226, 1337, 21398, 43682, 368, 74, 19866, 11, 21281, 8638, 5024, 19876, 340, 1427, 4037, 11, 6899, 74, 35938, 1328, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 61, "seek": 54600, "start": 553.0, "end": 556.0, "text": " Chwila chwila, to jest absolutnie kluczowe.", "tokens": [50714, 761, 86, 7371, 26237, 7371, 11, 281, 3492, 18757, 2766, 9671, 1311, 89, 6880, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 62, "seek": 54600, "start": 556.0, "end": 562.0, "text": " Czyli oni udowodniaj\u0105, \u017ce mo\u017cna wyspecjalizowa\u0107 tylko jeden ma\u0142y modu\u0142 tego analityka,", "tokens": [50864, 37099, 36317, 11727, 305, 378, 12679, 8555, 11, 3561, 17790, 27062, 494, 66, 22600, 590, 11445, 13219, 12906, 463, 6825, 1072, 84, 1221, 8627, 2624, 507, 2330, 11, 51164], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 63, "seek": 54600, "start": 562.0, "end": 566.0, "text": " a ca\u0142y kreatywny mened\u017cer pozostaje nietkni\u0119ty i uniwersalny.", "tokens": [51164, 257, 35226, 350, 620, 88, 43682, 1706, 292, 1427, 260, 21281, 555, 11153, 6899, 74, 35938, 874, 741, 36435, 5364, 304, 1634, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 64, "seek": 54600, "start": 566.0, "end": 569.0, "text": " To brzmi jak \u015bwi\u0119ty gra modu\u0142owej I.I.", "tokens": [51364, 1407, 738, 89, 3057, 4207, 8299, 22423, 874, 1295, 1072, 84, 1221, 21091, 286, 13, 40, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 65, "seek": 54600, "start": 569.0, "end": 571.0, "text": " Dok\u0142adnie tak.", "tokens": [51514, 29768, 10358, 2766, 991, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 66, "seek": 54600, "start": 571.0, "end": 574.0, "text": " To pokazuje niesamowit\u0105 elastyczno\u015b\u0107 tej architektury.", "tokens": [51614, 1407, 13010, 43317, 48100, 335, 305, 270, 1611, 806, 9820, 3689, 23293, 12573, 3912, 642, 2320, 2598, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07698809016834605, "compression_ratio": 1.4872727272727273, "no_speech_prob": 0.07399655133485794}, {"id": 67, "seek": 57400, "start": 574.0, "end": 582.0, "text": " Interfejs pozostaje uniwersalny, a my podmieniamy lub doszkalamy tylko ten jeden modu\u0142, kt\u00f3ry jest w danym momencie potrzebny.", "tokens": [50364, 5751, 2106, 25530, 21281, 555, 11153, 36435, 5364, 304, 1634, 11, 257, 452, 2497, 76, 1053, 2918, 88, 15980, 4491, 89, 19990, 7804, 13219, 2064, 12906, 1072, 84, 1221, 11, 9913, 3492, 261, 274, 1325, 76, 40883, 37595, 1634, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 68, "seek": 57400, "start": 582.0, "end": 587.0, "text": " Ok, czyli udowodnili, \u017ce ma t\u0119 analityczn\u0105 dusz\u0119 modeli typu BERT.", "tokens": [50764, 3477, 11, 16591, 11727, 305, 378, 77, 2312, 11, 3561, 463, 32489, 364, 1860, 3689, 13113, 14284, 11052, 2316, 72, 2125, 84, 363, 31479, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 69, "seek": 57400, "start": 587.0, "end": 592.0, "text": " Ale czy w tym procesie nie po\u015bwi\u0119cili tego, co jest magi\u0105 w GPT?", "tokens": [51014, 9366, 6430, 261, 8107, 17565, 414, 2838, 714, 1788, 22423, 66, 2312, 8627, 11, 598, 3492, 2258, 11404, 261, 26039, 51, 30, 51264], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 70, "seek": 57400, "start": 592.0, "end": 595.0, "text": " Czy ten model nadal potrafi improwizowa\u0107?", "tokens": [51264, 19832, 2064, 2316, 12617, 304, 1847, 10437, 72, 704, 1892, 590, 11445, 30, 51414], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 71, "seek": 57400, "start": 595.0, "end": 597.0, "text": " Uczy\u0107 si\u0119 w locie?", "tokens": [51414, 624, 33967, 3244, 261, 1628, 414, 30, 51514], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 72, "seek": 57400, "start": 597.0, "end": 599.0, "text": " Co z in-context learning?", "tokens": [51514, 3066, 710, 294, 12, 9000, 3828, 2539, 30, 51614], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 73, "seek": 57400, "start": 599.0, "end": 601.0, "text": " I to jest w\u0142a\u015bnie to po\u0142\u0105czenie ognia z wod\u0105.", "tokens": [51614, 286, 281, 3492, 14234, 281, 714, 15926, 39043, 277, 4568, 654, 710, 47751, 1611, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09787137541052414, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.02808503992855549}, {"id": 74, "seek": 60100, "start": 602.0, "end": 605.0, "text": " Okazuje si\u0119, \u017ce nie stracili tych zdolno\u015bci.", "tokens": [50414, 3477, 43317, 3244, 11, 3561, 2838, 1056, 326, 2312, 15180, 16221, 401, 16438, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09017143693081169, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.41721606254577637}, {"id": 75, "seek": 60100, "start": 605.0, "end": 609.0, "text": " Po dodatkowym treningu na zadaniach z instrukcjami, czyli instruction tuning,", "tokens": [50564, 6165, 13886, 33525, 31691, 2192, 773, 84, 1667, 42788, 3782, 608, 710, 1058, 25126, 66, 73, 4526, 11, 16591, 10951, 15164, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09017143693081169, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.41721606254577637}, {"id": 76, "seek": 60100, "start": 609.0, "end": 615.0, "text": " model nie tylko zachowa\u0142 zdolno\u015b\u0107 do in-context learning na poziomie por\u00f3wnywalnym z bazowym GPT,", "tokens": [50764, 2316, 2838, 13219, 29303, 30105, 16221, 401, 23293, 360, 294, 12, 9000, 3828, 2539, 1667, 38503, 40120, 1515, 812, 895, 27112, 304, 12996, 710, 27147, 31691, 26039, 51, 11, 51064], "temperature": 0.0, "avg_logprob": -0.09017143693081169, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.41721606254577637}, {"id": 77, "seek": 60100, "start": 615.0, "end": 623.0, "text": " ale te\u017c wykaza\u0142 znacznie lepsz\u0105 zdolno\u015b\u0107 do generalizacji zero shot na zupe\u0142nie nowe zadania, takie, kt\u00f3rych nigdy wcze\u015bniej nie widzia\u0142.", "tokens": [51064, 6775, 9516, 39287, 12257, 1221, 15397, 14875, 2766, 476, 1878, 8925, 16221, 401, 23293, 360, 2674, 590, 13152, 4018, 3347, 1667, 49922, 586, 68, 42788, 5609, 11, 15963, 11, 30382, 26996, 3173, 40785, 2838, 27486, 8908, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09017143693081169, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.41721606254577637}, {"id": 78, "seek": 60100, "start": 623.0, "end": 627.0, "text": " Czyli mamy model, kt\u00f3ry po pracyzyjnym fine tuningi,", "tokens": [51464, 37099, 17335, 2316, 11, 9913, 714, 582, 2551, 1229, 73, 12996, 2489, 15164, 72, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09017143693081169, "compression_ratio": 1.5070422535211268, "no_speech_prob": 0.41721606254577637}, {"id": 79, "seek": 62700, "start": 627.0, "end": 631.0, "text": " w tym treningu jest ekspertem w jednej dziedzinie, ale jednocze\u015bnie zachowuje elastyczno\u015b\u0107,", "tokens": [50364, 261, 8107, 2192, 773, 84, 3492, 30724, 15346, 443, 261, 5232, 11794, 9758, 15338, 259, 414, 11, 6775, 5232, 26694, 1381, 12221, 29303, 305, 13008, 806, 9820, 3689, 23293, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 80, "seek": 62700, "start": 631.0, "end": 635.0, "text": " \u017ceby nauczy\u0107 si\u0119 czego\u015b nowego z kilku przyk\u0142ad\u00f3w podanych w pr\u0105cie.", "tokens": [50564, 11316, 49103, 27150, 3244, 36559, 1788, 586, 6308, 710, 5128, 5279, 23144, 3901, 2497, 34644, 261, 582, 1611, 4260, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 81, "seek": 62700, "start": 635.0, "end": 636.0, "text": " Dok\u0142adnie.", "tokens": [50764, 29768, 10358, 2766, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 82, "seek": 62700, "start": 636.0, "end": 640.0, "text": " To, co opisujesz, to mistrzostwo w rozumieniu j\u0119zyka.", "tokens": [50814, 1407, 11, 598, 45477, 4579, 10430, 11, 281, 3544, 19390, 555, 6120, 261, 48797, 1053, 5951, 42309, 40940, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 83, "seek": 62700, "start": 640.0, "end": 644.0, "text": " Ale obietnica uniwersalnego interfejsu si\u0119ga przecie\u017c dalej.", "tokens": [51014, 9366, 1111, 1684, 32687, 36435, 5364, 304, 11858, 728, 2106, 73, 15091, 3244, 3680, 8325, 40082, 34257, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 84, "seek": 62700, "start": 644.0, "end": 649.0, "text": " Prawdziwy menad\u017cer nie tylko czyta raporty, ale te\u017c patrzy na wykresy i prototypy.", "tokens": [51214, 430, 15889, 3992, 9726, 1706, 345, 1427, 260, 2838, 13219, 6430, 1328, 5099, 477, 88, 11, 6775, 9516, 1947, 13047, 1667, 39287, 495, 88, 741, 46219, 8200, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 85, "seek": 62700, "start": 649.0, "end": 651.0, "text": " Czy ten model potrafi patrze\u0107?", "tokens": [51464, 19832, 2064, 2316, 1847, 10437, 72, 1947, 13503, 2162, 30, 51564], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 86, "seek": 62700, "start": 651.0, "end": 655.0, "text": " I tu w\u0142a\u015bnie zarna\u017a\u0107 si\u0119 prawdziwa magia i pokaz si\u0142y tej architektury.", "tokens": [51564, 286, 2604, 14234, 710, 21394, 10659, 2162, 3244, 41175, 3992, 4151, 2258, 654, 741, 13010, 921, 1511, 6825, 12573, 3912, 642, 2320, 2598, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09674764934339021, "compression_ratio": 1.4601769911504425, "no_speech_prob": 0.26682475209236145}, {"id": 87, "seek": 65500, "start": 656.0, "end": 662.0, "text": " Do\u0142\u0105czyli do systemu enkoder wizualny i sprawdzili, jak sobie radzi w zadaniach multimodalnych.", "tokens": [50414, 1144, 15926, 6522, 2081, 360, 1185, 84, 465, 74, 19866, 40808, 901, 1634, 741, 46192, 89, 2312, 11, 4207, 13652, 2843, 3992, 261, 42788, 3782, 608, 32972, 378, 304, 9399, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 88, "seek": 65500, "start": 662.0, "end": 667.0, "text": " I w trybie zero shot, czyli bez \u017cadnych wcze\u015bniejszych przyk\u0142ad\u00f3w,", "tokens": [50714, 286, 261, 853, 7392, 4018, 3347, 11, 16591, 10782, 39628, 9399, 40785, 45021, 23144, 3901, 11, 50964], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 89, "seek": 65500, "start": 667.0, "end": 671.0, "text": " model potrafi\u0142 generowa\u0107 opisy obraz\u00f3w z popularnych zestaw\u00f3w danych,", "tokens": [50964, 2316, 1847, 10437, 40622, 1337, 11445, 999, 14169, 22798, 89, 3901, 710, 3743, 9399, 37889, 1607, 3901, 274, 34644, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 90, "seek": 65500, "start": 671.0, "end": 674.0, "text": " jak Koko czy Flicker 30K.", "tokens": [51164, 4207, 591, 13704, 6430, 3235, 33804, 2217, 42, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 91, "seek": 65500, "start": 674.0, "end": 675.0, "text": " I jak mu posz\u0142o?", "tokens": [51314, 286, 4207, 2992, 1366, 89, 5249, 30, 51364], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 92, "seek": 65500, "start": 675.0, "end": 679.0, "text": " Ze znacznie lepszymi wynikami ni\u017c poprzednie modele o podobnej filozofii.", "tokens": [51364, 4853, 15397, 14875, 2766, 476, 1878, 1229, 3057, 31936, 1035, 4526, 28502, 1665, 81, 11312, 2766, 4391, 306, 277, 43024, 11794, 1387, 15151, 2670, 5597, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 93, "seek": 65500, "start": 679.0, "end": 683.0, "text": " Opisywanie tego, co jest na obrazku, to jedno.", "tokens": [51564, 12011, 14169, 86, 7155, 8627, 11, 598, 3492, 1667, 22798, 89, 5279, 11, 281, 5232, 1771, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08219394549517564, "compression_ratio": 1.421602787456446, "no_speech_prob": 0.053971365094184875}, {"id": 94, "seek": 68300, "start": 683.0, "end": 686.0, "text": " Ale co z pytaniami, kt\u00f3re wymagaj\u0105 czego\u015b wi\u0119cej?", "tokens": [50364, 9366, 598, 710, 25878, 282, 15568, 11, 8864, 29764, 559, 11133, 36559, 1788, 26004, 30, 50514], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 95, "seek": 68300, "start": 686.0, "end": 689.0, "text": " Takimi, kt\u00f3re \u0142\u0105cz\u0105 obraz z wiedz\u0105 o \u015bwiecie?", "tokens": [50514, 9118, 10121, 11, 8864, 220, 43558, 1611, 22798, 89, 710, 46894, 8925, 277, 40078, 4260, 30, 50664], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 96, "seek": 68300, "start": 689.0, "end": 691.0, "text": " Prawdziwi to.", "tokens": [50664, 430, 15889, 3992, 6253, 281, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 97, "seek": 68300, "start": 691.0, "end": 697.0, "text": " U\u017cyli bardzo wymagaj\u0105cego zestawu danych OKVQA, gdzie pytania wymagaj\u0105 wiedzy zewn\u0119trznej.", "tokens": [50764, 624, 7735, 2081, 9034, 29764, 559, 11133, 384, 1571, 37889, 1607, 84, 274, 34644, 2264, 53, 48, 32, 11, 18922, 25878, 5609, 29764, 559, 11133, 46894, 1229, 5277, 895, 1274, 6903, 89, 11794, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 98, "seek": 68300, "start": 697.0, "end": 702.0, "text": " Na przyk\u0142ad model widzi zdj\u0119cie samolotu i dostaje pytanie, kto go wynalaz\u0142?", "tokens": [51064, 6056, 23144, 2316, 5274, 3992, 49026, 4260, 3247, 401, 310, 84, 741, 20568, 11153, 36610, 11, 23780, 352, 31936, 304, 921, 1221, 30, 51314], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 99, "seek": 68300, "start": 702.0, "end": 704.0, "text": " I co? Odpowiada?", "tokens": [51314, 286, 598, 30, 12210, 14701, 39018, 30, 51414], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 100, "seek": 68300, "start": 704.0, "end": 706.0, "text": " I potrafi na nie odpowiedzie\u0107.", "tokens": [51414, 286, 1847, 10437, 72, 1667, 2838, 24314, 22078, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 101, "seek": 68300, "start": 706.0, "end": 708.0, "text": " A to pokazuje co\u015b fundamentalnego.", "tokens": [51514, 316, 281, 13010, 43317, 19241, 8088, 11858, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 102, "seek": 68300, "start": 708.0, "end": 711.0, "text": " Enkoder wizualny m\u00f3wi, widz\u0119 samolot.", "tokens": [51614, 2193, 74, 19866, 40808, 901, 1634, 24592, 11, 5274, 11052, 3247, 401, 310, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07158044137452778, "compression_ratio": 1.4448275862068964, "no_speech_prob": 0.0090938163921237}, {"id": 103, "seek": 71100, "start": 711.0, "end": 713.0, "text": " A dekoder, kt\u00f3ry jest modelem j\u0119zykowym,", "tokens": [50364, 316, 368, 74, 19866, 11, 9913, 3492, 4391, 10386, 49055, 74, 31691, 11, 50464], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 104, "seek": 71100, "start": 713.0, "end": 718.0, "text": " si\u0119ga do swojej ogromnej wbudowanej bazy wiedzy o \u015bwiecie i generuje odpowied\u017a.", "tokens": [50464, 3244, 3680, 360, 29489, 73, 34416, 298, 11794, 261, 18281, 23066, 73, 27147, 88, 46894, 1229, 277, 40078, 4260, 741, 1337, 13008, 36574, 10659, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 105, "seek": 71100, "start": 718.0, "end": 719.0, "text": " Bracia Wright.", "tokens": [50714, 1603, 28000, 25578, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 106, "seek": 71100, "start": 719.0, "end": 724.0, "text": " Czyli bodziec wizualny aktywuje abstrakcyjn\u0105 wiedz\u0119 zapisan\u0105 w cz\u0119\u015bci j\u0119zykowej.", "tokens": [50764, 37099, 16737, 3283, 66, 40808, 901, 1634, 9308, 874, 86, 13008, 10823, 11272, 42949, 13113, 46894, 11052, 14223, 14804, 1611, 261, 41314, 49055, 74, 21091, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 107, "seek": 71100, "start": 724.0, "end": 726.0, "text": " To robi ogromne wra\u017cenie.", "tokens": [51014, 1407, 47380, 34416, 298, 716, 7843, 41118, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 108, "seek": 71100, "start": 726.0, "end": 732.0, "text": " A jak wypada w klasycznym finetuningu w zadaniach VQA, czyli Visual Question Answering?", "tokens": [51114, 316, 4207, 46392, 1538, 261, 9671, 5871, 3689, 12996, 962, 302, 37726, 84, 261, 42788, 3782, 608, 691, 48, 32, 11, 16591, 23187, 14464, 24545, 278, 30, 51414], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 109, "seek": 71100, "start": 732.0, "end": 737.0, "text": " Czy mo\u017ce konkurowa\u0107 z modelami, kt\u00f3re by\u0142y budowane od zera tylko do tego celu?", "tokens": [51414, 19832, 12034, 21428, 374, 11445, 710, 2316, 4526, 11, 8864, 26366, 3265, 23066, 3611, 710, 1663, 13219, 360, 8627, 9277, 84, 30, 51664], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 110, "seek": 71100, "start": 737.0, "end": 740.0, "text": " To jest dobre pytanie, bo mo\u017cna by pomy\u015ble\u0107, \u017ce jest na straconej pozycji.", "tokens": [51664, 1407, 3492, 41959, 36610, 11, 748, 17790, 538, 280, 8488, 1788, 306, 2162, 11, 3561, 3492, 1667, 1056, 326, 546, 73, 49358, 19649, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07310385332849925, "compression_ratio": 1.4680232558139534, "no_speech_prob": 0.002928669797256589}, {"id": 111, "seek": 74000, "start": 740.0, "end": 749.0, "text": " No w\u0142a\u015bnie. Te wyspecjalizowane modele VQA cz\u0119sto maj\u0105 z g\u00f3ry okre\u015blony zamkni\u0119ty zestaw mo\u017cliwych odpowiedzi.", "tokens": [50364, 883, 14234, 13, 1989, 27062, 494, 66, 22600, 590, 23066, 4391, 306, 691, 48, 32, 34369, 26064, 710, 290, 812, 627, 3133, 265, 19212, 2526, 19876, 74, 35938, 874, 37889, 1607, 30854, 9726, 339, 36574, 3992, 13, 50814], "temperature": 0.0, "avg_logprob": -0.056988247581150224, "compression_ratio": 1.471311475409836, "no_speech_prob": 0.0729265958070755}, {"id": 112, "seek": 74000, "start": 749.0, "end": 754.0, "text": " Generowanie otwartej odpowiedzi jest orz\u0105d wielko\u015bci trudniejsze.", "tokens": [50814, 15409, 22028, 4337, 86, 11026, 73, 36574, 3992, 3492, 420, 23876, 20570, 4093, 6199, 32007, 44258, 13, 51064], "temperature": 0.0, "avg_logprob": -0.056988247581150224, "compression_ratio": 1.471311475409836, "no_speech_prob": 0.0729265958070755}, {"id": 113, "seek": 74000, "start": 754.0, "end": 758.0, "text": " I on daje sobie rad\u0119 w\u0142a\u015bnie dzi\u0119ki temu, \u017ce generuje otwarte odpowiedzi.", "tokens": [51064, 286, 322, 1120, 2884, 13652, 2843, 1274, 14234, 45003, 33346, 11, 3561, 1337, 13008, 4337, 86, 11026, 36574, 3992, 13, 51264], "temperature": 0.0, "avg_logprob": -0.056988247581150224, "compression_ratio": 1.471311475409836, "no_speech_prob": 0.0729265958070755}, {"id": 114, "seek": 74000, "start": 758.0, "end": 765.0, "text": " Przewy\u017csza inne modele generatywne, jest bardzo konkurencyjny wobec tych wyspecjalizowanych.", "tokens": [51264, 2114, 43551, 88, 1427, 82, 2394, 24170, 4391, 306, 1337, 21398, 86, 716, 11, 3492, 9034, 21428, 9873, 42949, 1634, 6020, 8123, 15180, 27062, 494, 66, 22600, 590, 23341, 339, 13, 51614], "temperature": 0.0, "avg_logprob": -0.056988247581150224, "compression_ratio": 1.471311475409836, "no_speech_prob": 0.0729265958070755}, {"id": 115, "seek": 76500, "start": 765.0, "end": 771.0, "text": " A w testach, gdzie poprawna odpowied\u017a na pytanie nie znajduje si\u0119 w predefiniowanym zbiorze, po prostu je wyprzedza.", "tokens": [50364, 316, 261, 1500, 608, 11, 18922, 1665, 5131, 629, 36574, 10659, 1667, 36610, 2838, 47570, 2884, 3244, 261, 659, 20595, 3812, 23341, 76, 710, 33362, 1381, 11, 714, 19518, 1506, 4628, 1424, 11312, 2394, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 116, "seek": 76500, "start": 771.0, "end": 773.0, "text": " Bo ma elastyczno\u015b\u0107.", "tokens": [50664, 3286, 463, 806, 9820, 3689, 23293, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 117, "seek": 76500, "start": 773.0, "end": 778.0, "text": " Bo jego elastyczno\u015b\u0107 pozwala mu sformu\u0142owa\u0107 odpowied\u017a, na kt\u00f3r\u0105 inne modele nie by\u0142y przygotowane.", "tokens": [50764, 3286, 26542, 806, 9820, 3689, 23293, 40557, 5159, 2992, 262, 837, 84, 1221, 11445, 36574, 10659, 11, 1667, 37415, 24170, 4391, 306, 2838, 26366, 35914, 23066, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 118, "seek": 76500, "start": 778.0, "end": 782.0, "text": " Ale jest jeszcze jeden eksperyment, kt\u00f3ry uwa\u017cam za najbardziej fascynuj\u0105cy.", "tokens": [51014, 9366, 3492, 14168, 12906, 30724, 610, 88, 518, 11, 9913, 48089, 335, 7949, 41857, 30632, 1344, 77, 13263, 1344, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 119, "seek": 76500, "start": 782.0, "end": 788.0, "text": " Bond dotyka czego\u015b, co przypomina zal\u0105\u017cek, samo\u015bwiadomo\u015bci w procesie rozumowania.", "tokens": [51214, 23604, 5893, 88, 2330, 36559, 1788, 11, 598, 41780, 49217, 29599, 27242, 916, 11, 36422, 37750, 13395, 6199, 261, 17565, 414, 48797, 21308, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 120, "seek": 76500, "start": 788.0, "end": 789.0, "text": " Opowiedz o tym.", "tokens": [51514, 12011, 305, 15338, 277, 8107, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06631331336229368, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.46495869755744934}, {"id": 121, "seek": 78900, "start": 789.0, "end": 792.0, "text": " U\u017cyto zestawu danych SNLE VIVI.", "tokens": [50364, 624, 7735, 1353, 37889, 1607, 84, 274, 34644, 13955, 2634, 691, 10375, 40, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 122, "seek": 78900, "start": 792.0, "end": 794.0, "text": " Zadanie jest wieloetapowe.", "tokens": [50514, 1176, 345, 7155, 3492, 20570, 78, 302, 569, 6880, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 123, "seek": 78900, "start": 794.0, "end": 801.0, "text": " Model patrzy na obrazek, czyta zdanie, a nast\u0119pnie ma oceni\u0107, czy zdanie logicznie wynika z obrazka.", "tokens": [50614, 17105, 1947, 13047, 1667, 22798, 19878, 11, 6430, 1328, 16221, 7155, 11, 257, 39662, 2766, 463, 10409, 268, 12757, 11, 6430, 16221, 7155, 9952, 89, 2766, 31936, 5439, 710, 22798, 89, 2330, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 124, "seek": 78900, "start": 801.0, "end": 802.0, "text": " Ok.", "tokens": [50964, 3477, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 125, "seek": 78900, "start": 802.0, "end": 803.0, "text": " Ale to nie wszystko.", "tokens": [51014, 9366, 281, 2838, 22607, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 126, "seek": 78900, "start": 803.0, "end": 812.0, "text": " Musi nie tylko wyda\u0107 werdykt np. wnioskowanie jest poprawne, ale r\u00f3wnie\u017c wygenerowa\u0107 wyja\u015bnienie w j\u0119zyku naturalnym np.", "tokens": [51064, 3569, 72, 2838, 13219, 4628, 2675, 2162, 2612, 3173, 2320, 33808, 13, 45368, 2717, 74, 22028, 3492, 1665, 5131, 716, 11, 6775, 20532, 4628, 21848, 11445, 4628, 2938, 1788, 77, 27385, 261, 49055, 5279, 3303, 12996, 33808, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 127, "seek": 78900, "start": 812.0, "end": 816.0, "text": " Poniewa\u017c zwierz\u0119 na zdj\u0119ciu to pies patrz\u0105cy w stron\u0119 kamery.", "tokens": [51514, 31756, 27806, 11873, 811, 11052, 1667, 49026, 30795, 281, 29640, 1947, 81, 8925, 1344, 261, 45766, 1274, 9727, 2109, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 128, "seek": 78900, "start": 816.0, "end": 818.0, "text": " I jak sobie z tym poradzi\u0142?", "tokens": [51714, 286, 4207, 13652, 710, 8107, 1515, 345, 3992, 1221, 30, 51814], "temperature": 0.0, "avg_logprob": -0.09685751597086588, "compression_ratio": 1.4137931034482758, "no_speech_prob": 0.7663714289665222}, {"id": 129, "seek": 81800, "start": 818.0, "end": 823.0, "text": " Nie tylko \u015bwietnie generowa\u0142 te wyja\u015bnienia osi\u0105gaj\u0105c wyniki lepsze ni\u017c poprzednie modele.", "tokens": [50364, 12016, 13219, 8299, 39083, 2766, 1337, 30105, 535, 4628, 2938, 1788, 77, 18811, 3003, 11404, 70, 38757, 31936, 9850, 476, 1878, 1381, 28502, 1665, 81, 11312, 2766, 4391, 306, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 130, "seek": 81800, "start": 823.0, "end": 825.0, "text": " Sta\u0142o si\u0119 co\u015b znacznie ciekawszego.", "tokens": [50614, 16959, 5249, 3244, 19241, 15397, 14875, 2766, 46419, 1607, 15453, 6308, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 131, "seek": 81800, "start": 825.0, "end": 833.0, "text": " Okaza\u0142o si\u0119, \u017ce sam fakt, \u017ce model musi wygenerowa\u0107 wyja\u015bnienie, poprawia jego dok\u0142adno\u015b\u0107 w g\u0142\u00f3wnym zadaniu.", "tokens": [50714, 3477, 12257, 5249, 3244, 11, 3561, 3247, 21310, 11, 3561, 2316, 37587, 4628, 21848, 11445, 4628, 2938, 1788, 77, 27385, 11, 1665, 5131, 654, 26542, 45864, 23293, 261, 18117, 812, 895, 4199, 42788, 25849, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 132, "seek": 81800, "start": 833.0, "end": 834.0, "text": " Zaraz, zaraz.", "tokens": [51114, 41580, 921, 11, 22675, 921, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 133, "seek": 81800, "start": 834.0, "end": 841.0, "text": " Czyli zmuszenie modelu do my\u015blenia na g\u0142os, do verbalizacji swojego rozumowania czy niego m\u0105drzejszym?", "tokens": [51164, 37099, 17020, 301, 16778, 2316, 84, 360, 48633, 6698, 654, 1667, 43767, 11, 360, 24781, 590, 13152, 13291, 39738, 48797, 21308, 6430, 49615, 275, 18962, 13503, 73, 7706, 76, 30, 51514], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 134, "seek": 81800, "start": 841.0, "end": 842.0, "text": " Na to wygl\u0105da.", "tokens": [51514, 6056, 281, 32015, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 135, "seek": 81800, "start": 842.0, "end": 845.0, "text": " To jest fascynuj\u0105co kontrintuicyjne.", "tokens": [51564, 1407, 3492, 30632, 1344, 77, 13263, 1291, 14373, 81, 686, 84, 2632, 73, 716, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0631826503856762, "compression_ratio": 1.4793103448275862, "no_speech_prob": 0.0060117244720458984}, {"id": 136, "seek": 84500, "start": 845.0, "end": 851.0, "text": " Zawsze my\u015bla\u0142y\u015bmy o tym wewn\u0119trznym monologu AI jako o czym\u015b, co spowalnia proces.", "tokens": [50364, 1176, 28354, 48633, 875, 6825, 10513, 277, 8107, 321, 895, 1274, 6903, 89, 12996, 1108, 1132, 84, 7318, 17123, 277, 31466, 1788, 11, 598, 637, 305, 304, 12679, 17565, 13, 50664], "temperature": 0.0, "avg_logprob": -0.03973515950716459, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.035748086869716644}, {"id": 137, "seek": 84500, "start": 851.0, "end": 854.0, "text": " A tu si\u0119 okazuje, \u017ce ta verbalizacja pomaga.", "tokens": [50664, 316, 2604, 3244, 3133, 43317, 11, 3561, 1846, 24781, 590, 23395, 12991, 9286, 13, 50814], "temperature": 0.0, "avg_logprob": -0.03973515950716459, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.035748086869716644}, {"id": 138, "seek": 84500, "start": 854.0, "end": 862.0, "text": " To tak jakby proces uk\u0142adania my\u015bli w s\u0142owa zmusza\u0142 model do pod\u0105\u017cania bardziej logiczn\u0105 \u015bcie\u017ck\u0105 neuronow\u0105.", "tokens": [50814, 1407, 991, 28976, 17565, 344, 15317, 5609, 452, 15350, 261, 15116, 5528, 17020, 301, 2394, 1221, 2316, 360, 2497, 27242, 5609, 27209, 9952, 89, 13113, 8299, 40082, 26304, 34090, 30297, 13, 51214], "temperature": 0.0, "avg_logprob": -0.03973515950716459, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.035748086869716644}, {"id": 139, "seek": 84500, "start": 862.0, "end": 870.0, "text": " Co wi\u0119cej, gdy badacze usun\u0119li z polecenia pro\u015bb\u0119 o generowanie wyja\u015bnienia, dok\u0142adno\u015b\u0107 w zadaniu klasyfikacji nieznacznie spad\u0142a.", "tokens": [51214, 3066, 26004, 11, 28405, 1578, 326, 1381, 505, 409, 1274, 2081, 710, 13208, 13037, 654, 447, 1788, 65, 1274, 277, 1337, 22028, 4628, 2938, 1788, 77, 18811, 11, 45864, 23293, 261, 42788, 25849, 9671, 5871, 31230, 13152, 2838, 22672, 14875, 2766, 637, 345, 5024, 13, 51614], "temperature": 0.0, "avg_logprob": -0.03973515950716459, "compression_ratio": 1.423913043478261, "no_speech_prob": 0.035748086869716644}, {"id": 140, "seek": 87000, "start": 871.0, "end": 872.0, "text": " To troch\u0119 jak w \u017cyciu.", "tokens": [50414, 1407, 24926, 4207, 261, 16136, 30795, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 141, "seek": 87000, "start": 872.0, "end": 876.0, "text": " Czasem dopieno, gdy pr\u00f3bujemy komo\u015b co\u015b wyt\u0142umaczy\u0107, to sami to do ko\u0144ca rozumiemy.", "tokens": [50464, 383, 24561, 443, 21900, 1053, 78, 11, 28405, 8565, 65, 21767, 5207, 78, 1788, 19241, 261, 4328, 49166, 14691, 2162, 11, 281, 3247, 72, 281, 360, 26470, 496, 48797, 414, 2226, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 142, "seek": 87000, "start": 876.0, "end": 877.0, "text": " W\u0142a\u015bnie.", "tokens": [50664, 343, 5024, 12221, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 143, "seek": 87000, "start": 877.0, "end": 880.0, "text": " I okazuje si\u0119, \u017ce ta zasada mo\u017ce dotyczy\u0107 te\u017c krzemu.", "tokens": [50714, 286, 3133, 43317, 3244, 11, 3561, 1846, 26530, 1538, 12034, 5893, 88, 33967, 9516, 15913, 24313, 84, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 144, "seek": 87000, "start": 880.0, "end": 882.0, "text": " To niesamowite.", "tokens": [50864, 1407, 48100, 335, 305, 642, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 145, "seek": 87000, "start": 882.0, "end": 888.0, "text": " Mamy wi\u0119c architektur\u0119, kt\u00f3ra dzia\u0142a i przynosi imponuj\u0105ce, a czasem zaskakuj\u0105ce rezultaty.", "tokens": [50964, 376, 7804, 16677, 3912, 642, 2320, 374, 1274, 11, 19456, 37903, 741, 6501, 16751, 72, 704, 266, 13263, 384, 11, 257, 13190, 443, 710, 3863, 514, 13263, 384, 48060, 723, 21398, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 146, "seek": 87000, "start": 888.0, "end": 894.0, "text": " Podsumujmy mo\u017ce jaki jest szerszy kontekst, jaki realny, du\u017cy problem to rozwi\u0105zuje.", "tokens": [51264, 12646, 82, 449, 4579, 2226, 12034, 24492, 3492, 7870, 433, 1229, 14373, 916, 372, 11, 24492, 957, 1634, 11, 1581, 7735, 1154, 281, 9544, 18234, 11728, 2884, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 147, "seek": 87000, "start": 894.0, "end": 898.0, "text": " Poza tym, \u017ce jest to eleganckie in\u017cynieryjnie.", "tokens": [51564, 6165, 2394, 8107, 11, 3561, 3492, 281, 1118, 1275, 547, 414, 294, 1427, 2534, 811, 88, 73, 2766, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09851471970720989, "compression_ratio": 1.45, "no_speech_prob": 0.34374675154685974}, {"id": 148, "seek": 89800, "start": 898.0, "end": 903.0, "text": " To jest, my\u015bl\u0119, milowy krok w kierunku stworzenia prawdziwie zunifikowanego modelu AI.", "tokens": [50364, 1407, 3492, 11, 37730, 11, 1962, 10089, 350, 31621, 261, 38767, 49910, 342, 28321, 14320, 41175, 3992, 8699, 710, 409, 45475, 37345, 6308, 2316, 84, 7318, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 149, "seek": 89800, "start": 903.0, "end": 909.0, "text": " Modelu, kt\u00f3ry nie tylko jest wielozadaniowy, ale fundamentalnie \u0142\u0105czy r\u00f3\u017cne paradygmaty dzia\u0142ania.", "tokens": [50614, 17105, 84, 11, 9913, 2838, 13219, 3492, 20570, 15151, 345, 3782, 10089, 11, 6775, 8088, 2766, 220, 15926, 6522, 47760, 13480, 18103, 15677, 88, 27121, 5609, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 150, "seek": 89800, "start": 909.0, "end": 913.0, "text": " Ta praca pokazuje, \u017ce mo\u017cna mie\u0107 ciastko i zje\u015b\u0107 ciastko.", "tokens": [50914, 6551, 582, 6628, 13010, 43317, 11, 3561, 17790, 35612, 6983, 525, 4093, 741, 710, 2884, 7753, 6983, 525, 4093, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 151, "seek": 89800, "start": 913.0, "end": 918.0, "text": " Mo\u017cna mie\u0107 precyzj\u0119 analityka i elastyczno\u015b\u0107 kreatora w jednym.", "tokens": [51114, 44736, 629, 35612, 659, 1344, 89, 11115, 364, 1860, 2330, 741, 806, 9820, 3689, 23293, 350, 620, 3252, 261, 5232, 12996, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 152, "seek": 89800, "start": 918.0, "end": 919.0, "text": " Tak.", "tokens": [51364, 9118, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 153, "seek": 89800, "start": 919.0, "end": 924.0, "text": " A co to oznacza w praktyce dla kogo\u015b, kto buduje aplikacje oparte na AI?", "tokens": [51414, 316, 598, 281, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 12285, 350, 23515, 1788, 11, 23780, 3265, 13008, 25522, 1035, 29293, 999, 11026, 1667, 7318, 30, 51664], "temperature": 0.0, "avg_logprob": -0.05826481410435268, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.015236849896609783}, {"id": 154, "seek": 92400, "start": 925.0, "end": 931.0, "text": " To tworzy co\u015b, co autorzy nazywaj\u0105 Universal Task Layer, czyli uniwersaln\u0105 warstw\u0119 zadaniow\u0105.", "tokens": [50414, 1407, 46288, 1229, 19241, 11, 598, 19510, 1229, 20151, 27112, 11133, 22617, 30428, 35166, 11, 16591, 36435, 5364, 304, 13113, 1516, 372, 86, 1274, 42788, 3782, 30297, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05240285858627437, "compression_ratio": 1.4132841328413284, "no_speech_prob": 0.0681602880358696}, {"id": 155, "seek": 92400, "start": 931.0, "end": 936.0, "text": " W tym podej\u015bciu j\u0119zyk naturalny staje si\u0119 prawdziwym interfejsem do interakcji,", "tokens": [50714, 343, 8107, 7468, 73, 6199, 84, 49055, 74, 3303, 1634, 342, 11153, 3244, 41175, 3992, 86, 4199, 728, 2106, 73, 19872, 360, 728, 514, 19649, 11, 50964], "temperature": 0.0, "avg_logprob": -0.05240285858627437, "compression_ratio": 1.4132841328413284, "no_speech_prob": 0.0681602880358696}, {"id": 156, "seek": 92400, "start": 936.0, "end": 939.0, "text": " a nawet do programowania r\u00f3\u017cnych wyspecjalizowanych modeli.", "tokens": [50964, 257, 22696, 360, 1461, 21308, 42602, 27062, 494, 66, 22600, 590, 23341, 339, 2316, 72, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05240285858627437, "compression_ratio": 1.4132841328413284, "no_speech_prob": 0.0681602880358696}, {"id": 157, "seek": 92400, "start": 939.0, "end": 945.0, "text": " Czyli zamiast pisa\u0107 skomplikowany kod, \u017ceby u\u017cy\u0107 modelu do rozpoznawania obraz\u00f3w?", "tokens": [51114, 37099, 710, 4526, 525, 280, 3837, 2162, 1110, 298, 564, 1035, 23341, 350, 378, 11, 11316, 34097, 2162, 2316, 84, 360, 9544, 2259, 35458, 86, 5609, 22798, 89, 3901, 30, 51414], "temperature": 0.0, "avg_logprob": -0.05240285858627437, "compression_ratio": 1.4132841328413284, "no_speech_prob": 0.0681602880358696}, {"id": 158, "seek": 92400, "start": 945.0, "end": 948.0, "text": " Po prostu piszemy mu polecenie w j\u0119zyku angielskim.", "tokens": [51414, 6165, 19518, 280, 23848, 3633, 2992, 13208, 13037, 414, 261, 49055, 5279, 2562, 1187, 5161, 332, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05240285858627437, "compression_ratio": 1.4132841328413284, "no_speech_prob": 0.0681602880358696}, {"id": 159, "seek": 94800, "start": 948.0, "end": 954.0, "text": " To odblokowuje te\u017c zupe\u0142nie nowe scenariusze, kt\u00f3re do tej pory by\u0142y, no, poza zasi\u0119giem.", "tokens": [50364, 1407, 3611, 5199, 453, 305, 13008, 9516, 49922, 586, 68, 4191, 27440, 1381, 11, 8864, 360, 12573, 280, 827, 26366, 11, 572, 11, 714, 2394, 26530, 5034, 70, 4907, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0958203494064207, "compression_ratio": 1.3197026022304832, "no_speech_prob": 0.1950276792049408}, {"id": 160, "seek": 94800, "start": 954.0, "end": 957.0, "text": " Zdecydowanie. Wyobra\u017cmy sobie tak\u0105 sytuacj\u0119.", "tokens": [50664, 1176, 1479, 1344, 67, 22028, 13, 14458, 24393, 1427, 2226, 13652, 31069, 28275, 29924, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0958203494064207, "compression_ratio": 1.3197026022304832, "no_speech_prob": 0.1950276792049408}, {"id": 161, "seek": 94800, "start": 957.0, "end": 964.0, "text": " Bierzemy model, kt\u00f3ry zosta\u0142 precyzyjnie dostrojony, fine-tuned i jest \u015bwiatowej klasy ekspertem w analizie obraz\u00f3w medycznych.", "tokens": [50814, 363, 34602, 3633, 2316, 11, 9913, 23154, 1221, 659, 1344, 1229, 73, 2766, 20568, 340, 73, 2526, 11, 2489, 12, 83, 43703, 741, 3492, 36425, 21091, 9671, 5871, 30724, 15346, 443, 261, 2624, 590, 414, 22798, 89, 3901, 1205, 17466, 9399, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0958203494064207, "compression_ratio": 1.3197026022304832, "no_speech_prob": 0.1950276792049408}, {"id": 162, "seek": 94800, "start": 964.0, "end": 967.0, "text": " Powiedzmy, zdj\u0119\u0107 rentgenowskich p\u0142uc.", "tokens": [51164, 14762, 15338, 2226, 11, 49026, 2162, 6214, 1766, 1509, 48349, 28695, 1311, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0958203494064207, "compression_ratio": 1.3197026022304832, "no_speech_prob": 0.1950276792049408}, {"id": 163, "seek": 94800, "start": 967.0, "end": 970.0, "text": " A teraz za pomoc\u0105 in-context learning.", "tokens": [51314, 316, 16854, 7949, 48962, 1611, 294, 12, 9000, 3828, 2539, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0958203494064207, "compression_ratio": 1.3197026022304832, "no_speech_prob": 0.1950276792049408}, {"id": 164, "seek": 97000, "start": 970.0, "end": 973.0, "text": " Maj\u0105c mu w pr\u0105cie zaledwie kilka przyk\u0142ad\u00f3w w j\u0119zyku naturalnym,", "tokens": [50364, 7048, 1611, 66, 2992, 261, 582, 1611, 4260, 710, 5573, 8699, 36466, 23144, 3901, 261, 49055, 5279, 3303, 12996, 11, 50514], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 165, "seek": 97000, "start": 973.0, "end": 978.0, "text": " uczymy go szuka\u0107 na tych zdj\u0119ciach zupe\u0142nie nowej, rzadkiej anomali.", "tokens": [50514, 344, 6522, 2226, 352, 7870, 13599, 2162, 1667, 15180, 49026, 537, 608, 49922, 586, 40779, 11, 367, 89, 345, 45145, 24769, 5103, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 166, "seek": 97000, "start": 978.0, "end": 982.0, "text": " Bez potrzeby ponownego, kosztownego treningu ca\u0142ego modelu.", "tokens": [50764, 879, 89, 28577, 2322, 9224, 648, 6308, 11, 19532, 2682, 648, 6308, 2192, 773, 84, 35224, 6308, 2316, 84, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 167, "seek": 97000, "start": 982.0, "end": 987.0, "text": " To jest po\u0142\u0105czenie specjalizacji i adaptacji, kt\u00f3re do tej pory by\u0142o niemo\u017cliwe.", "tokens": [50964, 1407, 3492, 714, 15926, 39043, 46433, 590, 13152, 741, 6231, 13152, 11, 8864, 360, 12573, 280, 827, 14811, 2838, 3280, 1427, 2081, 826, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 168, "seek": 97000, "start": 987.0, "end": 988.0, "text": " W\u0142a\u015bnie.", "tokens": [51214, 343, 5024, 12221, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 169, "seek": 97000, "start": 988.0, "end": 997.0, "text": " Czyli to jest \u015bcie\u017cka do budowy bardziej elastycznych, modu\u0142owych i, co za tym, idzie bardziej wydajnych system\u00f3w AI.", "tokens": [51264, 37099, 281, 3492, 8299, 40082, 2330, 360, 3265, 10089, 27209, 806, 9820, 3689, 9399, 11, 1072, 84, 1221, 19605, 741, 11, 598, 7949, 8107, 11, 4496, 3283, 27209, 25984, 1805, 9399, 1185, 3901, 7318, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06842961992536273, "compression_ratio": 1.4368600682593857, "no_speech_prob": 0.35485270619392395}, {"id": 170, "seek": 99700, "start": 998.0, "end": 1005.0, "text": " System\u00f3w, kt\u00f3re mog\u0105 postrzega\u0107 \u015bwiat za pomoc\u0105 wyspecjalizowanych modu\u0142\u00f3w percepcyjnych, naszych enkoder\u00f3w,", "tokens": [50414, 8910, 3901, 11, 8864, 34123, 2183, 19390, 6335, 2162, 36425, 7949, 48962, 1611, 27062, 494, 66, 22600, 590, 23341, 339, 1072, 84, 1221, 3901, 9016, 79, 42949, 9399, 11, 45002, 465, 74, 19866, 3901, 11, 50764], "temperature": 0.0, "avg_logprob": -0.07943721889525421, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.28174644708633423}, {"id": 171, "seek": 99700, "start": 1005.0, "end": 1011.0, "text": " a rozumowa\u0107, planowa\u0107 i wchodzi\u0107 w interakcj\u0119 za pomoc\u0105 centralnego, pot\u0119\u017cnego modu\u0142u j\u0119zykowego, czyli dekodera.", "tokens": [50764, 257, 48797, 11445, 11, 1393, 11445, 741, 261, 34616, 2162, 261, 728, 514, 41960, 7949, 48962, 1611, 5777, 11858, 11, 1847, 1274, 1427, 11858, 1072, 84, 24066, 49055, 74, 26576, 11, 16591, 368, 74, 378, 1663, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07943721889525421, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.28174644708633423}, {"id": 172, "seek": 99700, "start": 1011.0, "end": 1015.0, "text": " To architektura, kt\u00f3ra znacznie lepiej na\u015bladuje spos\u00f3b, w jaki my ludzie,", "tokens": [51064, 1407, 3912, 642, 2320, 2991, 11, 19456, 15397, 14875, 2766, 476, 39699, 1667, 1788, 9290, 13008, 22904, 11, 261, 24492, 452, 37025, 11, 51264], "temperature": 0.0, "avg_logprob": -0.07943721889525421, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.28174644708633423}, {"id": 173, "seek": 99700, "start": 1015.0, "end": 1020.0, "text": " integrujemy informacje z r\u00f3\u017cnych zmys\u0142\u00f3w i u\u017cywamy j\u0119zyka jako narz\u0119dzie do my\u015blenia.", "tokens": [51264, 3572, 21767, 1356, 29293, 710, 42602, 17020, 39508, 3901, 741, 34097, 86, 7804, 42309, 40940, 17123, 6714, 89, 42643, 360, 48633, 6698, 654, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07943721889525421, "compression_ratio": 1.4927536231884058, "no_speech_prob": 0.28174644708633423}, {"id": 174, "seek": 102000, "start": 1020.0, "end": 1028.0, "text": " Rozumowuj\u0105c, g\u0142\u00f3wna idea metalem to stworzenie modelu, kt\u00f3ry jest jak szwajcarski scyzoryk w \u015bwiecie AI,", "tokens": [50364, 43313, 449, 305, 44733, 11, 18117, 3901, 629, 1558, 1131, 304, 443, 281, 342, 28321, 16778, 2316, 84, 11, 9913, 3492, 4207, 7870, 86, 1805, 66, 685, 2984, 795, 37433, 827, 74, 261, 40078, 4260, 7318, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10885006611741434, "compression_ratio": 1.412, "no_speech_prob": 0.4199795722961426}, {"id": 175, "seek": 102000, "start": 1028.0, "end": 1032.0, "text": " ale taki, w kt\u00f3rym ka\u017cde narz\u0119dzie jest najwy\u017cszej klasy.", "tokens": [50764, 6775, 20065, 11, 261, 30120, 21912, 1479, 6714, 89, 42643, 3492, 11212, 9726, 1427, 82, 16920, 9671, 5871, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10885006611741434, "compression_ratio": 1.412, "no_speech_prob": 0.4199795722961426}, {"id": 176, "seek": 102000, "start": 1032.0, "end": 1034.0, "text": " Tak, to dobre por\u00f3wnianie.", "tokens": [50964, 9118, 11, 281, 41959, 1515, 812, 895, 952, 414, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10885006611741434, "compression_ratio": 1.412, "no_speech_prob": 0.4199795722961426}, {"id": 177, "seek": 102000, "start": 1034.0, "end": 1040.0, "text": " \u0141\u0105czy w sobie analityczn\u0105 g\u0142\u0119bie modeli dwukierunkowych z kreatywn\u0105 elastyczno\u015bci\u0105 modeli kausalnych.", "tokens": [51064, 36901, 1611, 6522, 261, 13652, 364, 1860, 3689, 13113, 18117, 1274, 7392, 2316, 72, 27379, 2034, 811, 3197, 19605, 710, 350, 620, 88, 895, 1611, 806, 9820, 3689, 16438, 1611, 2316, 72, 6799, 11765, 9399, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10885006611741434, "compression_ratio": 1.412, "no_speech_prob": 0.4199795722961426}, {"id": 178, "seek": 102000, "start": 1040.0, "end": 1044.0, "text": " Jest jednocze\u015bnie analitykiem i kreatorem.", "tokens": [51364, 24918, 5232, 26694, 1381, 12221, 364, 1860, 26116, 741, 350, 620, 37956, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10885006611741434, "compression_ratio": 1.412, "no_speech_prob": 0.4199795722961426}, {"id": 179, "seek": 104400, "start": 1044.0, "end": 1050.0, "text": " Idealne podsumowanie. To jest pr\u00f3ba stworzenia modelu, kt\u00f3ry nie jest tylko do\u015b\u0107 dobry we wszystkim,", "tokens": [50364, 13090, 304, 716, 31925, 449, 22028, 13, 1407, 3492, 8565, 4231, 342, 28321, 14320, 2316, 84, 11, 9913, 2838, 3492, 13219, 49333, 35884, 321, 30481, 11, 50664], "temperature": 0.0, "avg_logprob": -0.057985160187000534, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.49460241198539734}, {"id": 180, "seek": 104400, "start": 1050.0, "end": 1055.0, "text": " ale jest naprawd\u0119 wybitny w wielu kluczowych zdolno\u015bciach jednocze\u015bnie,", "tokens": [50664, 6775, 3492, 20970, 4628, 5260, 1634, 261, 40437, 9671, 1311, 89, 19605, 16221, 401, 16438, 608, 5232, 26694, 1381, 12221, 11, 50914], "temperature": 0.0, "avg_logprob": -0.057985160187000534, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.49460241198539734}, {"id": 181, "seek": 104400, "start": 1055.0, "end": 1059.0, "text": " dzi\u0119ki inteligentnej wsp\u00f3\u0142pracy wyspecjalizowanych komponent\u00f3w.", "tokens": [50914, 45003, 24777, 25002, 11794, 39069, 1424, 2551, 27062, 494, 66, 22600, 590, 23341, 339, 5207, 79, 30365, 3901, 13, 51114], "temperature": 0.0, "avg_logprob": -0.057985160187000534, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.49460241198539734}, {"id": 182, "seek": 104400, "start": 1059.0, "end": 1063.0, "text": " Na koniec zostawmy mo\u017ce naszych s\u0142uchaczy z prowokuj\u0105c\u0105 mysi\u0105.", "tokens": [51114, 6056, 5897, 35733, 31873, 1607, 2226, 12034, 45002, 15116, 625, 14691, 710, 45553, 453, 13263, 32557, 452, 82, 11404, 13, 51314], "temperature": 0.0, "avg_logprob": -0.057985160187000534, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.49460241198539734}, {"id": 183, "seek": 104400, "start": 1063.0, "end": 1071.0, "text": " Autorzy pracy pisz\u0105 wprost, \u017ce planuj\u0105 skalowa\u0107 ten model i dodawa\u0107 kolejne modalno\u015bci, takie jak d\u017awi\u0119k.", "tokens": [51314, 6049, 284, 1229, 35591, 26584, 8925, 261, 1424, 555, 11, 3561, 1393, 13263, 16890, 11445, 2064, 2316, 741, 13886, 10449, 2162, 23749, 716, 39745, 16438, 11, 15963, 4207, 274, 10659, 22423, 74, 13, 51714], "temperature": 0.0, "avg_logprob": -0.057985160187000534, "compression_ratio": 1.4252491694352158, "no_speech_prob": 0.49460241198539734}, {"id": 184, "seek": 107100, "start": 1071.0, "end": 1080.0, "text": " Je\u015bli jeden model j\u0119zykowy mo\u017ce sta\u0107 si\u0119 uniwersalnym interfejsem dla ca\u0142ego zestawu wyspecjalizowanych modu\u0142\u00f3w AI,", "tokens": [50364, 37086, 12906, 2316, 49055, 74, 10089, 12034, 11135, 2162, 3244, 36435, 5364, 304, 12996, 728, 2106, 73, 19872, 12285, 35224, 6308, 37889, 1607, 84, 27062, 494, 66, 22600, 590, 23341, 339, 1072, 84, 1221, 3901, 7318, 11, 50814], "temperature": 0.0, "avg_logprob": -0.05492653977980307, "compression_ratio": 1.3696498054474708, "no_speech_prob": 0.06452830880880356}, {"id": 185, "seek": 107100, "start": 1080.0, "end": 1086.0, "text": " to czy my w\u0142a\u015bnie jeste\u015bmy \u015bwiadkami narodze\u0144 zupe\u0142nie nowego rodzaju systemu operacyjnego?", "tokens": [50814, 281, 6430, 452, 14234, 35928, 21485, 345, 48737, 6714, 378, 49689, 49922, 586, 6308, 28607, 33166, 1185, 84, 2208, 31285, 11858, 30, 51114], "temperature": 0.0, "avg_logprob": -0.05492653977980307, "compression_ratio": 1.3696498054474708, "no_speech_prob": 0.06452830880880356}, {"id": 186, "seek": 107100, "start": 1086.0, "end": 1088.0, "text": " To jest bardzo trafne pytanie.", "tokens": [51114, 1407, 3492, 9034, 944, 69, 716, 36610, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05492653977980307, "compression_ratio": 1.3696498054474708, "no_speech_prob": 0.06452830880880356}, {"id": 187, "seek": 107100, "start": 1088.0, "end": 1095.0, "text": " Systemu, kt\u00f3rym nie steruje si\u0119 za pomoc\u0105 klikni\u0119\u0107, menu i linijek kodu, ale poprzez rozmow\u0119.", "tokens": [51214, 8910, 84, 11, 30120, 2838, 18924, 13008, 3244, 7949, 48962, 1611, 9671, 1035, 35938, 2162, 11, 6510, 741, 22896, 1718, 916, 350, 34873, 11, 6775, 1665, 13503, 89, 35234, 305, 1274, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05492653977980307, "compression_ratio": 1.3696498054474708, "no_speech_prob": 0.06452830880880356}, {"id": 188, "seek": 109500, "start": 1095.0, "end": 1104.0, "text": " Co si\u0119 stanie, gdy b\u0119dziemy mogli po prostu rozmawia\u0107 z systemem, kt\u00f3ry widzi, s\u0142yszy, czyta i ma dost\u0119p do ogromnej wyspecjalizowanej wiedzy?", "tokens": [50364, 3066, 3244, 40013, 11, 28405, 31966, 13172, 2081, 714, 19518, 35234, 34953, 2162, 710, 1185, 443, 11, 9913, 5274, 3992, 11, 15116, 749, 1229, 11, 6430, 1328, 741, 463, 48209, 360, 34416, 298, 11794, 27062, 494, 66, 22600, 590, 23066, 73, 46894, 1229, 30, 50814], "temperature": 0.0, "avg_logprob": -0.05534254206289159, "compression_ratio": 1.354978354978355, "no_speech_prob": 0.1609119027853012}, {"id": 189, "seek": 109500, "start": 1104.0, "end": 1108.0, "text": " A wszystko to za po\u015brednictwem jednego, sp\u00f3jnego, j\u0119zykowego interfejsu?", "tokens": [50814, 316, 22607, 281, 7949, 714, 1788, 986, 77, 985, 86, 443, 5232, 11858, 11, 637, 18999, 11858, 11, 49055, 74, 26576, 728, 2106, 73, 15091, 30, 51014], "temperature": 0.0, "avg_logprob": -0.05534254206289159, "compression_ratio": 1.354978354978355, "no_speech_prob": 0.1609119027853012}, {"id": 190, "seek": 109500, "start": 1108.0, "end": 1114.0, "text": " Czy to nie jest ostateczna definicja tego, co autorzy nazwali General Purpose Interface?", "tokens": [51014, 19832, 281, 2838, 3492, 277, 15406, 3689, 629, 1561, 299, 2938, 8627, 11, 598, 19510, 1229, 20151, 40054, 6996, 14682, 43501, 5751, 2868, 30, 51314], "temperature": 0.0, "avg_logprob": -0.05534254206289159, "compression_ratio": 1.354978354978355, "no_speech_prob": 0.1609119027853012}], "language": "pl"}