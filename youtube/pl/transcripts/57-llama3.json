{"text": " Witajcie w naszej analizie materia\u0142\u00f3w \u017ar\u00f3d\u0142owych. Dzisiaj bierzemy na tapet co\u015b naprawd\u0119 du\u017cego. W \u015bwiecie sztucznej inteligencji wszystko opiera si\u0119 na tak zwanych foundation models. To prawda, to te gigantyczne silniki, kt\u00f3re nap\u0119dzaj\u0105 praktycznie wszystko, co znamy, od czat bot\u00f3w po zaawansowane narz\u0119dzie analityczne. Pijmy, chcemy dzisiaj zajrze\u0107 pod mask\u0119 najnowszego i chyba najwa\u017cniejszego gracza na tej scenie modelu Lama 3 od Meta. Mamy przed sob\u0105 prac\u0119 badawcz\u0105, kt\u00f3ra opisuje ca\u0142\u0105 now\u0105 rodzin\u0119 tych modeli i od razu trzeba powiedzie\u0107, to nie jest po prostu jaka\u015b tam, wiesz, kolejna aktualizacja. Zdecydowanie nie. M\u00f3wimy o skali, kt\u00f3ra jeszcze powiedzmy dwa lata temu wydawa\u0142a si\u0119 czyst\u0105 fantastyk\u0105. Podajmy te liczby, bo one same w sobie robi\u0105 ogromne wra\u017cenie. Flagowy model ma 405 miliard\u00f3w parametr\u00f3w i by\u0142 trenowany na zbiorze danych, kt\u00f3ry zawiera\u0142 15 bilion\u00f3w, czyli 15,3 lion token\u00f3w. Niesamowite. A nasza misja jest prosta, prawda? Chcemy zrozumie\u0107, co tak naprawd\u0119 stanowi o sile Lama 3. Dok\u0142adnie. Nie interesuj\u0105 nas tylko suche liczby. Chcemy odkry\u0107, co kryje si\u0119 za kulisami. Jakie innowacje, jakie decyzje in\u017cynieryjne sprawi\u0142y, \u017ce ten model jest w stanie konkurowa\u0107, a czasem nawet wyprzedza\u0107 takich gigant\u00f3w jak GPT-4. To b\u0119dzie taka nasza pr\u00f3ba zrozumienia jak i dlaczego za tym wszystkim stoi. Dobrze, to zacznijmy od samego pocz\u0105tku. Meta nie stworzy\u0142a jednego monolitu, ale ca\u0142\u0105 rodzin\u0119 modeli. Nazwa\u0142y to the Lama 3 Heard of Models. A ten najwi\u0119kszy 405B to tak zwany G\u0119sty Transformer. Co to w og\u00f3le znaczy, \u017ce jest G\u0119sty? To wa\u017cna uwaga. G\u0119sty, czyli dense, oznacza w uproszczeniu, \u017ce to jest taka klasyczna, sprawdzona architektura, czyli nic nowego. W\u0142a\u015bnie. To nie jest \u017cadna eksperymentalna konstrukcja typu Mixture of Experts, kt\u00f3r\u0105 stosuj\u0105 niekt\u00f3rzy konkurenci. Meta postawi\u0142a na co\u015b, co dobrze zna, ale postanowi\u0142a doprowadzi\u0107 to do no niemal perfekcji. OK. Ten moder ma te\u017c okno kontekstowe do 128 tysi\u0105ce token\u00f3w i od podstaw by\u0142 projektowany pod kodowanie, rozumowanie i wieloj\u0119zyczno\u015b\u0107. Ale skoro nie ma rewolucji w architekturze, to gdzie le\u017cy sekret? Ja stawiam na dane. W AI prawie zawsze ostatecznie chodzi o dane. I to jest strzel w dziesi\u0105tk\u0119. Meta sama w tej pracy zdradza, \u017ce ich przepis na sukces opiera si\u0119 na trzech filarach, a dane s\u0105 tym pierwszym i absolutnie najwa\u017cniejszym. Jaki to by\u0142 skok? Ogromny z jeden osiem biliona token\u00f3w w Lamma 2 do pi\u0119tnastu bilion\u00f3w tutaj. Ale i to jest kluczowe. Nie chodzi\u0142o tylko o zalanie modelu wi\u0119ksz\u0105 ilo\u015bci\u0105 informacji. Chodzi\u0142o o tak\u0105 no niemal obsesyjn\u0105 dba\u0142o\u015b\u0107 o jako\u015b\u0107. OK, to dane. Jaki jest drugi filar? Czysta, brutalna skala. Moc obliczeniowa u\u017cyta do treningu wzros\u0142a niemal pi\u0119\u0107dziesi\u0119ciokrotnie w por\u00f3wnaniu do najwi\u0119kszej Lamma 2. Pi\u0119\u0107dziesi\u0119ciokrotnie tak. To pokazuje, \u017ce w tej grze, mimo ca\u0142ej finezji algorytm\u00f3w, posiadanie gigantycznych zasob\u00f3w obliczeniowych wci\u0105\u017c jest no decyduj\u0105ce. A trzeci sk\u0142adnik? Co\u015b, co nazywaj\u0105 zarz\u0105dzaniem z\u0142o\u017cono\u015bci\u0105. I to jest fascynuj\u0105ce, bo rzadko si\u0119 o tym m\u00f3wi. Zbudowanie i wytrenowanie takiego potwora to jest niewyobra\u017calne wyzwanie in\u017cynieryjne. Logistyczne, organizacyjne. Dok\u0142adnie. Porozmawiamy o tym za chwil\u0119, bo tam kryj\u0105 si\u0119 niesamowite historie. Czyli je\u015bli dobrze rozumiem, g\u0142\u00f3wna teza autor\u00f3w jest taka. Nie potrzebowali\u015bmy rewolucji w budowie silnika. W\u0142a\u015bnie. Bo okaza\u0142o si\u0119, \u017ce stary, sprawdzony silnik, ale zalany paliwem o niespotykanej jako\u015bci i w ogromnej ilo\u015bci nagle zacz\u0105\u0142 bi\u0107 rekordy pr\u0119dko\u015bci. Dok\u0142adnie tak. Ca\u0142a ta praca to w zasadzie dow\u00f3d na to, \u017ce ewolucja i dopracowanie istniej\u0105cych metod mo\u017ce przynie\u015b\u0107 lepsze efekty ni\u017c pogo\u0144 za nowinkami. To wa\u017cna lekcja. To zanurzmy si\u0119 w szczeg\u00f3\u0142y. Zaczyna si\u0119 od pre-training, czyli budowy tego surowego intelektu. Jak wygl\u0105da\u0142a ta obsesyjna dba\u0142o\u015b\u0107 o jako\u015b\u0107 danych? To by\u0142 wieloetapowy, niezwykle rygorystyczny proces. Zacz\u0119li od filtrowania. Czyli co, usuwali \u015bmieci? Tak, ale na masow\u0105 skal\u0119. Usun\u0119li ca\u0142e domeny znane z tego, \u017ce zawieraj\u0105 du\u017co danych osobowych, czyli PII, albo po prostu tre\u015bci niebezpieczne. Potem stworzyli w\u0142asny parser HTML, \u017ceby wyci\u0105ga\u0107 z internetu tekst w najczystszej postaci. A co z powt\u00f3rzyniami? Internet jest ich pe\u0142en. W\u0142a\u015bnie, to kolejny krok. Zastosowali bardzo agresywn\u0105 deduplikacj\u0119 na wielu poziomach. Na poziomie URL, potem ca\u0142ych dokument\u00f3w przy u\u017cyciu algorytmu minHash, a na ko\u0144cu zeszli nawet do poziomu pojedynczych linii jak tekstu. Chcieli, \u017ceby ka\u017cda informacja by\u0142a jak najbardziej unikalna. Dok\u0142adnie. Czekaj, w materiamach jest fragment, kt\u00f3ry mnie naprawd\u0119 zaintergowa\u0142. U\u017cyli poprzednich modeli Lama 2 jako s\u0119dzi\u00f3w jako\u015bci. To brzmi prawie jak paradoks. Prawda. I to jest genialne w swojej prostocie. Model sam pomaga utworzy\u0107 swojego nast\u0119pc\u0119. Tak, nauczyli modele Lama 2 rozpoznawa\u0107 tekst wysokiej jako\u015bci i u\u017cyli ich do automatycznej klasyfikacji gigantycznych zbior\u00f3w danych. Mo\u017cna powiedzie\u0107, \u017ce Lama 2 pe\u0142ni\u0142a rol\u0119 takiego kuratora, kt\u00f3ry przygotowywa\u0142 bibliotek\u0119 dla swojego m\u0105drzejszego potomka. To troch\u0119 jak praca dietetyka dla AI. Wspomniano te\u017c o tak zwanym data mix. Tak, to starannie skomponowana dieta dla modelu. I to kolejny kluczowy element. Czyli to nie by\u0142a przypadkowa mieszanka? Absolutnie nie. Oko\u0142o 50% to wiedza og\u00f3lna. 25% matematyka i rozumowanie. 17% kot, a 8% dane wieloj\u0119zyczne. I te proporcje nie zosta\u0142y wzi\u0119te z sufitu. Tylko sk\u0105d? Wyliczono je na podstawie eksperyment\u00f3w z tak zwanymi scaling laws. To s\u0105 prawa, kt\u00f3re pozwolaj\u0105 z du\u017c\u0105 dok\u0142adno\u015bci\u0105 przewidzie\u0107 jak zmiana diety wp\u0142ynie na zdolno\u015bci ko\u0144cowego modelu. Jeszcze zanim wydadz\u0105 miliony dolar\u00f3w na trening. Dok\u0142adnie. To sugeruje, \u017ce przysz\u0142o\u015b\u0107 to nie tyle nowe algorytmy, co perfekcyjne komponowanie diety treningowej pod konkretne cele. Zdecydowanie in\u017cynieria danych staje si\u0119 chyba wa\u017cniejsza ni\u017c in\u017cynieria samych modeli. A architektura m\u00f3wili\u015bmy, \u017ce to standard, ale by\u0142 jaki\u015b ulepszenia. Tak, kilka cichych, ale wa\u017cnych. Na przyk\u0142ad Grouped Query Attention, czyli GQA, co w praktyce po prostu znacz\u0105co przyspiesza generowanie odpowiedzi. W pracy wspomniano te\u017c o specjalnej masce uwagi. Co to takiego? Wyobra\u017a sobie, \u017ce w jednym d\u0142ugim zapytaniu podajesz modelowi kilka r\u00f3\u017cnych dokument\u00f3w. Ta maska dzia\u0142a jak separator, kt\u00f3ry zapobiega mieszaniu si\u0119 informacji mi\u0119dzy nimi. Proste, ale kluczowe dla sp\u00f3jno\u015bci w d\u0142ugim kontek\u015bcie. No w\u0142a\u015bnie. Ale przejd\u017amy do skali. Moc obliczeniowa wi\u0119ksza pi\u0119\u0107dziesi\u0105t razy. To brzmi jak logistyczny koszmar. Czy wszystko sz\u0142o g\u0142adko? Absolutnie nie sz\u0142o g\u0142adko. I to jest jedna z najciekawszych i najbardziej szczerych cz\u0119\u015bci tej pracy. Opowiedz. Model trenowano na klastrach maj\u0105cych do 16 tysi\u0119cy najnowszych procesor\u00f3w graficznych HASTO. I autorzy przyznaj\u0105, \u017ce w ci\u0105gu pi\u0119\u0107dziesi\u0119ciu czterech dni treningu zanotowali a\u017c 419 nieoczekiwanych przerw. 419 to brzmi jak katastrofa. Wi\u0119kszo\u015b\u0107 to by\u0142y prozeiczne awarje sprz\u0119tu. A jednak mimo tych wszystkich problem\u00f3w efektywny czas treningu, czyli czas, kiedy model faktycznie si\u0119 uczy\u0142, wynios\u0142 ponad 90 procent. To \u015bwiadczy o niesamowitej in\u017cynierii i automatyzacji. Zdecydowanie. W tym rozdziale znalaz\u0142em m\u00f3j ulubiony, kompletnie zaskakuj\u0105cy fakt. Dobowy wahanie wydajno\u015bci. Tak, to jest pere\u0142ka. Spowodowany temperatur\u0105. Tak zaobserwowali, \u017ce wydajno\u015b\u0107 ca\u0142ego klastra waha\u0142a si\u0119 o 1-2 procent w cyklu dobowym. Okaza\u0142o si\u0119, \u017ce by\u0142o to spowodowane zmianami temperatury otoczenia w serwerowni. Czyli wy\u017csza temperatura spowalnia\u0142a procesory? Dok\u0142adnie wp\u0142ywa\u0142a na ich taktowanie. To pokazuje, jak ekstremalnie wra\u017cliwe s\u0105 te systemy. M\u00f3wimy o wp\u0142ywie pogody za oknem na trening AI. Niewiarygodne. Dobrze. Mamy wi\u0119c ten surowy, pot\u0119\u017cny m\u00f3zg. Ale on jeszcze nie jest asystentem, prawda? Dok\u0142adnie. Nie potrafi prowadzi\u0107 rozmowy. Tutaj wkracza post-training. Czyli cywilizowanie modelu. Mo\u017cna tak powiedzie\u0107. G\u0142\u00f3wne techniki to supervised fine tuning, czyli SFT i nowsza, bardziej efektywna metoda Direct Preference Optimization, czyli DPO. W pracy pojawia si\u0119 termin rejection sampling. Brzmi technicznie. Ale idea jest prosta i bardzo skuteczna. To troch\u0119 jak casting do filmu. O, ciekawe por\u00f3wnanie. Model na dane polecenie generuje powiedzmy 10 r\u00f3\u017cnych odpowiedzi. 10 aktor\u00f3w. Nast\u0119pnie inny, mniejszy model, tak zwany Reward Modder, pe\u0142ni rol\u0119 re\u017cysera. I wybiera najlepszego. Ocenia wszystkie 10 i wybiera t\u0119 jedn\u0105, kt\u00f3ra zagra\u0142a najlepiej. I tylko ta najlepsza odpowied\u017a jest u\u017cywana do dalszego treningu. To taki wewn\u0119trzny mechanizm kontroli jako\u015bci. A jak wygl\u0105da\u0142o uczenie tych konkretnych zdolno\u015bci? Jak uczy si\u0119 modela my\u015blenia? To by\u0142 bardzo ukierunkowany proces. Na przyk\u0142ad w przypadku kodowania generowano dane syntetyczne z tak zwanym execution feedback. Czyli model pisa\u0142 kod, system pr\u00f3bowa\u0142 go uruchomi\u0107, a potem model dostawa\u0142 informacj\u0119 zwrotn\u0105, czy kod zadzia\u0142a\u0142, a je\u015bli nie, to jaki by\u0142 b\u0142\u0105d? Uczy\u0142 si\u0119 na w\u0142asnych, praktycznych b\u0142\u0119dach. Genialne. A matematyka? Tutaj kluczowe by\u0142o generowanie rozwi\u0105za\u0144 krok po kroku, a nast\u0119pnie u\u017cywanie mechanizm\u00f3w samo weryfikacji. Model sam sprawdza\u0142, czy jego \u015bcie\u017cka rozumowania ma sens. Uczono go nie tylko odpowiedzi, ale i poprawnego procesu my\u015blowego. A co z tym gigantycznym, 128 tys. oknem kontekstowym? M\u00f3wi\u0142e\u015b, \u017ce to by\u0142o wyzwanie, \u017ceby nie zepsu\u0107 wydajno\u015bci na kr\u00f3tkich zadaniach. I rozwi\u0105zanie tego problemu jest kolejnym zaskoczeniem. S\u0142ucham. Okaza\u0142o si\u0119, \u017ce wystarczy\u0142o doda\u0107 do danych treningowych. Na etapie post-training zaledwie 0,1% syntetycznych przyk\u0142ad\u00f3w z d\u0142ugim kontekstem. Ciekaj, tylko 0,1%? Tak. Taka mikroskopijna zmiana wystarczy\u0142a, by nauczy\u0107 go z zupe\u0142nie nowej, kluczowej umiej\u0119tno\u015bci, nie psuj\u0105c niczego innego. Absolutnie. To pokazuje, jak precyzyjna i wra\u017cliwa jest ta faza dostrajania. Czasem minimalna, ale dobrze ukierunkowana interwencja mo\u017ce przynie\u015b\u0107 ogromne rezultaty. Niesamowite, jaka in\u017cenieria za tym stoi. No dobrze, mamy wi\u0119c ten model. Jest pot\u0119\u017cny, dopracowany, ale jak Lama 3 wypada w starciu z GPT-4 czy Cloud? W\u0142a\u015bnie. Przejd\u017amy do wynik\u00f3w. I tutaj historia ma jakby dwa oblicza. To znaczy? Je\u015bli spojrzymy na standardowe akademickie benchmarki, Lama 3405B jest potwornie mocna. W niekt\u00f3rych jest nawet liderem. Na przyk\u0142ad w te\u015bcie rozumowania matematycznego GSM 8K czy w testach kodowania jak HumanEval Plus, gdzie przewy\u017csza GPT-4. Czyli w specjalistycznych dziedzinach jest w czo\u0142\u00f3wce? W absolutnej, \u015bwiatowej czo\u0142\u00f3wce, ale wspomnia\u0142e\u015b o drugim obliczu. Tak. Ewaluacje przeprowadzane przez ludzi, gdzie ocenia si\u0119 og\u00f3ln\u0105 pomocno\u015b\u0107 odpowiedzi, pokazuj\u0105 bardziej zniuansowany obraz. Tutaj Lama 3405B jest na r\u00f3wni z GPT-4, ale ma mieszane wyniki w por\u00f3wnaniu z najnowszymi modelami jak GPT-4O czy Cloth 3.5 Sonet. Czyli era jednego uniwersalnie najlepszego modelu do wszystkiego mog\u0142a si\u0119 sko\u0144czy\u0107 zanim na dobre si\u0119 zacz\u0119\u0142a? Dok\u0142adnie. Taka jest konkluzja. Wyb\u00f3r modelu coraz bardziej zale\u017cy od konkretnego zastosowania. Nie ma ju\u017c jednego kr\u00f3la. A co z multimodalno\u015bci\u0105? \u015awiat to nie tylko tekst. Tutaj meta podesz\u0142a do tego bardzo sprytnie stosuj\u0105c tak zwane podej\u015bcie kompozycyjne compositional approach. Jak to dzia\u0142a? Zamlast trenowa\u0107 od zera jeden gigantyczny potwornie drogi model, kt\u00f3ry rozumie wszystko, zrobili co\u015b innego. Wzi\u0119li swoj\u0105 wytrenowan\u0105 tekstow\u0105 Lama 3 i do\u0142\u0105czyli do niej modu\u0142y do obrazu i mowy. Dok\u0142adnie. Za pomoc\u0105 specjalnych, lekkich adapter\u00f3w do\u0142\u0105czyli do niej inne ju\u017c wcze\u015bniej wytrenowane modu\u0142y. Czyli zamiast budowa\u0107 nowy, uniwersalny samoch\u00f3d po prostu doczepili za awansowan\u0105 przyczep\u0119 do swojej sprawdzonej ci\u0119\u017car\u00f3wki. To idealna analogia. To rozwi\u0105zanie jest o wiele bardziej efektywne i chroni wydajno\u015b\u0107 tekstow\u0105 oryginalnego modelu. A wyliki s\u0105 bardzo obiecuj\u0105ce. Ich model Lama 3V przewy\u017csza GPT-4V we wszystkich testowanych benchmarkach wizualnych. Pozostaje jeszcze kwestia bezpiecze\u0144stwa. To gor\u0105cy temat. Tutaj te\u017c wida\u0107 kompleksowe podej\u015bcie. Zacz\u0119li odfiltrowania danych ju\u017c na etapie pre-training. Potem w fazie dostrajania zastosowali specjalny safety fine tuning. Jaki by\u0142 cel? Znalezienie z\u0142otego \u015brodka. Model ma blokowa\u0107 szkodliwe tre\u015bci, ale z drugiej strony unika\u0107 absurdalnych, frustruj\u0105cych odm\u00f3w na zupe\u0142nie niebezpieczne pytania. I do tego dochodzi jeszcze osobne narz\u0119dzie, prawda? Tak, udost\u0119pnili Lama Guard 3. To osobny, znacznie mniejszy model klasyfikator. Mo\u017ce dzia\u0142a\u0107 jako dodatkowa, zewn\u0119trzna warstwa ochronna, taki stra\u017cnik. Podsumowuj\u0105c historia Lama 3 to opowie\u015b\u0107 o pot\u0119dze skali, ale te\u017c o niemal rzemie\u015blniczym obsesyjnym skupieniu na jako\u015bci danych. Zdecydowanie sukces tego modelu nie wzi\u0105\u0142 si\u0119 z rewolucji, ale z dopracowania do perfekcji istniej\u0105cych metod i no tytanicznego wysi\u0142ku in\u017cynieryjnego. Sami autorzy sugeruj\u0105, \u017ce to dopiero pocz\u0105tek drogi. Tak, pisz\u0105, \u017ce znacz\u0105ce dalsze ulepszenia s\u0105 na horyzumcie i podkre\u015blaj\u0105, \u017ce najlepsze rezultaty osi\u0105gn\u0119li trzymaj\u0105c si\u0119 prostoty. I to prowadzi mnie do my\u015bli na koniec. W raporcie pada jedno pozornie techniczne zdanie, kt\u00f3re mo\u017ce by\u0107 najwa\u017cniejsze w ca\u0142ym dokumencie. Kt\u00f3re? M\u00f3wi o tym, \u017ce kluczowe dla sukcesu projektu by\u0142y decyzje organizacyjne. Np. \u015bwiadome i rygorystyczne oddzielenie zespo\u0142u pozyskuj\u0105cego dane od zespo\u0142u buduj\u0105cego model. Aha, \u017ceby unikn\u0105\u0107 zanieczyszczenia danych treningowych benchmarkami. Dok\u0142adnie. I to prowadzi do fascynuj\u0105cego pytania, kt\u00f3re wykracza daleko poza technologi\u0119. Czy w miar\u0119, jak modele staj\u0105 si\u0119 pot\u0119\u017cniejsze, nast\u0119pn\u0105 granic\u0105 rozwoju AI nie s\u0105 ju\u017c tylko algorytmy? Ale w\u0142a\u015bnie ludzkie i organizacyjne struktury, kt\u00f3re wok\u00f3\u0142 nich budujemy. W\u0142a\u015bnie. Jak zaprojektowa\u0107 firm\u0119, procesy, zespo\u0142y, by by\u0142y w stanie zbudowa\u0107 obiektywn\u0105, godn\u0105 zaufania i naprawd\u0119 inteligentn\u0105 maszyn\u0119? By\u0107 mo\u017ce to jest prawdziwe wyzwanie na nast\u0119pn\u0105 dekad\u0119.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.3200000000000003, "text": " Witajcie w naszej analizie materia\u0142\u00f3w \u017ar\u00f3d\u0142owych.", "tokens": [50364, 42299, 47276, 261, 42946, 2624, 590, 414, 2389, 8908, 3901, 50212, 43678, 1221, 19605, 13, 50530], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 1, "seek": 0, "start": 3.52, "end": 7.36, "text": " Dzisiaj bierzemy na tapet co\u015b naprawd\u0119 du\u017cego.", "tokens": [50540, 39448, 22356, 272, 34602, 3633, 1667, 5119, 302, 19241, 20970, 21783, 6308, 13, 50732], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 2, "seek": 0, "start": 7.5600000000000005, "end": 13.040000000000001, "text": " W \u015bwiecie sztucznej inteligencji wszystko opiera si\u0119 na tak zwanych foundation models.", "tokens": [50742, 343, 40078, 4260, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 22607, 999, 10609, 3244, 1667, 991, 11873, 34644, 7030, 5245, 13, 51016], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 3, "seek": 0, "start": 13.24, "end": 17.16, "text": " To prawda, to te gigantyczne silniki, kt\u00f3re nap\u0119dzaj\u0105 praktycznie", "tokens": [51026, 1407, 43607, 11, 281, 535, 8741, 394, 17466, 716, 3425, 77, 9850, 11, 8864, 9296, 6298, 89, 11133, 3206, 74, 45586, 51222], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 4, "seek": 0, "start": 17.36, "end": 22.0, "text": " wszystko, co znamy, od czat bot\u00f3w po zaawansowane narz\u0119dzie analityczne.", "tokens": [51232, 22607, 11, 598, 710, 5378, 88, 11, 3611, 6472, 267, 10592, 3901, 714, 7949, 1607, 599, 23066, 6714, 89, 42643, 364, 1860, 38491, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 5, "seek": 0, "start": 22.2, "end": 26.6, "text": " Pijmy, chcemy dzisiaj zajrze\u0107 pod mask\u0119 najnowszego i chyba najwa\u017cniejszego", "tokens": [51474, 430, 1718, 2226, 11, 28928, 2226, 25772, 33729, 13503, 2162, 2497, 6094, 1274, 11212, 77, 1509, 27725, 741, 31532, 11212, 27111, 10402, 15453, 6308, 51694], "temperature": 0.0, "avg_logprob": -0.17921439149325952, "compression_ratio": 1.4494773519163764, "no_speech_prob": 0.001491839881055057}, {"id": 6, "seek": 2660, "start": 26.6, "end": 30.560000000000002, "text": " gracza na tej scenie modelu Lama 3 od Meta.", "tokens": [50364, 11625, 2394, 1667, 12573, 4191, 414, 2316, 84, 441, 2404, 805, 3611, 6377, 64, 13, 50562], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 7, "seek": 2660, "start": 30.76, "end": 35.160000000000004, "text": " Mamy przed sob\u0105 prac\u0119 badawcz\u0105, kt\u00f3ra opisuje ca\u0142\u0105 now\u0105 rodzin\u0119 tych modeli", "tokens": [50572, 376, 7804, 18334, 18253, 1611, 22404, 1274, 272, 1538, 86, 3689, 1611, 11, 19456, 45477, 13008, 1335, 15926, 586, 1611, 8685, 23584, 1274, 15180, 2316, 72, 50792], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 8, "seek": 2660, "start": 35.36, "end": 40.04, "text": " i od razu trzeba powiedzie\u0107, to nie jest po prostu jaka\u015b tam, wiesz, kolejna aktualizacja.", "tokens": [50802, 741, 3611, 367, 8813, 25860, 27886, 11, 281, 2838, 3492, 714, 19518, 4207, 64, 1788, 7677, 11, 261, 15347, 11, 23749, 629, 13680, 901, 590, 23395, 13, 51036], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 9, "seek": 2660, "start": 40.24, "end": 41.24, "text": " Zdecydowanie nie.", "tokens": [51046, 1176, 1479, 1344, 67, 22028, 2838, 13, 51096], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 10, "seek": 2660, "start": 41.44, "end": 46.480000000000004, "text": " M\u00f3wimy o skali, kt\u00f3ra jeszcze powiedzmy dwa lata temu wydawa\u0142a si\u0119 czyst\u0105 fantastyk\u0105.", "tokens": [51106, 376, 3901, 13189, 277, 1110, 5103, 11, 19456, 14168, 27617, 2226, 35045, 46722, 33346, 25984, 10449, 5024, 3244, 6430, 372, 1611, 4115, 9820, 26304, 13, 51358], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 11, "seek": 2660, "start": 46.68000000000001, "end": 50.84, "text": " Podajmy te liczby, bo one same w sobie robi\u0105 ogromne wra\u017cenie.", "tokens": [51368, 12646, 1805, 2226, 535, 6169, 89, 2322, 11, 748, 472, 912, 261, 13652, 3870, 11404, 34416, 298, 716, 7843, 41118, 13, 51576], "temperature": 0.0, "avg_logprob": -0.13106131377043548, "compression_ratio": 1.431159420289855, "no_speech_prob": 0.3315993547439575}, {"id": 12, "seek": 5084, "start": 51.040000000000006, "end": 56.800000000000004, "text": " Flagowy model ma 405 miliard\u00f3w parametr\u00f3w i by\u0142 trenowany na zbiorze danych,", "tokens": [50374, 37461, 10089, 2316, 463, 3356, 20, 1962, 72, 515, 3901, 6220, 27965, 3901, 741, 16673, 23136, 23341, 1667, 710, 33362, 1381, 274, 34644, 11, 50662], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 13, "seek": 5084, "start": 57.0, "end": 63.52, "text": " kt\u00f3ry zawiera\u0142 15 bilion\u00f3w, czyli 15,3 lion token\u00f3w.", "tokens": [50672, 9913, 28165, 10609, 1221, 2119, 8588, 313, 3901, 11, 16591, 2119, 11, 18, 287, 313, 14862, 3901, 13, 50998], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 14, "seek": 5084, "start": 63.720000000000006, "end": 65.04, "text": " Niesamowite.", "tokens": [51008, 426, 530, 335, 305, 642, 13, 51074], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 15, "seek": 5084, "start": 65.24000000000001, "end": 67.72, "text": " A nasza misja jest prosta, prawda?", "tokens": [51084, 316, 5382, 2394, 3346, 2938, 3492, 582, 8638, 11, 43607, 30, 51208], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 16, "seek": 5084, "start": 67.92, "end": 72.0, "text": " Chcemy zrozumie\u0107, co tak naprawd\u0119 stanowi o sile Lama 3.", "tokens": [51218, 761, 384, 2226, 710, 27857, 449, 414, 2162, 11, 598, 991, 20970, 27984, 24503, 277, 262, 794, 441, 2404, 805, 13, 51422], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 17, "seek": 5084, "start": 72.2, "end": 73.12, "text": " Dok\u0142adnie.", "tokens": [51432, 29768, 10358, 2766, 13, 51478], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 18, "seek": 5084, "start": 73.32000000000001, "end": 75.64, "text": " Nie interesuj\u0105 nas tylko suche liczby.", "tokens": [51488, 12016, 20157, 13263, 5382, 13219, 1270, 68, 6169, 89, 2322, 13, 51604], "temperature": 0.0, "avg_logprob": -0.16243523949975366, "compression_ratio": 1.2995594713656389, "no_speech_prob": 0.0027940019499510527}, {"id": 19, "seek": 7564, "start": 75.84, "end": 78.88, "text": " Chcemy odkry\u0107, co kryje si\u0119 za kulisami.", "tokens": [50374, 761, 384, 2226, 3611, 43298, 2162, 11, 598, 34847, 2884, 3244, 7949, 27576, 271, 4526, 13, 50526], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 20, "seek": 7564, "start": 79.08, "end": 84.36, "text": " Jakie innowacje, jakie decyzje in\u017cynieryjne sprawi\u0142y, \u017ce ten model jest w stanie", "tokens": [50536, 15029, 414, 294, 3785, 29293, 11, 22124, 979, 37433, 2884, 294, 1427, 2534, 811, 88, 73, 716, 22734, 72, 6825, 11, 3561, 2064, 2316, 3492, 261, 40013, 50800], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 21, "seek": 7564, "start": 84.56, "end": 89.08, "text": " konkurowa\u0107, a czasem nawet wyprzedza\u0107 takich gigant\u00f3w jak GPT-4.", "tokens": [50810, 21428, 374, 11445, 11, 257, 13190, 443, 22696, 4628, 1424, 11312, 35873, 29607, 8741, 394, 3901, 4207, 26039, 51, 12, 19, 13, 51036], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 22, "seek": 7564, "start": 89.28, "end": 94.0, "text": " To b\u0119dzie taka nasza pr\u00f3ba zrozumienia jak i dlaczego za tym wszystkim stoi.", "tokens": [51046, 1407, 10562, 28017, 5382, 2394, 8565, 4231, 710, 27857, 449, 18811, 4207, 741, 37873, 39329, 7949, 8107, 30481, 342, 4869, 13, 51282], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 23, "seek": 7564, "start": 94.2, "end": 97.32, "text": " Dobrze, to zacznijmy od samego pocz\u0105tku.", "tokens": [51292, 29679, 13503, 11, 281, 710, 14875, 77, 1718, 2226, 3611, 912, 1571, 43959, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 24, "seek": 7564, "start": 97.52, "end": 102.04, "text": " Meta nie stworzy\u0142a jednego monolitu, ale ca\u0142\u0105 rodzin\u0119 modeli.", "tokens": [51458, 6377, 64, 2838, 342, 28321, 1229, 5024, 5232, 11858, 1108, 401, 6380, 11, 6775, 1335, 15926, 8685, 23584, 1274, 2316, 72, 13, 51684], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 25, "seek": 7564, "start": 102.24000000000001, "end": 105.52, "text": " Nazwa\u0142y to the Lama 3 Heard of Models.", "tokens": [51694, 11870, 4151, 6825, 281, 264, 441, 2404, 805, 634, 515, 295, 6583, 1625, 13, 51858], "temperature": 0.0, "avg_logprob": -0.13745827074871947, "compression_ratio": 1.3894389438943895, "no_speech_prob": 0.0068628522567451}, {"id": 26, "seek": 10564, "start": 106.2, "end": 110.84, "text": " A ten najwi\u0119kszy 405B to tak zwany G\u0119sty Transformer.", "tokens": [50392, 316, 2064, 48636, 1694, 1229, 3356, 20, 33, 281, 991, 11873, 1325, 460, 1274, 25134, 27938, 260, 13, 50624], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 27, "seek": 10564, "start": 111.04, "end": 112.8, "text": " Co to w og\u00f3le znaczy, \u017ce jest G\u0119sty?", "tokens": [50634, 3066, 281, 261, 29229, 36584, 11, 3561, 3492, 460, 1274, 25134, 30, 50722], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 28, "seek": 10564, "start": 113.0, "end": 113.96000000000001, "text": " To wa\u017cna uwaga.", "tokens": [50732, 1407, 27777, 629, 23147, 9286, 13, 50780], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 29, "seek": 10564, "start": 114.16, "end": 119.84, "text": " G\u0119sty, czyli dense, oznacza w uproszczeniu, \u017ce to jest taka klasyczna, sprawdzona", "tokens": [50790, 460, 1274, 25134, 11, 16591, 18011, 11, 277, 22672, 326, 2394, 261, 493, 2635, 89, 66, 39651, 11, 3561, 281, 3492, 28017, 9671, 5871, 3689, 629, 11, 46192, 13383, 51074], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 30, "seek": 10564, "start": 120.04, "end": 121.64, "text": " architektura, czyli nic nowego.", "tokens": [51084, 3912, 642, 2320, 2991, 11, 16591, 6201, 586, 6308, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 31, "seek": 10564, "start": 121.84, "end": 126.96000000000001, "text": " W\u0142a\u015bnie. To nie jest \u017cadna eksperymentalna konstrukcja typu Mixture of Experts,", "tokens": [51174, 343, 5024, 12221, 13, 1407, 2838, 3492, 39628, 629, 30724, 610, 88, 15875, 629, 34208, 25126, 34056, 2125, 84, 10204, 8890, 295, 12522, 1373, 11, 51430], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 32, "seek": 10564, "start": 127.16, "end": 129.68, "text": " kt\u00f3r\u0105 stosuj\u0105 niekt\u00f3rzy konkurenci.", "tokens": [51440, 37415, 43581, 13263, 2838, 43073, 13047, 21428, 9873, 537, 13, 51566], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 33, "seek": 10564, "start": 129.88, "end": 134.88, "text": " Meta postawi\u0142a na co\u015b, co dobrze zna, ale postanowi\u0142a doprowadzi\u0107 to do", "tokens": [51576, 6377, 64, 2183, 38402, 5024, 1667, 19241, 11, 598, 28335, 710, 629, 11, 6775, 2183, 282, 24503, 5024, 360, 35019, 28496, 281, 360, 51826], "temperature": 0.0, "avg_logprob": -0.16534761087783914, "compression_ratio": 1.4280936454849498, "no_speech_prob": 0.0026387793477624655}, {"id": 34, "seek": 13488, "start": 135.07999999999998, "end": 136.68, "text": " no niemal perfekcji.", "tokens": [50374, 572, 2838, 5579, 13826, 916, 19649, 13, 50454], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 35, "seek": 13488, "start": 136.88, "end": 142.72, "text": " OK. Ten moder ma te\u017c okno kontekstowe do 128 tysi\u0105ce token\u00f3w i od podstaw by\u0142", "tokens": [50464, 2264, 13, 9380, 1072, 260, 463, 9516, 3133, 1771, 14373, 916, 372, 6880, 360, 29810, 38156, 11404, 384, 14862, 3901, 741, 3611, 43443, 16673, 50756], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 36, "seek": 13488, "start": 142.92, "end": 146.92, "text": " projektowany pod kodowanie, rozumowanie i wieloj\u0119zyczno\u015b\u0107.", "tokens": [50766, 26261, 23341, 2497, 350, 378, 22028, 11, 48797, 22028, 741, 20570, 78, 11115, 1229, 3689, 23293, 13, 50966], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 37, "seek": 13488, "start": 147.12, "end": 150.64, "text": " Ale skoro nie ma rewolucji w architekturze, to gdzie le\u017cy sekret?", "tokens": [50976, 9366, 1110, 10780, 2838, 463, 319, 48481, 1311, 4013, 261, 3912, 642, 2320, 374, 1381, 11, 281, 18922, 476, 7735, 17215, 1505, 30, 51152], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 38, "seek": 13488, "start": 150.84, "end": 151.88, "text": " Ja stawiam na dane.", "tokens": [51162, 3530, 342, 1607, 2918, 1667, 49206, 13, 51214], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 39, "seek": 13488, "start": 152.07999999999998, "end": 154.56, "text": " W AI prawie zawsze ostatecznie chodzi o dane.", "tokens": [51224, 343, 7318, 3206, 8699, 30964, 277, 15406, 19923, 23998, 277, 49206, 13, 51348], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 40, "seek": 13488, "start": 154.76, "end": 156.76, "text": " I to jest strzel w dziesi\u0105tk\u0119.", "tokens": [51358, 286, 281, 3492, 1056, 12971, 261, 9758, 530, 11404, 83, 15724, 13, 51458], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 41, "seek": 13488, "start": 156.96, "end": 161.24, "text": " Meta sama w tej pracy zdradza, \u017ce ich przepis na sukces opiera si\u0119 na trzech", "tokens": [51468, 6377, 64, 17768, 261, 12573, 35591, 16221, 6206, 2394, 11, 3561, 1893, 30829, 271, 1667, 46432, 887, 999, 10609, 3244, 1667, 504, 19439, 51682], "temperature": 0.0, "avg_logprob": -0.15112121955498115, "compression_ratio": 1.4152249134948096, "no_speech_prob": 0.006837166380137205}, {"id": 42, "seek": 16124, "start": 161.24, "end": 166.76000000000002, "text": " filarach, a dane s\u0105 tym pierwszym i absolutnie najwa\u017cniejszym.", "tokens": [50364, 1387, 289, 608, 11, 257, 49206, 9015, 8107, 34016, 76, 741, 18757, 2766, 11212, 27111, 10402, 7706, 76, 13, 50640], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 43, "seek": 16124, "start": 166.96, "end": 168.04000000000002, "text": " Jaki to by\u0142 skok?", "tokens": [50650, 508, 7421, 281, 16673, 1110, 453, 30, 50704], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 44, "seek": 16124, "start": 168.24, "end": 173.92000000000002, "text": " Ogromny z jeden osiem biliona token\u00f3w w Lamma 2 do pi\u0119tnastu bilion\u00f3w tutaj.", "tokens": [50714, 422, 861, 298, 1634, 710, 12906, 3003, 4907, 8588, 21758, 14862, 3901, 261, 18825, 1696, 568, 360, 32677, 83, 77, 525, 84, 8588, 313, 3901, 12749, 13, 50998], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 45, "seek": 16124, "start": 174.12, "end": 175.92000000000002, "text": " Ale i to jest kluczowe.", "tokens": [51008, 9366, 741, 281, 3492, 9671, 1311, 89, 6880, 13, 51098], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 46, "seek": 16124, "start": 176.12, "end": 179.84, "text": " Nie chodzi\u0142o tylko o zalanie modelu wi\u0119ksz\u0105 ilo\u015bci\u0105 informacji.", "tokens": [51108, 12016, 23998, 5249, 13219, 277, 29599, 7155, 2316, 84, 29968, 8925, 1930, 44468, 1611, 1356, 13152, 13, 51294], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 47, "seek": 16124, "start": 180.04000000000002, "end": 184.04000000000002, "text": " Chodzi\u0142o o tak\u0105 no niemal obsesyjn\u0105 dba\u0142o\u015b\u0107 o jako\u015b\u0107.", "tokens": [51304, 761, 14543, 5249, 277, 31069, 572, 2838, 5579, 3181, 17823, 73, 13113, 274, 4231, 44742, 277, 17123, 7753, 13, 51504], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 48, "seek": 16124, "start": 184.24, "end": 185.20000000000002, "text": " OK, to dane.", "tokens": [51514, 2264, 11, 281, 49206, 13, 51562], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 49, "seek": 16124, "start": 185.4, "end": 186.56, "text": " Jaki jest drugi filar?", "tokens": [51572, 508, 7421, 3492, 4110, 72, 1387, 289, 30, 51630], "temperature": 0.0, "avg_logprob": -0.16766080930251484, "compression_ratio": 1.3828125, "no_speech_prob": 0.3428409695625305}, {"id": 50, "seek": 18656, "start": 186.68, "end": 188.04, "text": " Czysta, brutalna skala.", "tokens": [50370, 19832, 9140, 11, 17878, 629, 1110, 5159, 13, 50438], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 51, "seek": 18656, "start": 188.24, "end": 193.88, "text": " Moc obliczeniowa u\u017cyta do treningu wzros\u0142a niemal pi\u0119\u0107dziesi\u0119ciokrotnie w por\u00f3wnaniu do", "tokens": [50448, 376, 905, 1111, 1050, 42124, 5528, 34097, 1328, 360, 2192, 773, 84, 24809, 2635, 5024, 2838, 5579, 32677, 2162, 28168, 530, 5034, 537, 453, 10536, 2766, 261, 1515, 812, 895, 25849, 360, 50730], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 52, "seek": 18656, "start": 194.08, "end": 195.88, "text": " najwi\u0119kszej Lamma 2.", "tokens": [50740, 48636, 1694, 16920, 18825, 1696, 568, 13, 50830], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 53, "seek": 18656, "start": 196.08, "end": 198.36, "text": " Pi\u0119\u0107dziesi\u0119ciokrotnie tak.", "tokens": [50840, 430, 5034, 2162, 28168, 530, 5034, 537, 453, 10536, 2766, 991, 13, 50954], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 54, "seek": 18656, "start": 198.56, "end": 204.4, "text": " To pokazuje, \u017ce w tej grze, mimo ca\u0142ej finezji algorytm\u00f3w, posiadanie gigantycznych", "tokens": [50964, 1407, 13010, 43317, 11, 3561, 261, 12573, 677, 1381, 11, 275, 6934, 47631, 73, 2489, 89, 4013, 3501, 827, 83, 76, 3901, 11, 1366, 38069, 7155, 8741, 394, 17466, 9399, 51256], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 55, "seek": 18656, "start": 204.6, "end": 207.88, "text": " zasob\u00f3w obliczeniowych wci\u0105\u017c jest no decyduj\u0105ce.", "tokens": [51266, 26530, 996, 3901, 1111, 1050, 42124, 19605, 261, 537, 27242, 3492, 572, 979, 88, 769, 8555, 384, 13, 51430], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 56, "seek": 18656, "start": 208.08, "end": 209.4, "text": " A trzeci sk\u0142adnik?", "tokens": [51440, 316, 22266, 537, 1110, 10358, 13123, 30, 51506], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 57, "seek": 18656, "start": 209.6, "end": 212.6, "text": " Co\u015b, co nazywaj\u0105 zarz\u0105dzaniem z\u0142o\u017cono\u015bci\u0105.", "tokens": [51516, 3066, 1788, 11, 598, 20151, 27112, 11133, 22675, 23876, 21238, 4907, 710, 5249, 1427, 8957, 50227, 13, 51666], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 58, "seek": 18656, "start": 212.8, "end": 215.76, "text": " I to jest fascynuj\u0105ce, bo rzadko si\u0119 o tym m\u00f3wi.", "tokens": [51676, 286, 281, 3492, 30632, 1344, 77, 13263, 384, 11, 748, 367, 89, 345, 4093, 3244, 277, 8107, 24592, 13, 51824], "temperature": 0.0, "avg_logprob": -0.15405213973101448, "compression_ratio": 1.4560810810810811, "no_speech_prob": 0.15555430948734283}, {"id": 59, "seek": 21576, "start": 215.95999999999998, "end": 221.88, "text": " Zbudowanie i wytrenowanie takiego potwora to jest niewyobra\u017calne wyzwanie in\u017cynieryjne.", "tokens": [50374, 1176, 18281, 22028, 741, 261, 4328, 1095, 22028, 32296, 1847, 86, 3252, 281, 3492, 43622, 88, 24393, 1427, 304, 716, 4628, 14406, 7155, 294, 1427, 2534, 811, 88, 73, 716, 13, 50670], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 60, "seek": 21576, "start": 222.07999999999998, "end": 223.67999999999998, "text": " Logistyczne, organizacyjne.", "tokens": [50680, 10824, 468, 17466, 716, 11, 4645, 31285, 716, 13, 50760], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 61, "seek": 21576, "start": 223.88, "end": 224.79999999999998, "text": " Dok\u0142adnie.", "tokens": [50770, 29768, 10358, 2766, 13, 50816], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 62, "seek": 21576, "start": 225.0, "end": 229.2, "text": " Porozmawiamy o tym za chwil\u0119, bo tam kryj\u0105 si\u0119 niesamowite historie.", "tokens": [50826, 5269, 15151, 76, 1607, 2918, 88, 277, 8107, 7949, 41941, 1274, 11, 748, 7677, 34847, 8555, 3244, 48100, 335, 305, 642, 4058, 414, 13, 51036], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 63, "seek": 21576, "start": 229.39999999999998, "end": 232.64, "text": " Czyli je\u015bli dobrze rozumiem, g\u0142\u00f3wna teza autor\u00f3w jest taka.", "tokens": [51046, 37099, 25630, 28335, 48797, 4907, 11, 18117, 3901, 629, 535, 2394, 19510, 3901, 3492, 28017, 13, 51208], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 64, "seek": 21576, "start": 232.84, "end": 235.95999999999998, "text": " Nie potrzebowali\u015bmy rewolucji w budowie silnika.", "tokens": [51218, 12016, 37595, 305, 33955, 319, 48481, 1311, 4013, 261, 3265, 13998, 3425, 77, 5439, 13, 51374], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 65, "seek": 21576, "start": 236.16, "end": 236.76, "text": " W\u0142a\u015bnie.", "tokens": [51384, 343, 5024, 12221, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 66, "seek": 21576, "start": 236.95999999999998, "end": 242.2, "text": " Bo okaza\u0142o si\u0119, \u017ce stary, sprawdzony silnik, ale zalany paliwem o niespotykanej", "tokens": [51424, 3286, 3133, 12257, 5249, 3244, 11, 3561, 342, 822, 11, 46192, 44479, 3425, 13123, 11, 6775, 29599, 1325, 3984, 72, 86, 443, 277, 48100, 79, 6737, 74, 1929, 73, 51686], "temperature": 0.0, "avg_logprob": -0.12437934875488281, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.0028605256229639053}, {"id": 67, "seek": 24220, "start": 242.23999999999998, "end": 246.83999999999997, "text": " jako\u015bci i w ogromnej ilo\u015bci nagle zacz\u0105\u0142 bi\u0107 rekordy pr\u0119dko\u015bci.", "tokens": [50366, 17123, 6199, 741, 261, 34416, 298, 11794, 1930, 44468, 297, 15088, 34430, 8925, 1221, 3228, 2162, 33881, 765, 88, 582, 6298, 4093, 6199, 13, 50596], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 68, "seek": 24220, "start": 247.04, "end": 248.11999999999998, "text": " Dok\u0142adnie tak.", "tokens": [50606, 29768, 10358, 2766, 991, 13, 50660], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 69, "seek": 24220, "start": 248.32, "end": 252.79999999999998, "text": " Ca\u0142a ta praca to w zasadzie dow\u00f3d na to, \u017ce ewolucja i dopracowanie istniej\u0105cych", "tokens": [50670, 7544, 5024, 1846, 582, 6628, 281, 261, 44585, 3283, 9459, 17081, 1667, 281, 11, 3561, 43364, 401, 1311, 2938, 741, 360, 1424, 326, 22028, 1418, 2766, 8555, 31306, 50894], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 70, "seek": 24220, "start": 253.0, "end": 256.84, "text": " metod mo\u017ce przynie\u015b\u0107 lepsze efekty ni\u017c pogo\u0144 za nowinkami.", "tokens": [50904, 1131, 378, 12034, 6501, 2766, 7753, 476, 1878, 1381, 31482, 916, 874, 28502, 32037, 78, 5248, 7949, 586, 475, 4526, 13, 51096], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 71, "seek": 24220, "start": 257.03999999999996, "end": 257.96, "text": " To wa\u017cna lekcja.", "tokens": [51106, 1407, 27777, 629, 30863, 34056, 13, 51152], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 72, "seek": 24220, "start": 258.15999999999997, "end": 260.03999999999996, "text": " To zanurzmy si\u0119 w szczeg\u00f3\u0142y.", "tokens": [51162, 1407, 710, 282, 374, 89, 2226, 3244, 261, 22090, 1146, 812, 6825, 13, 51256], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 73, "seek": 24220, "start": 260.24, "end": 264.44, "text": " Zaczyna si\u0119 od pre-training, czyli budowy tego surowego intelektu.", "tokens": [51266, 1176, 14691, 629, 3244, 3611, 659, 12, 17227, 1760, 11, 16591, 3265, 10089, 8627, 1022, 26576, 2830, 306, 2320, 84, 13, 51476], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 74, "seek": 24220, "start": 264.64, "end": 268.52, "text": " Jak wygl\u0105da\u0142a ta obsesyjna dba\u0142o\u015b\u0107 o jako\u015b\u0107 danych?", "tokens": [51486, 15029, 32015, 5024, 1846, 3181, 17823, 73, 629, 274, 4231, 44742, 277, 17123, 7753, 274, 34644, 30, 51680], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 75, "seek": 24220, "start": 268.71999999999997, "end": 271.88, "text": " To by\u0142 wieloetapowy, niezwykle rygorystyczny proces.", "tokens": [51690, 1407, 16673, 20570, 78, 302, 569, 10089, 11, 33511, 9726, 14677, 367, 18103, 827, 372, 17466, 1634, 17565, 13, 51848], "temperature": 0.0, "avg_logprob": -0.10497048257411211, "compression_ratio": 1.4382716049382716, "no_speech_prob": 0.06370027363300323}, {"id": 76, "seek": 27188, "start": 271.92, "end": 273.24, "text": " Zacz\u0119li od filtrowania.", "tokens": [50366, 48082, 11052, 2081, 3611, 29148, 1892, 5609, 13, 50432], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 77, "seek": 27188, "start": 273.44, "end": 275.24, "text": " Czyli co, usuwali \u015bmieci?", "tokens": [50442, 37099, 598, 11, 32247, 86, 5103, 8299, 25210, 537, 30, 50532], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 78, "seek": 27188, "start": 275.44, "end": 276.88, "text": " Tak, ale na masow\u0105 skal\u0119.", "tokens": [50542, 9118, 11, 6775, 1667, 2300, 30297, 16890, 1274, 13, 50614], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 79, "seek": 27188, "start": 277.08, "end": 282.15999999999997, "text": " Usun\u0119li ca\u0142e domeny znane z tego, \u017ce zawieraj\u0105 du\u017co danych osobowych, czyli PII,", "tokens": [50624, 4958, 409, 1274, 2081, 47631, 3285, 43100, 15397, 1929, 710, 8627, 11, 3561, 28165, 811, 11133, 26673, 274, 34644, 19116, 8202, 16384, 11, 16591, 430, 9503, 11, 50878], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 80, "seek": 27188, "start": 282.36, "end": 284.52, "text": " albo po prostu tre\u015bci niebezpieczne.", "tokens": [50888, 22622, 714, 19518, 2192, 6199, 2838, 650, 89, 9144, 38491, 13, 50996], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 81, "seek": 27188, "start": 284.71999999999997, "end": 290.88, "text": " Potem stworzyli w\u0142asny parser HTML, \u017ceby wyci\u0105ga\u0107 z internetu tekst w najczystszej postaci.", "tokens": [51006, 9145, 443, 342, 28321, 1229, 2081, 43572, 1634, 21156, 260, 17995, 11, 11316, 4628, 34381, 3680, 2162, 710, 4705, 84, 16624, 372, 261, 11212, 6522, 372, 82, 16920, 2183, 22086, 13, 51314], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 82, "seek": 27188, "start": 291.08, "end": 292.28, "text": " A co z powt\u00f3rzyniami?", "tokens": [51324, 316, 598, 710, 3388, 4547, 13047, 77, 15568, 30, 51384], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 83, "seek": 27188, "start": 292.48, "end": 293.71999999999997, "text": " Internet jest ich pe\u0142en.", "tokens": [51394, 7703, 3492, 1893, 43205, 268, 13, 51456], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 84, "seek": 27188, "start": 293.92, "end": 295.56, "text": " W\u0142a\u015bnie, to kolejny krok.", "tokens": [51466, 343, 5024, 12221, 11, 281, 23749, 1634, 350, 31621, 13, 51548], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 85, "seek": 27188, "start": 295.76, "end": 299.24, "text": " Zastosowali bardzo agresywn\u0105 deduplikacj\u0119 na wielu poziomach.", "tokens": [51558, 1176, 525, 329, 305, 5103, 9034, 623, 495, 88, 895, 1611, 4172, 44810, 1035, 29924, 1667, 40437, 38503, 298, 608, 13, 51732], "temperature": 0.0, "avg_logprob": -0.139725312954042, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.009266584180295467}, {"id": 86, "seek": 29924, "start": 299.40000000000003, "end": 303.76, "text": " Na poziomie URL, potem ca\u0142ych dokument\u00f3w przy u\u017cyciu algorytmu minHash,", "tokens": [50372, 6056, 38503, 40120, 12905, 11, 36513, 35226, 339, 40858, 3901, 6501, 34097, 30795, 3501, 827, 83, 20140, 923, 39, 1299, 11, 50590], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 87, "seek": 29924, "start": 303.96000000000004, "end": 307.32, "text": " a na ko\u0144cu zeszli nawet do poziomu pojedynczych linii jak tekstu.", "tokens": [50600, 257, 1667, 26470, 12032, 710, 10430, 2081, 22696, 360, 38503, 298, 84, 714, 40543, 2534, 6522, 339, 287, 3812, 72, 4207, 16624, 372, 84, 13, 50768], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 88, "seek": 29924, "start": 307.52, "end": 311.36, "text": " Chcieli, \u017ceby ka\u017cda informacja by\u0142a jak najbardziej unikalna.", "tokens": [50778, 761, 537, 10148, 11, 11316, 21912, 2675, 1356, 23395, 23936, 4207, 41857, 517, 41216, 629, 13, 50970], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 89, "seek": 29924, "start": 311.56, "end": 312.32, "text": " Dok\u0142adnie.", "tokens": [50980, 29768, 10358, 2766, 13, 51018], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 90, "seek": 29924, "start": 312.52, "end": 317.44, "text": " Czekaj, w materiamach jest fragment, kt\u00f3ry mnie naprawd\u0119 zaintergowa\u0142.", "tokens": [51028, 383, 19878, 1805, 11, 261, 2389, 2918, 608, 3492, 26424, 11, 9913, 17661, 20970, 710, 491, 391, 70, 30105, 13, 51274], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 91, "seek": 29924, "start": 317.64, "end": 322.6, "text": " U\u017cyli poprzednich modeli Lama 2 jako s\u0119dzi\u00f3w jako\u015bci.", "tokens": [51284, 624, 7735, 2081, 1665, 81, 11312, 77, 480, 2316, 72, 441, 2404, 568, 17123, 262, 6298, 3992, 3901, 17123, 6199, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 92, "seek": 29924, "start": 322.8, "end": 324.24, "text": " To brzmi prawie jak paradoks.", "tokens": [51542, 1407, 738, 89, 3057, 3206, 8699, 4207, 13480, 25500, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 93, "seek": 29924, "start": 324.44, "end": 325.28000000000003, "text": " Prawda.", "tokens": [51624, 430, 5131, 2675, 13, 51666], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 94, "seek": 29924, "start": 325.48, "end": 327.56, "text": " I to jest genialne w swojej prostocie.", "tokens": [51676, 286, 281, 3492, 48228, 716, 261, 29489, 73, 10293, 905, 414, 13, 51780], "temperature": 0.0, "avg_logprob": -0.13814003638971864, "compression_ratio": 1.3908794788273615, "no_speech_prob": 0.08138323575258255}, {"id": 95, "seek": 32756, "start": 327.76, "end": 330.48, "text": " Model sam pomaga utworzy\u0107 swojego nast\u0119pc\u0119.", "tokens": [50374, 17105, 3247, 12991, 9286, 2839, 28321, 27150, 13291, 39738, 39662, 37965, 13, 50510], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 96, "seek": 32756, "start": 330.68, "end": 336.2, "text": " Tak, nauczyli modele Lama 2 rozpoznawa\u0107 tekst wysokiej jako\u015bci i u\u017cyli ich do", "tokens": [50520, 9118, 11, 49103, 1229, 2081, 4391, 306, 441, 2404, 568, 9544, 2259, 35458, 25234, 16624, 372, 27062, 453, 7764, 17123, 6199, 741, 34097, 2081, 1893, 360, 50796], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 97, "seek": 32756, "start": 336.4, "end": 339.6, "text": " automatycznej klasyfikacji gigantycznych zbior\u00f3w danych.", "tokens": [50806, 28034, 17466, 11794, 9671, 5871, 31230, 13152, 8741, 394, 17466, 9399, 710, 33362, 3901, 274, 34644, 13, 50966], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 98, "seek": 32756, "start": 339.8, "end": 343.92, "text": " Mo\u017cna powiedzie\u0107, \u017ce Lama 2 pe\u0142ni\u0142a rol\u0119 takiego kuratora, kt\u00f3ry", "tokens": [50976, 44736, 629, 27886, 11, 3561, 441, 2404, 568, 43205, 3722, 5024, 34109, 1274, 32296, 10072, 1639, 64, 11, 9913, 51182], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 99, "seek": 32756, "start": 344.12, "end": 347.84000000000003, "text": " przygotowywa\u0142 bibliotek\u0119 dla swojego m\u0105drzejszego potomka.", "tokens": [51192, 35914, 10089, 44603, 34344, 310, 916, 1274, 12285, 13291, 39738, 275, 18962, 13503, 25530, 27725, 1847, 298, 2330, 13, 51378], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 100, "seek": 32756, "start": 348.04, "end": 350.72, "text": " To troch\u0119 jak praca dietetyka dla AI.", "tokens": [51388, 1407, 24926, 4207, 582, 6628, 6339, 2210, 2330, 12285, 7318, 13, 51522], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 101, "seek": 32756, "start": 350.92, "end": 353.52, "text": " Wspomniano te\u017c o tak zwanym data mix.", "tokens": [51532, 343, 4952, 38131, 6254, 9516, 277, 991, 11873, 1325, 76, 1412, 2890, 13, 51662], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 102, "seek": 32756, "start": 353.72, "end": 357.4, "text": " Tak, to starannie skomponowana dieta dla modelu.", "tokens": [51672, 9118, 11, 281, 3543, 43433, 1110, 8586, 266, 40458, 37967, 12285, 2316, 84, 13, 51856], "temperature": 0.0, "avg_logprob": -0.14028121329642632, "compression_ratio": 1.4387096774193548, "no_speech_prob": 0.004332132171839476}, {"id": 103, "seek": 35756, "start": 357.6, "end": 359.4, "text": " I to kolejny kluczowy element.", "tokens": [50366, 286, 281, 23749, 1634, 9671, 1311, 89, 10089, 4478, 13, 50456], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 104, "seek": 35756, "start": 359.6, "end": 361.2, "text": " Czyli to nie by\u0142a przypadkowa mieszanka?", "tokens": [50466, 37099, 281, 2838, 23936, 33100, 74, 5528, 33039, 21729, 30, 50546], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 105, "seek": 35756, "start": 361.4, "end": 362.36, "text": " Absolutnie nie.", "tokens": [50556, 5813, 2308, 2766, 2838, 13, 50604], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 106, "seek": 35756, "start": 362.56, "end": 365.08, "text": " Oko\u0142o 50% to wiedza og\u00f3lna.", "tokens": [50614, 3477, 78, 5249, 2625, 4, 281, 46894, 2394, 5360, 15741, 629, 13, 50740], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 107, "seek": 35756, "start": 365.28000000000003, "end": 368.44, "text": " 25% matematyka i rozumowanie.", "tokens": [50750, 3552, 4, 3803, 8615, 88, 2330, 741, 48797, 22028, 13, 50908], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 108, "seek": 35756, "start": 368.64, "end": 372.92, "text": " 17% kot, a 8% dane wieloj\u0119zyczne.", "tokens": [50918, 3282, 4, 43029, 11, 257, 1649, 4, 49206, 20570, 78, 11115, 1229, 38491, 13, 51132], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 109, "seek": 35756, "start": 373.12, "end": 375.8, "text": " I te proporcje nie zosta\u0142y wzi\u0119te z sufitu.", "tokens": [51142, 286, 535, 2365, 36003, 2884, 2838, 23154, 6825, 261, 16706, 975, 710, 459, 6845, 84, 13, 51276], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 110, "seek": 35756, "start": 376.0, "end": 376.96, "text": " Tylko sk\u0105d?", "tokens": [51286, 49286, 4093, 1110, 18962, 30, 51334], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 111, "seek": 35756, "start": 377.16, "end": 382.4, "text": " Wyliczono je na podstawie eksperyment\u00f3w z tak zwanymi scaling laws.", "tokens": [51344, 343, 5088, 299, 89, 8957, 1506, 1667, 43443, 414, 30724, 610, 88, 518, 3901, 710, 991, 11873, 1325, 3057, 21589, 6064, 13, 51606], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 112, "seek": 35756, "start": 382.6, "end": 385.04, "text": " To s\u0105 prawa, kt\u00f3re pozwolaj\u0105 z du\u017c\u0105", "tokens": [51616, 1407, 9015, 3206, 4151, 11, 8864, 40557, 401, 11133, 710, 21783, 1611, 51738], "temperature": 0.0, "avg_logprob": -0.17369433416836505, "compression_ratio": 1.3283018867924528, "no_speech_prob": 0.00786374881863594}, {"id": 113, "seek": 38504, "start": 385.04, "end": 388.24, "text": " dok\u0142adno\u015bci\u0105 przewidzie\u0107 jak zmiana diety", "tokens": [50364, 45864, 16438, 1611, 39758, 327, 21214, 4207, 17020, 8497, 1026, 2210, 50524], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 114, "seek": 38504, "start": 388.44, "end": 391.12, "text": " wp\u0142ynie na zdolno\u015bci ko\u0144cowego modelu.", "tokens": [50534, 32444, 1221, 2534, 414, 1667, 16221, 401, 16438, 26470, 66, 26576, 2316, 84, 13, 50668], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 115, "seek": 38504, "start": 391.32, "end": 394.44, "text": " Jeszcze zanim wydadz\u0105 miliony dolar\u00f3w na trening.", "tokens": [50678, 2547, 89, 9680, 710, 17869, 4628, 20034, 8925, 1962, 46184, 360, 2200, 3901, 1667, 2192, 773, 13, 50834], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 116, "seek": 38504, "start": 394.64000000000004, "end": 395.04, "text": " Dok\u0142adnie.", "tokens": [50844, 29768, 10358, 2766, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 117, "seek": 38504, "start": 395.24, "end": 399.04, "text": " To sugeruje, \u017ce przysz\u0142o\u015b\u0107 to nie tyle nowe algorytmy, co", "tokens": [50874, 1407, 459, 1321, 13008, 11, 3561, 44018, 44742, 281, 2838, 39293, 586, 68, 3501, 827, 83, 2226, 11, 598, 51064], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 118, "seek": 38504, "start": 399.24, "end": 401.16, "text": " perfekcyjne komponowanie diety", "tokens": [51074, 13826, 916, 42949, 716, 5207, 79, 266, 22028, 1026, 2210, 51170], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 119, "seek": 38504, "start": 401.36, "end": 403.04, "text": " treningowej pod konkretne cele.", "tokens": [51180, 2192, 773, 21091, 2497, 36500, 716, 43165, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 120, "seek": 38504, "start": 403.24, "end": 409.04, "text": " Zdecydowanie in\u017cynieria danych staje si\u0119 chyba wa\u017cniejsza ni\u017c in\u017cynieria samych modeli.", "tokens": [51274, 1176, 1479, 1344, 67, 22028, 294, 1427, 2534, 811, 654, 274, 34644, 342, 11153, 3244, 31532, 27777, 30295, 2394, 28502, 294, 1427, 2534, 811, 654, 3247, 16384, 2316, 72, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 121, "seek": 38504, "start": 409.24, "end": 414.04, "text": " A architektura m\u00f3wili\u015bmy, \u017ce to standard, ale by\u0142 jaki\u015b ulepszenia.", "tokens": [51574, 316, 3912, 642, 2320, 2991, 13489, 43912, 11, 3561, 281, 3832, 11, 6775, 16673, 34721, 344, 306, 1878, 14320, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13933579438652088, "compression_ratio": 1.4733333333333334, "no_speech_prob": 0.07618770003318787}, {"id": 122, "seek": 41404, "start": 414.24, "end": 416.68, "text": " Tak, kilka cichych, ale wa\u017cnych.", "tokens": [50374, 9118, 11, 36466, 269, 480, 16384, 11, 6775, 27777, 9399, 13, 50496], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 123, "seek": 41404, "start": 416.88, "end": 423.24, "text": " Na przyk\u0142ad Grouped Query Attention, czyli GQA, co w praktyce po prostu znacz\u0105co", "tokens": [50506, 6056, 23144, 10500, 292, 2326, 2109, 31858, 11, 16591, 460, 48, 32, 11, 598, 261, 3206, 74, 874, 384, 714, 19518, 15397, 326, 8925, 1291, 50824], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 124, "seek": 41404, "start": 423.44, "end": 425.56, "text": " przyspiesza generowanie odpowiedzi.", "tokens": [50834, 6541, 749, 79, 530, 2394, 1337, 22028, 36574, 3992, 13, 50940], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 125, "seek": 41404, "start": 425.76000000000005, "end": 428.64000000000004, "text": " W pracy wspomniano te\u017c o specjalnej masce uwagi.", "tokens": [50950, 343, 35591, 17757, 38131, 6254, 9516, 277, 46433, 11794, 2300, 384, 23147, 20291, 13, 51094], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 126, "seek": 41404, "start": 428.84000000000003, "end": 429.40000000000003, "text": " Co to takiego?", "tokens": [51104, 3066, 281, 32296, 30, 51132], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 127, "seek": 41404, "start": 429.6, "end": 435.52000000000004, "text": " Wyobra\u017a sobie, \u017ce w jednym d\u0142ugim zapytaniu podajesz modelowi kilka r\u00f3\u017cnych dokument\u00f3w.", "tokens": [51142, 14458, 24393, 10659, 13652, 11, 3561, 261, 5232, 12996, 274, 34077, 332, 14223, 4328, 25849, 2497, 1805, 10430, 2316, 24503, 36466, 42602, 40858, 3901, 13, 51438], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 128, "seek": 41404, "start": 435.72, "end": 440.04, "text": " Ta maska dzia\u0142a jak separator, kt\u00f3ry zapobiega", "tokens": [51448, 6551, 2300, 2330, 37903, 4207, 3128, 1639, 11, 9913, 14223, 996, 414, 3680, 51664], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 129, "seek": 41404, "start": 440.24, "end": 443.28000000000003, "text": " mieszaniu si\u0119 informacji mi\u0119dzy nimi.", "tokens": [51674, 33039, 25849, 3244, 1356, 13152, 33964, 297, 10121, 13, 51826], "temperature": 0.0, "avg_logprob": -0.14259206786636233, "compression_ratio": 1.3793103448275863, "no_speech_prob": 0.001272035064175725}, {"id": 130, "seek": 44328, "start": 443.47999999999996, "end": 446.96, "text": " Proste, ale kluczowe dla sp\u00f3jno\u015bci w d\u0142ugim kontek\u015bcie.", "tokens": [50374, 2114, 555, 68, 11, 6775, 9671, 1311, 89, 6880, 12285, 637, 18999, 16438, 261, 274, 34077, 332, 14373, 916, 9815, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 131, "seek": 44328, "start": 447.15999999999997, "end": 448.44, "text": " No w\u0142a\u015bnie.", "tokens": [50558, 883, 14234, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 132, "seek": 44328, "start": 448.64, "end": 450.08, "text": " Ale przejd\u017amy do skali.", "tokens": [50632, 9366, 8325, 37109, 10659, 2226, 360, 1110, 5103, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 133, "seek": 44328, "start": 450.28, "end": 452.64, "text": " Moc obliczeniowa wi\u0119ksza pi\u0119\u0107dziesi\u0105t razy.", "tokens": [50714, 376, 905, 1111, 1050, 42124, 5528, 29968, 2394, 32677, 2162, 28168, 530, 11404, 83, 9639, 88, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 134, "seek": 44328, "start": 452.84, "end": 454.91999999999996, "text": " To brzmi jak logistyczny koszmar.", "tokens": [50842, 1407, 738, 89, 3057, 4207, 3565, 468, 17466, 1634, 19532, 89, 6209, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 135, "seek": 44328, "start": 455.11999999999995, "end": 456.44, "text": " Czy wszystko sz\u0142o g\u0142adko?", "tokens": [50956, 19832, 22607, 7870, 5249, 290, 10358, 4093, 30, 51022], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 136, "seek": 44328, "start": 456.64, "end": 458.03999999999996, "text": " Absolutnie nie sz\u0142o g\u0142adko.", "tokens": [51032, 5813, 2308, 2766, 2838, 7870, 5249, 290, 10358, 4093, 13, 51102], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 137, "seek": 44328, "start": 458.23999999999995, "end": 462.15999999999997, "text": " I to jest jedna z najciekawszych i najbardziej szczerych cz\u0119\u015bci tej pracy.", "tokens": [51112, 286, 281, 3492, 5232, 629, 710, 11212, 4260, 74, 1607, 45021, 741, 41857, 22090, 2109, 339, 41314, 12573, 35591, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 138, "seek": 44328, "start": 462.35999999999996, "end": 462.96, "text": " Opowiedz.", "tokens": [51318, 12011, 305, 15338, 13, 51348], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 139, "seek": 44328, "start": 463.15999999999997, "end": 468.59999999999997, "text": " Model trenowano na klastrach maj\u0105cych do 16 tysi\u0119cy najnowszych procesor\u00f3w graficznych", "tokens": [51358, 17105, 23136, 305, 3730, 1667, 9671, 525, 81, 608, 26064, 31306, 360, 3165, 38156, 47303, 11212, 77, 1509, 28051, 17565, 284, 3901, 1295, 1786, 89, 9399, 51630], "temperature": 0.0, "avg_logprob": -0.1305240930295458, "compression_ratio": 1.3973063973063973, "no_speech_prob": 0.008464932441711426}, {"id": 140, "seek": 46860, "start": 468.6, "end": 473.48, "text": " HASTO. I autorzy przyznaj\u0105, \u017ce w ci\u0105gu pi\u0119\u0107dziesi\u0119ciu czterech dni", "tokens": [50364, 389, 3160, 15427, 13, 286, 19510, 1229, 6501, 35458, 8555, 11, 3561, 261, 42398, 2794, 32677, 2162, 28168, 530, 5034, 30795, 269, 2682, 323, 339, 46125, 50608], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 141, "seek": 46860, "start": 473.68, "end": 478.40000000000003, "text": " treningu zanotowali a\u017c 419 nieoczekiwanych przerw.", "tokens": [50618, 2192, 773, 84, 710, 282, 310, 305, 5103, 48134, 1017, 3405, 2838, 905, 89, 14753, 86, 34644, 582, 4527, 86, 13, 50854], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 142, "seek": 46860, "start": 478.6, "end": 481.6, "text": " 419 to brzmi jak katastrofa.", "tokens": [50864, 1017, 3405, 281, 738, 89, 3057, 4207, 16536, 525, 340, 11771, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 143, "seek": 46860, "start": 481.8, "end": 484.40000000000003, "text": " Wi\u0119kszo\u015b\u0107 to by\u0142y prozeiczne awarje sprz\u0119tu.", "tokens": [51024, 30127, 1694, 4765, 7753, 281, 26366, 447, 1381, 17946, 716, 1714, 289, 2884, 6103, 11052, 9179, 13, 51154], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 144, "seek": 46860, "start": 484.6, "end": 487.48, "text": " A jednak mimo tych wszystkich problem\u00f3w efektywny czas", "tokens": [51164, 316, 25897, 275, 6934, 15180, 34234, 1154, 3901, 31482, 916, 874, 43682, 13190, 51308], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 145, "seek": 46860, "start": 487.68, "end": 493.16, "text": " treningu, czyli czas, kiedy model faktycznie si\u0119 uczy\u0142, wynios\u0142 ponad 90 procent.", "tokens": [51318, 2192, 773, 84, 11, 16591, 13190, 11, 18777, 2316, 33647, 45586, 3244, 344, 6522, 1221, 11, 31936, 2717, 1221, 9224, 345, 4289, 38826, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 146, "seek": 46860, "start": 493.36, "end": 496.68, "text": " To \u015bwiadczy o niesamowitej in\u017cynierii i automatyzacji.", "tokens": [51602, 1407, 21485, 345, 6522, 277, 48100, 335, 305, 642, 73, 294, 1427, 2534, 811, 5597, 741, 3553, 21398, 89, 13152, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1473860549926758, "compression_ratio": 1.3686006825938566, "no_speech_prob": 0.12074267119169235}, {"id": 147, "seek": 49668, "start": 496.84000000000003, "end": 497.92, "text": " Zdecydowanie.", "tokens": [50372, 1176, 1479, 1344, 67, 22028, 13, 50426], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 148, "seek": 49668, "start": 498.12, "end": 503.04, "text": " W tym rozdziale znalaz\u0142em m\u00f3j ulubiony, kompletnie zaskakuj\u0105cy fakt.", "tokens": [50436, 343, 8107, 9544, 28168, 25051, 710, 4660, 921, 11126, 275, 18999, 20352, 836, 46184, 11, 5207, 14657, 2766, 710, 3863, 514, 13263, 1344, 21310, 13, 50682], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 149, "seek": 49668, "start": 503.24, "end": 504.84000000000003, "text": " Dobowy wahanie wydajno\u015bci.", "tokens": [50692, 29679, 10089, 31979, 7155, 25984, 1805, 16438, 13, 50772], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 150, "seek": 49668, "start": 505.04, "end": 506.2, "text": " Tak, to jest pere\u0142ka.", "tokens": [50782, 9118, 11, 281, 3492, 280, 323, 1221, 2330, 13, 50840], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 151, "seek": 49668, "start": 506.40000000000003, "end": 508.0, "text": " Spowodowany temperatur\u0105.", "tokens": [50850, 1738, 305, 378, 23341, 3393, 19493, 1611, 13, 50930], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 152, "seek": 49668, "start": 508.2, "end": 514.64, "text": " Tak zaobserwowali, \u017ce wydajno\u015b\u0107 ca\u0142ego klastra waha\u0142a si\u0119 o 1-2 procent w cyklu dobowym.", "tokens": [50940, 9118, 7949, 16537, 260, 34354, 5103, 11, 3561, 25984, 1805, 23293, 35224, 6308, 9671, 525, 424, 261, 4408, 5024, 3244, 277, 502, 12, 17, 38826, 261, 3185, 74, 2781, 27082, 31691, 13, 51262], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 153, "seek": 49668, "start": 514.84, "end": 519.0, "text": " Okaza\u0142o si\u0119, \u017ce by\u0142o to spowodowane zmianami temperatury otoczenia w serwerowni.", "tokens": [51272, 3477, 12257, 5249, 3244, 11, 3561, 14811, 281, 637, 305, 378, 23066, 43591, 4526, 3393, 267, 2598, 4337, 905, 14320, 261, 816, 1554, 648, 72, 13, 51480], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 154, "seek": 49668, "start": 519.2, "end": 521.6, "text": " Czyli wy\u017csza temperatura spowalnia\u0142a procesory?", "tokens": [51490, 37099, 4628, 1427, 82, 2394, 36903, 637, 305, 304, 12679, 5024, 17565, 827, 30, 51610], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 155, "seek": 49668, "start": 521.8, "end": 524.44, "text": " Dok\u0142adnie wp\u0142ywa\u0142a na ich taktowanie.", "tokens": [51620, 29768, 10358, 2766, 32444, 6825, 4151, 5024, 1667, 1893, 991, 83, 22028, 13, 51752], "temperature": 0.0, "avg_logprob": -0.14681088702278847, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.043349407613277435}, {"id": 156, "seek": 52444, "start": 524.6400000000001, "end": 528.0, "text": " To pokazuje, jak ekstremalnie wra\u017cliwe s\u0105 te systemy.", "tokens": [50374, 1407, 13010, 43317, 11, 4207, 13359, 372, 2579, 304, 2766, 7843, 1427, 2081, 826, 9015, 535, 1185, 88, 13, 50542], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 157, "seek": 52444, "start": 528.2, "end": 531.4000000000001, "text": " M\u00f3wimy o wp\u0142ywie pogody za oknem na trening AI.", "tokens": [50552, 376, 3901, 13189, 277, 32444, 6825, 8699, 32037, 843, 7949, 3133, 25989, 1667, 2192, 773, 7318, 13, 50712], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 158, "seek": 52444, "start": 531.6, "end": 532.8800000000001, "text": " Niewiarygodne. Dobrze.", "tokens": [50722, 426, 1093, 29104, 21787, 716, 13, 29679, 13503, 13, 50786], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 159, "seek": 52444, "start": 533.08, "end": 536.0400000000001, "text": " Mamy wi\u0119c ten surowy, pot\u0119\u017cny m\u00f3zg.", "tokens": [50796, 376, 7804, 16677, 2064, 1022, 10089, 11, 1847, 1274, 1427, 1634, 32515, 89, 70, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 160, "seek": 52444, "start": 536.24, "end": 538.5200000000001, "text": " Ale on jeszcze nie jest asystentem, prawda?", "tokens": [50954, 9366, 322, 14168, 2838, 3492, 382, 38593, 317, 443, 11, 43607, 30, 51068], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 161, "seek": 52444, "start": 538.72, "end": 541.08, "text": " Dok\u0142adnie. Nie potrafi prowadzi\u0107 rozmowy.", "tokens": [51078, 29768, 10358, 2766, 13, 12016, 1847, 10437, 72, 36590, 28496, 35234, 10089, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 162, "seek": 52444, "start": 541.2800000000001, "end": 542.9200000000001, "text": " Tutaj wkracza post-training.", "tokens": [51206, 41819, 261, 74, 12080, 2394, 2183, 12, 17227, 1760, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 163, "seek": 52444, "start": 543.12, "end": 544.8800000000001, "text": " Czyli cywilizowanie modelu.", "tokens": [51298, 37099, 3185, 86, 47043, 22028, 2316, 84, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 164, "seek": 52444, "start": 545.08, "end": 546.36, "text": " Mo\u017cna tak powiedzie\u0107.", "tokens": [51396, 44736, 629, 991, 27886, 13, 51460], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 165, "seek": 52444, "start": 546.5600000000001, "end": 553.08, "text": " G\u0142\u00f3wne techniki to supervised fine tuning, czyli SFT i nowsza, bardziej efektywna metoda", "tokens": [51470, 460, 1221, 3901, 716, 1537, 9850, 281, 46533, 2489, 15164, 11, 16591, 31095, 51, 741, 586, 82, 2394, 11, 27209, 31482, 916, 874, 86, 629, 1131, 13449, 51796], "temperature": 0.0, "avg_logprob": -0.1467004642365085, "compression_ratio": 1.3851132686084142, "no_speech_prob": 0.02253490686416626}, {"id": 166, "seek": 55308, "start": 553.12, "end": 556.32, "text": " Direct Preference Optimization, czyli DPO.", "tokens": [50366, 18308, 6001, 5158, 35013, 2144, 11, 16591, 413, 34885, 13, 50526], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 167, "seek": 55308, "start": 556.5200000000001, "end": 559.5600000000001, "text": " W pracy pojawia si\u0119 termin rejection sampling.", "tokens": [50536, 343, 35591, 30655, 654, 3244, 10761, 26044, 21179, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 168, "seek": 55308, "start": 559.76, "end": 560.76, "text": " Brzmi technicznie.", "tokens": [50698, 1603, 89, 3057, 1537, 17946, 2766, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 169, "seek": 55308, "start": 560.96, "end": 563.96, "text": " Ale idea jest prosta i bardzo skuteczna.", "tokens": [50758, 9366, 1558, 3492, 582, 8638, 741, 9034, 1110, 1169, 3689, 629, 13, 50908], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 170, "seek": 55308, "start": 564.1600000000001, "end": 566.24, "text": " To troch\u0119 jak casting do filmu.", "tokens": [50918, 1407, 24926, 4207, 17301, 360, 2007, 84, 13, 51022], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 171, "seek": 55308, "start": 566.44, "end": 568.72, "text": " O, ciekawe por\u00f3wnanie.", "tokens": [51032, 422, 11, 30596, 2330, 826, 1515, 812, 895, 7155, 13, 51146], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 172, "seek": 55308, "start": 568.9200000000001, "end": 573.72, "text": " Model na dane polecenie generuje powiedzmy 10 r\u00f3\u017cnych odpowiedzi.", "tokens": [51156, 17105, 1667, 49206, 13208, 13037, 414, 1337, 13008, 27617, 2226, 1266, 42602, 36574, 3992, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 173, "seek": 55308, "start": 573.9200000000001, "end": 575.6800000000001, "text": " 10 aktor\u00f3w.", "tokens": [51406, 1266, 13680, 284, 3901, 13, 51494], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 174, "seek": 55308, "start": 575.88, "end": 578.96, "text": " Nast\u0119pnie inny, mniejszy model,", "tokens": [51504, 42185, 18085, 2766, 294, 1634, 11, 39513, 7706, 2316, 11, 51658], "temperature": 0.0, "avg_logprob": -0.1915660174387806, "compression_ratio": 1.3601694915254237, "no_speech_prob": 0.007749735843390226}, {"id": 175, "seek": 57896, "start": 579.1600000000001, "end": 583.32, "text": " tak zwany Reward Modder, pe\u0142ni rol\u0119 re\u017cysera.", "tokens": [50374, 991, 11873, 1325, 1300, 1007, 6583, 1068, 11, 43205, 3722, 34109, 1274, 319, 1427, 749, 1663, 13, 50582], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 176, "seek": 57896, "start": 583.52, "end": 584.6, "text": " I wybiera najlepszego.", "tokens": [50592, 286, 45780, 10609, 41903, 1878, 27725, 13, 50646], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 177, "seek": 57896, "start": 584.8000000000001, "end": 590.48, "text": " Ocenia wszystkie 10 i wybiera t\u0119 jedn\u0105, kt\u00f3ra zagra\u0142a najlepiej.", "tokens": [50656, 422, 13037, 654, 31723, 1266, 741, 45780, 10609, 32489, 5232, 13113, 11, 19456, 27001, 424, 5024, 41903, 39699, 13, 50940], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 178, "seek": 57896, "start": 590.6800000000001, "end": 594.8000000000001, "text": " I tylko ta najlepsza odpowied\u017a jest u\u017cywana do dalszego treningu.", "tokens": [50950, 286, 13219, 1846, 41903, 1878, 2394, 36574, 10659, 3492, 34097, 86, 2095, 360, 274, 1124, 27725, 2192, 773, 84, 13, 51156], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 179, "seek": 57896, "start": 595.0, "end": 597.96, "text": " To taki wewn\u0119trzny mechanizm kontroli jako\u015bci.", "tokens": [51166, 1407, 20065, 321, 895, 1274, 6903, 89, 1634, 4236, 590, 76, 14373, 340, 2081, 17123, 6199, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 180, "seek": 57896, "start": 598.1600000000001, "end": 601.4000000000001, "text": " A jak wygl\u0105da\u0142o uczenie tych konkretnych zdolno\u015bci?", "tokens": [51324, 316, 4207, 32015, 5249, 344, 39043, 15180, 36500, 9399, 16221, 401, 16438, 30, 51486], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 181, "seek": 57896, "start": 601.6, "end": 603.44, "text": " Jak uczy si\u0119 modela my\u015blenia?", "tokens": [51496, 15029, 344, 6522, 3244, 2316, 64, 48633, 6698, 654, 30, 51588], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 182, "seek": 57896, "start": 603.64, "end": 605.96, "text": " To by\u0142 bardzo ukierunkowany proces.", "tokens": [51598, 1407, 16673, 9034, 26769, 811, 3197, 23341, 17565, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13149029658390926, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.03520392253994942}, {"id": 183, "seek": 60596, "start": 606.2, "end": 608.4000000000001, "text": " Na przyk\u0142ad w przypadku kodowania", "tokens": [50376, 6056, 23144, 261, 41955, 350, 378, 21308, 50486], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 184, "seek": 60596, "start": 608.6, "end": 612.76, "text": " generowano dane syntetyczne z tak zwanym execution feedback.", "tokens": [50496, 1337, 305, 3730, 49206, 23980, 2210, 38491, 710, 991, 11873, 1325, 76, 15058, 5824, 13, 50704], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 185, "seek": 60596, "start": 612.96, "end": 618.64, "text": " Czyli model pisa\u0142 kod, system pr\u00f3bowa\u0142 go uruchomi\u0107, a potem model dostawa\u0142", "tokens": [50714, 37099, 2316, 280, 3837, 1221, 350, 378, 11, 1185, 8565, 65, 30105, 352, 4038, 625, 9220, 2162, 11, 257, 36513, 2316, 20568, 10449, 1221, 50998], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 186, "seek": 60596, "start": 618.84, "end": 623.52, "text": " informacj\u0119 zwrotn\u0105, czy kod zadzia\u0142a\u0142, a je\u015bli nie, to jaki by\u0142 b\u0142\u0105d?", "tokens": [51008, 1356, 29924, 49111, 310, 13113, 11, 6430, 350, 378, 42788, 89, 25605, 1221, 11, 257, 25630, 2838, 11, 281, 24492, 16673, 272, 15926, 67, 30, 51242], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 187, "seek": 60596, "start": 623.72, "end": 626.6, "text": " Uczy\u0142 si\u0119 na w\u0142asnych, praktycznych b\u0142\u0119dach.", "tokens": [51252, 624, 6522, 1221, 3244, 1667, 43572, 9399, 11, 3206, 74, 874, 3689, 9399, 272, 1221, 6298, 608, 13, 51396], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 188, "seek": 60596, "start": 626.8000000000001, "end": 629.12, "text": " Genialne. A matematyka?", "tokens": [51406, 3632, 831, 716, 13, 316, 3803, 8615, 88, 2330, 30, 51522], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 189, "seek": 60596, "start": 629.32, "end": 633.8000000000001, "text": " Tutaj kluczowe by\u0142o generowanie rozwi\u0105za\u0144 krok po kroku,", "tokens": [51532, 41819, 9671, 1311, 89, 6880, 14811, 1337, 22028, 9544, 18234, 2394, 5248, 350, 31621, 714, 45909, 5279, 11, 51756], "temperature": 0.0, "avg_logprob": -0.14672690943667763, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.03254035860300064}, {"id": 190, "seek": 63380, "start": 634.0, "end": 638.0, "text": " a nast\u0119pnie u\u017cywanie mechanizm\u00f3w samo weryfikacji.", "tokens": [50374, 257, 39662, 2766, 34097, 86, 7155, 4236, 590, 76, 3901, 36422, 261, 2109, 31230, 13152, 13, 50574], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 191, "seek": 63380, "start": 638.1999999999999, "end": 641.56, "text": " Model sam sprawdza\u0142, czy jego \u015bcie\u017cka rozumowania ma sens.", "tokens": [50584, 17105, 3247, 46192, 2394, 1221, 11, 6430, 26542, 8299, 40082, 2330, 9544, 449, 21308, 463, 2923, 13, 50752], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 192, "seek": 63380, "start": 641.76, "end": 646.76, "text": " Uczono go nie tylko odpowiedzi, ale i poprawnego procesu my\u015blowego.", "tokens": [50762, 624, 3689, 8957, 352, 2838, 13219, 36574, 3992, 11, 6775, 741, 1665, 5131, 11858, 17565, 84, 452, 19212, 26576, 13, 51012], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 193, "seek": 63380, "start": 646.9599999999999, "end": 651.7199999999999, "text": " A co z tym gigantycznym, 128 tys. oknem kontekstowym?", "tokens": [51022, 316, 598, 710, 8107, 8741, 394, 17466, 12996, 11, 29810, 38156, 13, 3133, 25989, 14373, 916, 372, 31691, 30, 51260], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 194, "seek": 63380, "start": 651.92, "end": 657.04, "text": " M\u00f3wi\u0142e\u015b, \u017ce to by\u0142o wyzwanie, \u017ceby nie zepsu\u0107 wydajno\u015bci na kr\u00f3tkich zadaniach.", "tokens": [51270, 376, 3901, 72, 19827, 1788, 11, 3561, 281, 14811, 4628, 14406, 7155, 11, 11316, 2838, 710, 10653, 84, 2162, 25984, 1805, 16438, 1667, 42366, 83, 48349, 42788, 3782, 608, 13, 51526], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 195, "seek": 63380, "start": 657.24, "end": 661.1999999999999, "text": " I rozwi\u0105zanie tego problemu jest kolejnym zaskoczeniem.", "tokens": [51536, 286, 9544, 22620, 7155, 8627, 1154, 84, 3492, 23749, 12996, 710, 3863, 905, 2904, 4907, 13, 51734], "temperature": 0.0, "avg_logprob": -0.11424695361744273, "compression_ratio": 1.3763440860215055, "no_speech_prob": 0.00597178190946579}, {"id": 196, "seek": 66120, "start": 661.32, "end": 665.48, "text": " S\u0142ucham. Okaza\u0142o si\u0119, \u017ce wystarczy\u0142o doda\u0107 do danych treningowych.", "tokens": [50370, 318, 1221, 625, 335, 13, 3477, 12257, 5249, 3244, 11, 3561, 4628, 9710, 6522, 5249, 360, 2675, 2162, 360, 274, 34644, 2192, 773, 19605, 13, 50578], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 197, "seek": 66120, "start": 665.6800000000001, "end": 673.08, "text": " Na etapie post-training zaledwie 0,1% syntetycznych przyk\u0142ad\u00f3w z d\u0142ugim kontekstem.", "tokens": [50588, 6056, 47634, 414, 2183, 12, 17227, 1760, 710, 5573, 8699, 1958, 11, 16, 4, 23980, 2210, 3689, 9399, 23144, 3901, 710, 274, 34077, 332, 14373, 916, 1099, 13, 50958], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 198, "seek": 66120, "start": 673.2800000000001, "end": 676.44, "text": " Ciekaj, tylko 0,1%? Tak.", "tokens": [50968, 383, 19487, 1805, 11, 13219, 1958, 11, 16, 4, 30, 9118, 13, 51126], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 199, "seek": 66120, "start": 676.6400000000001, "end": 681.24, "text": " Taka mikroskopijna zmiana wystarczy\u0142a, by nauczy\u0107 go z zupe\u0142nie nowej,", "tokens": [51136, 314, 7849, 23959, 2635, 43855, 1718, 629, 17020, 8497, 4628, 9710, 6522, 5024, 11, 538, 49103, 27150, 352, 710, 49922, 586, 40779, 11, 51366], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 200, "seek": 66120, "start": 681.44, "end": 684.96, "text": " kluczowej umiej\u0119tno\u015bci, nie psuj\u0105c niczego innego.", "tokens": [51376, 9671, 1311, 89, 21091, 1105, 7764, 46788, 16438, 11, 2838, 18815, 44733, 6201, 27725, 294, 11858, 13, 51552], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 201, "seek": 66120, "start": 685.1600000000001, "end": 689.88, "text": " Absolutnie. To pokazuje, jak precyzyjna i wra\u017cliwa jest ta faza dostrajania.", "tokens": [51562, 5813, 2308, 2766, 13, 1407, 13010, 43317, 11, 4207, 659, 1344, 1229, 73, 629, 741, 7843, 1427, 2081, 4151, 3492, 1846, 4375, 64, 20568, 48690, 5609, 13, 51798], "temperature": 0.0, "avg_logprob": -0.15276980726686243, "compression_ratio": 1.3780918727915195, "no_speech_prob": 0.01569931022822857}, {"id": 202, "seek": 68988, "start": 690.08, "end": 695.24, "text": " Czasem minimalna, ale dobrze ukierunkowana interwencja mo\u017ce przynie\u015b\u0107 ogromne rezultaty.", "tokens": [50374, 383, 24561, 443, 13206, 629, 11, 6775, 28335, 26769, 811, 3197, 40458, 728, 15615, 34056, 12034, 6501, 2766, 7753, 34416, 298, 716, 48060, 723, 21398, 13, 50632], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 203, "seek": 68988, "start": 695.4399999999999, "end": 698.04, "text": " Niesamowite, jaka in\u017cenieria za tym stoi.", "tokens": [50642, 426, 530, 335, 305, 642, 11, 4207, 64, 294, 1427, 268, 811, 654, 7949, 8107, 342, 4869, 13, 50772], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 204, "seek": 68988, "start": 698.24, "end": 699.88, "text": " No dobrze, mamy wi\u0119c ten model.", "tokens": [50782, 883, 28335, 11, 17335, 16677, 2064, 2316, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 205, "seek": 68988, "start": 700.08, "end": 706.0, "text": " Jest pot\u0119\u017cny, dopracowany, ale jak Lama 3 wypada w starciu z GPT-4 czy Cloud?", "tokens": [50874, 24918, 1847, 1274, 1427, 1634, 11, 360, 1424, 326, 23341, 11, 6775, 4207, 441, 2404, 805, 46392, 1538, 261, 3543, 30795, 710, 26039, 51, 12, 19, 6430, 8061, 30, 51170], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 206, "seek": 68988, "start": 706.2, "end": 707.92, "text": " W\u0142a\u015bnie. Przejd\u017amy do wynik\u00f3w.", "tokens": [51180, 343, 5024, 12221, 13, 2114, 16920, 67, 10659, 2226, 360, 31936, 1035, 3901, 13, 51266], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 207, "seek": 68988, "start": 708.12, "end": 710.08, "text": " I tutaj historia ma jakby dwa oblicza.", "tokens": [51276, 286, 12749, 18385, 463, 28976, 35045, 1111, 1050, 2394, 13, 51374], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 208, "seek": 68988, "start": 710.28, "end": 713.4, "text": " To znaczy? Je\u015bli spojrzymy na standardowe akademickie", "tokens": [51384, 1407, 36584, 30, 37086, 8243, 73, 13047, 2226, 1667, 3832, 6880, 9308, 49290, 618, 414, 51540], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 209, "seek": 68988, "start": 713.6, "end": 717.44, "text": " benchmarki, Lama 3405B jest potwornie mocna.", "tokens": [51550, 18927, 72, 11, 441, 2404, 805, 5254, 20, 33, 3492, 1847, 86, 1865, 414, 34962, 629, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16299415096159905, "compression_ratio": 1.3758169934640523, "no_speech_prob": 0.0028476514853537083}, {"id": 210, "seek": 71744, "start": 717.6800000000001, "end": 719.24, "text": " W niekt\u00f3rych jest nawet liderem.", "tokens": [50376, 343, 2838, 43073, 627, 339, 3492, 22696, 10252, 7333, 13, 50454], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 211, "seek": 71744, "start": 719.44, "end": 723.7600000000001, "text": " Na przyk\u0142ad w te\u015bcie rozumowania matematycznego GSM 8K czy w testach kodowania", "tokens": [50464, 6056, 23144, 261, 535, 9815, 48797, 21308, 3803, 8615, 17466, 11858, 460, 26693, 1649, 42, 6430, 261, 1500, 608, 350, 378, 21308, 50680], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 212, "seek": 71744, "start": 723.96, "end": 726.5200000000001, "text": " jak HumanEval Plus, gdzie przewy\u017csza GPT-4.", "tokens": [50690, 4207, 10294, 36, 3337, 7721, 11, 18922, 39758, 88, 1427, 82, 2394, 26039, 51, 12, 19, 13, 50818], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 213, "seek": 71744, "start": 726.72, "end": 729.6, "text": " Czyli w specjalistycznych dziedzinach jest w czo\u0142\u00f3wce?", "tokens": [50828, 37099, 261, 46433, 468, 17466, 9399, 9758, 15338, 259, 608, 3492, 261, 269, 4765, 1221, 3901, 384, 30, 50972], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 214, "seek": 71744, "start": 729.8000000000001, "end": 733.24, "text": " W absolutnej, \u015bwiatowej czo\u0142\u00f3wce, ale wspomnia\u0142e\u015b o drugim obliczu.", "tokens": [50982, 343, 18757, 11794, 11, 36425, 21091, 269, 4765, 1221, 3901, 384, 11, 6775, 17757, 38131, 8908, 68, 1788, 277, 4110, 332, 1111, 1050, 11728, 13, 51154], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 215, "seek": 71744, "start": 733.44, "end": 738.5600000000001, "text": " Tak. Ewaluacje przeprowadzane przez ludzi, gdzie ocenia si\u0119 og\u00f3ln\u0105 pomocno\u015b\u0107", "tokens": [51164, 9118, 13, 28101, 4929, 29293, 30829, 1892, 345, 89, 1929, 14064, 29586, 11, 18922, 10409, 268, 654, 3244, 5360, 15741, 13113, 48962, 23293, 51420], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 216, "seek": 71744, "start": 738.7600000000001, "end": 741.5200000000001, "text": " odpowiedzi, pokazuj\u0105 bardziej zniuansowany obraz.", "tokens": [51430, 36574, 3992, 11, 13010, 921, 13263, 27209, 710, 3722, 84, 599, 23341, 22798, 89, 13, 51568], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 217, "seek": 71744, "start": 741.72, "end": 746.08, "text": " Tutaj Lama 3405B jest na r\u00f3wni z GPT-4, ale ma", "tokens": [51578, 41819, 441, 2404, 805, 5254, 20, 33, 3492, 1667, 11416, 895, 72, 710, 26039, 51, 12, 19, 11, 6775, 463, 51796], "temperature": 0.0, "avg_logprob": -0.15358373097011022, "compression_ratio": 1.4156626506024097, "no_speech_prob": 0.0012511331588029861}, {"id": 218, "seek": 74608, "start": 746.08, "end": 752.6, "text": " mieszane wyniki w por\u00f3wnaniu z najnowszymi modelami jak GPT-4O czy Cloth 3.5 Sonet.", "tokens": [50364, 33039, 1929, 31936, 9850, 261, 1515, 812, 895, 25849, 710, 11212, 77, 1509, 1229, 3057, 2316, 4526, 4207, 26039, 51, 12, 19, 46, 6430, 2033, 900, 805, 13, 20, 5185, 302, 13, 50690], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 219, "seek": 74608, "start": 752.8000000000001, "end": 756.4000000000001, "text": " Czyli era jednego uniwersalnie najlepszego modelu do", "tokens": [50700, 37099, 4249, 5232, 11858, 36435, 5364, 304, 2766, 41903, 1878, 27725, 2316, 84, 360, 50880], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 220, "seek": 74608, "start": 756.6, "end": 759.48, "text": " wszystkiego mog\u0142a si\u0119 sko\u0144czy\u0107 zanim na dobre si\u0119 zacz\u0119\u0142a?", "tokens": [50890, 14615, 12200, 13172, 5024, 3244, 1110, 78, 5248, 33967, 710, 17869, 1667, 41959, 3244, 34430, 11052, 5024, 30, 51034], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 221, "seek": 74608, "start": 759.6800000000001, "end": 761.12, "text": " Dok\u0142adnie. Taka jest konkluzja.", "tokens": [51044, 29768, 10358, 2766, 13, 314, 7849, 3492, 21428, 2781, 89, 2938, 13, 51116], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 222, "seek": 74608, "start": 761.32, "end": 764.5200000000001, "text": " Wyb\u00f3r modelu coraz bardziej zale\u017cy od konkretnego zastosowania.", "tokens": [51126, 14458, 65, 15614, 2316, 84, 25899, 27209, 710, 37169, 3611, 36500, 11858, 36746, 329, 21308, 13, 51286], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 223, "seek": 74608, "start": 764.72, "end": 766.0400000000001, "text": " Nie ma ju\u017c jednego kr\u00f3la.", "tokens": [51296, 12016, 463, 10678, 5232, 11858, 42366, 875, 13, 51362], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 224, "seek": 74608, "start": 766.24, "end": 767.64, "text": " A co z multimodalno\u015bci\u0105?", "tokens": [51372, 316, 598, 710, 32972, 378, 304, 16438, 1611, 30, 51442], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 225, "seek": 74608, "start": 767.84, "end": 769.24, "text": " \u015awiat to nie tylko tekst.", "tokens": [51452, 27933, 6253, 267, 281, 2838, 13219, 16624, 372, 13, 51522], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 226, "seek": 74608, "start": 769.44, "end": 772.24, "text": " Tutaj meta podesz\u0142a do tego bardzo sprytnie", "tokens": [51532, 41819, 19616, 2497, 10430, 5024, 360, 8627, 9034, 637, 627, 83, 2766, 51672], "temperature": 0.0, "avg_logprob": -0.12400225321451823, "compression_ratio": 1.4158415841584158, "no_speech_prob": 0.0031230454333126545}, {"id": 227, "seek": 77224, "start": 772.36, "end": 776.44, "text": " stosuj\u0105c tak zwane podej\u015bcie kompozycyjne compositional approach.", "tokens": [50370, 43581, 44733, 991, 11873, 1929, 7468, 73, 9815, 5207, 2259, 1229, 42949, 716, 10199, 2628, 3109, 13, 50574], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 228, "seek": 77224, "start": 776.64, "end": 777.32, "text": " Jak to dzia\u0142a?", "tokens": [50584, 15029, 281, 37903, 30, 50618], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 229, "seek": 77224, "start": 777.52, "end": 782.84, "text": " Zamlast trenowa\u0107 od zera jeden gigantyczny potwornie drogi model, kt\u00f3ry rozumie wszystko,", "tokens": [50628, 45492, 15459, 23136, 11445, 3611, 710, 1663, 12906, 8741, 394, 17466, 1634, 1847, 86, 1865, 414, 3789, 7834, 2316, 11, 9913, 48797, 414, 22607, 11, 50894], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 230, "seek": 77224, "start": 783.04, "end": 784.64, "text": " zrobili co\u015b innego.", "tokens": [50904, 44399, 2312, 19241, 294, 11858, 13, 50984], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 231, "seek": 77224, "start": 784.84, "end": 789.0, "text": " Wzi\u0119li swoj\u0105 wytrenowan\u0105 tekstow\u0105 Lama 3", "tokens": [50994, 343, 16706, 2081, 49194, 261, 4328, 1095, 37345, 1611, 16624, 372, 30297, 441, 2404, 805, 51202], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 232, "seek": 77224, "start": 789.2, "end": 792.12, "text": " i do\u0142\u0105czyli do niej modu\u0142y do obrazu i mowy.", "tokens": [51212, 741, 360, 15926, 6522, 2081, 360, 2838, 73, 1072, 84, 6825, 360, 22798, 11728, 741, 275, 10089, 13, 51358], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 233, "seek": 77224, "start": 792.32, "end": 798.84, "text": " Dok\u0142adnie. Za pomoc\u0105 specjalnych, lekkich adapter\u00f3w do\u0142\u0105czyli do niej inne ju\u017c", "tokens": [51368, 29768, 10358, 2766, 13, 31440, 48962, 1611, 46433, 9399, 11, 476, 12809, 480, 22860, 3901, 360, 15926, 6522, 2081, 360, 2838, 73, 24170, 10678, 51694], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 234, "seek": 77224, "start": 799.04, "end": 800.6800000000001, "text": " wcze\u015bniej wytrenowane modu\u0142y.", "tokens": [51704, 40785, 261, 4328, 1095, 23066, 1072, 84, 6825, 13, 51786], "temperature": 0.0, "avg_logprob": -0.17874992594999425, "compression_ratio": 1.4551971326164874, "no_speech_prob": 0.055013034492731094}, {"id": 235, "seek": 80068, "start": 800.8399999999999, "end": 804.92, "text": " Czyli zamiast budowa\u0107 nowy, uniwersalny samoch\u00f3d po prostu doczepili za", "tokens": [50372, 37099, 710, 4526, 525, 3265, 11445, 586, 88, 11, 36435, 5364, 304, 1634, 3247, 8997, 17081, 714, 19518, 3211, 46342, 2312, 7949, 50576], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 236, "seek": 80068, "start": 805.12, "end": 808.16, "text": " awansowan\u0105 przyczep\u0119 do swojej sprawdzonej ci\u0119\u017car\u00f3wki.", "tokens": [50586, 1714, 599, 37345, 1611, 6501, 3689, 595, 1274, 360, 29489, 73, 46192, 16896, 73, 35484, 1427, 289, 3901, 2984, 13, 50738], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 237, "seek": 80068, "start": 808.3599999999999, "end": 810.3199999999999, "text": " To idealna analogia.", "tokens": [50748, 1407, 7157, 629, 16660, 654, 13, 50846], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 238, "seek": 80068, "start": 810.52, "end": 815.0, "text": " To rozwi\u0105zanie jest o wiele bardziej efektywne i chroni wydajno\u015b\u0107 tekstow\u0105", "tokens": [50856, 1407, 9544, 22620, 7155, 3492, 277, 33137, 27209, 31482, 916, 874, 86, 716, 741, 19393, 72, 25984, 1805, 23293, 16624, 372, 30297, 51080], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 239, "seek": 80068, "start": 815.1999999999999, "end": 816.64, "text": " oryginalnego modelu.", "tokens": [51090, 420, 88, 1494, 304, 11858, 2316, 84, 13, 51162], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 240, "seek": 80068, "start": 816.8399999999999, "end": 818.88, "text": " A wyliki s\u0105 bardzo obiecuj\u0105ce.", "tokens": [51172, 316, 4628, 75, 9850, 9015, 9034, 1111, 35733, 13263, 384, 13, 51274], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 241, "seek": 80068, "start": 819.0799999999999, "end": 824.76, "text": " Ich model Lama 3V przewy\u017csza GPT-4V we wszystkich testowanych benchmarkach", "tokens": [51284, 3141, 2316, 441, 2404, 805, 53, 39758, 88, 1427, 82, 2394, 26039, 51, 12, 19, 53, 321, 34234, 1500, 23341, 339, 18927, 608, 51568], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 242, "seek": 80068, "start": 824.9599999999999, "end": 825.4799999999999, "text": " wizualnych.", "tokens": [51578, 40808, 901, 9399, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 243, "seek": 80068, "start": 825.68, "end": 827.92, "text": " Pozostaje jeszcze kwestia bezpiecze\u0144stwa.", "tokens": [51614, 6165, 89, 555, 11153, 14168, 42035, 654, 47153, 9680, 12229, 4151, 13, 51726], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 244, "seek": 80068, "start": 828.12, "end": 829.1999999999999, "text": " To gor\u0105cy temat.", "tokens": [51736, 1407, 24012, 1611, 1344, 32954, 13, 51790], "temperature": 0.0, "avg_logprob": -0.1333585029993302, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0018613659776747227}, {"id": 245, "seek": 82920, "start": 829.4000000000001, "end": 831.6800000000001, "text": " Tutaj te\u017c wida\u0107 kompleksowe podej\u015bcie.", "tokens": [50374, 41819, 9516, 261, 46898, 5207, 781, 1694, 6880, 7468, 73, 9815, 13, 50488], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 246, "seek": 82920, "start": 831.88, "end": 835.12, "text": " Zacz\u0119li odfiltrowania danych ju\u017c na etapie pre-training.", "tokens": [50498, 48082, 11052, 2081, 3611, 69, 2352, 1892, 5609, 274, 34644, 10678, 1667, 47634, 414, 659, 12, 17227, 1760, 13, 50660], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 247, "seek": 82920, "start": 835.32, "end": 840.12, "text": " Potem w fazie dostrajania zastosowali specjalny safety fine tuning.", "tokens": [50670, 9145, 443, 261, 4375, 414, 20568, 48690, 5609, 36746, 329, 305, 5103, 46433, 1634, 4514, 2489, 15164, 13, 50910], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 248, "seek": 82920, "start": 840.32, "end": 841.24, "text": " Jaki by\u0142 cel?", "tokens": [50920, 508, 7421, 16673, 9277, 30, 50966], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 249, "seek": 82920, "start": 841.44, "end": 843.2, "text": " Znalezienie z\u0142otego \u015brodka.", "tokens": [50976, 1176, 77, 37646, 27385, 31614, 310, 6308, 28580, 2330, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 250, "seek": 82920, "start": 843.4000000000001, "end": 848.08, "text": " Model ma blokowa\u0107 szkodliwe tre\u015bci, ale z drugiej strony unika\u0107 absurdalnych,", "tokens": [51074, 17105, 463, 888, 453, 11445, 7870, 74, 378, 2081, 826, 2192, 6199, 11, 6775, 710, 47373, 32406, 517, 5439, 2162, 19774, 304, 9399, 11, 51308], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 251, "seek": 82920, "start": 848.2800000000001, "end": 851.08, "text": " frustruj\u0105cych odm\u00f3w na zupe\u0142nie niebezpieczne pytania.", "tokens": [51318, 7454, 894, 8555, 31306, 3611, 76, 3901, 1667, 49922, 2838, 650, 89, 9144, 38491, 25878, 5609, 13, 51458], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 252, "seek": 82920, "start": 851.2800000000001, "end": 853.6, "text": " I do tego dochodzi jeszcze osobne narz\u0119dzie, prawda?", "tokens": [51468, 286, 360, 8627, 9243, 14543, 14168, 41518, 716, 6714, 89, 42643, 11, 43607, 30, 51584], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 253, "seek": 82920, "start": 853.8000000000001, "end": 856.48, "text": " Tak, udost\u0119pnili Lama Guard 3.", "tokens": [51594, 9118, 11, 11727, 555, 18085, 77, 2312, 441, 2404, 11549, 805, 13, 51728], "temperature": 0.0, "avg_logprob": -0.13652353097271447, "compression_ratio": 1.3860759493670887, "no_speech_prob": 0.0010560819646343589}, {"id": 254, "seek": 85648, "start": 856.48, "end": 860.16, "text": " To osobny, znacznie mniejszy model klasyfikator.", "tokens": [50364, 1407, 41518, 1634, 11, 15397, 14875, 2766, 39513, 7706, 2316, 9671, 5871, 31230, 1639, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 255, "seek": 85648, "start": 860.36, "end": 865.4, "text": " Mo\u017ce dzia\u0142a\u0107 jako dodatkowa, zewn\u0119trzna warstwa ochronna, taki stra\u017cnik.", "tokens": [50558, 43774, 37903, 2162, 17123, 13886, 33525, 5528, 11, 5277, 895, 1274, 6903, 35458, 1516, 372, 4151, 3795, 2044, 629, 11, 20065, 2148, 1427, 13123, 13, 50810], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 256, "seek": 85648, "start": 865.6, "end": 871.6800000000001, "text": " Podsumowuj\u0105c historia Lama 3 to opowie\u015b\u0107 o pot\u0119dze skali, ale te\u017c o niemal", "tokens": [50820, 12646, 82, 449, 305, 44733, 18385, 441, 2404, 805, 281, 999, 13998, 7753, 277, 1847, 1274, 67, 1381, 1110, 5103, 11, 6775, 9516, 277, 2838, 5579, 51124], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 257, "seek": 85648, "start": 871.88, "end": 875.16, "text": " rzemie\u015blniczym obsesyjnym skupieniu na jako\u015bci danych.", "tokens": [51134, 367, 24313, 414, 19212, 7692, 26681, 3181, 17823, 73, 12996, 1110, 1010, 1053, 5951, 1667, 17123, 6199, 274, 34644, 13, 51298], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 258, "seek": 85648, "start": 875.36, "end": 880.04, "text": " Zdecydowanie sukces tego modelu nie wzi\u0105\u0142 si\u0119 z rewolucji, ale z dopracowania do", "tokens": [51308, 1176, 1479, 1344, 67, 22028, 46432, 887, 8627, 2316, 84, 2838, 261, 3992, 1611, 1221, 3244, 710, 319, 48481, 1311, 4013, 11, 6775, 710, 360, 1424, 326, 21308, 360, 51542], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 259, "seek": 85648, "start": 880.24, "end": 885.64, "text": " perfekcji istniej\u0105cych metod i no tytanicznego wysi\u0142ku in\u017cynieryjnego.", "tokens": [51552, 13826, 916, 19649, 1418, 2766, 8555, 31306, 1131, 378, 741, 572, 1104, 20356, 17946, 11858, 27062, 40622, 5279, 294, 1427, 2534, 811, 88, 73, 11858, 13, 51822], "temperature": 0.0, "avg_logprob": -0.1448576158092868, "compression_ratio": 1.412751677852349, "no_speech_prob": 0.027092596516013145}, {"id": 260, "seek": 88564, "start": 885.84, "end": 888.96, "text": " Sami autorzy sugeruj\u0105, \u017ce to dopiero pocz\u0105tek drogi.", "tokens": [50374, 44029, 19510, 1229, 459, 1321, 13263, 11, 3561, 281, 21900, 12030, 34397, 916, 3789, 7834, 13, 50530], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 261, "seek": 88564, "start": 889.16, "end": 894.72, "text": " Tak, pisz\u0105, \u017ce znacz\u0105ce dalsze ulepszenia s\u0105 na horyzumcie i podkre\u015blaj\u0105, \u017ce najlepsze", "tokens": [50540, 9118, 11, 26584, 8925, 11, 3561, 15397, 326, 8925, 384, 274, 1124, 1381, 344, 306, 1878, 14320, 9015, 1667, 276, 827, 89, 449, 4260, 741, 2497, 27885, 1788, 875, 8555, 11, 3561, 41903, 1878, 1381, 50818], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 262, "seek": 88564, "start": 894.92, "end": 898.0, "text": " rezultaty osi\u0105gn\u0119li trzymaj\u0105c si\u0119 prostoty.", "tokens": [50828, 48060, 723, 21398, 3003, 11404, 4568, 1274, 2081, 34573, 1696, 8555, 66, 3244, 10293, 6737, 13, 50982], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 263, "seek": 88564, "start": 898.1999999999999, "end": 900.12, "text": " I to prowadzi mnie do my\u015bli na koniec.", "tokens": [50992, 286, 281, 36590, 3992, 17661, 360, 452, 15350, 1667, 5897, 35733, 13, 51088], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 264, "seek": 88564, "start": 900.3199999999999, "end": 904.68, "text": " W raporcie pada jedno pozornie techniczne zdanie, kt\u00f3re mo\u017ce by\u0107 najwa\u017cniejsze w", "tokens": [51098, 343, 5099, 284, 4260, 26069, 5232, 1771, 21281, 1865, 414, 1537, 17946, 716, 16221, 7155, 11, 8864, 12034, 15069, 11212, 27111, 44258, 261, 51316], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 265, "seek": 88564, "start": 904.88, "end": 906.28, "text": " ca\u0142ym dokumencie. Kt\u00f3re?", "tokens": [51326, 35224, 4199, 25037, 16988, 4260, 13, 591, 4547, 265, 30, 51396], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 266, "seek": 88564, "start": 906.48, "end": 912.08, "text": " M\u00f3wi o tym, \u017ce kluczowe dla sukcesu projektu by\u0142y decyzje organizacyjne.", "tokens": [51406, 376, 3901, 72, 277, 8107, 11, 3561, 9671, 1311, 89, 6880, 12285, 46432, 887, 84, 26261, 84, 26366, 979, 37433, 2884, 4645, 31285, 716, 13, 51686], "temperature": 0.0, "avg_logprob": -0.10518042869817197, "compression_ratio": 1.4358108108108107, "no_speech_prob": 0.0024262131191790104}, {"id": 267, "seek": 91208, "start": 912.32, "end": 919.44, "text": " Np. \u015bwiadome i rygorystyczne oddzielenie zespo\u0142u pozyskuj\u0105cego dane od zespo\u0142u buduj\u0105cego model.", "tokens": [50376, 426, 79, 13, 21485, 345, 423, 741, 367, 18103, 827, 372, 17466, 716, 7401, 89, 12844, 414, 710, 279, 2259, 24066, 21281, 749, 74, 13263, 384, 1571, 49206, 3611, 710, 279, 2259, 24066, 3265, 13263, 384, 1571, 2316, 13, 50732], "temperature": 0.0, "avg_logprob": -0.13463225084192612, "compression_ratio": 1.4095940959409594, "no_speech_prob": 0.001363513176329434}, {"id": 268, "seek": 91208, "start": 919.64, "end": 924.6800000000001, "text": " Aha, \u017ceby unikn\u0105\u0107 zanieczyszczenia danych treningowych benchmarkami.", "tokens": [50742, 27448, 11, 11316, 517, 1035, 13113, 2162, 710, 7155, 3689, 20589, 38517, 274, 34644, 2192, 773, 19605, 18927, 4526, 13, 50994], "temperature": 0.0, "avg_logprob": -0.13463225084192612, "compression_ratio": 1.4095940959409594, "no_speech_prob": 0.001363513176329434}, {"id": 269, "seek": 91208, "start": 924.88, "end": 927.12, "text": " Dok\u0142adnie. I to prowadzi do", "tokens": [51004, 29768, 10358, 2766, 13, 286, 281, 36590, 3992, 360, 51116], "temperature": 0.0, "avg_logprob": -0.13463225084192612, "compression_ratio": 1.4095940959409594, "no_speech_prob": 0.001363513176329434}, {"id": 270, "seek": 91208, "start": 927.32, "end": 930.6, "text": " fascynuj\u0105cego pytania, kt\u00f3re wykracza daleko poza technologi\u0119.", "tokens": [51126, 30632, 1344, 77, 13263, 384, 1571, 25878, 5609, 11, 8864, 39287, 12080, 2394, 11702, 34241, 714, 2394, 1537, 1132, 5034, 13, 51290], "temperature": 0.0, "avg_logprob": -0.13463225084192612, "compression_ratio": 1.4095940959409594, "no_speech_prob": 0.001363513176329434}, {"id": 271, "seek": 91208, "start": 930.8000000000001, "end": 938.12, "text": " Czy w miar\u0119, jak modele staj\u0105 si\u0119 pot\u0119\u017cniejsze, nast\u0119pn\u0105 granic\u0105 rozwoju AI nie s\u0105 ju\u017c tylko algorytmy?", "tokens": [51300, 19832, 261, 2752, 289, 1274, 11, 4207, 4391, 306, 342, 11133, 3244, 1847, 1274, 1427, 44258, 11, 39662, 13113, 9370, 299, 1611, 9544, 6120, 8954, 7318, 2838, 9015, 10678, 13219, 3501, 827, 83, 2226, 30, 51666], "temperature": 0.0, "avg_logprob": -0.13463225084192612, "compression_ratio": 1.4095940959409594, "no_speech_prob": 0.001363513176329434}, {"id": 272, "seek": 93812, "start": 938.32, "end": 943.0, "text": " Ale w\u0142a\u015bnie ludzkie i organizacyjne struktury, kt\u00f3re wok\u00f3\u0142 nich budujemy.", "tokens": [50374, 9366, 14234, 15946, 89, 22872, 741, 4645, 31285, 716, 342, 19977, 2598, 11, 8864, 40022, 16181, 25570, 3265, 21767, 13, 50608], "temperature": 0.0, "avg_logprob": -0.12847645408228825, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.029003862291574478}, {"id": 273, "seek": 93812, "start": 943.2, "end": 949.04, "text": " W\u0142a\u015bnie. Jak zaprojektowa\u0107 firm\u0119, procesy, zespo\u0142y, by by\u0142y w stanie zbudowa\u0107 obiektywn\u0105,", "tokens": [50618, 343, 5024, 12221, 13, 15029, 14223, 340, 14930, 11445, 6174, 1274, 11, 17565, 88, 11, 710, 279, 2259, 6825, 11, 538, 26366, 261, 40013, 710, 18281, 11445, 1111, 19487, 874, 895, 1611, 11, 50910], "temperature": 0.0, "avg_logprob": -0.12847645408228825, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.029003862291574478}, {"id": 274, "seek": 93812, "start": 949.24, "end": 952.68, "text": " godn\u0105 zaufania i naprawd\u0119 inteligentn\u0105 maszyn\u0119?", "tokens": [50920, 3044, 13113, 710, 9507, 5609, 741, 20970, 24777, 25002, 13113, 2300, 1229, 77, 1274, 30, 51092], "temperature": 0.0, "avg_logprob": -0.12847645408228825, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.029003862291574478}, {"id": 275, "seek": 93812, "start": 952.88, "end": 955.88, "text": " By\u0107 mo\u017ce to jest prawdziwe wyzwanie na nast\u0119pn\u0105 dekad\u0119.", "tokens": [51102, 3146, 2162, 12034, 281, 3492, 41175, 3992, 826, 4628, 14406, 7155, 1667, 39662, 13113, 368, 34985, 1274, 13, 51252], "temperature": 0.0, "avg_logprob": -0.12847645408228825, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.029003862291574478}], "language": "pl"}