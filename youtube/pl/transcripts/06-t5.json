{"text": " Pomy\u015blmy o tej klasycznej fantazji z Science Fiction, uniwersalny translator. M\u00f3wisz do niego, a on od razu wszystko t\u0142umaczy. Ale co je\u015bli poszliby\u015bmy okrok dalej? Co je\u015bli to samo urz\u0105dzenie mog\u0142oby, no wiesz, strze\u015bci\u0107 artyku\u0142, odpowiedzie\u0107 na pytanie, oceni\u0107 gramatyk\u0119? Jakby ka\u017cde zadanie j\u0119zykowe da\u0142o si\u0119 sprowadzi\u0107 do jednego prostego formatu. Tekst na wej\u015bciu, tekst na wyj\u015bciu. Dzi\u015b bierzemy na warsztat prace, kt\u00f3ra dok\u0142adnie to zaproponowa\u0142a i no c\u00f3\u017c, wstrz\u0105s\u0142a \u015bwiatem AI. Mowa o artykule z Google Research, exploring the limits of transfer learning with a unified text-to-text transformer. A cel jaki sobie postawili by\u0142 od razu do\u015b\u0107 nietypowy. Nie chcieli wymy\u015ble\u0107 ko\u0142a na nowo. Zamiast tego zrobili co\u015b w rodzaju najwi\u0119kszego w historii testu por\u00f3wnawczego. Ich misj\u0105 by\u0142o znalezienie tego ostatecznego, najlepszego przepisu. I kluczem do tego wszystkiego jest w\u0142a\u015bnie ta idea, kt\u00f3r\u0105 poruszy\u0142a\u015b na pocz\u0105tku. Framework, kt\u00f3ry nazwali tekst-to-text. Zamiast budowa\u0107 ca\u0142\u0105 armi\u0119 wyspecjalizowanych moteli, jeden do t\u0142umacze\u0144, drugi do sentymentu, trzeci do czego\u015b innego, postawili wszystko na jedn\u0105 kart\u0119. Stwierdzili, ka\u017cdy problem da si\u0119 tak naprawd\u0119 potraktowa\u0107 jako zadanie generowania tekstu. Czekaj, jak to w\u0142a\u015bciwie dzia\u0142a? Bo na pierwszy rzut oka, no nie wiem, t\u0142umaczenie i klasyfikacja zdania to s\u0105 dwa zupe\u0142nie r\u00f3\u017cne \u015bwiaty. Dok\u0142adnie. Ale oni znale\u017ali spos\u00f3b, \u017ceby to po\u0142\u0105czy\u0107. W artykule daj\u0105 \u015bwietne, proste przyk\u0142ady. Chcesz co\u015b przet\u0142umaczy\u0107? Dajesz modelowi komend\u0119. Zwyk\u0142y tekst. Translate English to German. That is good. I oczekujesz, \u017ce on po prostu wygeneruje w odpowiedzi. Thus is good. OK. Chcesz sprawdzi\u0107 gramatyk\u0119? Dajesz mu co\u015b w stylu? I model ma odpowiedzie\u0107 jednym s\u0142owem. Not acceptable. A straszczenie. Summarize. I tu wklejasz ca\u0142y d\u0142ugi artyku\u0142, a model generuje zwi\u0119z\u0142e podsumowanie. Czyli ca\u0142y tryk polega na tym, \u017ceby nauczy\u0107 model, co oznaczaj\u0105 te pocz\u0105tkowe, magiczne s\u0142owa. Translate, summarize itd. Reszta to ju\u017c tylko generowanie tekstu. W\u0142a\u015bnie. I to radykalnie upraszcza wszystko. Nagle mamy jeden model, jedn\u0105 architektur\u0119, jedn\u0105 metod\u0119 trenowania. Dla dziesi\u0105tek r\u00f3\u017cnych zada\u0144. A to stworzy\u0142o im idealne, kontrolowane \u015brodowisko do eksperyment\u00f3w. Co by\u0142o przecie\u017c g\u0142\u00f3wnym celem tej pracy? OK, ale \u017ceby wytrenowa\u0107 taki wszechstronny model. Potrzeba paliwa. I to nie byle jakiego. Domy\u015blam si\u0119, \u017ce m\u00f3wimy tu o astronomicznych ilo\u015bciach danych. M\u00f3wimy o czym\u015b, co nazwali Colossal Clean Crawled Corpus. W skr\u00f3cie C4. To jest zbi\u00f3r danych o rozmiarze uwaga 750 GB. Wow. \u017beby da\u0107 jak\u0105\u015b skal\u0119, to odpowiednik setek tysi\u0119cy ksi\u0105\u017cek. Ale co wa\u017cniejsze, to nie jest po prostu \u015bmietnik z internetu. To dane starannie przefiltrowane. I z tego, co czyta\u0142am, niekt\u00f3re z tych filtr\u00f3w by\u0142y do\u015b\u0107... kreatywne. Oj, zdecydowanie. To nie by\u0142o proste filtrowanie. Na przyk\u0142ad automatycznie wyrzucali ka\u017cd\u0105 stron\u0119, kt\u00f3ra zawiera\u0142a fraz\u0119 Loren Ipsum. \u017beby pozby\u0107 si\u0119 szablon\u00f3w. Dok\u0142adnie. Tekst\u00f3w wype\u0142niaczy. Inna sprytna zasada. Odrzucali strony zawieraj\u0105ce nawias klamrowy. Bo to niemal zawsze oznacza kod programu, a nie naturalny j\u0119zyk. To ma sens. Model ma si\u0119 uczy\u0107 pisa\u0107 jak cz\u0142owiek, nie jak programista. Do tego dochodzi\u0142y bardziej subtelne filtry. Zachowywano tylko strony, kt\u00f3re mia\u0142y co najmniej pi\u0119\u0107 zda\u0144. A ka\u017cde musia\u0142o si\u0119 ko\u0144czy\u0107 kropk\u0105, wykrzykniciem lub znakiem zapytania. To prosty, ale skuteczny spos\u00f3b na odsianie nowie\u017c list zakup\u00f3w czy menu nawigacyjnych. No i co istotne, pozbyli si\u0119 stron zawieraj\u0105cych s\u0142owa z obszernej listy wulgaryzm\u00f3w. Dobrze, czyli dane mamy z g\u0142owy. Gigantyczne, ale posprz\u0105tany internet. A co z silnikiem? Czy tutaj te\u017c postawili na co\u015b zupe\u0142nie nowego, czy na tej ulepszyli to, co ju\u017c by\u0142o? I tu dochodzimy do pierwszego, ma\u0142ego zaskoczenia. Ca\u0142y \u015bwiat AI fascynowa\u0142 si\u0119 wtedy dwoma podej\u015bciami. Z jednej strony mieli\u015bmy modele typu encoder only, jak BERT. \u015awietne do rozumienia tekstu, do klasyfikacji. Z drugiej modele decoder only, jak GPT, kt\u00f3re by\u0142y mistrzami w generowaniu. No tak, wydawa\u0142oby si\u0119, \u017ce trzeba wybra\u0107 jedn\u0105 z tych dr\u00f3g, albo rozumienie, albo generowanie. A badaczy z Google powiedzieli, sprawdzam i wr\u00f3cili do klasyki. Postawili nas standardow\u0105 architektur\u0119 Transformer z obiema cz\u0119\u015bciami, encodelen i decoderem. I okaza\u0142o si\u0119, \u017ce ten stary dobry pomys\u0142 w ich nowym frameworku text-to-text bije na g\u0142ow\u0119 te nowocze\u015bniejsze, wyspecjalizowane alternatywy. Encoder m\u00f3g\u0142 zrozumie\u0107 tekst wej\u015bciowy, a decoder wygenerowa\u0107 odpowied\u017a. Dawa\u0142o im to elastyczno\u015b\u0107. W\u0142a\u015bnie. Co ciekawe, przetestowali te\u017c wersj\u0119 ze wsp\u00f3\u0142dzielonymi wagami mi\u0119dzy obiema cz\u0119\u015bciami, co zmniejszy\u0142o liczb\u0119 parametr\u00f3w o po\u0142ow\u0119, a wyniki by\u0142y niemal r\u00f3wnie dobre. To by\u0142 mocny sygna\u0142 w kierunku efektywno\u015bci. Czekaj, zatrzymajmy si\u0119 na chwil\u0119. Skoro ten korpus C4 to po prostu surowy tekst z internetu, bez \u017cadnych etykiet typu to jest dobre streszczenie, a to z\u0142e, to sk\u0105d model w og\u00f3le ma wiedzie\u0107, co jest dobr\u0105, a co z\u0142\u0105 odpowiedzi\u0105? Jak\u0105 si\u0119 czegokolwiek uczy na tym pierwszym, najwa\u017cniejszym etapie? To jest \u015bwietne pytanie i sedno ca\u0142ego pretrainingu. Zadanie, kt\u00f3re wymy\u015blili, nazywa si\u0119 dinoising, czyli odszumianie. Wyobra\u017a sobie, \u017ce bierzesz idealnie czysty, gramatyczny tekst z C4, a potem celowo go niszczysz. Ich metoda nazywa\u0142a si\u0119 span corruption. Losowo wycinali ca\u0142e fragmenty zda\u0144, spany i w ich dysce wstawiali taki pojedynczy, unikalny znacznik. Czyli dawali modelowi tekst z dziurami. I kazali mu odgadno\u015b\u0107, co w tych dziurach by\u0142o. Musia\u0142 na podstawie kontekstu wygenerowa\u0107 brakuj\u0105ce s\u0142owa w dobrej kolejno\u015bci. To jak taka ekstremalnie trudna wersja uzupe\u0142niania Luke w tek\u015bcie. Robi\u0105c to miliardy razy na zr\u00f3\u017cnicowanych danych, model jest zmuszony nauczy\u0107 si\u0119 gramatyki, logiki no i w ko\u0144cu ogromnej ilo\u015bci wiedzy o \u015bwiecie. Ta metoda okaza\u0142a si\u0119 te\u017c znacznie bardziej wydajna obliczeniowo, ni\u017c popularne wtedy maskowanie pojedynczych s\u0142\u00f3w jak w modelu Bert. Okej, rozpakujmy to. To jest jak wielkie \u015bledztwo. Mieli kilku podejrzanych architektur\u0119, dane, strategi\u0119 treningu. I musieli systematycznie sprawdza\u0107, kt\u00f3ry jest kluczowy. Mieli solidny fundament, wi\u0119c mogli zacz\u0105\u0107 wielkie testowanie. Dok\u0142adnie tak. I pierwszy trop zaprowadzi\u0142 ich z powrotem do danych. Potwierdzili co\u015b, co wydaje si\u0119 intuicyjne. Je\u015bli trenujesz model na danych z konkretnej dziedziny. Na przyk\u0142ad na artyku\u0142ach z Wikipedia. To b\u0119dzie on potem lepszy w zadaniach zwi\u0105zanych z t\u0105 dziedzin\u0105, jak odpowiadanie na pytania encyklopedyczne. To akurat logiczne. Jak uczysz si\u0119 do egzaminu z historii, to czytasz podr\u0119czniki do historii i nie do fizyki. Tak, ale to nie by\u0142 najwa\u017cniejszy wniosek. Odkryli co\u015b znacznie ciekawszego. Okaza\u0142o si\u0119, \u017ce wydajno\u015b\u0107 modelu dramatycznie spada, je\u015bli zbi\u00f3r danych jest na tyle ma\u0142y, \u017ce podczas pretreningu trzeba go wielokrotnie powtarza\u0107. Czyli model zaczyna uczy\u0107 si\u0119 na pami\u0119\u0107, zamiast generalizowa\u0107. Troch\u0119 jak ucze\u0144, kt\u00f3ry zakuwa na blach\u0119 odpowiedzi do testu, zamiast zrozumie\u0107 materia\u0142. Idealna analogia. Model zamiast uczy\u0107 si\u0119 regu\u0142 j\u0119zykowych, zaczyna zapami\u0119tywa\u0107 konkretne zdania, co jest katastrof\u0105 dla jego zdolno\u015bci adaptacji. To pokaza\u0142o, jak absolutnie kluczowy jest dost\u0119p do ogromnych, niepowtarzalnych zbior\u00f3w danych. Lepiej mie\u0107 wi\u0119cej zr\u00f3\u017cnicowanego materia\u0142u, je\u015bli przejdzie si\u0119 przez niego tylko raz. Dobrze, a co z drugim elementem uk\u0142adanki? Mamy ju\u017c ten pot\u0119\u017cny, wst\u0119pnie wytrenowany model. Co dalej? Jak go dostosowa\u0107 do konkretnego zadania? Intuicja podpowiada, \u017ce to troch\u0119 ryzykowne. Uczymy model przez miesi\u0105ce og\u00f3lnej wiedzy, a potem pozwalamy mu cz\u0119\u015b\u0107 z tego zapomnie\u0107. W\u0142a\u015bnie. To jest fascynuj\u0105ce. Przetestowali r\u00f3\u017cne strategie, w tym popularne wtedy adapter layers, czyli dodawania takich ma\u0142ych, doczepianych modu\u0142\u00f3w, kt\u00f3re si\u0119 trenowa\u0142o, a reszta gigantycznego modelu pozostawa\u0142a zamro\u017cona. Tanie obiczeniowo i bezpieczne, tak. Tak si\u0119 wydawa\u0142o, ale wynik by\u0142 jednoznaczny. Najlepsze rezultaty dawa\u0142 fine tuning wszystkich parametr\u00f3w modelu. Okaza\u0142o si\u0119, \u017ce model nie tyle zapomina, co uczy si\u0119, jak swoj\u0105 ogromn\u0105, og\u00f3ln\u0105 wiedz\u0119 najlepiej zastosowa\u0107 w nowym, specyficznym kontek\u015bcie. To podej\u015bcie wszystko albo nic, cho\u0107 najdro\u017csze. Dawa\u0142o po prostu najlepsz\u0105 jako\u015b\u0107. I wreszcie dochodzimy do trzeciego wielkiego pytania. Skalowanie. To jest co\u015b, co w AI nazywa si\u0119 czasem gorzk\u0105 lekcj\u0105. Tak, s\u0142ynna bitter lesson. M\u00f3wi ona, \u017ce na d\u0142u\u017csz\u0105 met\u0119 wygrywaj\u0105 niekoniecznie najbardziej eleganckie algorytmy, ale te proste i og\u00f3lne, kt\u00f3re potrafi\u0105 w pe\u0142ni wykorzysta\u0107 rosn\u0105c\u0105 moc obliczeniow\u0105. Goszka, bo to troch\u0119 upokarzaj\u0105ce dla badaczy. Tyle lat wymy\u015blania, sprytnych sztuczek, a na ko\u0144cu przychodzi kto\u015b, kto po prostu buduje 10 razy wi\u0119kszy model i wygrywa. Dok\u0142adnie. Ale autorzy Ty5 postawili to pytanie bardzo konkretnie. Masz 4 razy wi\u0119cej mocy obliczeniowej, jak j\u0105 najlepiej wykorzysta\u0107. I por\u00f3wnali 3 opcje. Czyli? Trenowa\u0107 ten sam model, ale 4 razy d\u0142u\u017cej. U\u017cy\u0107 4 razy wi\u0119kszego modelu przez ten sam czas. Czy mo\u017ce wytrenowa\u0107 4 mniejsze i u\u015bredni cich odpowiedzi? Taki ensemble. W\u0142a\u015bnie. I wyniki by\u0142y pouczaj\u0105ce. Okaza\u0142o si\u0119, \u017ce cho\u0107 wszystkie te strategie poprawia\u0142y wyniki, to bardzo cz\u0119sto trenowanie po prostu wi\u0119kszego modelu przynosi\u0142o lepsze rezultaty. Lepsze ni\u017c trenowanie mniejszego modelu przez znacznie d\u0142u\u017cszy czas. Wniosek jest prosty. Ta pojemna\u015b\u0107 sieci, jej rozmiar, ma ogromne znaczenie. A potem zrobili to, co sugerowa\u0142a gorszka lekcja. Przeskalowa\u0142y to wszystko do rozmiar\u00f3w, kt\u00f3re w tamtym czasie by\u0142y wr\u0119cz niewyobra\u017calne. Zgadza si\u0119. Zbudowa\u0142y ca\u0142\u0105 rodzin\u0119 modeli, kt\u00f3r\u0105 nazwa\u0142y T5, czyli Text to Text Transfer Transformer. By\u0142y wersje Small, Base, Large, a na samym szczycie znalaz\u0142y si\u0119 dwa potwory. Model strzema miliardami i wreszcie ten najwi\u0119kszy z 11 miliardami parametr\u00f3w. Ten ostatni by\u0142 trenowany na bilionie token\u00f3w. To s\u0105 liczby, kt\u00f3re trudno sobie nawet wyobrazi\u0107. No dobrze. Wi\u0119c zbudowali ten j\u0119zykowy odpowiednik Gwiazdy \u015amierci. Jakie by\u0142y efekty, kiedy skierowali go na najtrudniejsze benchmarki j\u0119zykowe? Spektakularne. Model osi\u0105gn\u0105\u0142 status State of the Art, czyli pobi\u0142 dotychczasowe rekordy na 18 z 24 testowanych zada\u0144. Strzeszanie, odpowiadanie na pytania, klasyfikacja tekstu, praktycznie ca\u0142y przekr\u00f3j problem\u00f3w NLP. By\u0142 jaki\u015b wynik, kt\u00f3ry zrobi\u0142 szczeg\u00f3lne wra\u017cenie? Zdecydowanie. Benchmark o nazwie Super Glue. Zosta\u0142 on specjalnie zaprojektowany jako nast\u0119pca popularnego glue, ale z zadaniami o wiele, wiele trudniejszymi. Mia\u0142 by\u0107 testem, kt\u00f3rego maszyny na d\u0142ugo nie przejd\u0105. A T5? Najwi\u0119ksza wersja T5 nie tylko pobi\u0142a dotychczasowy rekord, ale niemal zr\u00f3bna\u0142a si\u0119 z wynikiem osi\u0105ganym przez przeci\u0119tnego cz\u0142owieka. To by\u0142 moment, w kt\u00f3rym wielu badaczy zrozumia\u0142o, \u017ce granice mo\u017cliwo\u015bci le\u017c\u0105 znacznie dalej ni\u017c s\u0105dzono. Ale nie by\u0142 idealny, prawda? Gdzie\u015b sobie nie poradzi\u0142. W zadaniach t\u0142umaczenia maszynowego, ty pi\u0105ty by\u0142 dobry, ale nie pobi\u0142 tam rekord\u00f3w. A prawdopodobn\u0105 przyczyn\u0105 jest to, \u017ce jego gigantyczny pre-training odbywa\u0142 si\u0119 niemal wy\u0142\u0105cznie na angloj\u0119zycznych danych z C4. I najlepsze modele do t\u0142umacze\u0144 mia\u0142y jakiego\u015b asa w r\u0119kawie? Mia\u0142y. U\u017cywa\u0142y sprytnej sztuczki, znanej jako Back Translation. Bierze si\u0119 tekst, na przyk\u0142ad po niemiecku, t\u0142umaczy go maszynowo z powrotem na angielski i w ten spos\u00f3b tworzy si\u0119 nowe, syntetyczne dane treningowe. Tego zabrak\u0142o T5. To pokazuje, \u017ce nawet przy niewyobra\u017calnej skali specyfika danych wci\u0105\u017c ma kluczowe znaczenie. Wi\u0119c co to wszystko oznacza, jaki jest g\u0142\u00f3wny wniosek z tej monumentalnej pracy? My\u015bl\u0119, \u017ce znaczenie pracy polega nie tyle na wynalezieniu jednej magicznej technice, co na stworzeniu niezwykle klarownej przetestowanej mapy drogowej. Oni nie tyle dokonali skok\u00f3w nieznane, co metodycznie zbadali i zoptymalizowali ca\u0142\u0105 istniej\u0105c\u0105 wiedz\u0119. A potem pokazali, co si\u0119 stanie, gdy zastosuje si\u0119 j\u0105 na niespotykan\u0105 dot\u0105d skal\u0119. Pokazali, \u017ce prostota i unifikacja, po\u0142\u0105czone z brutaln\u0105 si\u0142\u0105 obliczeniow\u0105, to przepis na przesuwanie granic. Czyli podsumowuj\u0105c. Si\u0142a idei, tekst to tekst. Absolutnie fundamentalne znaczenie czystych i ogromnych danych. I zimne potwierdzenie gorzkiej lekcji. Inteligentne skalowanie, czyli wi\u0119ksze modele i wi\u0119cej danych, to wci\u0105\u017c najpewniejsza droga do post\u0119pu. Tak, to jest esencja. Ale ta praca pozostawia nas te\u017c z bardzo wa\u017cnym, prowokuj\u0105cym pytaniem na przysz\u0142o\u015b\u0107. Te gigantyczne modele s\u0105 niezwykle pot\u0119\u017cne, ale ich trenowanie i u\u017cywanie jest te\u017c ekstremalnie drogie. Wymaga zasob\u00f3w dost\u0119pnych tylko dla garstki najwi\u0119kszych korporacji. Czyli pytanie brzmi, czy przysz\u0142o\u015b\u0107 zaawansowanej sztucznej inteligencji nale\u017cy wy\u0142\u0105cznie do tych, kt\u00f3rzy maj\u0105 najg\u0142\u0119bsze kieszenie? To jest w\u0142a\u015bnie to pytanie. A mo\u017ce nast\u0119pny wielki prze\u0142om nie b\u0119dzie polega\u0142 na budowaniu jeszcze wi\u0119kszego T5, ale na znalezieniu sposob\u00f3w, by t\u0119 wiedz\u0119 uczyni\u0107 bardziej efektywn\u0105, dost\u0119pn\u0105. Na przyk\u0142ad poprzez techniki takie jak distillation, czyli proces destylowania wiedzy z ogromnego modelu nauczyciela do znacznie mniejszego, zwinnego modelu ucznia, takiego, kt\u00f3ry zmie\u015bci si\u0119 na telefonie. To fundamentalne pytanie o przysz\u0142\u0105 demokratyzacj\u0119 tej niesamowitej technologii.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.84, "text": " Pomy\u015blmy o tej klasycznej fantazji z Science Fiction, uniwersalny translator.", "tokens": [50364, 430, 8488, 19212, 2226, 277, 12573, 9671, 5871, 3689, 11794, 4115, 921, 4013, 710, 8976, 479, 4105, 11, 36435, 5364, 304, 1634, 35223, 13, 50656], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 1, "seek": 0, "start": 5.84, "end": 9.040000000000001, "text": " M\u00f3wisz do niego, a on od razu wszystko t\u0142umaczy.", "tokens": [50656, 376, 3901, 23848, 360, 49615, 11, 257, 322, 3611, 367, 8813, 22607, 256, 49166, 14691, 13, 50816], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 2, "seek": 0, "start": 9.040000000000001, "end": 13.08, "text": " Ale co je\u015bli poszliby\u015bmy okrok dalej?", "tokens": [50816, 9366, 598, 25630, 1366, 89, 38270, 88, 10513, 3133, 31621, 34257, 30, 51018], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 3, "seek": 0, "start": 13.08, "end": 17.68, "text": " Co je\u015bli to samo urz\u0105dzenie mog\u0142oby, no wiesz, strze\u015bci\u0107 artyku\u0142,", "tokens": [51018, 3066, 25630, 281, 36422, 4038, 23876, 16778, 13172, 1221, 13944, 11, 572, 261, 15347, 11, 1056, 1381, 6199, 2162, 594, 874, 5279, 1221, 11, 51248], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 4, "seek": 0, "start": 17.68, "end": 20.72, "text": " odpowiedzie\u0107 na pytanie, oceni\u0107 gramatyk\u0119?", "tokens": [51248, 24314, 22078, 1667, 36610, 11, 10409, 268, 12757, 21353, 21398, 15724, 30, 51400], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 5, "seek": 0, "start": 20.72, "end": 25.88, "text": " Jakby ka\u017cde zadanie j\u0119zykowe da\u0142o si\u0119 sprowadzi\u0107 do jednego prostego formatu.", "tokens": [51400, 15029, 2322, 21912, 1479, 42788, 7155, 49055, 74, 6880, 1120, 5249, 3244, 637, 1892, 345, 28496, 360, 5232, 11858, 10293, 6308, 7877, 84, 13, 51658], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 6, "seek": 0, "start": 25.88, "end": 28.36, "text": " Tekst na wej\u015bciu, tekst na wyj\u015bciu.", "tokens": [51658, 27821, 372, 1667, 321, 73, 6199, 84, 11, 16624, 372, 1667, 4628, 73, 6199, 84, 13, 51782], "temperature": 0.0, "avg_logprob": -0.16424136691623265, "compression_ratio": 1.402061855670103, "no_speech_prob": 0.06527668982744217}, {"id": 7, "seek": 2836, "start": 28.48, "end": 33.12, "text": " Dzi\u015b bierzemy na warsztat prace, kt\u00f3ra dok\u0142adnie to zaproponowa\u0142a i no c\u00f3\u017c,", "tokens": [50370, 413, 3992, 1788, 272, 34602, 3633, 1667, 13718, 2682, 267, 582, 617, 11, 19456, 45864, 2766, 281, 14223, 1513, 266, 5528, 5024, 741, 572, 6333, 1427, 11, 50602], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 8, "seek": 2836, "start": 33.12, "end": 35.2, "text": " wstrz\u0105s\u0142a \u015bwiatem AI.", "tokens": [50602, 261, 9733, 8925, 82, 5024, 21485, 26851, 7318, 13, 50706], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 9, "seek": 2836, "start": 35.2, "end": 37.92, "text": " Mowa o artykule z Google Research,", "tokens": [50706, 376, 5528, 277, 594, 874, 74, 2271, 710, 3329, 10303, 11, 50842], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 10, "seek": 2836, "start": 37.92, "end": 43.44, "text": " exploring the limits of transfer learning with a unified text-to-text transformer.", "tokens": [50842, 12736, 264, 10406, 295, 5003, 2539, 365, 257, 26787, 2487, 12, 1353, 12, 25111, 31782, 13, 51118], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 11, "seek": 2836, "start": 43.44, "end": 47.28, "text": " A cel jaki sobie postawili by\u0142 od razu do\u015b\u0107 nietypowy.", "tokens": [51118, 316, 9277, 24492, 13652, 2183, 1607, 2312, 16673, 3611, 367, 8813, 49333, 297, 4014, 79, 10089, 13, 51310], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 12, "seek": 2836, "start": 47.28, "end": 49.44, "text": " Nie chcieli wymy\u015ble\u0107 ko\u0142a na nowo.", "tokens": [51310, 12016, 417, 537, 10148, 4628, 2226, 1788, 306, 2162, 8384, 5024, 1667, 586, 78, 13, 51418], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 13, "seek": 2836, "start": 49.44, "end": 51.92, "text": " Zamiast tego zrobili co\u015b w rodzaju", "tokens": [51418, 1176, 4526, 525, 8627, 44399, 2312, 19241, 261, 28607, 33166, 51542], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 14, "seek": 2836, "start": 51.92, "end": 54.879999999999995, "text": " najwi\u0119kszego w historii testu por\u00f3wnawczego.", "tokens": [51542, 48636, 1694, 27725, 261, 4058, 5597, 1500, 84, 1515, 3901, 629, 86, 3689, 6308, 13, 51690], "temperature": 0.0, "avg_logprob": -0.14773240296737009, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.032492976635694504}, {"id": 15, "seek": 5488, "start": 54.92, "end": 59.760000000000005, "text": " Ich misj\u0105 by\u0142o znalezienie tego ostatecznego, najlepszego przepisu.", "tokens": [50366, 3141, 3346, 8555, 14811, 15397, 37646, 27385, 8627, 277, 15406, 3689, 11858, 11, 41903, 1878, 27725, 30829, 25871, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 16, "seek": 5488, "start": 59.760000000000005, "end": 64.48, "text": " I kluczem do tego wszystkiego jest w\u0142a\u015bnie ta idea, kt\u00f3r\u0105 poruszy\u0142a\u015b na pocz\u0105tku.", "tokens": [50608, 286, 9671, 1311, 24313, 360, 8627, 14615, 12200, 3492, 14234, 1846, 1558, 11, 37415, 1515, 301, 1229, 5024, 1788, 1667, 43959, 13, 50844], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 17, "seek": 5488, "start": 64.48, "end": 67.8, "text": " Framework, kt\u00f3ry nazwali tekst-to-text.", "tokens": [50844, 31628, 1902, 11, 9913, 20151, 40054, 16624, 372, 12, 1353, 12, 25111, 13, 51010], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 18, "seek": 5488, "start": 67.8, "end": 70.88, "text": " Zamiast budowa\u0107 ca\u0142\u0105 armi\u0119 wyspecjalizowanych moteli,", "tokens": [51010, 1176, 4526, 525, 3265, 11445, 1335, 15926, 594, 3057, 1274, 27062, 494, 66, 22600, 590, 23341, 339, 2184, 10148, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 19, "seek": 5488, "start": 70.88, "end": 74.88, "text": " jeden do t\u0142umacze\u0144, drugi do sentymentu, trzeci do czego\u015b innego,", "tokens": [51164, 12906, 360, 256, 49166, 326, 49689, 11, 4110, 72, 360, 2279, 88, 518, 84, 11, 22266, 537, 360, 36559, 1788, 294, 11858, 11, 51364], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 20, "seek": 5488, "start": 74.88, "end": 77.08, "text": " postawili wszystko na jedn\u0105 kart\u0119.", "tokens": [51364, 2183, 1607, 2312, 22607, 1667, 5232, 13113, 29120, 1274, 13, 51474], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 21, "seek": 5488, "start": 77.08, "end": 80.96000000000001, "text": " Stwierdzili, ka\u017cdy problem da si\u0119 tak naprawd\u0119 potraktowa\u0107 jako", "tokens": [51474, 745, 40717, 28168, 2312, 11, 31615, 1154, 1120, 3244, 991, 20970, 1847, 32249, 11445, 17123, 51668], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 22, "seek": 5488, "start": 80.96000000000001, "end": 83.08, "text": " zadanie generowania tekstu.", "tokens": [51668, 42788, 7155, 1337, 21308, 16624, 372, 84, 13, 51774], "temperature": 0.0, "avg_logprob": -0.1427008783495104, "compression_ratio": 1.495114006514658, "no_speech_prob": 0.03541114553809166}, {"id": 23, "seek": 8308, "start": 83.12, "end": 85.16, "text": " Czekaj, jak to w\u0142a\u015bciwie dzia\u0142a?", "tokens": [50366, 383, 19878, 1805, 11, 4207, 281, 50108, 37903, 30, 50468], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 24, "seek": 8308, "start": 85.16, "end": 89.08, "text": " Bo na pierwszy rzut oka, no nie wiem, t\u0142umaczenie i klasyfikacja zdania", "tokens": [50468, 3286, 1667, 34016, 367, 89, 325, 277, 2330, 11, 572, 2838, 26522, 11, 256, 49166, 326, 16778, 741, 9671, 5871, 31230, 23395, 16221, 5609, 50664], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 25, "seek": 8308, "start": 89.08, "end": 91.2, "text": " to s\u0105 dwa zupe\u0142nie r\u00f3\u017cne \u015bwiaty.", "tokens": [50664, 281, 9015, 35045, 49922, 47760, 21485, 21398, 13, 50770], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 26, "seek": 8308, "start": 91.2, "end": 92.12, "text": " Dok\u0142adnie.", "tokens": [50770, 29768, 10358, 2766, 13, 50816], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 27, "seek": 8308, "start": 92.12, "end": 94.75999999999999, "text": " Ale oni znale\u017ali spos\u00f3b, \u017ceby to po\u0142\u0105czy\u0107.", "tokens": [50816, 9366, 36317, 15397, 1220, 10659, 2081, 22904, 11, 11316, 281, 714, 15926, 33967, 13, 50948], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 28, "seek": 8308, "start": 94.75999999999999, "end": 97.44, "text": " W artykule daj\u0105 \u015bwietne, proste przyk\u0142ady.", "tokens": [50948, 343, 594, 874, 74, 2271, 1120, 8555, 8299, 39083, 716, 11, 10293, 68, 6501, 74, 1221, 880, 13, 51082], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 29, "seek": 8308, "start": 97.44, "end": 99.47999999999999, "text": " Chcesz co\u015b przet\u0142umaczy\u0107?", "tokens": [51082, 761, 887, 89, 19241, 6541, 302, 49166, 14691, 2162, 30, 51184], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 30, "seek": 8308, "start": 99.47999999999999, "end": 101.08, "text": " Dajesz modelowi komend\u0119.", "tokens": [51184, 413, 1805, 10430, 2316, 24503, 5207, 521, 1274, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 31, "seek": 8308, "start": 101.08, "end": 102.68, "text": " Zwyk\u0142y tekst.", "tokens": [51264, 1176, 9726, 74, 6825, 16624, 372, 13, 51344], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 32, "seek": 8308, "start": 102.68, "end": 104.92, "text": " Translate English to German.", "tokens": [51344, 6531, 17593, 3669, 281, 6521, 13, 51456], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 33, "seek": 8308, "start": 104.92, "end": 106.44, "text": " That is good.", "tokens": [51456, 663, 307, 665, 13, 51532], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 34, "seek": 8308, "start": 106.44, "end": 109.28, "text": " I oczekujesz, \u017ce on po prostu wygeneruje w odpowiedzi.", "tokens": [51532, 286, 277, 3689, 916, 4579, 10430, 11, 3561, 322, 714, 19518, 4628, 21848, 13008, 261, 36574, 3992, 13, 51674], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 35, "seek": 8308, "start": 109.28, "end": 110.56, "text": " Thus is good.", "tokens": [51674, 13827, 307, 665, 13, 51738], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 36, "seek": 8308, "start": 110.56, "end": 111.48, "text": " OK.", "tokens": [51738, 2264, 13, 51784], "temperature": 0.0, "avg_logprob": -0.14580932206022526, "compression_ratio": 1.3968253968253967, "no_speech_prob": 0.03920254111289978}, {"id": 37, "seek": 11148, "start": 111.52000000000001, "end": 113.2, "text": " Chcesz sprawdzi\u0107 gramatyk\u0119?", "tokens": [50366, 761, 887, 89, 46192, 28496, 21353, 21398, 15724, 30, 50450], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 38, "seek": 11148, "start": 113.2, "end": 115.4, "text": " Dajesz mu co\u015b w stylu?", "tokens": [50450, 413, 1805, 10430, 2992, 19241, 261, 7952, 2781, 30, 50560], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 39, "seek": 11148, "start": 118.84, "end": 121.4, "text": " I model ma odpowiedzie\u0107 jednym s\u0142owem.", "tokens": [50732, 286, 2316, 463, 24314, 22078, 5232, 12996, 15116, 305, 443, 13, 50860], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 40, "seek": 11148, "start": 121.4, "end": 122.96000000000001, "text": " Not acceptable.", "tokens": [50860, 1726, 15513, 13, 50938], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 41, "seek": 11148, "start": 122.96000000000001, "end": 124.4, "text": " A straszczenie.", "tokens": [50938, 316, 1056, 19601, 39043, 13, 51010], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 42, "seek": 11148, "start": 124.4, "end": 125.64, "text": " Summarize.", "tokens": [51010, 8626, 6209, 1125, 13, 51072], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 43, "seek": 11148, "start": 125.64, "end": 130.68, "text": " I tu wklejasz ca\u0142y d\u0142ugi artyku\u0142, a model generuje zwi\u0119z\u0142e podsumowanie.", "tokens": [51072, 286, 2604, 261, 14677, 73, 19601, 35226, 44042, 24780, 594, 874, 5279, 1221, 11, 257, 2316, 1337, 13008, 710, 22423, 89, 19827, 31925, 449, 22028, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 44, "seek": 11148, "start": 130.68, "end": 135.48000000000002, "text": " Czyli ca\u0142y tryk polega na tym, \u017ceby nauczy\u0107 model, co oznaczaj\u0105 te", "tokens": [51324, 37099, 35226, 853, 74, 13208, 3680, 1667, 8107, 11, 11316, 49103, 27150, 2316, 11, 598, 277, 22672, 14875, 11133, 535, 51564], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 45, "seek": 11148, "start": 135.48000000000002, "end": 137.76, "text": " pocz\u0105tkowe, magiczne s\u0142owa.", "tokens": [51564, 34397, 74, 6880, 11, 5585, 43077, 15116, 5528, 13, 51678], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 46, "seek": 11148, "start": 137.76, "end": 140.2, "text": " Translate, summarize itd.", "tokens": [51678, 6531, 17593, 11, 20858, 309, 67, 13, 51800], "temperature": 0.0, "avg_logprob": -0.2454676513671875, "compression_ratio": 1.368, "no_speech_prob": 0.020336616784334183}, {"id": 47, "seek": 14020, "start": 140.23999999999998, "end": 142.95999999999998, "text": " Reszta to ju\u017c tylko generowanie tekstu.", "tokens": [50366, 5015, 89, 1328, 281, 10678, 13219, 1337, 22028, 16624, 372, 84, 13, 50502], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 48, "seek": 14020, "start": 142.95999999999998, "end": 144.16, "text": " W\u0142a\u015bnie.", "tokens": [50502, 343, 5024, 12221, 13, 50562], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 49, "seek": 14020, "start": 144.16, "end": 146.28, "text": " I to radykalnie upraszcza wszystko.", "tokens": [50562, 286, 281, 367, 880, 19990, 2766, 493, 3906, 89, 41524, 22607, 13, 50668], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 50, "seek": 14020, "start": 146.28, "end": 151.83999999999997, "text": " Nagle mamy jeden model, jedn\u0105 architektur\u0119, jedn\u0105 metod\u0119 trenowania.", "tokens": [50668, 426, 15088, 17335, 12906, 2316, 11, 5232, 13113, 3912, 642, 2320, 374, 1274, 11, 5232, 13113, 1131, 378, 1274, 23136, 21308, 13, 50946], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 51, "seek": 14020, "start": 151.83999999999997, "end": 154.44, "text": " Dla dziesi\u0105tek r\u00f3\u017cnych zada\u0144.", "tokens": [50946, 413, 875, 9758, 530, 11404, 47611, 42602, 710, 1538, 5248, 13, 51076], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 52, "seek": 14020, "start": 154.44, "end": 158.95999999999998, "text": " A to stworzy\u0142o im idealne, kontrolowane \u015brodowisko do eksperyment\u00f3w.", "tokens": [51076, 316, 281, 342, 28321, 1229, 5249, 566, 7157, 716, 11, 14373, 6623, 23066, 28580, 305, 43442, 360, 30724, 610, 88, 518, 3901, 13, 51302], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 53, "seek": 14020, "start": 158.95999999999998, "end": 161.23999999999998, "text": " Co by\u0142o przecie\u017c g\u0142\u00f3wnym celem tej pracy?", "tokens": [51302, 3066, 14811, 8325, 40082, 18117, 812, 895, 4199, 1769, 10386, 12573, 35591, 30, 51416], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 54, "seek": 14020, "start": 161.23999999999998, "end": 166.32, "text": " OK, ale \u017ceby wytrenowa\u0107 taki wszechstronny model.", "tokens": [51416, 2264, 11, 6775, 11316, 261, 4328, 1095, 11445, 20065, 37647, 19439, 372, 2044, 1634, 2316, 13, 51670], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 55, "seek": 14020, "start": 166.32, "end": 167.92, "text": " Potrzeba paliwa.", "tokens": [51670, 9145, 13503, 4231, 3984, 72, 4151, 13, 51750], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 56, "seek": 14020, "start": 167.92, "end": 169.67999999999998, "text": " I to nie byle jakiego.", "tokens": [51750, 286, 281, 2838, 538, 306, 4207, 12200, 13, 51838], "temperature": 0.0, "avg_logprob": -0.11151508331298828, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.003362037939950824}, {"id": 57, "seek": 16968, "start": 169.76000000000002, "end": 173.92000000000002, "text": " Domy\u015blam si\u0119, \u017ce m\u00f3wimy tu o astronomicznych ilo\u015bciach danych.", "tokens": [50368, 413, 8488, 1788, 4326, 3244, 11, 3561, 13489, 13189, 2604, 277, 26302, 17946, 9399, 1930, 44468, 608, 274, 34644, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 58, "seek": 16968, "start": 173.92000000000002, "end": 178.20000000000002, "text": " M\u00f3wimy o czym\u015b, co nazwali Colossal Clean Crawled Corpus.", "tokens": [50576, 376, 3901, 13189, 277, 31466, 1788, 11, 598, 20151, 40054, 4004, 772, 304, 18463, 37877, 1493, 3925, 31624, 13, 50790], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 59, "seek": 16968, "start": 178.20000000000002, "end": 180.0, "text": " W skr\u00f3cie C4.", "tokens": [50790, 343, 1110, 11721, 4260, 383, 19, 13, 50880], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 60, "seek": 16968, "start": 180.0, "end": 185.4, "text": " To jest zbi\u00f3r danych o rozmiarze uwaga 750 GB.", "tokens": [50880, 1407, 3492, 710, 5614, 15614, 274, 34644, 277, 9544, 3057, 289, 1381, 23147, 9286, 31682, 26809, 13, 51150], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 61, "seek": 16968, "start": 185.4, "end": 186.28, "text": " Wow.", "tokens": [51150, 3153, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 62, "seek": 16968, "start": 186.28, "end": 190.56, "text": " \u017beby da\u0107 jak\u0105\u015b skal\u0119, to odpowiednik setek tysi\u0119cy ksi\u0105\u017cek.", "tokens": [51194, 46864, 2322, 1120, 2162, 46719, 1788, 16890, 1274, 11, 281, 36574, 13123, 992, 916, 38156, 47303, 39311, 916, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 63, "seek": 16968, "start": 190.56, "end": 194.28, "text": " Ale co wa\u017cniejsze, to nie jest po prostu \u015bmietnik z internetu.", "tokens": [51408, 9366, 598, 27777, 44258, 11, 281, 2838, 3492, 714, 19518, 46991, 1684, 13123, 710, 4705, 84, 13, 51594], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 64, "seek": 16968, "start": 194.28, "end": 196.96, "text": " To dane starannie przefiltrowane.", "tokens": [51594, 1407, 49206, 3543, 43433, 8325, 69, 2352, 1892, 1929, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1510939930760583, "compression_ratio": 1.345724907063197, "no_speech_prob": 0.017602987587451935}, {"id": 65, "seek": 19696, "start": 197.0, "end": 202.28, "text": " I z tego, co czyta\u0142am, niekt\u00f3re z tych filtr\u00f3w by\u0142y do\u015b\u0107... kreatywne.", "tokens": [50366, 286, 710, 8627, 11, 598, 6430, 1328, 20177, 11, 2838, 43073, 265, 710, 15180, 29148, 81, 3901, 26366, 49333, 485, 350, 620, 27112, 716, 13, 50630], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 66, "seek": 19696, "start": 202.28, "end": 204.32000000000002, "text": " Oj, zdecydowanie.", "tokens": [50630, 47100, 11, 49749, 1344, 67, 22028, 13, 50732], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 67, "seek": 19696, "start": 204.32000000000002, "end": 206.4, "text": " To nie by\u0142o proste filtrowanie.", "tokens": [50732, 1407, 2838, 14811, 10293, 68, 1387, 6903, 22028, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 68, "seek": 19696, "start": 206.4, "end": 211.24, "text": " Na przyk\u0142ad automatycznie wyrzucali ka\u017cd\u0105 stron\u0119, kt\u00f3ra zawiera\u0142a fraz\u0119 Loren Ipsum.", "tokens": [50836, 6056, 23144, 28034, 17466, 2766, 4628, 19390, 1311, 5103, 21912, 67, 1611, 45766, 1274, 11, 19456, 28165, 10609, 5024, 6600, 11052, 37162, 286, 1878, 449, 13, 51078], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 69, "seek": 19696, "start": 211.24, "end": 212.8, "text": " \u017beby pozby\u0107 si\u0119 szablon\u00f3w.", "tokens": [51078, 46864, 2322, 21281, 2322, 2162, 3244, 7870, 455, 14864, 3901, 13, 51156], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 70, "seek": 19696, "start": 212.8, "end": 213.60000000000002, "text": " Dok\u0142adnie.", "tokens": [51156, 29768, 10358, 2766, 13, 51196], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 71, "seek": 19696, "start": 213.60000000000002, "end": 215.08, "text": " Tekst\u00f3w wype\u0142niaczy.", "tokens": [51196, 27821, 372, 3901, 4628, 31457, 3722, 14691, 13, 51270], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 72, "seek": 19696, "start": 215.08, "end": 216.52, "text": " Inna sprytna zasada.", "tokens": [51270, 682, 629, 637, 627, 83, 629, 26530, 1538, 13, 51342], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 73, "seek": 19696, "start": 216.52, "end": 219.64000000000001, "text": " Odrzucali strony zawieraj\u0105ce nawias klamrowy.", "tokens": [51342, 12210, 19390, 1311, 5103, 32406, 28165, 811, 11133, 384, 18969, 4609, 350, 4326, 1892, 88, 13, 51498], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 74, "seek": 19696, "start": 219.64000000000001, "end": 223.12, "text": " Bo to niemal zawsze oznacza kod programu, a nie naturalny j\u0119zyk.", "tokens": [51498, 3286, 281, 2838, 5579, 30964, 277, 22672, 326, 2394, 350, 378, 1461, 84, 11, 257, 2838, 3303, 1634, 49055, 74, 13, 51672], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 75, "seek": 19696, "start": 223.12, "end": 224.24, "text": " To ma sens.", "tokens": [51672, 1407, 463, 2923, 13, 51728], "temperature": 0.0, "avg_logprob": -0.14216730071277153, "compression_ratio": 1.4511784511784511, "no_speech_prob": 0.035849396139383316}, {"id": 76, "seek": 22424, "start": 224.24, "end": 227.84, "text": " Model ma si\u0119 uczy\u0107 pisa\u0107 jak cz\u0142owiek, nie jak programista.", "tokens": [50364, 17105, 463, 3244, 344, 33967, 280, 3837, 2162, 4207, 36282, 74, 11, 2838, 4207, 1461, 5236, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 77, "seek": 22424, "start": 227.84, "end": 231.08, "text": " Do tego dochodzi\u0142y bardziej subtelne filtry.", "tokens": [50544, 1144, 8627, 9243, 14543, 6825, 27209, 7257, 338, 716, 29148, 627, 13, 50706], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 78, "seek": 22424, "start": 231.08, "end": 234.60000000000002, "text": " Zachowywano tylko strony, kt\u00f3re mia\u0142y co najmniej pi\u0119\u0107 zda\u0144.", "tokens": [50706, 21028, 10089, 86, 3730, 13219, 32406, 11, 8864, 21290, 6825, 598, 11212, 47658, 32677, 2162, 710, 2675, 5248, 13, 50882], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 79, "seek": 22424, "start": 234.60000000000002, "end": 239.20000000000002, "text": " A ka\u017cde musia\u0142o si\u0119 ko\u0144czy\u0107 kropk\u0105, wykrzykniciem lub znakiem zapytania.", "tokens": [50882, 316, 21912, 1479, 1038, 654, 5249, 3244, 26470, 33967, 350, 1513, 26304, 11, 39287, 13047, 5457, 299, 4907, 15980, 15397, 514, 4907, 14223, 4328, 5609, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 80, "seek": 22424, "start": 239.20000000000002, "end": 244.96, "text": " To prosty, ale skuteczny spos\u00f3b na odsianie nowie\u017c list zakup\u00f3w czy menu nawigacyjnych.", "tokens": [51112, 1407, 10293, 88, 11, 6775, 1110, 1169, 3689, 1634, 22904, 1667, 3611, 82, 952, 414, 586, 414, 1427, 1329, 23810, 1010, 3901, 6430, 6510, 18969, 328, 31285, 9399, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 81, "seek": 22424, "start": 244.96, "end": 250.16000000000003, "text": " No i co istotne, pozbyli si\u0119 stron zawieraj\u0105cych s\u0142owa z obszernej listy wulgaryzm\u00f3w.", "tokens": [51400, 883, 741, 598, 1418, 310, 716, 11, 21281, 2322, 2081, 3244, 45766, 28165, 811, 11133, 31306, 15116, 5528, 710, 3181, 89, 1248, 40779, 1329, 88, 261, 425, 36214, 89, 76, 3901, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 82, "seek": 22424, "start": 250.16000000000003, "end": 252.72, "text": " Dobrze, czyli dane mamy z g\u0142owy.", "tokens": [51660, 29679, 13503, 11, 16591, 49206, 17335, 710, 18117, 10089, 13, 51788], "temperature": 0.0, "avg_logprob": -0.1210361149000085, "compression_ratio": 1.4475308641975309, "no_speech_prob": 0.09052924066781998}, {"id": 83, "seek": 25272, "start": 252.72, "end": 255.6, "text": " Gigantyczne, ale posprz\u0105tany internet.", "tokens": [50364, 40489, 394, 17466, 716, 11, 6775, 1366, 1424, 8925, 83, 1325, 4705, 13, 50508], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 84, "seek": 25272, "start": 255.6, "end": 257.12, "text": " A co z silnikiem?", "tokens": [50508, 316, 598, 710, 3425, 13123, 4907, 30, 50584], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 85, "seek": 25272, "start": 257.12, "end": 262.12, "text": " Czy tutaj te\u017c postawili na co\u015b zupe\u0142nie nowego, czy na tej ulepszyli to, co ju\u017c by\u0142o?", "tokens": [50584, 19832, 12749, 9516, 2183, 1607, 2312, 1667, 19241, 49922, 586, 6308, 11, 6430, 1667, 12573, 344, 306, 1878, 1229, 2081, 281, 11, 598, 10678, 14811, 30, 50834], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 86, "seek": 25272, "start": 262.12, "end": 265.92, "text": " I tu dochodzimy do pierwszego, ma\u0142ego zaskoczenia.", "tokens": [50834, 286, 2604, 9243, 378, 89, 13189, 360, 27623, 27725, 11, 463, 1221, 6308, 710, 3863, 905, 14320, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 87, "seek": 25272, "start": 265.92, "end": 269.56, "text": " Ca\u0142y \u015bwiat AI fascynowa\u0142 si\u0119 wtedy dwoma podej\u015bciami.", "tokens": [51024, 7544, 6825, 36425, 7318, 30632, 1344, 3785, 64, 1221, 3244, 26959, 27379, 6440, 7468, 73, 6199, 4526, 13, 51206], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 88, "seek": 25272, "start": 269.56, "end": 274.12, "text": " Z jednej strony mieli\u015bmy modele typu encoder only, jak BERT.", "tokens": [51206, 1176, 5232, 11794, 32406, 41214, 10513, 4391, 306, 2125, 84, 2058, 19866, 787, 11, 4207, 363, 31479, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 89, "seek": 25272, "start": 274.12, "end": 277.16, "text": " \u015awietne do rozumienia tekstu, do klasyfikacji.", "tokens": [51434, 27933, 39083, 716, 360, 48797, 18811, 16624, 372, 84, 11, 360, 9671, 5871, 31230, 13152, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 90, "seek": 25272, "start": 277.16, "end": 282.2, "text": " Z drugiej modele decoder only, jak GPT, kt\u00f3re by\u0142y mistrzami w generowaniu.", "tokens": [51586, 1176, 47373, 4391, 306, 979, 19866, 787, 11, 4207, 26039, 51, 11, 8864, 26366, 3544, 19390, 4526, 261, 1337, 305, 25849, 13, 51838], "temperature": 0.0, "avg_logprob": -0.1160129522665953, "compression_ratio": 1.428115015974441, "no_speech_prob": 0.0461835041642189}, {"id": 91, "seek": 28220, "start": 282.2, "end": 287.68, "text": " No tak, wydawa\u0142oby si\u0119, \u017ce trzeba wybra\u0107 jedn\u0105 z tych dr\u00f3g, albo rozumienie, albo generowanie.", "tokens": [50364, 883, 991, 11, 25984, 10449, 1221, 13944, 3244, 11, 3561, 25860, 4628, 6198, 2162, 5232, 13113, 710, 15180, 1224, 14047, 11, 22622, 48797, 27385, 11, 22622, 1337, 22028, 13, 50638], "temperature": 0.0, "avg_logprob": -0.135484825481068, "compression_ratio": 1.3543307086614174, "no_speech_prob": 0.003496702527627349}, {"id": 92, "seek": 28220, "start": 287.68, "end": 294.03999999999996, "text": " A badaczy z Google powiedzieli, sprawdzam i wr\u00f3cili do klasyki.", "tokens": [50638, 316, 1578, 14691, 710, 3329, 27617, 23099, 11, 46192, 28915, 741, 928, 40993, 2312, 360, 9671, 5871, 2984, 13, 50956], "temperature": 0.0, "avg_logprob": -0.135484825481068, "compression_ratio": 1.3543307086614174, "no_speech_prob": 0.003496702527627349}, {"id": 93, "seek": 28220, "start": 294.03999999999996, "end": 302.15999999999997, "text": " Postawili nas standardow\u0105 architektur\u0119 Transformer z obiema cz\u0119\u015bciami, encodelen i decoderem.", "tokens": [50956, 10223, 1607, 2312, 5382, 3832, 30297, 3912, 642, 2320, 374, 1274, 27938, 260, 710, 1111, 414, 1696, 41314, 4526, 11, 2058, 378, 14818, 741, 979, 378, 7333, 13, 51362], "temperature": 0.0, "avg_logprob": -0.135484825481068, "compression_ratio": 1.3543307086614174, "no_speech_prob": 0.003496702527627349}, {"id": 94, "seek": 28220, "start": 302.15999999999997, "end": 308.28, "text": " I okaza\u0142o si\u0119, \u017ce ten stary dobry pomys\u0142 w ich nowym frameworku text-to-text", "tokens": [51362, 286, 3133, 12257, 5249, 3244, 11, 3561, 2064, 342, 822, 35884, 12991, 39508, 261, 1893, 586, 4199, 8388, 84, 2487, 12, 1353, 12, 25111, 51668], "temperature": 0.0, "avg_logprob": -0.135484825481068, "compression_ratio": 1.3543307086614174, "no_speech_prob": 0.003496702527627349}, {"id": 95, "seek": 30828, "start": 308.4, "end": 313.47999999999996, "text": " bije na g\u0142ow\u0119 te nowocze\u015bniejsze, wyspecjalizowane alternatywy.", "tokens": [50370, 10317, 68, 1667, 18117, 305, 1274, 535, 586, 905, 1381, 1788, 44258, 11, 27062, 494, 66, 22600, 590, 23066, 5400, 21398, 9726, 13, 50624], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 96, "seek": 30828, "start": 313.47999999999996, "end": 318.91999999999996, "text": " Encoder m\u00f3g\u0142 zrozumie\u0107 tekst wej\u015bciowy, a decoder wygenerowa\u0107 odpowied\u017a.", "tokens": [50624, 29584, 19866, 275, 14047, 1221, 710, 27857, 449, 414, 2162, 16624, 372, 321, 73, 6199, 10089, 11, 257, 979, 19866, 4628, 21848, 11445, 36574, 10659, 13, 50896], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 97, "seek": 30828, "start": 318.91999999999996, "end": 320.71999999999997, "text": " Dawa\u0142o im to elastyczno\u015b\u0107.", "tokens": [50896, 413, 10449, 5249, 566, 281, 806, 9820, 3689, 23293, 13, 50986], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 98, "seek": 30828, "start": 320.71999999999997, "end": 322.35999999999996, "text": " W\u0142a\u015bnie.", "tokens": [50986, 343, 5024, 12221, 13, 51068], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 99, "seek": 30828, "start": 322.35999999999996, "end": 328.11999999999995, "text": " Co ciekawe, przetestowali te\u017c wersj\u0119 ze wsp\u00f3\u0142dzielonymi wagami mi\u0119dzy obiema cz\u0119\u015bciami,", "tokens": [51068, 3066, 30596, 2330, 826, 11, 6541, 302, 377, 305, 5103, 9516, 261, 433, 11115, 5277, 39069, 28168, 1187, 2526, 3057, 36854, 4526, 33964, 1111, 414, 1696, 41314, 4526, 11, 51356], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 100, "seek": 30828, "start": 328.11999999999995, "end": 333.55999999999995, "text": " co zmniejszy\u0142o liczb\u0119 parametr\u00f3w o po\u0142ow\u0119, a wyniki by\u0142y niemal r\u00f3wnie dobre.", "tokens": [51356, 598, 17020, 10402, 7706, 5249, 6169, 89, 65, 1274, 6220, 27965, 3901, 277, 714, 1221, 305, 1274, 11, 257, 31936, 9850, 26366, 2838, 5579, 11416, 14215, 41959, 13, 51628], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 101, "seek": 30828, "start": 333.55999999999995, "end": 336.2, "text": " To by\u0142 mocny sygna\u0142 w kierunku efektywno\u015bci.", "tokens": [51628, 1407, 16673, 34962, 1634, 943, 70, 629, 1221, 261, 38767, 49910, 31482, 916, 874, 20944, 6199, 13, 51760], "temperature": 0.0, "avg_logprob": -0.09155042810377732, "compression_ratio": 1.4129692832764504, "no_speech_prob": 0.0679776519536972}, {"id": 102, "seek": 33620, "start": 336.2, "end": 338.56, "text": " Czekaj, zatrzymajmy si\u0119 na chwil\u0119.", "tokens": [50364, 383, 19878, 1805, 11, 35802, 13047, 1696, 73, 2226, 3244, 1667, 41941, 1274, 13, 50482], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 103, "seek": 33620, "start": 338.56, "end": 343.92, "text": " Skoro ten korpus C4 to po prostu surowy tekst z internetu,", "tokens": [50482, 7324, 10780, 2064, 14784, 31624, 383, 19, 281, 714, 19518, 1022, 10089, 16624, 372, 710, 4705, 84, 11, 50750], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 104, "seek": 33620, "start": 343.92, "end": 348.92, "text": " bez \u017cadnych etykiet typu to jest dobre streszczenie, a to z\u0142e,", "tokens": [50750, 10782, 39628, 9399, 1030, 46127, 1684, 2125, 84, 281, 3492, 41959, 342, 495, 89, 39043, 11, 257, 281, 710, 19827, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 105, "seek": 33620, "start": 348.92, "end": 353.4, "text": " to sk\u0105d model w og\u00f3le ma wiedzie\u0107, co jest dobr\u0105, a co z\u0142\u0105 odpowiedzi\u0105?", "tokens": [51000, 281, 1110, 18962, 2316, 261, 29229, 463, 261, 22078, 11, 598, 3492, 23067, 1611, 11, 257, 598, 710, 15926, 36574, 3992, 1611, 30, 51224], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 106, "seek": 33620, "start": 353.4, "end": 357.96, "text": " Jak\u0105 si\u0119 czegokolwiek uczy na tym pierwszym, najwa\u017cniejszym etapie?", "tokens": [51224, 15029, 1611, 3244, 6472, 1146, 49207, 44674, 344, 6522, 1667, 8107, 34016, 76, 11, 11212, 27111, 10402, 7706, 76, 47634, 414, 30, 51452], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 107, "seek": 33620, "start": 357.96, "end": 361.88, "text": " To jest \u015bwietne pytanie i sedno ca\u0142ego pretrainingu.", "tokens": [51452, 1407, 3492, 8299, 39083, 716, 36610, 741, 9643, 1771, 35224, 6308, 1162, 424, 1760, 84, 13, 51648], "temperature": 0.0, "avg_logprob": -0.13720861077308655, "compression_ratio": 1.3984674329501916, "no_speech_prob": 0.011230144649744034}, {"id": 108, "seek": 36188, "start": 361.88, "end": 366.6, "text": " Zadanie, kt\u00f3re wymy\u015blili, nazywa si\u0119 dinoising, czyli odszumianie.", "tokens": [50364, 1176, 345, 7155, 11, 8864, 4628, 2226, 19212, 2312, 11, 20151, 88, 4151, 3244, 274, 2982, 3436, 11, 16591, 3611, 15453, 449, 952, 414, 13, 50600], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 109, "seek": 36188, "start": 366.6, "end": 373.56, "text": " Wyobra\u017a sobie, \u017ce bierzesz idealnie czysty, gramatyczny tekst z C4, a potem celowo go niszczysz.", "tokens": [50600, 14458, 24393, 10659, 13652, 11, 3561, 272, 34602, 10430, 7157, 2766, 6430, 25134, 11, 21353, 267, 17466, 1634, 16624, 372, 710, 383, 19, 11, 257, 36513, 9277, 19941, 352, 297, 23848, 3689, 20589, 13, 50948], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 110, "seek": 36188, "start": 373.56, "end": 376.12, "text": " Ich metoda nazywa\u0142a si\u0119 span corruption.", "tokens": [50948, 3141, 1131, 13449, 20151, 88, 4151, 5024, 3244, 16174, 17959, 13, 51076], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 111, "seek": 36188, "start": 376.12, "end": 379.68, "text": " Losowo wycinali ca\u0142e fragmenty zda\u0144, spany", "tokens": [51076, 7632, 19941, 4628, 20021, 5103, 47631, 26424, 88, 710, 2675, 5248, 11, 637, 1325, 51254], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 112, "seek": 36188, "start": 379.68, "end": 383.2, "text": " i w ich dysce wstawiali taki pojedynczy, unikalny znacznik.", "tokens": [51254, 741, 261, 1893, 15243, 384, 261, 22580, 831, 72, 20065, 714, 40543, 2534, 6522, 11, 517, 41216, 1634, 15397, 14875, 13123, 13, 51430], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 113, "seek": 36188, "start": 383.2, "end": 386.56, "text": " Czyli dawali modelowi tekst z dziurami.", "tokens": [51430, 37099, 43438, 5103, 2316, 24503, 16624, 372, 710, 31981, 374, 4526, 13, 51598], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 114, "seek": 36188, "start": 386.56, "end": 389.44, "text": " I kazali mu odgadno\u015b\u0107, co w tych dziurach by\u0142o.", "tokens": [51598, 286, 30623, 5103, 2992, 3611, 70, 345, 23293, 11, 598, 261, 15180, 31981, 374, 608, 14811, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16409591017969397, "compression_ratio": 1.4432624113475176, "no_speech_prob": 0.08037398010492325}, {"id": 115, "seek": 38944, "start": 389.44, "end": 395.0, "text": " Musia\u0142 na podstawie kontekstu wygenerowa\u0107 brakuj\u0105ce s\u0142owa w dobrej kolejno\u015bci.", "tokens": [50364, 3569, 8908, 1667, 43443, 414, 14373, 916, 372, 84, 4628, 21848, 11445, 1548, 74, 13263, 384, 15116, 5528, 261, 41959, 73, 23749, 16438, 13, 50642], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 116, "seek": 38944, "start": 395.0, "end": 399.0, "text": " To jak taka ekstremalnie trudna wersja uzupe\u0142niania Luke w tek\u015bcie.", "tokens": [50642, 1407, 4207, 28017, 13359, 372, 2579, 304, 2766, 32007, 629, 261, 433, 2938, 344, 11728, 31457, 77, 952, 654, 13044, 261, 16624, 9815, 13, 50842], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 117, "seek": 38944, "start": 399.0, "end": 405.44, "text": " Robi\u0105c to miliardy razy na zr\u00f3\u017cnicowanych danych, model jest zmuszony nauczy\u0107 si\u0119 gramatyki, logiki", "tokens": [50842, 5424, 11404, 66, 281, 1962, 72, 515, 88, 9639, 88, 1667, 710, 11721, 1427, 7692, 23341, 339, 274, 34644, 11, 2316, 3492, 17020, 22378, 2526, 49103, 27150, 3244, 21353, 21398, 2984, 11, 3565, 9850, 51164], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 118, "seek": 38944, "start": 405.44, "end": 408.44, "text": " no i w ko\u0144cu ogromnej ilo\u015bci wiedzy o \u015bwiecie.", "tokens": [51164, 572, 741, 261, 26470, 12032, 34416, 298, 11794, 1930, 44468, 46894, 1229, 277, 40078, 4260, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 119, "seek": 38944, "start": 408.44, "end": 412.08, "text": " Ta metoda okaza\u0142a si\u0119 te\u017c znacznie bardziej wydajna obliczeniowo,", "tokens": [51314, 6551, 1131, 13449, 3133, 12257, 5024, 3244, 9516, 15397, 14875, 2766, 27209, 25984, 1805, 629, 1111, 1050, 42124, 19941, 11, 51496], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 120, "seek": 38944, "start": 412.08, "end": 415.84, "text": " ni\u017c popularne wtedy maskowanie pojedynczych s\u0142\u00f3w jak w modelu Bert.", "tokens": [51496, 28502, 3743, 716, 26959, 6094, 22028, 714, 40543, 2534, 6522, 339, 15116, 3901, 4207, 261, 2316, 84, 29594, 13, 51684], "temperature": 0.0, "avg_logprob": -0.11727808011288675, "compression_ratio": 1.435897435897436, "no_speech_prob": 0.1739652156829834}, {"id": 121, "seek": 41584, "start": 415.84, "end": 419.76, "text": " Okej, rozpakujmy to. To jest jak wielkie \u015bledztwo.", "tokens": [50364, 29094, 73, 11, 9544, 45944, 4579, 2226, 281, 13, 1407, 3492, 4207, 20570, 22872, 8299, 1493, 2682, 6120, 13, 50560], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 122, "seek": 41584, "start": 419.76, "end": 424.35999999999996, "text": " Mieli kilku podejrzanych architektur\u0119, dane, strategi\u0119 treningu.", "tokens": [50560, 376, 23099, 5128, 5279, 7468, 73, 19390, 34644, 3912, 642, 2320, 374, 1274, 11, 49206, 11, 5464, 5034, 2192, 773, 84, 13, 50790], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 123, "seek": 41584, "start": 424.35999999999996, "end": 427.71999999999997, "text": " I musieli systematycznie sprawdza\u0107, kt\u00f3ry jest kluczowy.", "tokens": [50790, 286, 1038, 23099, 1185, 267, 17466, 2766, 46192, 35873, 11, 9913, 3492, 9671, 1311, 89, 10089, 13, 50958], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 124, "seek": 41584, "start": 427.71999999999997, "end": 431.28, "text": " Mieli solidny fundament, wi\u0119c mogli zacz\u0105\u0107 wielkie testowanie.", "tokens": [50958, 376, 23099, 5100, 1634, 6073, 11, 16677, 13172, 2081, 34430, 8925, 2162, 20570, 22872, 1500, 22028, 13, 51136], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 125, "seek": 41584, "start": 431.28, "end": 433.28, "text": " Dok\u0142adnie tak.", "tokens": [51136, 29768, 10358, 2766, 991, 13, 51236], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 126, "seek": 41584, "start": 433.28, "end": 438.0, "text": " I pierwszy trop zaprowadzi\u0142 ich z powrotem do danych.", "tokens": [51236, 286, 34016, 9006, 14223, 1892, 345, 3992, 1221, 1893, 710, 3388, 10536, 443, 360, 274, 34644, 13, 51472], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 127, "seek": 41584, "start": 438.0, "end": 441.0, "text": " Potwierdzili co\u015b, co wydaje si\u0119 intuicyjne.", "tokens": [51472, 9145, 40717, 28168, 2312, 19241, 11, 598, 49165, 3244, 560, 84, 2632, 73, 716, 13, 51622], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 128, "seek": 41584, "start": 441.0, "end": 443.88, "text": " Je\u015bli trenujesz model na danych z konkretnej dziedziny.", "tokens": [51622, 37086, 23136, 4579, 10430, 2316, 1667, 274, 34644, 710, 36500, 11794, 9758, 15338, 3519, 13, 51766], "temperature": 0.0, "avg_logprob": -0.12493111182903421, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.1518135368824005}, {"id": 129, "seek": 44388, "start": 443.88, "end": 445.88, "text": " Na przyk\u0142ad na artyku\u0142ach z Wikipedia.", "tokens": [50364, 6056, 23144, 1667, 594, 874, 5279, 1221, 608, 710, 28999, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 130, "seek": 44388, "start": 445.88, "end": 449.24, "text": " To b\u0119dzie on potem lepszy w zadaniach zwi\u0105zanych z t\u0105 dziedzin\u0105,", "tokens": [50464, 1407, 10562, 322, 36513, 476, 1878, 1229, 261, 42788, 3782, 608, 27741, 34644, 710, 32294, 9758, 15338, 259, 1611, 11, 50632], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 131, "seek": 44388, "start": 449.24, "end": 451.88, "text": " jak odpowiadanie na pytania encyklopedyczne.", "tokens": [50632, 4207, 24314, 38069, 7155, 1667, 25878, 5609, 465, 1344, 7837, 404, 6038, 38491, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 132, "seek": 44388, "start": 451.88, "end": 453.88, "text": " To akurat logiczne.", "tokens": [50764, 1407, 9308, 44108, 9952, 43077, 13, 50864], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 133, "seek": 44388, "start": 453.88, "end": 458.48, "text": " Jak uczysz si\u0119 do egzaminu z historii, to czytasz podr\u0119czniki do historii i nie do fizyki.", "tokens": [50864, 15029, 344, 3689, 20589, 3244, 360, 24263, 89, 7428, 84, 710, 4058, 5597, 11, 281, 6430, 83, 19601, 15305, 1274, 3689, 77, 9850, 360, 4058, 5597, 741, 2838, 360, 21000, 88, 2984, 13, 51094], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 134, "seek": 44388, "start": 458.48, "end": 461.48, "text": " Tak, ale to nie by\u0142 najwa\u017cniejszy wniosek.", "tokens": [51094, 9118, 11, 6775, 281, 2838, 16673, 11212, 27111, 10402, 7706, 261, 3722, 541, 74, 13, 51244], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 135, "seek": 44388, "start": 461.48, "end": 464.48, "text": " Odkryli co\u015b znacznie ciekawszego.", "tokens": [51244, 12210, 43298, 2081, 19241, 15397, 14875, 2766, 46419, 1607, 15453, 6308, 13, 51394], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 136, "seek": 44388, "start": 464.48, "end": 467.48, "text": " Okaza\u0142o si\u0119, \u017ce wydajno\u015b\u0107 modelu dramatycznie spada,", "tokens": [51394, 3477, 12257, 5249, 3244, 11, 3561, 25984, 1805, 23293, 2316, 84, 42749, 17466, 2766, 637, 1538, 11, 51544], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 137, "seek": 44388, "start": 467.48, "end": 469.48, "text": " je\u015bli zbi\u00f3r danych jest na tyle ma\u0142y,", "tokens": [51544, 25630, 710, 5614, 15614, 274, 34644, 3492, 1667, 39293, 463, 6825, 11, 51644], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 138, "seek": 44388, "start": 469.48, "end": 473.48, "text": " \u017ce podczas pretreningu trzeba go wielokrotnie powtarza\u0107.", "tokens": [51644, 3561, 2497, 30989, 1162, 1095, 7050, 25860, 352, 20570, 453, 10536, 2766, 3388, 23480, 35873, 13, 51844], "temperature": 0.0, "avg_logprob": -0.14018758495202224, "compression_ratio": 1.5029761904761905, "no_speech_prob": 0.047101885080337524}, {"id": 139, "seek": 47348, "start": 473.48, "end": 476.48, "text": " Czyli model zaczyna uczy\u0107 si\u0119 na pami\u0119\u0107,", "tokens": [50364, 37099, 2316, 43811, 629, 344, 33967, 3244, 1667, 31088, 2162, 11, 50514], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 140, "seek": 47348, "start": 476.48, "end": 478.48, "text": " zamiast generalizowa\u0107.", "tokens": [50514, 710, 4526, 525, 2674, 590, 11445, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 141, "seek": 47348, "start": 478.48, "end": 482.48, "text": " Troch\u0119 jak ucze\u0144, kt\u00f3ry zakuwa na blach\u0119 odpowiedzi do testu,", "tokens": [50614, 19406, 23006, 4207, 344, 9680, 5248, 11, 9913, 23810, 84, 4151, 1667, 888, 608, 1274, 36574, 3992, 360, 1500, 84, 11, 50814], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 142, "seek": 47348, "start": 482.48, "end": 484.48, "text": " zamiast zrozumie\u0107 materia\u0142.", "tokens": [50814, 710, 4526, 525, 710, 27857, 449, 414, 2162, 2389, 8908, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 143, "seek": 47348, "start": 484.48, "end": 485.48, "text": " Idealna analogia.", "tokens": [50914, 13090, 304, 629, 16660, 654, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 144, "seek": 47348, "start": 485.48, "end": 488.48, "text": " Model zamiast uczy\u0107 si\u0119 regu\u0142 j\u0119zykowych,", "tokens": [50964, 17105, 710, 4526, 525, 344, 33967, 3244, 1121, 84, 1221, 49055, 74, 19605, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 145, "seek": 47348, "start": 488.48, "end": 490.48, "text": " zaczyna zapami\u0119tywa\u0107 konkretne zdania,", "tokens": [51114, 43811, 629, 14223, 23806, 874, 25234, 36500, 716, 16221, 5609, 11, 51214], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 146, "seek": 47348, "start": 490.48, "end": 493.48, "text": " co jest katastrof\u0105 dla jego zdolno\u015bci adaptacji.", "tokens": [51214, 598, 3492, 16536, 525, 340, 69, 1611, 12285, 26542, 16221, 401, 16438, 6231, 13152, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 147, "seek": 47348, "start": 493.48, "end": 497.48, "text": " To pokaza\u0142o, jak absolutnie kluczowy jest dost\u0119p do ogromnych,", "tokens": [51364, 1407, 13010, 12257, 5249, 11, 4207, 18757, 2766, 9671, 1311, 89, 10089, 3492, 48209, 360, 34416, 298, 9399, 11, 51564], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 148, "seek": 47348, "start": 497.48, "end": 499.48, "text": " niepowtarzalnych zbior\u00f3w danych.", "tokens": [51564, 2838, 14701, 23480, 89, 304, 9399, 710, 33362, 3901, 274, 34644, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 149, "seek": 47348, "start": 499.48, "end": 502.48, "text": " Lepiej mie\u0107 wi\u0119cej zr\u00f3\u017cnicowanego materia\u0142u,", "tokens": [51664, 441, 595, 7764, 35612, 26004, 710, 11721, 1427, 7692, 37345, 6308, 2389, 8908, 84, 11, 51814], "temperature": 0.0, "avg_logprob": -0.07710346543645284, "compression_ratio": 1.5177993527508091, "no_speech_prob": 0.08786504715681076}, {"id": 150, "seek": 50248, "start": 502.48, "end": 504.48, "text": " je\u015bli przejdzie si\u0119 przez niego tylko raz.", "tokens": [50364, 25630, 8325, 73, 13096, 3244, 14064, 49615, 13219, 9639, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 151, "seek": 50248, "start": 504.48, "end": 507.48, "text": " Dobrze, a co z drugim elementem uk\u0142adanki?", "tokens": [50464, 29679, 13503, 11, 257, 598, 710, 4110, 332, 4478, 443, 344, 15317, 27203, 30, 50614], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 152, "seek": 50248, "start": 507.48, "end": 510.48, "text": " Mamy ju\u017c ten pot\u0119\u017cny, wst\u0119pnie wytrenowany model.", "tokens": [50614, 376, 7804, 10678, 2064, 1847, 1274, 1427, 1634, 11, 261, 372, 18085, 2766, 261, 4328, 1095, 23341, 2316, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 153, "seek": 50248, "start": 510.48, "end": 511.48, "text": " Co dalej?", "tokens": [50764, 3066, 34257, 30, 50814], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 154, "seek": 50248, "start": 511.48, "end": 514.48, "text": " Jak go dostosowa\u0107 do konkretnego zadania?", "tokens": [50814, 15029, 352, 20568, 329, 11445, 360, 36500, 11858, 42788, 5609, 30, 50964], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 155, "seek": 50248, "start": 514.48, "end": 517.48, "text": " Intuicja podpowiada, \u017ce to troch\u0119 ryzykowne.", "tokens": [50964, 5681, 84, 299, 2938, 2497, 14701, 39018, 11, 3561, 281, 24926, 20791, 1229, 74, 648, 68, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 156, "seek": 50248, "start": 517.48, "end": 520.48, "text": " Uczymy model przez miesi\u0105ce og\u00f3lnej wiedzy,", "tokens": [51114, 624, 6522, 2226, 2316, 14064, 41543, 11404, 384, 5360, 15741, 11794, 46894, 1229, 11, 51264], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 157, "seek": 50248, "start": 520.48, "end": 523.48, "text": " a potem pozwalamy mu cz\u0119\u015b\u0107 z tego zapomnie\u0107.", "tokens": [51264, 257, 36513, 40557, 304, 7804, 2992, 47149, 710, 8627, 14223, 298, 2766, 2162, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 158, "seek": 50248, "start": 523.48, "end": 524.48, "text": " W\u0142a\u015bnie.", "tokens": [51414, 343, 5024, 12221, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 159, "seek": 50248, "start": 524.48, "end": 526.48, "text": " To jest fascynuj\u0105ce.", "tokens": [51464, 1407, 3492, 30632, 1344, 77, 13263, 384, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 160, "seek": 50248, "start": 526.48, "end": 531.48, "text": " Przetestowali r\u00f3\u017cne strategie, w tym popularne wtedy adapter layers,", "tokens": [51564, 2114, 40399, 377, 305, 5103, 47760, 5464, 414, 11, 261, 8107, 3743, 716, 26959, 22860, 7914, 11, 51814], "temperature": 0.0, "avg_logprob": -0.0591209473148469, "compression_ratio": 1.4044585987261147, "no_speech_prob": 0.009845834225416183}, {"id": 161, "seek": 53148, "start": 531.48, "end": 534.48, "text": " czyli dodawania takich ma\u0142ych, doczepianych modu\u0142\u00f3w,", "tokens": [50364, 16591, 13886, 1607, 5609, 29607, 463, 47655, 11, 3211, 46342, 952, 16384, 1072, 84, 1221, 3901, 11, 50514], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 162, "seek": 53148, "start": 534.48, "end": 539.48, "text": " kt\u00f3re si\u0119 trenowa\u0142o, a reszta gigantycznego modelu pozostawa\u0142a zamro\u017cona.", "tokens": [50514, 8864, 3244, 23136, 5528, 5249, 11, 257, 725, 89, 1328, 8741, 394, 17466, 11858, 2316, 84, 21281, 555, 10449, 5024, 19876, 340, 1427, 4037, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 163, "seek": 53148, "start": 539.48, "end": 542.48, "text": " Tanie obiczeniowo i bezpieczne, tak.", "tokens": [50764, 314, 7155, 1111, 299, 42124, 19941, 741, 47153, 38491, 11, 991, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 164, "seek": 53148, "start": 542.48, "end": 545.48, "text": " Tak si\u0119 wydawa\u0142o, ale wynik by\u0142 jednoznaczny.", "tokens": [50914, 9118, 3244, 25984, 10449, 5249, 11, 6775, 31936, 1035, 16673, 5232, 1771, 22672, 14875, 1634, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 165, "seek": 53148, "start": 545.48, "end": 550.48, "text": " Najlepsze rezultaty dawa\u0142 fine tuning wszystkich parametr\u00f3w modelu.", "tokens": [51064, 31576, 306, 1878, 1381, 48060, 723, 21398, 1120, 44603, 2489, 15164, 34234, 6220, 27965, 3901, 2316, 84, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 166, "seek": 53148, "start": 550.48, "end": 553.48, "text": " Okaza\u0142o si\u0119, \u017ce model nie tyle zapomina,", "tokens": [51314, 3477, 12257, 5249, 3244, 11, 3561, 2316, 2838, 39293, 14223, 49217, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 167, "seek": 53148, "start": 553.48, "end": 556.48, "text": " co uczy si\u0119, jak swoj\u0105 ogromn\u0105, og\u00f3ln\u0105 wiedz\u0119", "tokens": [51464, 598, 344, 6522, 3244, 11, 4207, 49194, 34416, 298, 13113, 11, 5360, 15741, 13113, 46894, 11052, 51614], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 168, "seek": 53148, "start": 556.48, "end": 560.48, "text": " najlepiej zastosowa\u0107 w nowym, specyficznym kontek\u015bcie.", "tokens": [51614, 41903, 39699, 36746, 329, 11445, 261, 586, 4199, 11, 768, 1344, 1786, 89, 12996, 14373, 916, 9815, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0775629344739412, "compression_ratio": 1.4865771812080537, "no_speech_prob": 0.006401658058166504}, {"id": 169, "seek": 56048, "start": 560.48, "end": 564.48, "text": " To podej\u015bcie wszystko albo nic, cho\u0107 najdro\u017csze.", "tokens": [50364, 1407, 7468, 73, 9815, 22607, 22622, 6201, 11, 1586, 2162, 11212, 45869, 1427, 82, 1381, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 170, "seek": 56048, "start": 564.48, "end": 566.48, "text": " Dawa\u0142o po prostu najlepsz\u0105 jako\u015b\u0107.", "tokens": [50564, 413, 10449, 5249, 714, 19518, 41903, 1878, 8925, 17123, 7753, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 171, "seek": 56048, "start": 566.48, "end": 570.48, "text": " I wreszcie dochodzimy do trzeciego wielkiego pytania.", "tokens": [50664, 286, 261, 495, 89, 4260, 9243, 378, 89, 13189, 360, 22266, 4260, 1571, 20570, 42349, 25878, 5609, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 172, "seek": 56048, "start": 570.48, "end": 571.48, "text": " Skalowanie.", "tokens": [50864, 7324, 304, 22028, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 173, "seek": 56048, "start": 571.48, "end": 575.48, "text": " To jest co\u015b, co w AI nazywa si\u0119 czasem gorzk\u0105 lekcj\u0105.", "tokens": [50914, 1407, 3492, 19241, 11, 598, 261, 7318, 20151, 88, 4151, 3244, 13190, 443, 24012, 89, 26304, 30863, 66, 8555, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 174, "seek": 56048, "start": 575.48, "end": 577.48, "text": " Tak, s\u0142ynna bitter lesson.", "tokens": [51114, 9118, 11, 15116, 2534, 629, 13871, 6898, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 175, "seek": 56048, "start": 577.48, "end": 581.48, "text": " M\u00f3wi ona, \u017ce na d\u0142u\u017csz\u0105 met\u0119 wygrywaj\u0105 niekoniecznie", "tokens": [51214, 376, 3901, 72, 20325, 11, 3561, 1667, 274, 24066, 1427, 82, 8925, 1131, 1274, 4628, 70, 47705, 11133, 2838, 18295, 414, 19923, 51414], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 176, "seek": 56048, "start": 581.48, "end": 583.48, "text": " najbardziej eleganckie algorytmy,", "tokens": [51414, 41857, 1118, 1275, 547, 414, 3501, 827, 83, 2226, 11, 51514], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 177, "seek": 56048, "start": 583.48, "end": 585.48, "text": " ale te proste i og\u00f3lne,", "tokens": [51514, 6775, 535, 10293, 68, 741, 5360, 15741, 716, 11, 51614], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 178, "seek": 56048, "start": 585.48, "end": 589.48, "text": " kt\u00f3re potrafi\u0105 w pe\u0142ni wykorzysta\u0107 rosn\u0105c\u0105 moc obliczeniow\u0105.", "tokens": [51614, 8864, 1847, 10437, 11404, 261, 43205, 3722, 43606, 49590, 2162, 18953, 13113, 32557, 34962, 1111, 1050, 42124, 30297, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0676906813615523, "compression_ratio": 1.4111842105263157, "no_speech_prob": 0.0019065425731241703}, {"id": 179, "seek": 58948, "start": 589.48, "end": 593.48, "text": " Goszka, bo to troch\u0119 upokarzaj\u0105ce dla badaczy.", "tokens": [50364, 460, 329, 89, 2330, 11, 748, 281, 24926, 493, 453, 49763, 11133, 384, 12285, 1578, 14691, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 180, "seek": 58948, "start": 593.48, "end": 595.48, "text": " Tyle lat wymy\u015blania, sprytnych sztuczek,", "tokens": [50564, 314, 2072, 4465, 4628, 2226, 19212, 5609, 11, 637, 627, 83, 9399, 262, 2682, 1311, 19878, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 181, "seek": 58948, "start": 595.48, "end": 597.48, "text": " a na ko\u0144cu przychodzi kto\u015b,", "tokens": [50664, 257, 1667, 26470, 12032, 6501, 34616, 32982, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 182, "seek": 58948, "start": 597.48, "end": 601.48, "text": " kto po prostu buduje 10 razy wi\u0119kszy model i wygrywa.", "tokens": [50764, 23780, 714, 19518, 3265, 13008, 1266, 9639, 88, 29968, 1229, 2316, 741, 4628, 70, 627, 4151, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 183, "seek": 58948, "start": 601.48, "end": 602.48, "text": " Dok\u0142adnie.", "tokens": [50964, 29768, 10358, 2766, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 184, "seek": 58948, "start": 602.48, "end": 606.48, "text": " Ale autorzy Ty5 postawili to pytanie bardzo konkretnie.", "tokens": [51014, 9366, 19510, 1229, 5569, 20, 2183, 1607, 2312, 281, 36610, 9034, 36500, 2766, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 185, "seek": 58948, "start": 606.48, "end": 609.48, "text": " Masz 4 razy wi\u0119cej mocy obliczeniowej,", "tokens": [51214, 5224, 89, 1017, 9639, 88, 26004, 705, 1344, 1111, 1050, 42124, 21091, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 186, "seek": 58948, "start": 609.48, "end": 611.48, "text": " jak j\u0105 najlepiej wykorzysta\u0107.", "tokens": [51364, 4207, 35692, 41903, 39699, 43606, 49590, 2162, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 187, "seek": 58948, "start": 611.48, "end": 612.48, "text": " I por\u00f3wnali 3 opcje.", "tokens": [51464, 286, 1515, 812, 895, 5103, 805, 999, 44261, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 188, "seek": 58948, "start": 612.48, "end": 613.48, "text": " Czyli?", "tokens": [51514, 37099, 30, 51564], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 189, "seek": 58948, "start": 613.48, "end": 616.48, "text": " Trenowa\u0107 ten sam model, ale 4 razy d\u0142u\u017cej.", "tokens": [51564, 314, 1095, 11445, 2064, 3247, 2316, 11, 6775, 1017, 9639, 88, 274, 24066, 38493, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10052716409837878, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.008954465389251709}, {"id": 190, "seek": 61648, "start": 616.48, "end": 619.48, "text": " U\u017cy\u0107 4 razy wi\u0119kszego modelu przez ten sam czas.", "tokens": [50364, 624, 7735, 2162, 1017, 9639, 88, 29968, 27725, 2316, 84, 14064, 2064, 3247, 13190, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 191, "seek": 61648, "start": 619.48, "end": 623.48, "text": " Czy mo\u017ce wytrenowa\u0107 4 mniejsze i u\u015bredni cich odpowiedzi?", "tokens": [50514, 19832, 12034, 261, 4328, 1095, 11445, 1017, 275, 44258, 741, 344, 1788, 986, 3722, 269, 480, 36574, 3992, 30, 50714], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 192, "seek": 61648, "start": 623.48, "end": 624.48, "text": " Taki ensemble.", "tokens": [50714, 314, 7421, 19492, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 193, "seek": 61648, "start": 624.48, "end": 625.48, "text": " W\u0142a\u015bnie.", "tokens": [50764, 343, 5024, 12221, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 194, "seek": 61648, "start": 625.48, "end": 627.48, "text": " I wyniki by\u0142y pouczaj\u0105ce.", "tokens": [50814, 286, 31936, 9850, 26366, 714, 1311, 89, 11133, 384, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 195, "seek": 61648, "start": 627.48, "end": 631.48, "text": " Okaza\u0142o si\u0119, \u017ce cho\u0107 wszystkie te strategie poprawia\u0142y wyniki,", "tokens": [50914, 3477, 12257, 5249, 3244, 11, 3561, 1586, 2162, 31723, 535, 5464, 414, 1665, 5131, 654, 6825, 31936, 9850, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 196, "seek": 61648, "start": 631.48, "end": 634.48, "text": " to bardzo cz\u0119sto trenowanie po prostu wi\u0119kszego modelu", "tokens": [51114, 281, 9034, 34369, 23136, 22028, 714, 19518, 29968, 27725, 2316, 84, 51264], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 197, "seek": 61648, "start": 634.48, "end": 636.48, "text": " przynosi\u0142o lepsze rezultaty.", "tokens": [51264, 6501, 16751, 72, 5249, 476, 1878, 1381, 48060, 723, 21398, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 198, "seek": 61648, "start": 636.48, "end": 640.48, "text": " Lepsze ni\u017c trenowanie mniejszego modelu przez znacznie d\u0142u\u017cszy czas.", "tokens": [51364, 441, 10653, 1381, 28502, 23136, 22028, 275, 30295, 27725, 2316, 84, 14064, 15397, 14875, 2766, 274, 24066, 1427, 7706, 13190, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 199, "seek": 61648, "start": 640.48, "end": 642.48, "text": " Wniosek jest prosty.", "tokens": [51564, 343, 3722, 541, 74, 3492, 10293, 88, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07643512222501966, "compression_ratio": 1.544776119402985, "no_speech_prob": 0.10340172052383423}, {"id": 200, "seek": 64248, "start": 642.48, "end": 646.48, "text": " Ta pojemna\u015b\u0107 sieci, jej rozmiar, ma ogromne znaczenie.", "tokens": [50364, 6551, 714, 30833, 629, 7753, 2804, 537, 11, 28924, 9544, 3057, 289, 11, 463, 34416, 298, 716, 15397, 326, 16778, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 201, "seek": 64248, "start": 646.48, "end": 650.48, "text": " A potem zrobili to, co sugerowa\u0142a gorszka lekcja.", "tokens": [50564, 316, 36513, 44399, 2312, 281, 11, 598, 459, 1321, 5528, 5024, 290, 830, 89, 2330, 30863, 34056, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 202, "seek": 64248, "start": 650.48, "end": 652.48, "text": " Przeskalowa\u0142y to wszystko do rozmiar\u00f3w,", "tokens": [50764, 2114, 12214, 19990, 5528, 6825, 281, 22607, 360, 9544, 3057, 289, 3901, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 203, "seek": 64248, "start": 652.48, "end": 655.48, "text": " kt\u00f3re w tamtym czasie by\u0142y wr\u0119cz niewyobra\u017calne.", "tokens": [50864, 8864, 261, 7677, 874, 76, 42667, 26366, 928, 1274, 3689, 43622, 88, 24393, 1427, 304, 716, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 204, "seek": 64248, "start": 655.48, "end": 657.48, "text": " Zgadza si\u0119.", "tokens": [51014, 1176, 70, 345, 2394, 3244, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 205, "seek": 64248, "start": 657.48, "end": 661.48, "text": " Zbudowa\u0142y ca\u0142\u0105 rodzin\u0119 modeli, kt\u00f3r\u0105 nazwa\u0142y T5,", "tokens": [51114, 1176, 18281, 5528, 6825, 1335, 15926, 8685, 23584, 1274, 2316, 72, 11, 37415, 20151, 4151, 6825, 314, 20, 11, 51314], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 206, "seek": 64248, "start": 661.48, "end": 665.48, "text": " czyli Text to Text Transfer Transformer.", "tokens": [51314, 16591, 18643, 281, 18643, 35025, 27938, 260, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 207, "seek": 64248, "start": 665.48, "end": 668.48, "text": " By\u0142y wersje Small, Base, Large,", "tokens": [51514, 3146, 6825, 261, 433, 2884, 15287, 11, 21054, 11, 33092, 11, 51664], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 208, "seek": 64248, "start": 668.48, "end": 671.48, "text": " a na samym szczycie znalaz\u0142y si\u0119 dwa potwory.", "tokens": [51664, 257, 1667, 3247, 4199, 7870, 6522, 4260, 710, 4660, 921, 6825, 3244, 35045, 1847, 86, 827, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09211343765258789, "compression_ratio": 1.4187725631768953, "no_speech_prob": 0.07081224024295807}, {"id": 209, "seek": 67148, "start": 671.48, "end": 678.48, "text": " Model strzema miliardami i wreszcie ten najwi\u0119kszy z 11 miliardami parametr\u00f3w.", "tokens": [50364, 17105, 1056, 89, 5619, 1962, 72, 515, 4526, 741, 261, 495, 89, 4260, 2064, 48636, 1694, 1229, 710, 2975, 1962, 72, 515, 4526, 6220, 27965, 3901, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 210, "seek": 67148, "start": 678.48, "end": 681.48, "text": " Ten ostatni by\u0142 trenowany na bilionie token\u00f3w.", "tokens": [50714, 9380, 32686, 3722, 16673, 23136, 23341, 1667, 8588, 313, 414, 14862, 3901, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 211, "seek": 67148, "start": 681.48, "end": 684.48, "text": " To s\u0105 liczby, kt\u00f3re trudno sobie nawet wyobrazi\u0107.", "tokens": [50864, 1407, 9015, 6169, 89, 2322, 11, 8864, 32007, 1771, 13652, 22696, 4628, 24393, 28496, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 212, "seek": 67148, "start": 684.48, "end": 686.48, "text": " No dobrze.", "tokens": [51014, 883, 28335, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 213, "seek": 67148, "start": 686.48, "end": 689.48, "text": " Wi\u0119c zbudowali ten j\u0119zykowy odpowiednik Gwiazdy \u015amierci.", "tokens": [51114, 32508, 710, 18281, 305, 5103, 2064, 49055, 74, 10089, 36574, 13123, 460, 86, 654, 89, 3173, 27933, 76, 811, 537, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 214, "seek": 67148, "start": 689.48, "end": 691.48, "text": " Jakie by\u0142y efekty,", "tokens": [51264, 15029, 414, 26366, 31482, 916, 874, 11, 51364], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 215, "seek": 67148, "start": 691.48, "end": 694.48, "text": " kiedy skierowali go na najtrudniejsze benchmarki j\u0119zykowe?", "tokens": [51364, 18777, 1110, 811, 305, 5103, 352, 1667, 11212, 6903, 532, 44258, 18927, 72, 49055, 74, 6880, 30, 51514], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 216, "seek": 67148, "start": 694.48, "end": 696.48, "text": " Spektakularne.", "tokens": [51514, 3550, 2320, 514, 1040, 716, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 217, "seek": 67148, "start": 696.48, "end": 698.48, "text": " Model osi\u0105gn\u0105\u0142 status State of the Art,", "tokens": [51614, 17105, 3003, 11404, 4568, 1611, 1221, 6558, 4533, 295, 264, 5735, 11, 51714], "temperature": 0.0, "avg_logprob": -0.0792460137225212, "compression_ratio": 1.4064748201438848, "no_speech_prob": 0.010688502341508865}, {"id": 218, "seek": 69848, "start": 698.48, "end": 703.48, "text": " czyli pobi\u0142 dotychczasowe rekordy na 18 z 24 testowanych zada\u0144.", "tokens": [50364, 16591, 714, 5614, 1221, 5893, 16384, 30989, 6880, 33881, 765, 88, 1667, 2443, 710, 4022, 1500, 23341, 339, 710, 1538, 5248, 13, 50614], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 219, "seek": 69848, "start": 703.48, "end": 706.48, "text": " Strzeszanie, odpowiadanie na pytania, klasyfikacja tekstu,", "tokens": [50614, 8251, 89, 10430, 7155, 11, 24314, 38069, 7155, 1667, 25878, 5609, 11, 9671, 5871, 31230, 23395, 16624, 372, 84, 11, 50764], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 220, "seek": 69848, "start": 706.48, "end": 708.48, "text": " praktycznie ca\u0142y przekr\u00f3j problem\u00f3w NLP.", "tokens": [50764, 3206, 74, 45586, 35226, 29785, 11721, 73, 1154, 3901, 426, 45196, 13, 50864], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 221, "seek": 69848, "start": 708.48, "end": 711.48, "text": " By\u0142 jaki\u015b wynik, kt\u00f3ry zrobi\u0142 szczeg\u00f3lne wra\u017cenie?", "tokens": [50864, 3146, 1221, 34721, 31936, 1035, 11, 9913, 24483, 1221, 49624, 716, 7843, 41118, 30, 51014], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 222, "seek": 69848, "start": 711.48, "end": 713.48, "text": " Zdecydowanie.", "tokens": [51014, 1176, 1479, 1344, 67, 22028, 13, 51114], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 223, "seek": 69848, "start": 713.48, "end": 715.48, "text": " Benchmark o nazwie Super Glue.", "tokens": [51114, 3964, 339, 5638, 277, 20151, 8699, 4548, 49832, 13, 51214], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 224, "seek": 69848, "start": 715.48, "end": 718.48, "text": " Zosta\u0142 on specjalnie zaprojektowany jako nast\u0119pca popularnego glue,", "tokens": [51214, 1176, 8638, 1221, 322, 46433, 2766, 14223, 340, 14930, 23341, 17123, 39662, 496, 3743, 11858, 8998, 11, 51364], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 225, "seek": 69848, "start": 718.48, "end": 721.48, "text": " ale z zadaniami o wiele, wiele trudniejszymi.", "tokens": [51364, 6775, 710, 710, 11338, 15568, 277, 33137, 11, 33137, 32007, 10402, 7706, 3057, 13, 51514], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 226, "seek": 69848, "start": 721.48, "end": 724.48, "text": " Mia\u0142 by\u0107 testem, kt\u00f3rego maszyny na d\u0142ugo nie przejd\u0105.", "tokens": [51514, 376, 8908, 15069, 1500, 443, 11, 46951, 2300, 1229, 1634, 1667, 44042, 20746, 2838, 8325, 37109, 1611, 13, 51664], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 227, "seek": 69848, "start": 724.48, "end": 726.48, "text": " A T5?", "tokens": [51664, 316, 314, 20, 30, 51764], "temperature": 0.0, "avg_logprob": -0.057704273658462715, "compression_ratio": 1.3907692307692308, "no_speech_prob": 0.02042762003839016}, {"id": 228, "seek": 72648, "start": 726.48, "end": 729.48, "text": " Najwi\u0119ksza wersja T5 nie tylko pobi\u0142a dotychczasowy rekord,", "tokens": [50364, 31576, 22423, 1694, 2394, 261, 433, 2938, 314, 20, 2838, 13219, 714, 5614, 5024, 5893, 16384, 30989, 10089, 33881, 765, 11, 50514], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 229, "seek": 72648, "start": 729.48, "end": 733.48, "text": " ale niemal zr\u00f3bna\u0142a si\u0119 z wynikiem osi\u0105ganym przez przeci\u0119tnego cz\u0142owieka.", "tokens": [50514, 6775, 2838, 5579, 710, 11721, 65, 629, 5024, 3244, 710, 31936, 1035, 4907, 3003, 11404, 1275, 4199, 14064, 39622, 46788, 11858, 36282, 2330, 13, 50714], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 230, "seek": 72648, "start": 733.48, "end": 736.48, "text": " To by\u0142 moment, w kt\u00f3rym wielu badaczy zrozumia\u0142o,", "tokens": [50714, 1407, 16673, 1623, 11, 261, 30120, 40437, 1578, 14691, 710, 27857, 449, 654, 5249, 11, 50864], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 231, "seek": 72648, "start": 736.48, "end": 739.48, "text": " \u017ce granice mo\u017cliwo\u015bci le\u017c\u0105 znacznie dalej ni\u017c s\u0105dzono.", "tokens": [50864, 3561, 9370, 573, 30854, 36476, 476, 1427, 1611, 15397, 14875, 2766, 34257, 28502, 9015, 28168, 8957, 13, 51014], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 232, "seek": 72648, "start": 739.48, "end": 742.48, "text": " Ale nie by\u0142 idealny, prawda? Gdzie\u015b sobie nie poradzi\u0142.", "tokens": [51014, 9366, 2838, 16673, 7157, 1634, 11, 43607, 30, 460, 13096, 1788, 13652, 2838, 1515, 345, 3992, 1221, 13, 51164], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 233, "seek": 72648, "start": 742.48, "end": 744.48, "text": " W zadaniach t\u0142umaczenia maszynowego,", "tokens": [51164, 343, 42788, 3782, 608, 256, 49166, 326, 14320, 2300, 1229, 3785, 6308, 11, 51264], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 234, "seek": 72648, "start": 744.48, "end": 747.48, "text": " ty pi\u0105ty by\u0142 dobry, ale nie pobi\u0142 tam rekord\u00f3w.", "tokens": [51264, 1104, 3895, 1611, 874, 16673, 35884, 11, 6775, 2838, 714, 5614, 1221, 7677, 33881, 765, 3901, 13, 51414], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 235, "seek": 72648, "start": 747.48, "end": 749.48, "text": " A prawdopodobn\u0105 przyczyn\u0105 jest to,", "tokens": [51414, 316, 41175, 46684, 996, 13113, 6501, 6522, 13113, 3492, 281, 11, 51514], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 236, "seek": 72648, "start": 749.48, "end": 752.48, "text": " \u017ce jego gigantyczny pre-training odbywa\u0142 si\u0119 niemal wy\u0142\u0105cznie", "tokens": [51514, 3561, 26542, 8741, 394, 17466, 1634, 659, 12, 17227, 1760, 3611, 2322, 44603, 3244, 2838, 5579, 4628, 15926, 19923, 51664], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 237, "seek": 72648, "start": 752.48, "end": 755.48, "text": " na angloj\u0119zycznych danych z C4.", "tokens": [51664, 1667, 2562, 752, 11115, 1229, 3689, 9399, 274, 34644, 710, 383, 19, 13, 51814], "temperature": 0.0, "avg_logprob": -0.04833561244763826, "compression_ratio": 1.5083333333333333, "no_speech_prob": 0.0042300596833229065}, {"id": 238, "seek": 75548, "start": 755.48, "end": 758.48, "text": " I najlepsze modele do t\u0142umacze\u0144 mia\u0142y jakiego\u015b asa w r\u0119kawie?", "tokens": [50364, 286, 41903, 1878, 1381, 4391, 306, 360, 256, 49166, 326, 49689, 21290, 6825, 4207, 12200, 1788, 382, 64, 261, 41197, 74, 1607, 414, 30, 50514], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 239, "seek": 75548, "start": 758.48, "end": 759.48, "text": " Mia\u0142y.", "tokens": [50514, 376, 654, 6825, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 240, "seek": 75548, "start": 759.48, "end": 763.48, "text": " U\u017cywa\u0142y sprytnej sztuczki, znanej jako Back Translation.", "tokens": [50564, 624, 7735, 4151, 6825, 637, 627, 83, 11794, 262, 2682, 1311, 89, 2984, 11, 15397, 1929, 73, 17123, 5833, 6531, 24278, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 241, "seek": 75548, "start": 763.48, "end": 765.48, "text": " Bierze si\u0119 tekst, na przyk\u0142ad po niemiecku,", "tokens": [50764, 363, 811, 1381, 3244, 16624, 372, 11, 1667, 23144, 714, 2838, 25210, 547, 84, 11, 50864], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 242, "seek": 75548, "start": 765.48, "end": 767.48, "text": " t\u0142umaczy go maszynowo z powrotem na angielski", "tokens": [50864, 256, 49166, 14691, 352, 2300, 1229, 3785, 78, 710, 3388, 10536, 443, 1667, 2562, 1187, 18020, 50964], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 243, "seek": 75548, "start": 767.48, "end": 771.48, "text": " i w ten spos\u00f3b tworzy si\u0119 nowe, syntetyczne dane treningowe.", "tokens": [50964, 741, 261, 2064, 22904, 46288, 1229, 3244, 586, 68, 11, 23980, 2210, 38491, 49206, 2192, 773, 6880, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 244, "seek": 75548, "start": 771.48, "end": 773.48, "text": " Tego zabrak\u0142o T5.", "tokens": [51164, 314, 6308, 24838, 11272, 5249, 314, 20, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 245, "seek": 75548, "start": 773.48, "end": 776.48, "text": " To pokazuje, \u017ce nawet przy niewyobra\u017calnej skali", "tokens": [51264, 1407, 13010, 43317, 11, 3561, 22696, 6501, 43622, 88, 24393, 1427, 304, 11794, 1110, 5103, 51414], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 246, "seek": 75548, "start": 776.48, "end": 779.48, "text": " specyfika danych wci\u0105\u017c ma kluczowe znaczenie.", "tokens": [51414, 768, 1344, 69, 5439, 274, 34644, 261, 537, 27242, 463, 9671, 1311, 89, 6880, 15397, 326, 16778, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 247, "seek": 75548, "start": 779.48, "end": 781.48, "text": " Wi\u0119c co to wszystko oznacza,", "tokens": [51564, 32508, 598, 281, 22607, 277, 22672, 326, 2394, 11, 51664], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 248, "seek": 75548, "start": 781.48, "end": 784.48, "text": " jaki jest g\u0142\u00f3wny wniosek z tej monumentalnej pracy?", "tokens": [51664, 24492, 3492, 18117, 812, 43682, 261, 3722, 541, 74, 710, 12573, 43105, 11794, 35591, 30, 51814], "temperature": 0.0, "avg_logprob": -0.07484147396493465, "compression_ratio": 1.452662721893491, "no_speech_prob": 0.09730213135480881}, {"id": 249, "seek": 78448, "start": 784.48, "end": 788.48, "text": " My\u015bl\u0119, \u017ce znaczenie pracy polega nie tyle na wynalezieniu", "tokens": [50364, 1222, 28749, 11, 3561, 15397, 326, 16778, 35591, 13208, 3680, 2838, 39293, 1667, 31936, 37646, 1053, 5951, 50564], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 250, "seek": 78448, "start": 788.48, "end": 791.48, "text": " jednej magicznej technice, co na stworzeniu", "tokens": [50564, 5232, 11794, 5585, 89, 11794, 1537, 573, 11, 598, 1667, 342, 28321, 39651, 50714], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 251, "seek": 78448, "start": 791.48, "end": 794.48, "text": " niezwykle klarownej przetestowanej mapy drogowej.", "tokens": [50714, 33511, 9726, 14677, 14743, 648, 40779, 6541, 302, 377, 23066, 73, 4471, 88, 3789, 70, 21091, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 252, "seek": 78448, "start": 794.48, "end": 797.48, "text": " Oni nie tyle dokonali skok\u00f3w nieznane,", "tokens": [50864, 1282, 72, 2838, 39293, 360, 18295, 5103, 1110, 453, 3901, 2838, 22672, 1929, 11, 51014], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 253, "seek": 78448, "start": 797.48, "end": 802.48, "text": " co metodycznie zbadali i zoptymalizowali ca\u0142\u0105 istniej\u0105c\u0105 wiedz\u0119.", "tokens": [51014, 598, 1131, 843, 19923, 710, 27580, 5103, 741, 710, 404, 874, 5579, 590, 305, 5103, 1335, 15926, 1418, 2766, 8555, 32557, 46894, 11052, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 254, "seek": 78448, "start": 802.48, "end": 804.48, "text": " A potem pokazali, co si\u0119 stanie,", "tokens": [51264, 316, 36513, 13010, 921, 5103, 11, 598, 3244, 40013, 11, 51364], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 255, "seek": 78448, "start": 804.48, "end": 807.48, "text": " gdy zastosuje si\u0119 j\u0105 na niespotykan\u0105 dot\u0105d skal\u0119.", "tokens": [51364, 28405, 36746, 329, 13008, 3244, 35692, 1667, 48100, 79, 6737, 5225, 1611, 5893, 18962, 16890, 1274, 13, 51514], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 256, "seek": 78448, "start": 807.48, "end": 809.48, "text": " Pokazali, \u017ce prostota i unifikacja,", "tokens": [51514, 14958, 921, 5103, 11, 3561, 10293, 5377, 741, 517, 45475, 23395, 11, 51614], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 257, "seek": 78448, "start": 809.48, "end": 812.48, "text": " po\u0142\u0105czone z brutaln\u0105 si\u0142\u0105 obliczeniow\u0105,", "tokens": [51614, 714, 43558, 546, 710, 17878, 13113, 1511, 15926, 1111, 1050, 42124, 30297, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0701116756269127, "compression_ratio": 1.508650519031142, "no_speech_prob": 0.03544643521308899}, {"id": 258, "seek": 81248, "start": 812.48, "end": 814.48, "text": " to przepis na przesuwanie granic.", "tokens": [50364, 281, 30829, 271, 1667, 6541, 279, 36824, 7155, 9370, 299, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 259, "seek": 81248, "start": 814.48, "end": 816.48, "text": " Czyli podsumowuj\u0105c.", "tokens": [50464, 37099, 31925, 449, 305, 44733, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 260, "seek": 81248, "start": 816.48, "end": 819.48, "text": " Si\u0142a idei, tekst to tekst.", "tokens": [50564, 4909, 5024, 1153, 72, 11, 16624, 372, 281, 16624, 372, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 261, "seek": 81248, "start": 819.48, "end": 823.48, "text": " Absolutnie fundamentalne znaczenie czystych i ogromnych danych.", "tokens": [50714, 5813, 2308, 2766, 8088, 716, 15397, 326, 16778, 6430, 372, 16384, 741, 34416, 298, 9399, 274, 34644, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 262, "seek": 81248, "start": 823.48, "end": 826.48, "text": " I zimne potwierdzenie gorzkiej lekcji.", "tokens": [50914, 286, 710, 332, 716, 1847, 40717, 67, 16778, 24012, 30154, 7764, 30863, 19649, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 263, "seek": 81248, "start": 826.48, "end": 830.48, "text": " Inteligentne skalowanie, czyli wi\u0119ksze modele i wi\u0119cej danych,", "tokens": [51064, 19762, 25002, 716, 16890, 22028, 11, 16591, 29968, 1381, 4391, 306, 741, 26004, 274, 34644, 11, 51264], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 264, "seek": 81248, "start": 830.48, "end": 833.48, "text": " to wci\u0105\u017c najpewniejsza droga do post\u0119pu.", "tokens": [51264, 281, 261, 537, 27242, 11212, 494, 895, 7764, 82, 2394, 3789, 3680, 360, 2183, 18085, 84, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 265, "seek": 81248, "start": 833.48, "end": 835.48, "text": " Tak, to jest esencja.", "tokens": [51414, 9118, 11, 281, 3492, 785, 22660, 2938, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 266, "seek": 81248, "start": 835.48, "end": 838.48, "text": " Ale ta praca pozostawia nas te\u017c z bardzo wa\u017cnym,", "tokens": [51514, 9366, 1846, 582, 6628, 21281, 555, 34953, 5382, 9516, 710, 9034, 27777, 12996, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 267, "seek": 81248, "start": 838.48, "end": 840.48, "text": " prowokuj\u0105cym pytaniem na przysz\u0142o\u015b\u0107.", "tokens": [51664, 45553, 453, 13263, 1344, 76, 25878, 282, 4907, 1667, 44018, 44742, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06335843489474098, "compression_ratio": 1.4676258992805755, "no_speech_prob": 0.012177908793091774}, {"id": 268, "seek": 84048, "start": 840.48, "end": 843.48, "text": " Te gigantyczne modele s\u0105 niezwykle pot\u0119\u017cne,", "tokens": [50364, 1989, 8741, 394, 17466, 716, 4391, 306, 9015, 33511, 9726, 14677, 1847, 1274, 1427, 716, 11, 50514], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 269, "seek": 84048, "start": 843.48, "end": 847.48, "text": " ale ich trenowanie i u\u017cywanie jest te\u017c ekstremalnie drogie.", "tokens": [50514, 6775, 1893, 23136, 22028, 741, 34097, 86, 7155, 3492, 9516, 13359, 372, 2579, 304, 2766, 3789, 9997, 13, 50714], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 270, "seek": 84048, "start": 847.48, "end": 851.48, "text": " Wymaga zasob\u00f3w dost\u0119pnych tylko dla garstki najwi\u0119kszych korporacji.", "tokens": [50714, 343, 4199, 9286, 26530, 996, 3901, 48209, 9399, 13219, 12285, 3691, 372, 2984, 48636, 1694, 28051, 14784, 2816, 13152, 13, 50914], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 271, "seek": 84048, "start": 851.48, "end": 853.48, "text": " Czyli pytanie brzmi,", "tokens": [50914, 37099, 36610, 738, 89, 3057, 11, 51014], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 272, "seek": 84048, "start": 853.48, "end": 856.48, "text": " czy przysz\u0142o\u015b\u0107 zaawansowanej sztucznej inteligencji", "tokens": [51014, 6430, 44018, 44742, 7949, 1607, 599, 23066, 73, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 51164], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 273, "seek": 84048, "start": 856.48, "end": 860.48, "text": " nale\u017cy wy\u0142\u0105cznie do tych, kt\u00f3rzy maj\u0105 najg\u0142\u0119bsze kieszenie?", "tokens": [51164, 297, 37169, 4628, 15926, 19923, 360, 15180, 11, 25382, 26064, 11212, 70, 46564, 929, 1381, 350, 530, 16778, 30, 51364], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 274, "seek": 84048, "start": 860.48, "end": 862.48, "text": " To jest w\u0142a\u015bnie to pytanie.", "tokens": [51364, 1407, 3492, 14234, 281, 36610, 13, 51464], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 275, "seek": 84048, "start": 862.48, "end": 864.48, "text": " A mo\u017ce nast\u0119pny wielki prze\u0142om", "tokens": [51464, 316, 12034, 39662, 1634, 20570, 2984, 8325, 1221, 298, 51564], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 276, "seek": 84048, "start": 864.48, "end": 867.48, "text": " nie b\u0119dzie polega\u0142 na budowaniu jeszcze wi\u0119kszego T5,", "tokens": [51564, 2838, 10562, 13208, 3680, 1221, 1667, 3265, 305, 25849, 14168, 29968, 27725, 314, 20, 11, 51714], "temperature": 0.0, "avg_logprob": -0.04974918694331728, "compression_ratio": 1.4462540716612378, "no_speech_prob": 0.002415706170722842}, {"id": 277, "seek": 86748, "start": 867.48, "end": 869.48, "text": " ale na znalezieniu sposob\u00f3w,", "tokens": [50364, 6775, 1667, 15397, 37646, 1053, 5951, 20443, 996, 3901, 11, 50464], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 278, "seek": 86748, "start": 869.48, "end": 873.48, "text": " by t\u0119 wiedz\u0119 uczyni\u0107 bardziej efektywn\u0105, dost\u0119pn\u0105.", "tokens": [50464, 538, 32489, 46894, 11052, 344, 6522, 3722, 2162, 27209, 31482, 916, 874, 895, 1611, 11, 48209, 13113, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 279, "seek": 86748, "start": 873.48, "end": 876.48, "text": " Na przyk\u0142ad poprzez techniki takie jak distillation,", "tokens": [50664, 6056, 23144, 1665, 13503, 89, 1537, 9850, 15963, 4207, 42923, 399, 11, 50814], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 280, "seek": 86748, "start": 876.48, "end": 880.48, "text": " czyli proces destylowania wiedzy z ogromnego modelu nauczyciela", "tokens": [50814, 16591, 17565, 2677, 5088, 21308, 46894, 1229, 710, 34416, 298, 11858, 2316, 84, 49103, 1229, 537, 4053, 51014], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 281, "seek": 86748, "start": 880.48, "end": 884.48, "text": " do znacznie mniejszego, zwinnego modelu ucznia,", "tokens": [51014, 360, 15397, 14875, 2766, 39513, 15453, 6308, 11, 710, 9136, 11858, 2316, 84, 35403, 12679, 11, 51214], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 282, "seek": 86748, "start": 884.48, "end": 887.48, "text": " takiego, kt\u00f3ry zmie\u015bci si\u0119 na telefonie.", "tokens": [51214, 32296, 11, 9913, 17020, 414, 6199, 3244, 1667, 26812, 414, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}, {"id": 283, "seek": 86748, "start": 887.48, "end": 892.48, "text": " To fundamentalne pytanie o przysz\u0142\u0105 demokratyzacj\u0119 tej niesamowitej technologii.", "tokens": [51364, 1407, 8088, 716, 36610, 277, 44018, 15926, 49432, 37433, 29924, 12573, 48100, 335, 305, 642, 73, 1537, 1132, 5597, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06459335920189609, "compression_ratio": 1.4448669201520912, "no_speech_prob": 0.11414550244808197}], "language": "pl"}