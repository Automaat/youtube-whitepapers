{"text": " Witajcie. Dzisiaj bierzemy na warsztat prac\u0119 naukow\u0105, kt\u00f3ra, no szczerze m\u00f3wi\u0105c, sporo namiesza\u0142a w \u015bwiecie AI. Zdecydowanie. M\u00f3wimy o direct preference optimization. Your language model is secretly a reward model. Dok\u0142adnie. Mamy te niesamowite, pot\u0119\u017cne modele j\u0119zykowe, kt\u00f3re wiedz\u0105 niemal wszystko. Ale od lat jest to fundamentalne pytanie. Jak sprawi\u0107, by zachowywa\u0142y si\u0119 tak, jak chcemy? To jest sedno problemu, kt\u00f3ry nazywamy alignmentem. Dostosowywanie modeli. Jak nauczy\u0107 je, by by\u0142y pomocne, nieszkodliwe i, no wiesz, zgodne z ludzkimi preferencjami? I to nie jest jaka\u015b niszowa kwestia. To jedno z kluczowych wyzwa\u0144 dla ca\u0142ej bran\u017cy AI. Od tego zale\u017cy, czy te narzenia b\u0119d\u0105 naprawd\u0119 u\u017cyteczne i, co wa\u017cniejsze, bezpieczne. No tak. A dotychczasowym z\u0142otym standardem by\u0142o reinforcement learning from human feedback, czyli w skr\u00f3cie RLHF. Metoda, dzi\u0119ki kt\u00f3rej wczesne wersje chat GPT sta\u0142y si\u0119 tak dobre? Skuteczna, ale powiedzmy to wprost. To prawdziwy potw\u00f3r pod wzgl\u0119dem z\u0142o\u017cono\u015bci. O tak. Niestabilna, piekielnie droga obliczeniowo. To wieloetapowy, naprawd\u0119 skomplikowany proces. I tu na scen\u0119 wchodz\u0105 badacze ze Stanfordu z prac\u0105 zaprezentowan\u0105 na Neuryps 2023. Proponuj\u0105 co\u015b radykalnie prostszego. Co\u015b, co nazwali Direct Preference Optimization, czyli DPO. Twierdz\u0105, \u017ce mo\u017cna osi\u0105gn\u0105\u0107 te same, a nawet lepsze rezultaty, omijaj\u0105c ca\u0142\u0105 t\u0119 maszyneri\u0119 uczenia przez wzmocnienie. Co brzmi jak rewolucja. Zatem nasza misja jest jasna. Zrozumie\u0107, na czym polega magia DPO, dlaczego to tak wa\u017cne i co to oznacza dla przysz\u0142o\u015bci AI. Super. Dobra, to roz\u0142o\u017cmy to na czynniki pierwsze. \u017beby doceni\u0107 prostot\u0119 DPO, musimy najpierw zrozumie\u0107, dlaczego RLHF jest takie skomplikowane. Jasne. RLHF to taki proces w trzech aktach. Pierwszy akt to Supervised Fine Tuning, czyli SFT. Ok. Bierzemy du\u017cy, wst\u0119pnie wytrenowany model i powiedzmy dostrajamy go na zbior\u0119 wysokiej jako\u015bci przyk\u0142ad\u00f3w. Na przyk\u0142ad idealnych rozm\u00f3w z asystentem AI. Czyli uczymy go na\u015bladowa\u0107 najlepsze wzorce. To daje nam punkt wyj\u015bcia, tak? Dok\u0142adnie. Solidny, ale jeszcze sulowy. Model po SFT potrafi odpowiada\u0107, ale niekoniecznie czuje, co jest lepsze, a co gorsze z ludzkiego punktu widzenia. Aha. I tu wchodzi akt drugi. Tak. Budowa zupe\u0142nie osobnego modelu. Tak zwanego Reward Model, czyli modelu nagrody. To jest ten s\u0119dzia, kt\u00f3ry b\u0119dzie ocenia\u0142 prac\u0119 g\u0142\u00f3wnego modelu. W\u0142a\u015bnie. A ten s\u0119dzia uczy si\u0119 na podstawie ogromnej liczby ludzkich por\u00f3wna\u0144. Czyli ludzie dostaj\u0105 dwie odpowiedzi i m\u00f3wi\u0105, odpowied\u017a A jest lepsza ni\u017c B. Tak. I model nagrody uczy si\u0119 na tysi\u0105cach takich przyk\u0142ad\u00f3w przewidywa\u0107, kt\u00f3r\u0105 odpowied\u017a cz\u0142owiek by wybra\u0142. Ok. Mamy model bazowy po SFT i mamy s\u0119dziego. Co dalej? A tu zaczyna si\u0119 akt trzeci. Najbardziej skomplikowany. Optymalizacja z u\u017cyciem RL, czyli uczenia przez wzmocnienie. Tutaj wchodz\u0105 te algorytmy jak PPO? Dok\u0142adnie. Proces wygl\u0105da mniej wi\u0119cej tak. Model generuje odpowied\u017a, s\u0119dzia, czyli Reward Model j\u0105 ocenia, a algorytm RL m\u00f3wi modelowi. Dobra robota, r\u00f3b tak dalej albo \u017ale, spr\u00f3buj inaczej. Tak. Celem jest maksymalizacja tej oceny od s\u0119dziego. Ale jest tu jeszcze jeden haczyk. Ten, \u017ceby model nie zacz\u0105\u0142 generowa\u0107 jakich\u015b dziwnych rzeczy, \u017ceby tylko dosta\u0107 nagrod\u0119. W\u0142a\u015bnie. I do tego s\u0142u\u017cy tak zwana dywergencja KL. To jest co\u015b w rodzaju niewidzialnej smyczy, kt\u00f3ra pilnuje, \u017ceby model nie odbieg\u0142 za daleko od tego, co umia\u0142 po etapie SFT. Chcemy go poprawi\u0107, a nie zepsu\u0107. No w\u0142a\u015bnie. Ca\u0142a ta konstrukcja, to jak budowanie ogromnego rusztowania, tylko po to, \u017ceby pomalowa\u0107 obraz. Trze oddzielne modele, drogie pr\u00f3bkowanie w p\u0119tli RLL i ci\u0105g\u0142a niestabilno\u015b\u0107. I tu dochodzimy do sedna. Autorzy pracy spojrzeli na to ca\u0142e rusztowanie i zadali pytanie, a co je\u015bli wcale go nie potrzebujemy? Co je\u015bli mo\u017cna malowa\u0107 ten obraz bezpo\u015brednio? I to jest ten moment AHA. Jaka jest g\u0142\u00f3wna teza DPO? \u017be ca\u0142y problem optymalizacji z RLHF mo\u017cna rozwi\u0105za\u0107 analitycznie, bez jawnego modelu nagrody i bez uczenia przez wzmocnienie. Jak to mo\u017cliwe? Okaza\u0142o si\u0119, \u017ce istnieje \u015bcis\u0142e matematyczne powi\u0105zanie mi\u0119dzy optymalnym modelem nagrody, a optymaln\u0105 strategi\u0105 generowania tekstu. Czyli oni to po prostu wyliczyli? Mhm, w pewnym sensie tak. Udowodnili, \u017ce mo\u017cna przekszta\u0142ci\u0107 problem trenowania s\u0119dziego w problem, kt\u00f3ry mo\u017cna rozwi\u0105za\u0107 bezpo\u015brednio na g\u0142\u00f3wnym modelu. To brzmi... elegancko. Zamiast budowa\u0107 wieloetapowy system nawigacji, znale\u017ali jedn\u0105 formu\u0142\u0119 matematyczn\u0105, kt\u00f3ra od razu wskazuje cel. Dok\u0142adnie, i st\u0105d ten genialny tytu\u0142 pracy. Tw\u00f3j model j\u0119zykowy w sekrecie jest modelem nagrody. W DPO nie ma oddzielnego s\u0119dziego. Nie ma. Sie\u0107 neuronowa samego modelu j\u0119zykowego pe\u0142ni podw\u00f3jn\u0105 rol\u0119. Generuje tekst i jednocze\u015bnie nie jawnie reprezentuje system oceny. Czyli ca\u0142y ten skomplikowany trzyetapowy taniec z RLHF. Zostaje zast\u0105piony przez jeden prosty etap Fine Tuning z odpowiednio dobran\u0105 funkcj\u0105 straty. Ok, czyli sprowadzamy ten potwornie z\u0142o\u017cony problem do czego\u015b, co przypomina prost\u0105 klasyfikacj\u0119 binarn\u0105. W\u0142a\u015bnie. Mamy par\u0119 odpowiedzi wygrywaj\u0105c\u0105 i przegrywaj\u0105c\u0105. I celem jest po prostu zwi\u0119kszenia prawdopodowie\u0144stwa wygenerowania tej lepszej. Tak, w uproszczeniu. To brzmi prosto. Mo\u017ce nawet zbyt prosto. Gdzie jest haczyk? Przecie\u017c pr\u00f3bowano ju\u017c podobnych metod, jak unlikely heaving. I nie dzia\u0142a\u0142y one zbyt dobrze. To jest kluczowe pytanie i tu kryje si\u0119 ca\u0142a finezja DPO. To nie jest naivne si\u0142owe, nagradzanie dobrych i karanie z\u0142ych odpowiedzi. A co to jest w takim razie? DPO robi to w znacznie bardziej wyrafinowany spos\u00f3b. Wyobra\u017a sobie, \u017ce uczysz dziecko. Je\u015bli ju\u017c robi co\u015b dobrze, tylko lekko je chwali\u015b. Ale je\u015bli robi du\u017cy b\u0142\u0105d, twoja reakcja jest znacznie silniejsza. Czyli si\u0142a lekcji jest proporcjonalna do wielko\u015bci b\u0142\u0119du? Dok\u0142adnie tak. Waga z jak\u0105 aktualizowane s\u0105 parametry nie jest sta\u0142a, jest dynamiczna. Aha. Je\u015bli model ju\u017c teraz bez \u017cadnej aktualizacji, ocenie preferowan\u0105 odpowied\u017a znacznie wy\u017cej ni\u017c t\u0119 gorsz\u0105, to aktualizacja jest bardzo niewielka. Ok. I tak jeste\u015b na dobrej drodze. W\u0142a\u015bnie. Ale je\u015bli sytuacja jest odwrotna, je\u015bli model b\u0142\u0119dnie faworyzuje przegrywaj\u0105c\u0105 odpowied\u017a, wtedy aktualizacja jest bardzo silna. System wie, \u017ce musi dokona\u0107 du\u017cej korekty. Rozumiem. W pracy autorze nazywaj\u0105 to dynamic par example importance weight. I to w\u0142a\u015bnie ten mechanizm zapobiega degeneracji modelu, kt\u00f3r\u0105 obserwowano przy prostszych podej\u015bciach. No dobrze, ale czy na pewno niczego nie tracimy, pozbywaj\u0105c si\u0119 tego dedykowanego modelu nagrody? Mo\u017ce ten s\u0119dzia potrafi\u0142 uchwyci\u0107 jakie\u015b niuanse, kt\u00f3re DPO pomija? To \u015bwietna uwaga. I teoretycznie mog\u0142oby tak by\u0107. Ale jak poka\u017c\u0105 eksperymenty, w praktyce okazuje si\u0119, \u017ce najwi\u0119kszym problemem RLH wcale nie by\u0142a niedoskona\u0142o\u015b\u0107 modelu nagrody. Tylko co? Niestabielno\u015b\u0107 i nieefektywno\u015b\u0107 samego procesu optymalizacji RL. DPO, omijaj\u0105c ten proces, jest w stanie osi\u0105gn\u0105\u0107 lepsze wyniki. Jest te\u017c parametr beta, kt\u00f3ry pe\u0142ni rol\u0119 tej smyczy KL. Kontroluje, jak bardzo model mo\u017ce si\u0119 zmieni\u0107. No dobrze, teoria brzmi rewelacyjnie. Niesamowite, \u017ce jednym ruchem wyeliminowali ca\u0142y najbardziej problematyczny etap. Ale teoria to jedno. Jak to si\u0119 sprawdzi\u0142o w praktyce? Autorzy przeprowadzili seri\u0119 bardzo wymownych eksperyment\u00f3w. Pierwszy dotyczy\u0142 kontrolowanej generacji sentymentu. Czyli? Zadanie by\u0142o proste. Nauczy\u0107 model pisa\u0107 recenzje film\u00f3w z AMDB, kt\u00f3re maj\u0105 jednoznacznie pozytywny wyd\u017awi\u0119k. Co ciekawe, do oceny u\u017cyli innego klasyfikatora sentymentu, co da\u0142o im obiektywn\u0105 prawdziw\u0105 funkcj\u0119 nagrody do por\u00f3wna\u0144. I co pokaza\u0142y wyniki? Wymiki s\u0105 uderzaj\u0105ce. Na wykresie, kt\u00f3ry pokazuje kompromis mi\u0119dzy maksymalizacj\u0105 nagrody, a utrzymaniem modelu blisko orygina\u0142u, krzywa dla DPO wprost dominuje nadkrzyw\u0105 dla PPO. Osi\u0105ga wy\u017csz\u0105 nagrod\u0119 przy tym samym poziomie zmiany modelu. Tak, ale najciekawsze jest co innego. DPO okaza\u0142o si\u0119 lepsze nawet od wariantu, kt\u00f3ry nazwali PPO GT, gdzie GT oznacza Ground Truth. Chyla. Czyli w tym wariancie PPO mia\u0142o fory. Dosta\u0142o dost\u0119p do tej prawdziwej funkcji nagrody, a nie tylko do wyuczonego niedoskona\u0142ego modelu. Dok\u0142adnie, to by\u0142 wariant z oszustwem, kt\u00f3ry mia\u0142 pokaza\u0107 g\u00f3rny pu\u0142ap mo\u017cliwo\u015bci PPO. I DPO go pokona\u0142o. To prowadzi do wa\u017cnego wniosku. Tak. Skoro DPO jest lepsze nawet od PPO z pe\u0142n\u0105 wiedz\u0105 o prawdziwej nagrodzie, to znaczy, \u017ce w\u0105skim gard\u0142em w RLHF nie jest jako\u015b\u0107 modelu nagrody. Tylko sam algorytm optymizacji RL, kt\u00f3ry jest po prostu niestabilny i nieefektywny. DPO omija ten problem w ca\u0142o\u015bci. To faktycznie zmienia zasady gry. A co z bardziej z\u0142o\u017conymi zadaniami, jak streszczenia? Drugi eksperyment dotyczy\u0142 streszczenia post\u00f3w z reddita w stylu TLDR. Tutaj oceny dokonywa\u0142 GPT-4. I znowu. DPO okaza\u0142o si\u0119 lepsze. O ile? Osi\u0105gn\u0119\u0142o wska\u017anik zwyci\u0119stw na pozionie 61% w por\u00f3wnaniu do 57% dla PPO. Co wi\u0119cej, okaza\u0142o si\u0119 znacznie bardziej stabilne. Wyniki PPO mocno si\u0119 pogarsza\u0142y przy zmianie temperatury pr\u00f3bkowania. DPO pozostawa\u0142o oni wzruszone. A najtrudniejsze zadanie, czyli diolog? U\u017cyto tu zbioru danych Anthropic HH, kt\u00f3re celem jest prowadzenie pomocnej i nieszkodliwej konwersacji. W tym eksperymencie DPO by\u0142o jedyn\u0105 obliczeniowo wydajn\u0105 metod\u0105, kt\u00f3ra faktycznie poprawi\u0142a wyniki. I co ciekawe, zadzia\u0142a\u0142o r\u00f3wnie dobrze jak bardzo kosztowna metoda Best of 128. Dok\u0142adnie. Metoda Best of 128 polega na wygenerowaniu 128 odpowiedzi i wybraniu najlepszej. To jest, wiesz, si\u0142owe podej\u015bcie. Kompletnie niepraktyczne ze wzgl\u0119du na koszty. A DPO osi\u0105ga ten sam poziom jako\u015bci bez tej ogromnej pracy. Warto te\u017c doda\u0107, \u017ce autorze sprawdzili, czy GPT-4 jest wiarygodnym s\u0119dziom. Jest. Okaza\u0142o si\u0119, \u017ce jego oceny mocno koreluj\u0105 z ludzkimi os\u0105dami. Wi\u0119c tak. W porz\u0105dku. To co to wszystko oznacza w praktyce? Jakie s\u0105 konsekwencje tego odkrycia? Przede wszystkim DPO radykalnie obni\u017ca barier\u0119 wej\u015bcia do \u015bwiata Elainment Modeli. Proces, kt\u00f3ry by\u0142 zarezerwowany dla garstki najwi\u0119kszych laboratori\u00f3w, staje si\u0119 znacznie prostsze. Prostszy stabilniejszy i ta\u0144szy nie potrzeba ju\u017c zespo\u0142u ekspert\u00f3w od RL i gigantycznej infrastruktury. To w zasadzie Fine Tuning z niestandardow\u0105 funkcj\u0105 straty. I to ma ogromne konsekwencje dla ca\u0142ego ekosystemu. Dok\u0142adnie. Je\u015bli po\u0142\u0105czymy to z szerszym obrazem, zobaczymy, dlaczego DPO jest jednym z motor\u00f3w nap\u0119dowych rewolucji Open Sourceowej w AI. To dlatego modele jak ZEFIR, czy najnowsze wersje LAMA tak szybko zaadaptowa\u0142y DPO. Tak. To pozwoli\u0142o spo\u0142eczno\u015bci Open Source dogoni\u0107, a w niekt\u00f3rych zadaniach nawet przegoni\u0107. Zamkni\u0119te modele trenowane za setki milion\u00f3w dolar\u00f3w. To demokratyzuje dost\u0119p do tworzenia wysokiej jako\u015bci dostosowanych modeli. Ale praca nie odpowiada na wszystkie pytania, prawda? Oczywi\u015bcie, \u017ce nie. Autorzy sami wskazuj\u0105 kilka otwartych \u015bcie\u017cek. Po pierwsze, jak modele trenowane DPO generalizuj\u0105 na zadania, kt\u00f3re odbiegaj\u0105 od danych treningowych. Wst\u0119pne wyniki s\u0105 obiecuj\u0105ce, ale potrzeba wi\u0119cej bada\u0144. Po drugie, jak w kontek\u015bcie DPO wygl\u0105da problem Reward Over Optimization. Czyli sytuacji, gdy model uczy si\u0119 wykorzystywa\u0107 luki w systemie oceny. Szczeg\u00f3lnie interesuj\u0105ce, skoro model nagrody jest niejawny. I wreszcie, jak DPO skaluje si\u0119 do najwi\u0119kszych modeli. Chocia\u017c patrz\u0105c na sukcesy najnowszych modeli, wydaje si\u0119, \u017ce skaluje si\u0119 bardzo dobrze. Podsumowuj\u0105c, Direct Preference Optimization to pot\u0119\u017cna i niezwykle elegancka alternatywa dla z\u0142o\u017conego RLHF. Zmienia problem dostosowywania modeli z trudnego zadania RL w znacznie prostsze zadanie klasyfikacyjne. A wyniki pokazuj\u0105, \u017ce jest co najmniej tak samo dobre, a cz\u0119sto nawet lepsze i bardziej stabilne ni\u017c dotyk czasowe metody. To prawdziwy prze\u0142om. My\u015bl\u0119, \u017ce to zostawia nas z jedn\u0105 fascynuj\u0105c\u0105 my\u015bl\u0105. Skoro proces dostrajania modeli do naszych subtelnych ludzkich preferencji staje si\u0119 tak prosty i bezpo\u015bredni, to otwiera zupe\u0142nie nowe mo\u017cliwo\u015bci. By\u0107 mo\u017ce zbli\u017camy si\u0119 do RLHF, kt\u00f3rej ka\u017cdy b\u0119dzie mog\u0142 w prosty spos\u00f3b dostroi\u0107 swojego osobistego asystenta AI do swojego stylu komunikacji czy warto\u015bci. Co by to znaczy\u0142o, gdyby AI mog\u0142o uczy\u0107 si\u0119 naszych preferencji? Nie przez skomplikowany trening w laboratorium, ale przez prost\u0105, bezpo\u015bredni\u0105 optymalizacj\u0119 na podstawie kilku naszych wybor\u00f3w. I to jest pytanie, kt\u00f3re pozostawiam do dalszej refleksji.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.4, "text": " Witajcie. Dzisiaj bierzemy na warsztat prac\u0119 naukow\u0105, kt\u00f3ra, no szczerze m\u00f3wi\u0105c, sporo namiesza\u0142a w \u015bwiecie AI.", "tokens": [50364, 42299, 47276, 13, 39448, 22356, 272, 34602, 3633, 1667, 13718, 2682, 267, 22404, 1274, 35616, 74, 30297, 11, 19456, 11, 572, 22090, 260, 1381, 46591, 66, 11, 637, 10780, 8835, 530, 2394, 5024, 261, 40078, 4260, 7318, 13, 50734], "temperature": 0.0, "avg_logprob": -0.16026731872558594, "compression_ratio": 1.4054982817869415, "no_speech_prob": 0.005111027974635363}, {"id": 1, "seek": 0, "start": 7.4, "end": 15.6, "text": " Zdecydowanie. M\u00f3wimy o direct preference optimization. Your language model is secretly a reward model.", "tokens": [50734, 1176, 1479, 1344, 67, 22028, 13, 376, 3901, 13189, 277, 2047, 17502, 19618, 13, 2260, 2856, 2316, 307, 22611, 257, 7782, 2316, 13, 51144], "temperature": 0.0, "avg_logprob": -0.16026731872558594, "compression_ratio": 1.4054982817869415, "no_speech_prob": 0.005111027974635363}, {"id": 2, "seek": 0, "start": 15.6, "end": 22.0, "text": " Dok\u0142adnie. Mamy te niesamowite, pot\u0119\u017cne modele j\u0119zykowe, kt\u00f3re wiedz\u0105 niemal wszystko.", "tokens": [51144, 29768, 10358, 2766, 13, 376, 7804, 535, 48100, 335, 305, 642, 11, 1847, 1274, 1427, 716, 4391, 306, 49055, 74, 6880, 11, 8864, 46894, 8925, 2838, 5579, 22607, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16026731872558594, "compression_ratio": 1.4054982817869415, "no_speech_prob": 0.005111027974635363}, {"id": 3, "seek": 0, "start": 22.0, "end": 28.5, "text": " Ale od lat jest to fundamentalne pytanie. Jak sprawi\u0107, by zachowywa\u0142y si\u0119 tak, jak chcemy?", "tokens": [51464, 9366, 3611, 4465, 3492, 281, 8088, 716, 36610, 13, 15029, 22734, 12757, 11, 538, 29303, 10089, 4151, 6825, 3244, 991, 11, 4207, 28928, 2226, 30, 51789], "temperature": 0.0, "avg_logprob": -0.16026731872558594, "compression_ratio": 1.4054982817869415, "no_speech_prob": 0.005111027974635363}, {"id": 4, "seek": 2850, "start": 28.5, "end": 33.5, "text": " To jest sedno problemu, kt\u00f3ry nazywamy alignmentem. Dostosowywanie modeli.", "tokens": [50364, 1407, 3492, 9643, 1771, 1154, 84, 11, 9913, 20151, 27112, 7804, 18515, 443, 13, 413, 555, 329, 10089, 86, 7155, 2316, 72, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10331818964574244, "compression_ratio": 1.4084084084084083, "no_speech_prob": 0.005409529432654381}, {"id": 5, "seek": 2850, "start": 33.5, "end": 39.9, "text": " Jak nauczy\u0107 je, by by\u0142y pomocne, nieszkodliwe i, no wiesz, zgodne z ludzkimi preferencjami?", "tokens": [50614, 15029, 49103, 27150, 1506, 11, 538, 26366, 48962, 716, 11, 297, 15347, 74, 378, 2081, 826, 741, 11, 572, 261, 15347, 11, 710, 21787, 716, 710, 15946, 30154, 10121, 4382, 22660, 73, 4526, 30, 50934], "temperature": 0.0, "avg_logprob": -0.10331818964574244, "compression_ratio": 1.4084084084084083, "no_speech_prob": 0.005409529432654381}, {"id": 6, "seek": 2850, "start": 39.9, "end": 44.7, "text": " I to nie jest jaka\u015b niszowa kwestia. To jedno z kluczowych wyzwa\u0144 dla ca\u0142ej bran\u017cy AI.", "tokens": [50934, 286, 281, 2838, 3492, 4207, 64, 1788, 297, 23848, 5528, 42035, 654, 13, 1407, 5232, 1771, 710, 9671, 1311, 89, 19605, 4628, 89, 4151, 5248, 12285, 47631, 73, 12029, 7735, 7318, 13, 51174], "temperature": 0.0, "avg_logprob": -0.10331818964574244, "compression_ratio": 1.4084084084084083, "no_speech_prob": 0.005409529432654381}, {"id": 7, "seek": 2850, "start": 44.7, "end": 49.6, "text": " Od tego zale\u017cy, czy te narzenia b\u0119d\u0105 naprawd\u0119 u\u017cyteczne i, co wa\u017cniejsze, bezpieczne.", "tokens": [51174, 12210, 8627, 710, 37169, 11, 6430, 535, 6714, 14320, 26239, 20970, 34097, 975, 38491, 741, 11, 598, 27777, 44258, 11, 47153, 38491, 13, 51419], "temperature": 0.0, "avg_logprob": -0.10331818964574244, "compression_ratio": 1.4084084084084083, "no_speech_prob": 0.005409529432654381}, {"id": 8, "seek": 2850, "start": 49.6, "end": 58.3, "text": " No tak. A dotychczasowym z\u0142otym standardem by\u0142o reinforcement learning from human feedback, czyli w skr\u00f3cie RLHF.", "tokens": [51419, 883, 991, 13, 316, 5893, 16384, 30989, 31691, 31614, 310, 4199, 3832, 443, 14811, 29280, 2539, 490, 1952, 5824, 11, 16591, 261, 1110, 11721, 4260, 497, 43, 39, 37, 13, 51854], "temperature": 0.0, "avg_logprob": -0.10331818964574244, "compression_ratio": 1.4084084084084083, "no_speech_prob": 0.005409529432654381}, {"id": 9, "seek": 5830, "start": 58.3, "end": 62.4, "text": " Metoda, dzi\u0119ki kt\u00f3rej wczesne wersje chat GPT sta\u0142y si\u0119 tak dobre?", "tokens": [50364, 6377, 13449, 11, 45003, 36023, 261, 3689, 279, 716, 261, 433, 2884, 5081, 26039, 51, 11135, 6825, 3244, 991, 41959, 30, 50569], "temperature": 0.0, "avg_logprob": -0.10320132318204336, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.006553648039698601}, {"id": 10, "seek": 5830, "start": 62.4, "end": 68.89999999999999, "text": " Skuteczna, ale powiedzmy to wprost. To prawdziwy potw\u00f3r pod wzgl\u0119dem z\u0142o\u017cono\u015bci.", "tokens": [50569, 7324, 1169, 3689, 629, 11, 6775, 27617, 2226, 281, 261, 1424, 555, 13, 1407, 41175, 3992, 9726, 1847, 86, 15614, 2497, 48538, 6298, 443, 710, 5249, 1427, 8957, 6199, 13, 50894], "temperature": 0.0, "avg_logprob": -0.10320132318204336, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.006553648039698601}, {"id": 11, "seek": 5830, "start": 68.89999999999999, "end": 76.3, "text": " O tak. Niestabilna, piekielnie droga obliczeniowo. To wieloetapowy, naprawd\u0119 skomplikowany proces.", "tokens": [50894, 422, 991, 13, 426, 6495, 5177, 629, 11, 1730, 74, 1187, 2766, 3789, 3680, 1111, 1050, 42124, 19941, 13, 1407, 20570, 78, 302, 569, 10089, 11, 20970, 1110, 298, 564, 1035, 23341, 17565, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10320132318204336, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.006553648039698601}, {"id": 12, "seek": 5830, "start": 76.3, "end": 83.9, "text": " I tu na scen\u0119 wchodz\u0105 badacze ze Stanfordu z prac\u0105 zaprezentowan\u0105 na Neuryps 2023.", "tokens": [51264, 286, 2604, 1667, 4191, 1274, 261, 29914, 8925, 1578, 326, 1381, 5277, 20374, 84, 710, 22404, 1611, 14223, 265, 14185, 37345, 1611, 1667, 1734, 2598, 1878, 44377, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10320132318204336, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.006553648039698601}, {"id": 13, "seek": 5830, "start": 83.9, "end": 86.3, "text": " Proponuj\u0105 co\u015b radykalnie prostszego.", "tokens": [51644, 21944, 266, 13263, 19241, 367, 880, 19990, 2766, 10293, 15453, 6308, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10320132318204336, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.006553648039698601}, {"id": 14, "seek": 8630, "start": 86.3, "end": 90.89999999999999, "text": " Co\u015b, co nazwali Direct Preference Optimization, czyli DPO.", "tokens": [50364, 3066, 1788, 11, 598, 20151, 40054, 18308, 6001, 5158, 35013, 2144, 11, 16591, 413, 34885, 13, 50594], "temperature": 0.0, "avg_logprob": -0.10834699425815551, "compression_ratio": 1.3488372093023255, "no_speech_prob": 0.018338726833462715}, {"id": 15, "seek": 8630, "start": 90.89999999999999, "end": 97.5, "text": " Twierdz\u0105, \u017ce mo\u017cna osi\u0105gn\u0105\u0107 te same, a nawet lepsze rezultaty, omijaj\u0105c ca\u0142\u0105 t\u0119 maszyneri\u0119 uczenia przez wzmocnienie.", "tokens": [50594, 314, 40717, 67, 8925, 11, 3561, 17790, 3003, 11404, 4568, 36374, 535, 912, 11, 257, 22696, 476, 1878, 1381, 48060, 723, 21398, 11, 3406, 1718, 38757, 1335, 15926, 32489, 2300, 1229, 1193, 5034, 344, 38517, 14064, 24809, 76, 905, 77, 27385, 13, 50924], "temperature": 0.0, "avg_logprob": -0.10834699425815551, "compression_ratio": 1.3488372093023255, "no_speech_prob": 0.018338726833462715}, {"id": 16, "seek": 8630, "start": 97.5, "end": 108.9, "text": " Co brzmi jak rewolucja. Zatem nasza misja jest jasna. Zrozumie\u0107, na czym polega magia DPO, dlaczego to tak wa\u017cne i co to oznacza dla przysz\u0142o\u015bci AI. Super.", "tokens": [50924, 3066, 738, 89, 3057, 4207, 319, 48481, 1311, 2938, 13, 1176, 26851, 5382, 2394, 3346, 2938, 3492, 361, 296, 629, 13, 1176, 27857, 449, 414, 2162, 11, 1667, 31466, 13208, 3680, 2258, 654, 413, 34885, 11, 37873, 39329, 281, 991, 46110, 741, 598, 281, 277, 22672, 326, 2394, 12285, 44018, 35059, 7318, 13, 4548, 13, 51494], "temperature": 0.0, "avg_logprob": -0.10834699425815551, "compression_ratio": 1.3488372093023255, "no_speech_prob": 0.018338726833462715}, {"id": 17, "seek": 10890, "start": 108.9, "end": 117.5, "text": " Dobra, to roz\u0142o\u017cmy to na czynniki pierwsze. \u017beby doceni\u0107 prostot\u0119 DPO, musimy najpierw zrozumie\u0107, dlaczego RLHF jest takie skomplikowane.", "tokens": [50364, 413, 24393, 11, 281, 9544, 5249, 1427, 2226, 281, 1667, 6430, 26384, 9850, 45994, 13, 46864, 2322, 3211, 268, 12757, 10293, 310, 1274, 413, 34885, 11, 43449, 11212, 45119, 86, 710, 27857, 449, 414, 2162, 11, 37873, 39329, 497, 43, 39, 37, 3492, 15963, 1110, 298, 564, 1035, 23066, 13, 50794], "temperature": 0.0, "avg_logprob": -0.10794738435397183, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.41844797134399414}, {"id": 18, "seek": 10890, "start": 117.5, "end": 125.5, "text": " Jasne. RLHF to taki proces w trzech aktach. Pierwszy akt to Supervised Fine Tuning, czyli SFT.", "tokens": [50794, 34023, 716, 13, 497, 43, 39, 37, 281, 20065, 17565, 261, 504, 19439, 13680, 608, 13, 16676, 30012, 13680, 281, 4548, 24420, 12024, 21363, 278, 11, 16591, 318, 25469, 13, 51194], "temperature": 0.0, "avg_logprob": -0.10794738435397183, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.41844797134399414}, {"id": 19, "seek": 10890, "start": 125.5, "end": 137.9, "text": " Ok. Bierzemy du\u017cy, wst\u0119pnie wytrenowany model i powiedzmy dostrajamy go na zbior\u0119 wysokiej jako\u015bci przyk\u0142ad\u00f3w. Na przyk\u0142ad idealnych rozm\u00f3w z asystentem AI.", "tokens": [51194, 3477, 13, 363, 34602, 3633, 1581, 7735, 11, 261, 372, 18085, 2766, 261, 4328, 1095, 23341, 2316, 741, 27617, 2226, 20568, 48690, 7804, 352, 1667, 710, 33362, 1274, 27062, 453, 7764, 17123, 6199, 23144, 3901, 13, 6056, 23144, 7157, 9399, 35234, 3901, 710, 382, 38593, 317, 443, 7318, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10794738435397183, "compression_ratio": 1.370748299319728, "no_speech_prob": 0.41844797134399414}, {"id": 20, "seek": 13790, "start": 137.9, "end": 142.3, "text": " Czyli uczymy go na\u015bladowa\u0107 najlepsze wzorce. To daje nam punkt wyj\u015bcia, tak?", "tokens": [50364, 37099, 344, 6522, 2226, 352, 1667, 1788, 9290, 11445, 41903, 1878, 1381, 24809, 284, 384, 13, 1407, 1120, 2884, 8835, 39561, 4628, 73, 1788, 2755, 11, 991, 30, 50584], "temperature": 0.0, "avg_logprob": -0.08428842074250521, "compression_ratio": 1.46875, "no_speech_prob": 0.0327448807656765}, {"id": 21, "seek": 13790, "start": 142.3, "end": 153.3, "text": " Dok\u0142adnie. Solidny, ale jeszcze sulowy. Model po SFT potrafi odpowiada\u0107, ale niekoniecznie czuje, co jest lepsze, a co gorsze z ludzkiego punktu widzenia.", "tokens": [50584, 29768, 10358, 2766, 13, 26664, 1634, 11, 6775, 14168, 17603, 10089, 13, 17105, 714, 318, 25469, 1847, 10437, 72, 24314, 39018, 2162, 11, 6775, 2838, 18295, 414, 19923, 6472, 13008, 11, 598, 3492, 476, 1878, 1381, 11, 257, 598, 290, 830, 1381, 710, 15946, 30154, 12200, 39561, 84, 5274, 14320, 13, 51134], "temperature": 0.0, "avg_logprob": -0.08428842074250521, "compression_ratio": 1.46875, "no_speech_prob": 0.0327448807656765}, {"id": 22, "seek": 13790, "start": 153.3, "end": 155.70000000000002, "text": " Aha. I tu wchodzi akt drugi.", "tokens": [51134, 27448, 13, 286, 2604, 261, 34616, 13680, 4110, 72, 13, 51254], "temperature": 0.0, "avg_logprob": -0.08428842074250521, "compression_ratio": 1.46875, "no_speech_prob": 0.0327448807656765}, {"id": 23, "seek": 13790, "start": 155.70000000000002, "end": 162.5, "text": " Tak. Budowa zupe\u0142nie osobnego modelu. Tak zwanego Reward Model, czyli modelu nagrody.", "tokens": [51254, 9118, 13, 6384, 5528, 49922, 41518, 11858, 2316, 84, 13, 9118, 710, 7916, 6308, 1300, 1007, 17105, 11, 16591, 2316, 84, 17096, 340, 3173, 13, 51594], "temperature": 0.0, "avg_logprob": -0.08428842074250521, "compression_ratio": 1.46875, "no_speech_prob": 0.0327448807656765}, {"id": 24, "seek": 13790, "start": 162.5, "end": 165.70000000000002, "text": " To jest ten s\u0119dzia, kt\u00f3ry b\u0119dzie ocenia\u0142 prac\u0119 g\u0142\u00f3wnego modelu.", "tokens": [51594, 1407, 3492, 2064, 262, 6298, 40395, 11, 9913, 10562, 10409, 268, 8908, 22404, 1274, 18117, 3901, 11858, 2316, 84, 13, 51754], "temperature": 0.0, "avg_logprob": -0.08428842074250521, "compression_ratio": 1.46875, "no_speech_prob": 0.0327448807656765}, {"id": 25, "seek": 16570, "start": 165.7, "end": 176.5, "text": " W\u0142a\u015bnie. A ten s\u0119dzia uczy si\u0119 na podstawie ogromnej liczby ludzkich por\u00f3wna\u0144. Czyli ludzie dostaj\u0105 dwie odpowiedzi i m\u00f3wi\u0105, odpowied\u017a A jest lepsza ni\u017c B.", "tokens": [50364, 343, 5024, 12221, 13, 316, 2064, 262, 6298, 40395, 344, 6522, 3244, 1667, 43443, 414, 34416, 298, 11794, 6169, 89, 2322, 15946, 30154, 480, 1515, 3901, 629, 5248, 13, 37099, 37025, 20568, 11133, 274, 8699, 36574, 3992, 741, 46591, 11, 36574, 10659, 316, 3492, 476, 1878, 2394, 28502, 363, 13, 50904], "temperature": 0.0, "avg_logprob": -0.07243780791759491, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07691730558872223}, {"id": 26, "seek": 16570, "start": 176.5, "end": 183.5, "text": " Tak. I model nagrody uczy si\u0119 na tysi\u0105cach takich przyk\u0142ad\u00f3w przewidywa\u0107, kt\u00f3r\u0105 odpowied\u017a cz\u0142owiek by wybra\u0142.", "tokens": [50904, 9118, 13, 286, 2316, 17096, 340, 3173, 344, 6522, 3244, 1667, 38156, 11404, 66, 608, 29607, 23144, 3901, 39758, 38836, 25234, 11, 37415, 36574, 10659, 36282, 74, 538, 4628, 6198, 1221, 13, 51254], "temperature": 0.0, "avg_logprob": -0.07243780791759491, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07691730558872223}, {"id": 27, "seek": 16570, "start": 183.5, "end": 187.7, "text": " Ok. Mamy model bazowy po SFT i mamy s\u0119dziego. Co dalej?", "tokens": [51254, 3477, 13, 376, 7804, 2316, 27147, 10089, 714, 318, 25469, 741, 17335, 262, 42643, 1571, 13, 3066, 34257, 30, 51464], "temperature": 0.0, "avg_logprob": -0.07243780791759491, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07691730558872223}, {"id": 28, "seek": 16570, "start": 187.7, "end": 192.29999999999998, "text": " A tu zaczyna si\u0119 akt trzeci. Najbardziej skomplikowany.", "tokens": [51464, 316, 2604, 43811, 629, 3244, 13680, 22266, 537, 13, 31576, 40392, 1110, 298, 564, 1035, 23341, 13, 51694], "temperature": 0.0, "avg_logprob": -0.07243780791759491, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07691730558872223}, {"id": 29, "seek": 19230, "start": 192.3, "end": 197.70000000000002, "text": " Optymalizacja z u\u017cyciem RL, czyli uczenia przez wzmocnienie.", "tokens": [50364, 21455, 4199, 304, 590, 23395, 710, 34097, 4260, 76, 497, 43, 11, 16591, 344, 38517, 14064, 24809, 76, 905, 77, 27385, 13, 50634], "temperature": 0.0, "avg_logprob": -0.09609156799316407, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.062368158251047134}, {"id": 30, "seek": 19230, "start": 197.70000000000002, "end": 200.70000000000002, "text": " Tutaj wchodz\u0105 te algorytmy jak PPO?", "tokens": [50634, 41819, 261, 29914, 8925, 535, 3501, 827, 83, 2226, 4207, 430, 34885, 30, 50784], "temperature": 0.0, "avg_logprob": -0.09609156799316407, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.062368158251047134}, {"id": 31, "seek": 19230, "start": 200.70000000000002, "end": 213.3, "text": " Dok\u0142adnie. Proces wygl\u0105da mniej wi\u0119cej tak. Model generuje odpowied\u017a, s\u0119dzia, czyli Reward Model j\u0105 ocenia, a algorytm RL m\u00f3wi modelowi.", "tokens": [50784, 29768, 10358, 2766, 13, 1705, 887, 32015, 39513, 26004, 991, 13, 17105, 1337, 13008, 36574, 10659, 11, 262, 6298, 40395, 11, 16591, 1300, 1007, 17105, 35692, 10409, 268, 654, 11, 257, 3501, 827, 83, 76, 497, 43, 24592, 2316, 24503, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09609156799316407, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.062368158251047134}, {"id": 32, "seek": 19230, "start": 213.3, "end": 217.70000000000002, "text": " Dobra robota, r\u00f3b tak dalej albo \u017ale, spr\u00f3buj inaczej.", "tokens": [51414, 413, 24393, 3870, 5377, 11, 11416, 65, 991, 34257, 22622, 50212, 306, 11, 6103, 14216, 4579, 33230, 16920, 13, 51634], "temperature": 0.0, "avg_logprob": -0.09609156799316407, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.062368158251047134}, {"id": 33, "seek": 19230, "start": 217.70000000000002, "end": 221.9, "text": " Tak. Celem jest maksymalizacja tej oceny od s\u0119dziego.", "tokens": [51634, 9118, 13, 8257, 10386, 3492, 963, 3187, 5579, 590, 23395, 12573, 10409, 43100, 3611, 262, 42643, 1571, 13, 51844], "temperature": 0.0, "avg_logprob": -0.09609156799316407, "compression_ratio": 1.392156862745098, "no_speech_prob": 0.062368158251047134}, {"id": 34, "seek": 22190, "start": 221.9, "end": 224.1, "text": " Ale jest tu jeszcze jeden haczyk.", "tokens": [50364, 9366, 3492, 2604, 14168, 12906, 324, 6522, 74, 13, 50474], "temperature": 0.0, "avg_logprob": -0.08029036443741595, "compression_ratio": 1.3818897637795275, "no_speech_prob": 0.00995214655995369}, {"id": 35, "seek": 22190, "start": 224.1, "end": 229.1, "text": " Ten, \u017ceby model nie zacz\u0105\u0142 generowa\u0107 jakich\u015b dziwnych rzeczy, \u017ceby tylko dosta\u0107 nagrod\u0119.", "tokens": [50474, 9380, 11, 11316, 2316, 2838, 34430, 8925, 1221, 1337, 11445, 4207, 480, 1788, 31981, 895, 16384, 26297, 11, 11316, 13219, 274, 8638, 2162, 17096, 11452, 1274, 13, 50724], "temperature": 0.0, "avg_logprob": -0.08029036443741595, "compression_ratio": 1.3818897637795275, "no_speech_prob": 0.00995214655995369}, {"id": 36, "seek": 22190, "start": 229.1, "end": 234.3, "text": " W\u0142a\u015bnie. I do tego s\u0142u\u017cy tak zwana dywergencja KL.", "tokens": [50724, 343, 5024, 12221, 13, 286, 360, 8627, 48459, 7735, 991, 11873, 2095, 14584, 1554, 1766, 34056, 47991, 13, 50984], "temperature": 0.0, "avg_logprob": -0.08029036443741595, "compression_ratio": 1.3818897637795275, "no_speech_prob": 0.00995214655995369}, {"id": 37, "seek": 22190, "start": 234.3, "end": 242.70000000000002, "text": " To jest co\u015b w rodzaju niewidzialnej smyczy, kt\u00f3ra pilnuje, \u017ceby model nie odbieg\u0142 za daleko od tego, co umia\u0142 po etapie SFT.", "tokens": [50984, 1407, 3492, 19241, 261, 28607, 33166, 43622, 327, 17787, 11794, 899, 88, 6522, 11, 19456, 6429, 77, 13008, 11, 11316, 2316, 2838, 3611, 7392, 70, 1221, 7949, 11702, 34241, 3611, 8627, 11, 598, 1105, 8908, 714, 47634, 414, 318, 25469, 13, 51404], "temperature": 0.0, "avg_logprob": -0.08029036443741595, "compression_ratio": 1.3818897637795275, "no_speech_prob": 0.00995214655995369}, {"id": 38, "seek": 22190, "start": 242.70000000000002, "end": 244.9, "text": " Chcemy go poprawi\u0107, a nie zepsu\u0107.", "tokens": [51404, 761, 384, 2226, 352, 1665, 5131, 12757, 11, 257, 2838, 710, 10653, 84, 2162, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08029036443741595, "compression_ratio": 1.3818897637795275, "no_speech_prob": 0.00995214655995369}, {"id": 39, "seek": 24490, "start": 244.9, "end": 252.5, "text": " No w\u0142a\u015bnie. Ca\u0142a ta konstrukcja, to jak budowanie ogromnego rusztowania, tylko po to, \u017ceby pomalowa\u0107 obraz.", "tokens": [50364, 883, 14234, 13, 7544, 5024, 1846, 34208, 25126, 34056, 11, 281, 4207, 3265, 22028, 34416, 298, 11858, 38684, 2682, 21308, 11, 13219, 714, 281, 11, 11316, 12991, 304, 11445, 22798, 89, 13, 50744], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 40, "seek": 24490, "start": 252.5, "end": 258.5, "text": " Trze oddzielne modele, drogie pr\u00f3bkowanie w p\u0119tli RLL i ci\u0105g\u0142a niestabilno\u015b\u0107.", "tokens": [50744, 1765, 1381, 7401, 42280, 716, 4391, 306, 11, 3789, 9997, 8565, 65, 74, 22028, 261, 280, 46788, 2081, 497, 24010, 741, 42398, 70, 5024, 3867, 377, 5177, 23293, 13, 51044], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 41, "seek": 24490, "start": 258.5, "end": 260.3, "text": " I tu dochodzimy do sedna.", "tokens": [51044, 286, 2604, 9243, 378, 89, 13189, 360, 9643, 629, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 42, "seek": 24490, "start": 260.3, "end": 266.3, "text": " Autorzy pracy spojrzeli na to ca\u0142e rusztowanie i zadali pytanie, a co je\u015bli wcale go nie potrzebujemy?", "tokens": [51134, 6049, 284, 1229, 35591, 8243, 73, 19390, 10148, 1667, 281, 47631, 38684, 2682, 22028, 741, 42788, 5103, 36610, 11, 257, 598, 25630, 261, 37088, 352, 2838, 37595, 21767, 30, 51434], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 43, "seek": 24490, "start": 266.3, "end": 269.5, "text": " Co je\u015bli mo\u017cna malowa\u0107 ten obraz bezpo\u015brednio?", "tokens": [51434, 3066, 25630, 17790, 2806, 11445, 2064, 22798, 89, 10782, 2259, 1788, 986, 41084, 30, 51594], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 44, "seek": 24490, "start": 269.5, "end": 270.9, "text": " I to jest ten moment AHA.", "tokens": [51594, 286, 281, 3492, 2064, 1623, 316, 4983, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 45, "seek": 24490, "start": 270.9, "end": 272.7, "text": " Jaka jest g\u0142\u00f3wna teza DPO?", "tokens": [51664, 508, 7849, 3492, 18117, 3901, 629, 535, 2394, 413, 34885, 30, 51754], "temperature": 0.0, "avg_logprob": -0.1031898204112213, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.07731541246175766}, {"id": 46, "seek": 27270, "start": 272.7, "end": 281.7, "text": " \u017be ca\u0142y problem optymalizacji z RLHF mo\u017cna rozwi\u0105za\u0107 analitycznie, bez jawnego modelu nagrody i bez uczenia przez wzmocnienie.", "tokens": [50364, 46864, 35226, 1154, 2427, 4199, 304, 590, 13152, 710, 497, 43, 39, 37, 17790, 9544, 18234, 35873, 364, 1860, 19923, 11, 10782, 18162, 11858, 2316, 84, 17096, 340, 3173, 741, 10782, 344, 38517, 14064, 24809, 76, 905, 77, 27385, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 47, "seek": 27270, "start": 281.7, "end": 282.9, "text": " Jak to mo\u017cliwe?", "tokens": [50814, 15029, 281, 30854, 826, 30, 50874], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 48, "seek": 27270, "start": 282.9, "end": 291.09999999999997, "text": " Okaza\u0142o si\u0119, \u017ce istnieje \u015bcis\u0142e matematyczne powi\u0105zanie mi\u0119dzy optymalnym modelem nagrody, a optymaln\u0105 strategi\u0105 generowania tekstu.", "tokens": [50874, 3477, 12257, 5249, 3244, 11, 3561, 1418, 2766, 2884, 8299, 26720, 19827, 3803, 8615, 17466, 716, 3388, 11404, 89, 7155, 33964, 2427, 4199, 304, 12996, 4391, 10386, 17096, 340, 3173, 11, 257, 2427, 4199, 304, 13113, 5464, 11404, 1337, 21308, 16624, 372, 84, 13, 51284], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 49, "seek": 27270, "start": 291.09999999999997, "end": 292.9, "text": " Czyli oni to po prostu wyliczyli?", "tokens": [51284, 37099, 36317, 281, 714, 19518, 4628, 1050, 1229, 2081, 30, 51374], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 50, "seek": 27270, "start": 292.9, "end": 294.7, "text": " Mhm, w pewnym sensie tak.", "tokens": [51374, 26272, 11, 261, 47160, 4199, 2923, 414, 991, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 51, "seek": 27270, "start": 294.7, "end": 301.7, "text": " Udowodnili, \u017ce mo\u017cna przekszta\u0142ci\u0107 problem trenowania s\u0119dziego w problem, kt\u00f3ry mo\u017cna rozwi\u0105za\u0107 bezpo\u015brednio na g\u0142\u00f3wnym modelu.", "tokens": [51464, 624, 67, 305, 378, 77, 2312, 11, 3561, 17790, 29785, 15453, 46426, 39162, 1154, 23136, 21308, 262, 42643, 1571, 261, 1154, 11, 9913, 17790, 9544, 18234, 35873, 10782, 2259, 1788, 986, 41084, 1667, 18117, 812, 895, 4199, 2316, 84, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07332536909315321, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.051096223294734955}, {"id": 52, "seek": 30170, "start": 301.7, "end": 304.3, "text": " To brzmi... elegancko.", "tokens": [50364, 1407, 738, 89, 3057, 485, 1118, 1275, 41416, 13, 50494], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 53, "seek": 30170, "start": 304.3, "end": 311.3, "text": " Zamiast budowa\u0107 wieloetapowy system nawigacji, znale\u017ali jedn\u0105 formu\u0142\u0119 matematyczn\u0105, kt\u00f3ra od razu wskazuje cel.", "tokens": [50494, 1176, 4526, 525, 3265, 11445, 20570, 78, 302, 569, 10089, 1185, 18969, 328, 13152, 11, 15397, 1220, 10659, 2081, 5232, 13113, 1254, 84, 46564, 3803, 8615, 17466, 13113, 11, 19456, 3611, 367, 8813, 261, 5161, 43317, 9277, 13, 50844], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 54, "seek": 30170, "start": 311.3, "end": 314.5, "text": " Dok\u0142adnie, i st\u0105d ten genialny tytu\u0142 pracy.", "tokens": [50844, 29768, 10358, 2766, 11, 741, 342, 18962, 2064, 48228, 1634, 1104, 9179, 1221, 35591, 13, 51004], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 55, "seek": 30170, "start": 314.5, "end": 317.3, "text": " Tw\u00f3j model j\u0119zykowy w sekrecie jest modelem nagrody.", "tokens": [51004, 2574, 18999, 2316, 49055, 74, 10089, 261, 17215, 265, 4260, 3492, 4391, 10386, 17096, 340, 3173, 13, 51144], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 56, "seek": 30170, "start": 317.3, "end": 319.7, "text": " W DPO nie ma oddzielnego s\u0119dziego.", "tokens": [51144, 343, 413, 34885, 2838, 463, 7401, 42280, 11858, 262, 42643, 1571, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 57, "seek": 30170, "start": 319.7, "end": 320.5, "text": " Nie ma.", "tokens": [51264, 12016, 463, 13, 51304], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 58, "seek": 30170, "start": 320.5, "end": 325.09999999999997, "text": " Sie\u0107 neuronowa samego modelu j\u0119zykowego pe\u0142ni podw\u00f3jn\u0105 rol\u0119.", "tokens": [51304, 3559, 2162, 34090, 5528, 912, 1571, 2316, 84, 49055, 74, 26576, 43205, 3722, 2497, 86, 18999, 13113, 34109, 1274, 13, 51534], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 59, "seek": 30170, "start": 325.09999999999997, "end": 329.9, "text": " Generuje tekst i jednocze\u015bnie nie jawnie reprezentuje system oceny.", "tokens": [51534, 15409, 13008, 16624, 372, 741, 5232, 26694, 1381, 12221, 2838, 18162, 2766, 1085, 265, 14185, 13008, 1185, 10409, 43100, 13, 51774], "temperature": 0.0, "avg_logprob": -0.08932145645743922, "compression_ratio": 1.419463087248322, "no_speech_prob": 0.009412740357220173}, {"id": 60, "seek": 32990, "start": 329.9, "end": 334.29999999999995, "text": " Czyli ca\u0142y ten skomplikowany trzyetapowy taniec z RLHF.", "tokens": [50364, 37099, 35226, 2064, 1110, 298, 564, 1035, 23341, 34573, 302, 569, 10089, 256, 7155, 66, 710, 497, 43, 39, 37, 13, 50584], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 61, "seek": 32990, "start": 334.29999999999995, "end": 339.7, "text": " Zostaje zast\u0105piony przez jeden prosty etap Fine Tuning z odpowiednio dobran\u0105 funkcj\u0105 straty.", "tokens": [50584, 1176, 555, 11153, 36746, 1611, 79, 46184, 14064, 12906, 10293, 88, 47634, 12024, 21363, 278, 710, 36574, 41084, 23067, 282, 1611, 26476, 66, 8555, 1056, 21398, 13, 50854], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 62, "seek": 32990, "start": 339.7, "end": 346.09999999999997, "text": " Ok, czyli sprowadzamy ten potwornie z\u0142o\u017cony problem do czego\u015b, co przypomina prost\u0105 klasyfikacj\u0119 binarn\u0105.", "tokens": [50854, 3477, 11, 16591, 637, 1892, 345, 89, 7804, 2064, 1847, 86, 1865, 414, 710, 5249, 1427, 2526, 1154, 360, 36559, 1788, 11, 598, 41780, 49217, 10293, 1611, 9671, 5871, 31230, 29924, 5171, 1083, 1611, 13, 51174], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 63, "seek": 32990, "start": 346.09999999999997, "end": 346.7, "text": " W\u0142a\u015bnie.", "tokens": [51174, 343, 5024, 12221, 13, 51204], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 64, "seek": 32990, "start": 346.7, "end": 352.09999999999997, "text": " Mamy par\u0119 odpowiedzi wygrywaj\u0105c\u0105 i przegrywaj\u0105c\u0105.", "tokens": [51204, 376, 7804, 971, 1274, 36574, 3992, 4628, 70, 47705, 11133, 32557, 741, 6541, 1146, 47705, 11133, 32557, 13, 51474], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 65, "seek": 32990, "start": 352.09999999999997, "end": 356.5, "text": " I celem jest po prostu zwi\u0119kszenia prawdopodowie\u0144stwa wygenerowania tej lepszej.", "tokens": [51474, 286, 1769, 10386, 3492, 714, 19518, 11873, 5034, 1694, 14320, 41175, 46684, 13998, 12229, 4151, 4628, 21848, 21308, 12573, 476, 1878, 16920, 13, 51694], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 66, "seek": 32990, "start": 356.5, "end": 358.29999999999995, "text": " Tak, w uproszczeniu.", "tokens": [51694, 9118, 11, 261, 493, 2635, 89, 66, 39651, 13, 51784], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 67, "seek": 32990, "start": 358.29999999999995, "end": 359.7, "text": " To brzmi prosto.", "tokens": [51784, 1407, 738, 89, 3057, 10293, 78, 13, 51854], "temperature": 0.0, "avg_logprob": -0.08682334570237148, "compression_ratio": 1.4933774834437086, "no_speech_prob": 0.02839312143623829}, {"id": 68, "seek": 35970, "start": 359.9, "end": 361.9, "text": " Mo\u017ce nawet zbyt prosto.", "tokens": [50374, 43774, 22696, 710, 2322, 83, 10293, 78, 13, 50474], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 69, "seek": 35970, "start": 361.9, "end": 363.09999999999997, "text": " Gdzie jest haczyk?", "tokens": [50474, 460, 13096, 3492, 324, 6522, 74, 30, 50534], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 70, "seek": 35970, "start": 363.09999999999997, "end": 367.09999999999997, "text": " Przecie\u017c pr\u00f3bowano ju\u017c podobnych metod, jak unlikely heaving.", "tokens": [50534, 2114, 1381, 40082, 8565, 8202, 3730, 10678, 43024, 9399, 1131, 378, 11, 4207, 17518, 3577, 278, 13, 50734], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 71, "seek": 35970, "start": 367.09999999999997, "end": 368.9, "text": " I nie dzia\u0142a\u0142y one zbyt dobrze.", "tokens": [50734, 286, 2838, 37903, 6825, 472, 710, 2322, 83, 28335, 13, 50824], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 72, "seek": 35970, "start": 368.9, "end": 373.3, "text": " To jest kluczowe pytanie i tu kryje si\u0119 ca\u0142a finezja DPO.", "tokens": [50824, 1407, 3492, 9671, 1311, 89, 6880, 36610, 741, 2604, 34847, 2884, 3244, 1335, 5024, 2489, 89, 2938, 413, 34885, 13, 51044], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 73, "seek": 35970, "start": 373.3, "end": 378.9, "text": " To nie jest naivne si\u0142owe, nagradzanie dobrych i karanie z\u0142ych odpowiedzi.", "tokens": [51044, 1407, 2838, 3492, 1667, 592, 716, 1511, 1221, 6880, 11, 17096, 6206, 89, 7155, 35884, 339, 741, 7917, 7155, 710, 47655, 36574, 3992, 13, 51324], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 74, "seek": 35970, "start": 378.9, "end": 380.5, "text": " A co to jest w takim razie?", "tokens": [51324, 316, 598, 281, 3492, 261, 31732, 9639, 414, 30, 51404], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 75, "seek": 35970, "start": 380.5, "end": 384.3, "text": " DPO robi to w znacznie bardziej wyrafinowany spos\u00f3b.", "tokens": [51404, 413, 34885, 47380, 281, 261, 15397, 14875, 2766, 27209, 4628, 424, 5194, 23341, 22904, 13, 51594], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 76, "seek": 35970, "start": 384.3, "end": 386.5, "text": " Wyobra\u017a sobie, \u017ce uczysz dziecko.", "tokens": [51594, 14458, 24393, 10659, 13652, 11, 3561, 344, 3689, 20589, 17953, 41416, 13, 51704], "temperature": 0.0, "avg_logprob": -0.10609771164370255, "compression_ratio": 1.4384057971014492, "no_speech_prob": 0.0017367007676512003}, {"id": 77, "seek": 38650, "start": 386.5, "end": 390.1, "text": " Je\u015bli ju\u017c robi co\u015b dobrze, tylko lekko je chwali\u015b.", "tokens": [50364, 37086, 10678, 47380, 19241, 28335, 11, 13219, 30863, 4093, 1506, 26237, 5103, 1788, 13, 50544], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 78, "seek": 38650, "start": 390.1, "end": 394.9, "text": " Ale je\u015bli robi du\u017cy b\u0142\u0105d, twoja reakcja jest znacznie silniejsza.", "tokens": [50544, 9366, 25630, 47380, 1581, 7735, 272, 15926, 67, 11, 732, 2938, 319, 514, 34056, 3492, 15397, 14875, 2766, 3425, 30295, 2394, 13, 50784], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 79, "seek": 38650, "start": 394.9, "end": 398.3, "text": " Czyli si\u0142a lekcji jest proporcjonalna do wielko\u015bci b\u0142\u0119du?", "tokens": [50784, 37099, 1511, 5024, 30863, 19649, 3492, 2365, 36003, 15735, 304, 629, 360, 20570, 4093, 6199, 272, 46564, 769, 30, 50954], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 80, "seek": 38650, "start": 398.3, "end": 399.5, "text": " Dok\u0142adnie tak.", "tokens": [50954, 29768, 10358, 2766, 991, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 81, "seek": 38650, "start": 399.5, "end": 404.7, "text": " Waga z jak\u0105 aktualizowane s\u0105 parametry nie jest sta\u0142a, jest dynamiczna.", "tokens": [51014, 343, 9286, 710, 46719, 13680, 901, 590, 23066, 9015, 6220, 9889, 2838, 3492, 11135, 5024, 11, 3492, 8546, 35458, 13, 51274], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 82, "seek": 38650, "start": 404.7, "end": 405.3, "text": " Aha.", "tokens": [51274, 27448, 13, 51304], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 83, "seek": 38650, "start": 405.3, "end": 408.9, "text": " Je\u015bli model ju\u017c teraz bez \u017cadnej aktualizacji,", "tokens": [51304, 37086, 2316, 10678, 16854, 10782, 39628, 11794, 13680, 901, 590, 13152, 11, 51484], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 84, "seek": 38650, "start": 408.9, "end": 412.9, "text": " ocenie preferowan\u0105 odpowied\u017a znacznie wy\u017cej ni\u017c t\u0119 gorsz\u0105,", "tokens": [51484, 10409, 268, 414, 4382, 37345, 1611, 36574, 10659, 15397, 14875, 2766, 4628, 38493, 28502, 32489, 290, 830, 8925, 11, 51684], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 85, "seek": 38650, "start": 412.9, "end": 415.5, "text": " to aktualizacja jest bardzo niewielka.", "tokens": [51684, 281, 13680, 901, 590, 23395, 3492, 9034, 43622, 1187, 2330, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08497974607679579, "compression_ratio": 1.5244755244755244, "no_speech_prob": 0.011792926117777824}, {"id": 86, "seek": 41550, "start": 415.5, "end": 418.5, "text": " Ok. I tak jeste\u015b na dobrej drodze.", "tokens": [50364, 3477, 13, 286, 991, 25255, 1788, 1667, 41959, 73, 3789, 67, 1381, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 87, "seek": 41550, "start": 418.5, "end": 419.5, "text": " W\u0142a\u015bnie.", "tokens": [50514, 343, 5024, 12221, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 88, "seek": 41550, "start": 419.5, "end": 421.5, "text": " Ale je\u015bli sytuacja jest odwrotna,", "tokens": [50564, 9366, 25630, 28275, 23395, 3492, 3611, 7449, 310, 629, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 89, "seek": 41550, "start": 421.5, "end": 424.9, "text": " je\u015bli model b\u0142\u0119dnie faworyzuje przegrywaj\u0105c\u0105 odpowied\u017a,", "tokens": [50664, 25630, 2316, 272, 1221, 6298, 2766, 283, 1607, 827, 11728, 2884, 6541, 1146, 47705, 11133, 32557, 36574, 10659, 11, 50834], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 90, "seek": 41550, "start": 424.9, "end": 427.3, "text": " wtedy aktualizacja jest bardzo silna.", "tokens": [50834, 26959, 13680, 901, 590, 23395, 3492, 9034, 3425, 629, 13, 50954], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 91, "seek": 41550, "start": 427.3, "end": 430.5, "text": " System wie, \u017ce musi dokona\u0107 du\u017cej korekty.", "tokens": [50954, 8910, 3355, 11, 3561, 37587, 25037, 4037, 2162, 1581, 38493, 350, 418, 74, 874, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 92, "seek": 41550, "start": 430.5, "end": 431.5, "text": " Rozumiem.", "tokens": [51114, 43313, 449, 4907, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 93, "seek": 41550, "start": 431.5, "end": 436.7, "text": " W pracy autorze nazywaj\u0105 to dynamic par example importance weight.", "tokens": [51164, 343, 35591, 19510, 1381, 20151, 27112, 11133, 281, 8546, 971, 1365, 7379, 3364, 13, 51424], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 94, "seek": 41550, "start": 436.7, "end": 440.3, "text": " I to w\u0142a\u015bnie ten mechanizm zapobiega degeneracji modelu,", "tokens": [51424, 286, 281, 14234, 2064, 4236, 590, 76, 14223, 996, 414, 3680, 40520, 13152, 2316, 84, 11, 51604], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 95, "seek": 41550, "start": 440.3, "end": 443.1, "text": " kt\u00f3r\u0105 obserwowano przy prostszych podej\u015bciach.", "tokens": [51604, 37415, 12887, 34354, 3730, 6501, 10293, 45021, 7468, 73, 6199, 608, 13, 51744], "temperature": 0.0, "avg_logprob": -0.10272226402227827, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0024354932829737663}, {"id": 96, "seek": 44310, "start": 443.1, "end": 445.5, "text": " No dobrze, ale czy na pewno niczego nie tracimy,", "tokens": [50364, 883, 28335, 11, 6775, 6430, 1667, 33002, 6201, 27725, 2838, 504, 326, 13189, 11, 50484], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 97, "seek": 44310, "start": 445.5, "end": 448.5, "text": " pozbywaj\u0105c si\u0119 tego dedykowanego modelu nagrody?", "tokens": [50484, 21281, 2322, 86, 38757, 3244, 8627, 4172, 46127, 37345, 6308, 2316, 84, 17096, 340, 3173, 30, 50634], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 98, "seek": 44310, "start": 448.5, "end": 453.1, "text": " Mo\u017ce ten s\u0119dzia potrafi\u0142 uchwyci\u0107 jakie\u015b niuanse, kt\u00f3re DPO pomija?", "tokens": [50634, 43774, 2064, 262, 6298, 40395, 1847, 10437, 40622, 344, 339, 9726, 39162, 31163, 3867, 6139, 405, 11, 8864, 413, 34885, 12991, 20642, 30, 50864], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 99, "seek": 44310, "start": 453.1, "end": 454.5, "text": " To \u015bwietna uwaga.", "tokens": [50864, 1407, 8299, 39083, 629, 23147, 9286, 13, 50934], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 100, "seek": 44310, "start": 454.5, "end": 456.70000000000005, "text": " I teoretycznie mog\u0142oby tak by\u0107.", "tokens": [50934, 286, 535, 418, 45586, 13172, 1221, 13944, 991, 15069, 13, 51044], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 101, "seek": 44310, "start": 456.70000000000005, "end": 458.70000000000005, "text": " Ale jak poka\u017c\u0105 eksperymenty,", "tokens": [51044, 9366, 4207, 13010, 18264, 1611, 30724, 610, 88, 518, 88, 11, 51144], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 102, "seek": 44310, "start": 458.70000000000005, "end": 462.3, "text": " w praktyce okazuje si\u0119, \u017ce najwi\u0119kszym problemem RLH", "tokens": [51144, 261, 3206, 74, 874, 384, 3133, 43317, 3244, 11, 3561, 48636, 1694, 26681, 1154, 443, 497, 43, 39, 51324], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 103, "seek": 44310, "start": 462.3, "end": 465.1, "text": " wcale nie by\u0142a niedoskona\u0142o\u015b\u0107 modelu nagrody.", "tokens": [51324, 261, 37088, 2838, 23936, 32488, 329, 74, 4037, 44742, 2316, 84, 17096, 340, 3173, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 104, "seek": 44310, "start": 465.1, "end": 465.90000000000003, "text": " Tylko co?", "tokens": [51464, 49286, 4093, 598, 30, 51504], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 105, "seek": 44310, "start": 465.90000000000003, "end": 470.90000000000003, "text": " Niestabielno\u015b\u0107 i nieefektywno\u015b\u0107 samego procesu optymalizacji RL.", "tokens": [51504, 426, 6495, 455, 1187, 23293, 741, 2838, 5666, 916, 874, 20944, 7753, 912, 1571, 17565, 84, 2427, 4199, 304, 590, 13152, 497, 43, 13, 51754], "temperature": 0.0, "avg_logprob": -0.08725319839105374, "compression_ratio": 1.403174603174603, "no_speech_prob": 0.0019944387022405863}, {"id": 106, "seek": 47090, "start": 471.09999999999997, "end": 475.29999999999995, "text": " DPO, omijaj\u0105c ten proces, jest w stanie osi\u0105gn\u0105\u0107 lepsze wyniki.", "tokens": [50374, 413, 34885, 11, 3406, 1718, 38757, 2064, 17565, 11, 3492, 261, 40013, 3003, 11404, 4568, 36374, 476, 1878, 1381, 31936, 9850, 13, 50584], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 107, "seek": 47090, "start": 475.29999999999995, "end": 479.29999999999995, "text": " Jest te\u017c parametr beta, kt\u00f3ry pe\u0142ni rol\u0119 tej smyczy KL.", "tokens": [50584, 24918, 9516, 6220, 27965, 9861, 11, 9913, 43205, 3722, 34109, 1274, 12573, 262, 2226, 6522, 47991, 13, 50784], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 108, "seek": 47090, "start": 479.29999999999995, "end": 482.29999999999995, "text": " Kontroluje, jak bardzo model mo\u017ce si\u0119 zmieni\u0107.", "tokens": [50784, 20629, 340, 2781, 2884, 11, 4207, 9034, 2316, 12034, 3244, 17020, 1053, 12757, 13, 50934], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 109, "seek": 47090, "start": 482.29999999999995, "end": 485.09999999999997, "text": " No dobrze, teoria brzmi rewelacyjnie.", "tokens": [50934, 883, 28335, 11, 535, 8172, 738, 89, 3057, 319, 45512, 31285, 2766, 13, 51074], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 110, "seek": 47090, "start": 485.09999999999997, "end": 490.7, "text": " Niesamowite, \u017ce jednym ruchem wyeliminowali ca\u0142y najbardziej problematyczny etap.", "tokens": [51074, 426, 530, 335, 305, 642, 11, 3561, 5232, 12996, 367, 625, 443, 4628, 338, 4395, 305, 5103, 35226, 41857, 1154, 267, 17466, 1634, 47634, 13, 51354], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 111, "seek": 47090, "start": 490.7, "end": 492.09999999999997, "text": " Ale teoria to jedno.", "tokens": [51354, 9366, 535, 8172, 281, 5232, 1771, 13, 51424], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 112, "seek": 47090, "start": 492.09999999999997, "end": 494.29999999999995, "text": " Jak to si\u0119 sprawdzi\u0142o w praktyce?", "tokens": [51424, 15029, 281, 3244, 46192, 3992, 5249, 261, 3206, 74, 874, 384, 30, 51534], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 113, "seek": 47090, "start": 494.29999999999995, "end": 498.29999999999995, "text": " Autorzy przeprowadzili seri\u0119 bardzo wymownych eksperyment\u00f3w.", "tokens": [51534, 6049, 284, 1229, 30829, 1892, 345, 89, 2312, 816, 5034, 9034, 29764, 648, 16384, 30724, 610, 88, 518, 3901, 13, 51734], "temperature": 0.0, "avg_logprob": -0.0846071887660671, "compression_ratio": 1.4155405405405406, "no_speech_prob": 0.001335859065875411}, {"id": 114, "seek": 49830, "start": 498.3, "end": 501.7, "text": " Pierwszy dotyczy\u0142 kontrolowanej generacji sentymentu.", "tokens": [50364, 16676, 30012, 5893, 88, 6522, 1221, 14373, 6623, 23066, 73, 1337, 13152, 2279, 88, 518, 84, 13, 50534], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 115, "seek": 49830, "start": 501.7, "end": 502.7, "text": " Czyli?", "tokens": [50534, 37099, 30, 50584], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 116, "seek": 49830, "start": 502.7, "end": 504.1, "text": " Zadanie by\u0142o proste.", "tokens": [50584, 1176, 345, 7155, 14811, 10293, 68, 13, 50654], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 117, "seek": 49830, "start": 504.1, "end": 507.1, "text": " Nauczy\u0107 model pisa\u0107 recenzje film\u00f3w z AMDB,", "tokens": [50654, 6056, 1311, 27150, 2316, 280, 3837, 2162, 850, 11368, 2884, 2007, 3901, 710, 34808, 33, 11, 50804], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 118, "seek": 49830, "start": 507.1, "end": 510.1, "text": " kt\u00f3re maj\u0105 jednoznacznie pozytywny wyd\u017awi\u0119k.", "tokens": [50804, 8864, 26064, 5232, 1771, 22672, 14875, 2766, 49358, 874, 43682, 25984, 10659, 22423, 74, 13, 50954], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 119, "seek": 49830, "start": 510.1, "end": 514.1, "text": " Co ciekawe, do oceny u\u017cyli innego klasyfikatora sentymentu,", "tokens": [50954, 3066, 30596, 2330, 826, 11, 360, 10409, 43100, 34097, 2081, 294, 11858, 9671, 5871, 31230, 1639, 64, 2279, 88, 518, 84, 11, 51154], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 120, "seek": 49830, "start": 514.1, "end": 518.1, "text": " co da\u0142o im obiektywn\u0105 prawdziw\u0105 funkcj\u0119 nagrody do por\u00f3wna\u0144.", "tokens": [51154, 598, 1120, 5249, 566, 1111, 19487, 874, 895, 1611, 41175, 3992, 86, 1611, 26476, 41960, 17096, 340, 3173, 360, 1515, 3901, 629, 5248, 13, 51354], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 121, "seek": 49830, "start": 518.1, "end": 519.7, "text": " I co pokaza\u0142y wyniki?", "tokens": [51354, 286, 598, 13010, 12257, 6825, 31936, 9850, 30, 51434], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 122, "seek": 49830, "start": 519.7, "end": 521.7, "text": " Wymiki s\u0105 uderzaj\u0105ce.", "tokens": [51434, 343, 4199, 9850, 9015, 344, 1068, 89, 11133, 384, 13, 51534], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 123, "seek": 49830, "start": 521.7, "end": 525.9, "text": " Na wykresie, kt\u00f3ry pokazuje kompromis mi\u0119dzy maksymalizacj\u0105 nagrody,", "tokens": [51534, 6056, 39287, 495, 414, 11, 9913, 13010, 43317, 5207, 28722, 271, 33964, 963, 3187, 5579, 590, 326, 8555, 17096, 340, 3173, 11, 51744], "temperature": 0.0, "avg_logprob": -0.08668266643177379, "compression_ratio": 1.4059405940594059, "no_speech_prob": 0.3367721736431122}, {"id": 124, "seek": 52590, "start": 525.9, "end": 528.9, "text": " a utrzymaniem modelu blisko orygina\u0142u,", "tokens": [50364, 257, 2839, 13047, 1601, 4907, 2316, 84, 888, 43442, 420, 18103, 1426, 24066, 11, 50514], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 125, "seek": 52590, "start": 528.9, "end": 532.9, "text": " krzywa dla DPO wprost dominuje nadkrzyw\u0105 dla PPO.", "tokens": [50514, 350, 13047, 4151, 12285, 413, 34885, 261, 1424, 555, 8859, 13008, 12617, 74, 13047, 86, 1611, 12285, 430, 34885, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 126, "seek": 52590, "start": 532.9, "end": 536.9, "text": " Osi\u0105ga wy\u017csz\u0105 nagrod\u0119 przy tym samym poziomie zmiany modelu.", "tokens": [50714, 422, 7691, 1611, 3680, 4628, 1427, 82, 8925, 17096, 11452, 1274, 6501, 8107, 3247, 4199, 38503, 40120, 43591, 88, 2316, 84, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 127, "seek": 52590, "start": 536.9, "end": 539.9, "text": " Tak, ale najciekawsze jest co innego.", "tokens": [50914, 9118, 11, 6775, 11212, 4260, 74, 28354, 3492, 598, 294, 11858, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 128, "seek": 52590, "start": 539.9, "end": 544.9, "text": " DPO okaza\u0142o si\u0119 lepsze nawet od wariantu, kt\u00f3ry nazwali PPO GT,", "tokens": [51064, 413, 34885, 3133, 12257, 5249, 3244, 476, 1878, 1381, 22696, 3611, 1516, 5798, 84, 11, 9913, 20151, 40054, 430, 34885, 17530, 11, 51314], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 129, "seek": 52590, "start": 544.9, "end": 547.9, "text": " gdzie GT oznacza Ground Truth.", "tokens": [51314, 18922, 17530, 277, 22672, 326, 2394, 28371, 20522, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 130, "seek": 52590, "start": 547.9, "end": 548.9, "text": " Chyla.", "tokens": [51464, 761, 88, 875, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 131, "seek": 52590, "start": 548.9, "end": 552.9, "text": " Czyli w tym wariancie PPO mia\u0142o fory.", "tokens": [51514, 37099, 261, 8107, 1516, 952, 4260, 430, 34885, 21290, 5249, 283, 827, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12366477055336113, "compression_ratio": 1.3868312757201646, "no_speech_prob": 0.03124968335032463}, {"id": 132, "seek": 55290, "start": 552.9, "end": 556.9, "text": " Dosta\u0142o dost\u0119p do tej prawdziwej funkcji nagrody,", "tokens": [50364, 413, 8638, 5249, 48209, 360, 12573, 41175, 3992, 826, 73, 26476, 19649, 17096, 340, 3173, 11, 50564], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 133, "seek": 55290, "start": 556.9, "end": 559.9, "text": " a nie tylko do wyuczonego niedoskona\u0142ego modelu.", "tokens": [50564, 257, 2838, 13219, 360, 4628, 1311, 16896, 1571, 32488, 329, 74, 4037, 1221, 6308, 2316, 84, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 134, "seek": 55290, "start": 559.9, "end": 562.9, "text": " Dok\u0142adnie, to by\u0142 wariant z oszustwem,", "tokens": [50714, 29768, 10358, 2766, 11, 281, 16673, 1516, 5798, 710, 3003, 37677, 86, 443, 11, 50864], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 135, "seek": 55290, "start": 562.9, "end": 565.9, "text": " kt\u00f3ry mia\u0142 pokaza\u0107 g\u00f3rny pu\u0142ap mo\u017cliwo\u015bci PPO.", "tokens": [50864, 9913, 27989, 13010, 12257, 2162, 290, 15614, 1634, 2362, 1221, 569, 30854, 36476, 430, 34885, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 136, "seek": 55290, "start": 565.9, "end": 567.9, "text": " I DPO go pokona\u0142o.", "tokens": [51014, 286, 413, 34885, 352, 13010, 4037, 5249, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 137, "seek": 55290, "start": 567.9, "end": 569.9, "text": " To prowadzi do wa\u017cnego wniosku.", "tokens": [51114, 1407, 36590, 3992, 360, 27777, 11858, 45368, 2717, 5279, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 138, "seek": 55290, "start": 569.9, "end": 570.9, "text": " Tak.", "tokens": [51214, 9118, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 139, "seek": 55290, "start": 570.9, "end": 575.9, "text": " Skoro DPO jest lepsze nawet od PPO z pe\u0142n\u0105 wiedz\u0105 o prawdziwej nagrodzie,", "tokens": [51264, 7324, 10780, 413, 34885, 3492, 476, 1878, 1381, 22696, 3611, 430, 34885, 710, 43205, 13113, 46894, 8925, 277, 41175, 3992, 826, 73, 17096, 11452, 3283, 11, 51514], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 140, "seek": 55290, "start": 575.9, "end": 580.9, "text": " to znaczy, \u017ce w\u0105skim gard\u0142em w RLHF nie jest jako\u015b\u0107 modelu nagrody.", "tokens": [51514, 281, 36584, 11, 3561, 261, 1611, 5161, 332, 5628, 11126, 261, 497, 43, 39, 37, 2838, 3492, 17123, 7753, 2316, 84, 17096, 340, 3173, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05073407718113491, "compression_ratio": 1.4377224199288257, "no_speech_prob": 0.011467069387435913}, {"id": 141, "seek": 58090, "start": 580.9, "end": 586.9, "text": " Tylko sam algorytm optymizacji RL, kt\u00f3ry jest po prostu niestabilny i nieefektywny.", "tokens": [50364, 49286, 4093, 3247, 3501, 827, 83, 76, 2427, 4199, 590, 13152, 497, 43, 11, 9913, 3492, 714, 19518, 3867, 377, 5177, 1634, 741, 2838, 5666, 916, 874, 43682, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 142, "seek": 58090, "start": 586.9, "end": 589.9, "text": " DPO omija ten problem w ca\u0142o\u015bci.", "tokens": [50664, 413, 34885, 3406, 20642, 2064, 1154, 261, 1335, 35059, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 143, "seek": 58090, "start": 589.9, "end": 591.9, "text": " To faktycznie zmienia zasady gry.", "tokens": [50814, 1407, 33647, 45586, 17020, 18811, 26530, 880, 41974, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 144, "seek": 58090, "start": 591.9, "end": 594.9, "text": " A co z bardziej z\u0142o\u017conymi zadaniami, jak streszczenia?", "tokens": [50914, 316, 598, 710, 27209, 710, 5249, 1427, 2526, 3057, 710, 11338, 15568, 11, 4207, 342, 495, 89, 38517, 30, 51064], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 145, "seek": 58090, "start": 594.9, "end": 599.9, "text": " Drugi eksperyment dotyczy\u0142 streszczenia post\u00f3w z reddita w stylu TLDR.", "tokens": [51064, 2491, 24780, 30724, 610, 88, 518, 5893, 88, 6522, 1221, 342, 495, 89, 38517, 2183, 3901, 710, 2182, 67, 2786, 261, 7952, 2781, 40277, 9301, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 146, "seek": 58090, "start": 599.9, "end": 602.9, "text": " Tutaj oceny dokonywa\u0142 GPT-4.", "tokens": [51314, 41819, 10409, 43100, 25037, 2526, 44603, 26039, 51, 12, 19, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 147, "seek": 58090, "start": 602.9, "end": 603.9, "text": " I znowu.", "tokens": [51464, 286, 710, 3785, 84, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 148, "seek": 58090, "start": 603.9, "end": 605.9, "text": " DPO okaza\u0142o si\u0119 lepsze.", "tokens": [51514, 413, 34885, 3133, 12257, 5249, 3244, 476, 1878, 1381, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 149, "seek": 58090, "start": 605.9, "end": 606.9, "text": " O ile?", "tokens": [51614, 422, 15465, 30, 51664], "temperature": 0.0, "avg_logprob": -0.08140430987720758, "compression_ratio": 1.3706563706563706, "no_speech_prob": 0.051992353051900864}, {"id": 150, "seek": 60690, "start": 606.9, "end": 615.9, "text": " Osi\u0105gn\u0119\u0142o wska\u017anik zwyci\u0119stw na pozionie 61% w por\u00f3wnaniu do 57% dla PPO.", "tokens": [50364, 422, 7691, 1611, 4568, 1274, 5249, 261, 20771, 10659, 13123, 43436, 537, 1274, 372, 86, 1667, 38503, 32242, 28294, 4, 261, 1515, 812, 895, 25849, 360, 21423, 4, 12285, 430, 34885, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06747888601743258, "compression_ratio": 1.287037037037037, "no_speech_prob": 0.0582992285490036}, {"id": 151, "seek": 60690, "start": 615.9, "end": 619.9, "text": " Co wi\u0119cej, okaza\u0142o si\u0119 znacznie bardziej stabilne.", "tokens": [50814, 3066, 26004, 11, 3133, 12257, 5249, 3244, 15397, 14875, 2766, 27209, 11652, 716, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06747888601743258, "compression_ratio": 1.287037037037037, "no_speech_prob": 0.0582992285490036}, {"id": 152, "seek": 60690, "start": 619.9, "end": 624.9, "text": " Wyniki PPO mocno si\u0119 pogarsza\u0142y przy zmianie temperatury pr\u00f3bkowania.", "tokens": [51014, 343, 2534, 9850, 430, 34885, 34962, 1771, 3244, 32037, 685, 2394, 6825, 6501, 43591, 414, 3393, 267, 2598, 8565, 65, 74, 21308, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06747888601743258, "compression_ratio": 1.287037037037037, "no_speech_prob": 0.0582992285490036}, {"id": 153, "seek": 60690, "start": 624.9, "end": 626.9, "text": " DPO pozostawa\u0142o oni wzruszone.", "tokens": [51264, 413, 34885, 21281, 555, 10449, 5249, 36317, 24809, 13783, 16896, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06747888601743258, "compression_ratio": 1.287037037037037, "no_speech_prob": 0.0582992285490036}, {"id": 154, "seek": 60690, "start": 626.9, "end": 628.9, "text": " A najtrudniejsze zadanie, czyli diolog?", "tokens": [51364, 316, 11212, 6903, 532, 44258, 42788, 7155, 11, 16591, 1026, 1132, 30, 51464], "temperature": 0.0, "avg_logprob": -0.06747888601743258, "compression_ratio": 1.287037037037037, "no_speech_prob": 0.0582992285490036}, {"id": 155, "seek": 62890, "start": 629.9, "end": 632.9, "text": " U\u017cyto tu zbioru danych Anthropic HH,", "tokens": [50414, 624, 7735, 1353, 2604, 710, 33362, 84, 274, 34644, 12727, 39173, 389, 39, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 156, "seek": 62890, "start": 632.9, "end": 636.9, "text": " kt\u00f3re celem jest prowadzenie pomocnej i nieszkodliwej konwersacji.", "tokens": [50564, 8864, 1769, 10386, 3492, 36590, 16778, 48962, 11794, 741, 297, 15347, 74, 378, 2081, 826, 73, 5897, 5364, 13152, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 157, "seek": 62890, "start": 636.9, "end": 641.9, "text": " W tym eksperymencie DPO by\u0142o jedyn\u0105 obliczeniowo wydajn\u0105 metod\u0105,", "tokens": [50764, 343, 8107, 30724, 610, 88, 2558, 4260, 413, 34885, 14811, 5232, 2534, 1611, 1111, 1050, 42124, 19941, 25984, 1805, 13113, 1131, 378, 1611, 11, 51014], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 158, "seek": 62890, "start": 641.9, "end": 644.9, "text": " kt\u00f3ra faktycznie poprawi\u0142a wyniki.", "tokens": [51014, 19456, 33647, 45586, 1665, 5131, 72, 5024, 31936, 9850, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 159, "seek": 62890, "start": 644.9, "end": 649.9, "text": " I co ciekawe, zadzia\u0142a\u0142o r\u00f3wnie dobrze jak bardzo kosztowna metoda Best of 128.", "tokens": [51164, 286, 598, 30596, 2330, 826, 11, 42788, 89, 25605, 5249, 11416, 14215, 28335, 4207, 9034, 19532, 2682, 305, 629, 1131, 13449, 9752, 295, 29810, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 160, "seek": 62890, "start": 649.9, "end": 650.9, "text": " Dok\u0142adnie.", "tokens": [51414, 29768, 10358, 2766, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 161, "seek": 62890, "start": 650.9, "end": 657.9, "text": " Metoda Best of 128 polega na wygenerowaniu 128 odpowiedzi i wybraniu najlepszej.", "tokens": [51464, 6377, 13449, 9752, 295, 29810, 13208, 3680, 1667, 4628, 21848, 305, 25849, 29810, 36574, 3992, 741, 4628, 1443, 25849, 41903, 1878, 16920, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08854304341708913, "compression_ratio": 1.4175824175824177, "no_speech_prob": 0.2099030315876007}, {"id": 162, "seek": 65790, "start": 657.9, "end": 659.9, "text": " To jest, wiesz, si\u0142owe podej\u015bcie.", "tokens": [50364, 1407, 3492, 11, 261, 15347, 11, 1511, 1221, 6880, 7468, 73, 9815, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 163, "seek": 65790, "start": 659.9, "end": 661.9, "text": " Kompletnie niepraktyczne ze wzgl\u0119du na koszty.", "tokens": [50464, 14286, 14657, 2766, 2838, 79, 11272, 874, 38491, 5277, 48538, 1274, 769, 1667, 19532, 89, 874, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 164, "seek": 65790, "start": 661.9, "end": 667.9, "text": " A DPO osi\u0105ga ten sam poziom jako\u015bci bez tej ogromnej pracy.", "tokens": [50564, 316, 413, 34885, 3003, 11404, 3680, 2064, 3247, 38503, 298, 17123, 6199, 10782, 12573, 34416, 298, 11794, 35591, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 165, "seek": 65790, "start": 667.9, "end": 672.9, "text": " Warto te\u017c doda\u0107, \u017ce autorze sprawdzili, czy GPT-4 jest wiarygodnym s\u0119dziom.", "tokens": [50864, 343, 15864, 9516, 360, 2675, 2162, 11, 3561, 19510, 1381, 46192, 89, 2312, 11, 6430, 26039, 51, 12, 19, 3492, 26393, 822, 21787, 12996, 262, 6298, 3992, 298, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 166, "seek": 65790, "start": 672.9, "end": 673.9, "text": " Jest.", "tokens": [51114, 24918, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 167, "seek": 65790, "start": 673.9, "end": 677.9, "text": " Okaza\u0142o si\u0119, \u017ce jego oceny mocno koreluj\u0105 z ludzkimi os\u0105dami.", "tokens": [51164, 3477, 12257, 5249, 3244, 11, 3561, 26542, 10409, 43100, 34962, 1771, 350, 418, 2781, 8555, 710, 15946, 89, 74, 10121, 3003, 18962, 4526, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 168, "seek": 65790, "start": 677.9, "end": 679.9, "text": " Wi\u0119c tak.", "tokens": [51364, 32508, 991, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 169, "seek": 65790, "start": 679.9, "end": 680.9, "text": " W porz\u0105dku.", "tokens": [51464, 343, 1515, 23876, 5279, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 170, "seek": 65790, "start": 680.9, "end": 683.9, "text": " To co to wszystko oznacza w praktyce?", "tokens": [51514, 1407, 598, 281, 22607, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 30, 51664], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 171, "seek": 65790, "start": 683.9, "end": 685.9, "text": " Jakie s\u0105 konsekwencje tego odkrycia?", "tokens": [51664, 15029, 414, 9015, 47020, 74, 15615, 44261, 8627, 3611, 43298, 2755, 30, 51764], "temperature": 0.0, "avg_logprob": -0.06700675487518311, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.024450097233057022}, {"id": 172, "seek": 68590, "start": 686.9, "end": 691.9, "text": " Przede wszystkim DPO radykalnie obni\u017ca barier\u0119 wej\u015bcia do \u015bwiata Elainment Modeli.", "tokens": [50414, 2114, 89, 4858, 30481, 413, 34885, 367, 880, 19990, 2766, 1111, 3722, 35075, 2159, 811, 1274, 321, 73, 1788, 2755, 360, 21485, 3274, 2699, 491, 518, 6583, 10148, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 173, "seek": 68590, "start": 691.9, "end": 697.9, "text": " Proces, kt\u00f3ry by\u0142 zarezerwowany dla garstki najwi\u0119kszych laboratori\u00f3w, staje si\u0119 znacznie prostsze.", "tokens": [50664, 1705, 887, 11, 9913, 16673, 710, 543, 4527, 86, 23341, 12285, 3691, 372, 2984, 48636, 1694, 28051, 5938, 39842, 3901, 11, 342, 11153, 3244, 15397, 14875, 2766, 10293, 82, 1381, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 174, "seek": 68590, "start": 697.9, "end": 704.9, "text": " Prostszy stabilniejszy i ta\u0144szy nie potrzeba ju\u017c zespo\u0142u ekspert\u00f3w od RL i gigantycznej infrastruktury.", "tokens": [50964, 2114, 555, 7706, 11652, 10402, 7706, 741, 1846, 5248, 7706, 2838, 28577, 4231, 10678, 710, 279, 2259, 24066, 30724, 15346, 3901, 3611, 497, 43, 741, 8741, 394, 17466, 11794, 6534, 19977, 2598, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 175, "seek": 68590, "start": 704.9, "end": 708.9, "text": " To w zasadzie Fine Tuning z niestandardow\u0105 funkcj\u0105 straty.", "tokens": [51314, 1407, 261, 44585, 3283, 12024, 21363, 278, 710, 3867, 377, 474, 515, 30297, 26476, 66, 8555, 1056, 21398, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 176, "seek": 68590, "start": 708.9, "end": 711.9, "text": " I to ma ogromne konsekwencje dla ca\u0142ego ekosystemu.", "tokens": [51514, 286, 281, 463, 34416, 298, 716, 47020, 74, 15615, 44261, 12285, 35224, 6308, 13359, 329, 9321, 84, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 177, "seek": 68590, "start": 711.9, "end": 712.9, "text": " Dok\u0142adnie.", "tokens": [51664, 29768, 10358, 2766, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06972609983908164, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.03486465662717819}, {"id": 178, "seek": 71290, "start": 712.9, "end": 721.9, "text": " Je\u015bli po\u0142\u0105czymy to z szerszym obrazem, zobaczymy, dlaczego DPO jest jednym z motor\u00f3w nap\u0119dowych rewolucji Open Sourceowej w AI.", "tokens": [50364, 37086, 714, 15926, 6522, 2226, 281, 710, 7870, 433, 26681, 22798, 24313, 11, 37273, 2226, 11, 37873, 39329, 413, 34885, 3492, 5232, 12996, 710, 5932, 3901, 9296, 6298, 19605, 319, 48481, 1311, 4013, 7238, 29629, 21091, 261, 7318, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1003255110520583, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.09960991889238358}, {"id": 179, "seek": 71290, "start": 721.9, "end": 726.9, "text": " To dlatego modele jak ZEFIR, czy najnowsze wersje LAMA tak szybko zaadaptowa\u0142y DPO.", "tokens": [50814, 1407, 32205, 4391, 306, 4207, 1176, 36, 37, 7740, 11, 6430, 11212, 77, 1509, 1381, 261, 433, 2884, 441, 38136, 991, 36456, 4093, 7949, 345, 2796, 5528, 6825, 413, 34885, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1003255110520583, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.09960991889238358}, {"id": 180, "seek": 71290, "start": 726.9, "end": 727.9, "text": " Tak.", "tokens": [51064, 9118, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1003255110520583, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.09960991889238358}, {"id": 181, "seek": 71290, "start": 727.9, "end": 733.9, "text": " To pozwoli\u0142o spo\u0142eczno\u015bci Open Source dogoni\u0107, a w niekt\u00f3rych zadaniach nawet przegoni\u0107.", "tokens": [51114, 1407, 40557, 9384, 5249, 36851, 89, 16438, 7238, 29629, 3000, 266, 12757, 11, 257, 261, 2838, 43073, 627, 339, 42788, 3782, 608, 22696, 6541, 1146, 266, 12757, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1003255110520583, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.09960991889238358}, {"id": 182, "seek": 71290, "start": 733.9, "end": 737.9, "text": " Zamkni\u0119te modele trenowane za setki milion\u00f3w dolar\u00f3w.", "tokens": [51414, 45492, 74, 35938, 975, 4391, 306, 23136, 23066, 7949, 992, 2984, 1962, 313, 3901, 360, 2200, 3901, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1003255110520583, "compression_ratio": 1.3800738007380073, "no_speech_prob": 0.09960991889238358}, {"id": 183, "seek": 73790, "start": 737.9, "end": 742.9, "text": " To demokratyzuje dost\u0119p do tworzenia wysokiej jako\u015bci dostosowanych modeli.", "tokens": [50364, 1407, 49432, 37433, 13008, 48209, 360, 46288, 14320, 27062, 453, 7764, 17123, 6199, 20568, 329, 23341, 339, 2316, 72, 13, 50614], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 184, "seek": 73790, "start": 742.9, "end": 745.9, "text": " Ale praca nie odpowiada na wszystkie pytania, prawda?", "tokens": [50614, 9366, 582, 6628, 2838, 24314, 39018, 1667, 31723, 25878, 5609, 11, 43607, 30, 50764], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 185, "seek": 73790, "start": 745.9, "end": 746.9, "text": " Oczywi\u015bcie, \u017ce nie.", "tokens": [50764, 42980, 11, 3561, 2838, 13, 50814], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 186, "seek": 73790, "start": 746.9, "end": 750.9, "text": " Autorzy sami wskazuj\u0105 kilka otwartych \u015bcie\u017cek.", "tokens": [50814, 6049, 284, 1229, 3247, 72, 261, 5161, 921, 13263, 36466, 4337, 29587, 16384, 8299, 40082, 916, 13, 51014], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 187, "seek": 73790, "start": 750.9, "end": 757.9, "text": " Po pierwsze, jak modele trenowane DPO generalizuj\u0105 na zadania, kt\u00f3re odbiegaj\u0105 od danych treningowych.", "tokens": [51014, 6165, 45994, 11, 4207, 4391, 306, 23136, 23066, 413, 34885, 2674, 590, 13263, 1667, 42788, 5609, 11, 8864, 3611, 7392, 70, 11133, 3611, 274, 34644, 2192, 773, 19605, 13, 51364], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 188, "seek": 73790, "start": 757.9, "end": 760.9, "text": " Wst\u0119pne wyniki s\u0105 obiecuj\u0105ce, ale potrzeba wi\u0119cej bada\u0144.", "tokens": [51364, 343, 372, 18085, 716, 31936, 9850, 9015, 1111, 35733, 13263, 384, 11, 6775, 28577, 4231, 26004, 272, 1538, 5248, 13, 51514], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 189, "seek": 73790, "start": 760.9, "end": 766.9, "text": " Po drugie, jak w kontek\u015bcie DPO wygl\u0105da problem Reward Over Optimization.", "tokens": [51514, 6165, 4110, 414, 11, 4207, 261, 14373, 916, 9815, 413, 34885, 32015, 1154, 1300, 1007, 4886, 35013, 2144, 13, 51814], "temperature": 0.0, "avg_logprob": -0.054324891069810165, "compression_ratio": 1.49, "no_speech_prob": 0.28259819746017456}, {"id": 190, "seek": 76690, "start": 766.9, "end": 771.9, "text": " Czyli sytuacji, gdy model uczy si\u0119 wykorzystywa\u0107 luki w systemie oceny.", "tokens": [50364, 37099, 28275, 13152, 11, 28405, 2316, 344, 6522, 3244, 43606, 1229, 25134, 25234, 287, 11788, 261, 1185, 414, 10409, 43100, 13, 50614], "temperature": 0.0, "avg_logprob": -0.060987380698875146, "compression_ratio": 1.429078014184397, "no_speech_prob": 0.017020761966705322}, {"id": 191, "seek": 76690, "start": 771.9, "end": 774.9, "text": " Szczeg\u00f3lnie interesuj\u0105ce, skoro model nagrody jest niejawny.", "tokens": [50614, 24699, 3689, 38079, 2766, 20157, 13263, 384, 11, 1110, 10780, 2316, 17096, 340, 3173, 3492, 2838, 2938, 43682, 13, 50764], "temperature": 0.0, "avg_logprob": -0.060987380698875146, "compression_ratio": 1.429078014184397, "no_speech_prob": 0.017020761966705322}, {"id": 192, "seek": 76690, "start": 774.9, "end": 778.9, "text": " I wreszcie, jak DPO skaluje si\u0119 do najwi\u0119kszych modeli.", "tokens": [50764, 286, 261, 495, 89, 4260, 11, 4207, 413, 34885, 16890, 13008, 3244, 360, 48636, 1694, 28051, 2316, 72, 13, 50964], "temperature": 0.0, "avg_logprob": -0.060987380698875146, "compression_ratio": 1.429078014184397, "no_speech_prob": 0.017020761966705322}, {"id": 193, "seek": 76690, "start": 778.9, "end": 783.9, "text": " Chocia\u017c patrz\u0105c na sukcesy najnowszych modeli, wydaje si\u0119, \u017ce skaluje si\u0119 bardzo dobrze.", "tokens": [50964, 12366, 42673, 1947, 81, 8925, 66, 1667, 46432, 887, 88, 11212, 77, 1509, 28051, 2316, 72, 11, 49165, 3244, 11, 3561, 16890, 13008, 3244, 9034, 28335, 13, 51214], "temperature": 0.0, "avg_logprob": -0.060987380698875146, "compression_ratio": 1.429078014184397, "no_speech_prob": 0.017020761966705322}, {"id": 194, "seek": 76690, "start": 783.9, "end": 794.9, "text": " Podsumowuj\u0105c, Direct Preference Optimization to pot\u0119\u017cna i niezwykle elegancka alternatywa dla z\u0142o\u017conego RLHF.", "tokens": [51214, 12646, 82, 449, 305, 44733, 11, 18308, 6001, 5158, 35013, 2144, 281, 1847, 1274, 1427, 629, 741, 33511, 9726, 14677, 1118, 1275, 39342, 5400, 21398, 4151, 12285, 710, 5249, 1427, 546, 1571, 497, 43, 39, 37, 13, 51764], "temperature": 0.0, "avg_logprob": -0.060987380698875146, "compression_ratio": 1.429078014184397, "no_speech_prob": 0.017020761966705322}, {"id": 195, "seek": 79490, "start": 794.9, "end": 802.9, "text": " Zmienia problem dostosowywania modeli z trudnego zadania RL w znacznie prostsze zadanie klasyfikacyjne.", "tokens": [50364, 1176, 76, 18811, 1154, 20568, 329, 10089, 86, 5609, 2316, 72, 710, 32007, 11858, 42788, 5609, 497, 43, 261, 15397, 14875, 2766, 10293, 82, 1381, 42788, 7155, 9671, 5871, 31230, 31285, 716, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06763295592548692, "compression_ratio": 1.3771929824561404, "no_speech_prob": 0.003636566922068596}, {"id": 196, "seek": 79490, "start": 802.9, "end": 806.9, "text": " A wyniki pokazuj\u0105, \u017ce jest co najmniej tak samo dobre,", "tokens": [50764, 316, 31936, 9850, 13010, 921, 13263, 11, 3561, 3492, 598, 11212, 47658, 991, 36422, 41959, 11, 50964], "temperature": 0.0, "avg_logprob": -0.06763295592548692, "compression_ratio": 1.3771929824561404, "no_speech_prob": 0.003636566922068596}, {"id": 197, "seek": 79490, "start": 806.9, "end": 810.9, "text": " a cz\u0119sto nawet lepsze i bardziej stabilne ni\u017c dotyk czasowe metody.", "tokens": [50964, 257, 34369, 22696, 476, 1878, 1381, 741, 27209, 11652, 716, 28502, 5893, 46127, 13190, 6880, 1131, 843, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06763295592548692, "compression_ratio": 1.3771929824561404, "no_speech_prob": 0.003636566922068596}, {"id": 198, "seek": 79490, "start": 810.9, "end": 812.9, "text": " To prawdziwy prze\u0142om.", "tokens": [51164, 1407, 41175, 3992, 9726, 8325, 1221, 298, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06763295592548692, "compression_ratio": 1.3771929824561404, "no_speech_prob": 0.003636566922068596}, {"id": 199, "seek": 79490, "start": 812.9, "end": 816.9, "text": " My\u015bl\u0119, \u017ce to zostawia nas z jedn\u0105 fascynuj\u0105c\u0105 my\u015bl\u0105.", "tokens": [51264, 1222, 28749, 11, 3561, 281, 31873, 34953, 5382, 710, 5232, 13113, 30632, 1344, 77, 13263, 32557, 452, 19212, 1611, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06763295592548692, "compression_ratio": 1.3771929824561404, "no_speech_prob": 0.003636566922068596}, {"id": 200, "seek": 81690, "start": 817.9, "end": 824.9, "text": " Skoro proces dostrajania modeli do naszych subtelnych ludzkich preferencji staje si\u0119 tak prosty i bezpo\u015bredni,", "tokens": [50414, 7324, 10780, 17565, 20568, 48690, 5609, 2316, 72, 360, 45002, 7257, 338, 9399, 15946, 30154, 480, 4382, 268, 19649, 342, 11153, 3244, 991, 10293, 88, 741, 10782, 2259, 1788, 986, 3722, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09738756815592448, "compression_ratio": 1.4423791821561338, "no_speech_prob": 0.5716642141342163}, {"id": 201, "seek": 81690, "start": 824.9, "end": 827.9, "text": " to otwiera zupe\u0142nie nowe mo\u017cliwo\u015bci.", "tokens": [50764, 281, 4337, 86, 10609, 49922, 586, 68, 30854, 36476, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09738756815592448, "compression_ratio": 1.4423791821561338, "no_speech_prob": 0.5716642141342163}, {"id": 202, "seek": 81690, "start": 827.9, "end": 835.9, "text": " By\u0107 mo\u017ce zbli\u017camy si\u0119 do RLHF, kt\u00f3rej ka\u017cdy b\u0119dzie mog\u0142 w prosty spos\u00f3b dostroi\u0107 swojego osobistego asystenta AI", "tokens": [50914, 3146, 2162, 12034, 710, 32117, 1427, 7804, 3244, 360, 497, 43, 39, 37, 11, 36023, 31615, 10562, 13172, 1221, 261, 10293, 88, 22904, 20568, 340, 12757, 13291, 39738, 41518, 468, 6308, 382, 38593, 8938, 7318, 51314], "temperature": 0.0, "avg_logprob": -0.09738756815592448, "compression_ratio": 1.4423791821561338, "no_speech_prob": 0.5716642141342163}, {"id": 203, "seek": 81690, "start": 835.9, "end": 838.9, "text": " do swojego stylu komunikacji czy warto\u015bci.", "tokens": [51314, 360, 13291, 39738, 7952, 2781, 45359, 1035, 13152, 6430, 31830, 6199, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09738756815592448, "compression_ratio": 1.4423791821561338, "no_speech_prob": 0.5716642141342163}, {"id": 204, "seek": 81690, "start": 838.9, "end": 842.9, "text": " Co by to znaczy\u0142o, gdyby AI mog\u0142o uczy\u0107 si\u0119 naszych preferencji?", "tokens": [51464, 3066, 538, 281, 36584, 5249, 11, 28405, 2322, 7318, 13172, 5249, 344, 33967, 3244, 45002, 4382, 268, 19649, 30, 51664], "temperature": 0.0, "avg_logprob": -0.09738756815592448, "compression_ratio": 1.4423791821561338, "no_speech_prob": 0.5716642141342163}, {"id": 205, "seek": 84290, "start": 842.9, "end": 845.9, "text": " Nie przez skomplikowany trening w laboratorium,", "tokens": [50364, 12016, 14064, 1110, 298, 564, 1035, 23341, 2192, 773, 261, 5938, 41679, 11, 50514], "temperature": 0.0, "avg_logprob": -0.04830629378557205, "compression_ratio": 1.2215189873417722, "no_speech_prob": 0.28672075271606445}, {"id": 206, "seek": 84290, "start": 845.9, "end": 850.9, "text": " ale przez prost\u0105, bezpo\u015bredni\u0105 optymalizacj\u0119 na podstawie kilku naszych wybor\u00f3w.", "tokens": [50514, 6775, 14064, 10293, 1611, 11, 10782, 2259, 1788, 986, 3722, 1611, 2427, 4199, 304, 590, 29924, 1667, 43443, 414, 5128, 5279, 45002, 4628, 3918, 3901, 13, 50764], "temperature": 0.0, "avg_logprob": -0.04830629378557205, "compression_ratio": 1.2215189873417722, "no_speech_prob": 0.28672075271606445}, {"id": 207, "seek": 84290, "start": 850.9, "end": 854.9, "text": " I to jest pytanie, kt\u00f3re pozostawiam do dalszej refleksji.", "tokens": [50764, 286, 281, 3492, 36610, 11, 8864, 21281, 555, 1607, 2918, 360, 274, 1124, 16920, 36549, 1694, 4013, 13, 50964], "temperature": 0.0, "avg_logprob": -0.04830629378557205, "compression_ratio": 1.2215189873417722, "no_speech_prob": 0.28672075271606445}], "language": "pl"}