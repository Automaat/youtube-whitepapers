{"text": " W porz\u0105dku. Roz\u0142o\u017cmy to naczynniki pierwsze. Wyobra\u017amy sobie tak\u0105 sytuacj\u0119. Mamy powiedzmy ograniczony bud\u017cet na zbudowanie samochodu wy\u015bcigowego. Intuicja podpowiada\u0142aby, \u017ceby skonstruowa\u0107 mniejszy dopracowany silnik i perfekcyjnie go dostroi\u0107. Wycisn\u0105\u0107 z niego ostatnie soki, prawda? No tak, to brzmi logicznie. A co je\u015bli badania pokaza\u0142yby, \u017ce znacznie, ale to znacznie lepszym pomys\u0142em jest zbudowanie ogromnego, pot\u0119\u017cnego silnika, ale uruchomienie go tylko na u\u0142amek jego mo\u017cliwo\u015bci? To jest w\u0142a\u015bnie to. Okazuje si\u0119, \u017ce dok\u0142adnie to odkryli badacze z OpenAI w pracy, kt\u00f3ra no c\u00f3\u017c, strz\u0105sn\u0119\u0142a posadami ca\u0142ego \u015bwiata AI. To by\u0142o jak podanie im jakiego\u015b kamienia z rozetty? Dok\u0142adnie. Nagle po latach b\u0142\u0105dzenia troch\u0119 po omacku, kierowania si\u0119 g\u0142\u00f3wnie intuicj\u0105, kto\u015b da\u0142 in\u017cynierom zestaw, no nie wiem, praw fizyki, kt\u00f3re rz\u0105dz\u0105 ich wszech\u015bwiatem. W\u0142a\u015bnie o to chodzi. Dzi\u015b analizujemy prac\u0119 naukow\u0105 zatytu\u0142owan\u0105 Scaling Laws for Neural Language Models autorstwa Jared Akaplana i jego zespo\u0142u. I to nie b\u0119dzie \u017cadna przesada, je\u015bli powiem, \u017ce to w\u0142a\u015bnie ten dokument da\u0142 zielone \u015bwiat\u0142o, dlatego ca\u0142ego wy\u015bcigu na gigantyczne modele. Tak, tego, kt\u00f3rego \u015bwiadkami jeste\u015bmy dzisiaj. Naszym celem jest wi\u0119c zrozumienie tych praw skali. Dowiemy si\u0119, dlaczego prosta, brutalna si\u0142a okaza\u0142a si\u0119 wa\u017cniejsza ni\u017c jaka\u015b finezyjna in\u017cynieria i jak strategicznie alokowa\u0107 zasoby, \u017ceby budowa\u0107 coraz pot\u0119\u017cniejsze systemy AI. Innymi s\u0142owy spr\u00f3bujemy zrozumie\u0107, dlaczego strategia bigger is better to nie jest tylko marketingowy slogan, ale twarda matematyczna zasada. No w\u0142a\u015bnie, to zacznijmy od tego pierwszego fundamentalnego uderzenia w dotychczasowe przekonania. Ok. Przez lata ca\u0142e laboratoria, wiesz, chwali\u0142y si\u0119 swoimi unikalnymi, innowacyjnymi architekturami. A ten artyku\u0142 zdaje si\u0119 m\u00f3wi\u0107, \u017ce to wszystko detale. Tak, detale, kt\u00f3re nie maj\u0105 wi\u0119kszego znaczenia. A liczy si\u0119 tylko jedno, skala. To by\u0142o absolutnie rewolucyjne. Ja pami\u0119tam, jak na pocz\u0105tku kariery sp\u0119dza\u0142y\u015bmy ca\u0142e noce, pr\u00f3buj\u0105c wycisn\u0105\u0107 ostatni u\u0142amek procenta z modelu. Modyfikuj\u0105c architektury. Tak, dodaj\u0105c warstwy tu, poszerzaj\u0105c je tam. A ta praca pokaza\u0142a, \u017ce w du\u017cej mierze gonili\u015bmy za duchami. Klucze nie jest sprytna konstrukcja. A czysta, surowa liczba parametr\u00f3w. W\u0142a\u015bnie. Czekaj, czekaj, bo to brzmi no zbyt prosto. Chcesz powiedzie\u0107, \u017ce ca\u0142a ta sztuka projektowania architektur, te wszystkie debaty, czy model powinien by\u0107 g\u0142\u0119bszy, czy szerszy. To wszystko w zasadzie nie ma wi\u0119kszego znaczenia. To si\u0119 wydaje a\u017c niewiarygodne. Wiem, wiem, \u017ce tak to brzmi, ale dane s\u0105 po prostu nieub\u0142agane. Oczywi\u015bcie m\u00f3wimy tu o szerokim, ale jednak ograniczonym zakresie. Jasne. Nie mo\u017cna zbudowa\u0107 modelu o jednej warstwie i oczekiwa\u0107 cud\u00f3w. Ale w granicach rozs\u0105dku tak. Kszta\u0142t okaza\u0142 si\u0119 drugorz\u0119dny. Czyli jak por\u00f3wnali te modele? Kiedy badacze por\u00f3wnali modele o tej samej liczbie parametr\u00f3w, ale zupe\u0142nie innej budowie. Jeden by\u0142, powiedzmy, wysoki i w\u0105ski, jak wie\u017cowiec, a drugi niski i szeroki, jak supermarket. Mhm. To ich wydajno\u015b\u0107 by\u0142a prawie taka sama. Niemal identyczna. R\u00f3\u017cnice by\u0142y na poziomie b\u0142\u0119du statystycznego. Ale jest tam ten wa\u017cny szczeg\u00f3\u0142. W pracy jest mowa, \u017ce licz\u0105 si\u0119 parametry non-embedding. To jest chyba kluczowe rozr\u00f3\u017cnienie. Jakby\u015bmy to mogli wyt\u0142umaczy\u0107. Wyobra\u017amy sobie, \u017ce model j\u0119zykowy sk\u0142ada si\u0119 z dw\u00f3ch cz\u0119\u015bci. Ok. Pierwsza to taki gigantyczny s\u0142ownik polskomaszynowy. To s\u0105 w\u0142a\u015bnie parametry embedding. T\u0142umacz\u0105 s\u0142owa na j\u0119zyk komputera. Dok\u0142adnie. T\u0142umacz\u0105 s\u0142owa jak kot czy biegnie na wektore liczb. Druga cz\u0119\u015b\u0107 to w\u0142a\u015bciwy m\u00f3zg, kt\u00f3ry z tych przet\u0142umaczonych poj\u0119\u0107 buduje logiczne zdania. I rozumie kontekst. To s\u0105 parametry non-embedding. I to w\u0142a\u015bnie wielko\u015b\u0107 tego m\u00f3zgu ma znaczenie? Tak. Ta praca pokaza\u0142a, \u017ce to wielko\u015b\u0107 tego m\u00f3zgu ma decyduj\u0105ce znaczenie, a nie wielko\u015b\u0107 s\u0142ownika. To troch\u0119 tak, jakby\u015bmy ocenia\u0107 pisarza po tym, jak g\u0142\u0119boko rozumie relacje mi\u0119dzy postaciami, a nie po tym, jak gruby jest jego s\u0142ownik wyraz\u00f3w obcych. Idealna analogia. A oni zrobili sprytny eksperyment, \u017ceby to udowodni\u0107, prawda? Tak. To by\u0142o genialne w swojej prostocie. Na pocz\u0105tku, kiedy patrzyli na wyniki, wliczaj\u0105c wszystkie parametry, wydawa\u0142o si\u0119, \u017ce g\u0142\u0119bsze modele s\u0105 lepsze. By\u0142 chaos. Ale to by\u0142a iluzja. Ca\u0142kowita. Kiedy odfiltrowali te parametry s\u0142ownikowe, sta\u0142o si\u0119 co\u015b niezwyk\u0142ego. Co takiego? Burza\u0142y obraz. Nagle zobaczyli czysty, prosty trend. Skala jest kr\u00f3lem, a kszta\u0142t to co najwy\u017cej dworzanin. Skoro ju\u017c wiemy, \u017ce liczy si\u0119 g\u0142\u00f3wnie rozmiar, to nasuwa si\u0119 pytanie. Czy ten post\u0119p jest chaotyczny? Czy po prostu budujemy wi\u0119kszy model i, no wiesz, mamy nadziej\u0119, \u017ce zadzia\u0142a? Dobre pytanie. A mo\u017ce jest w tym jaka\u015b metoda? I tu dochodzimy do drugiego kluczowego punktu. Ten post\u0119p jest szokuj\u0105co przewidywalny. To jest w\u0142a\u015bnie sedno praw skalu. W artykule pojawia si\u0119 poj\u0119cie power law, czyli prawo pot\u0119gowe. Znamy je z natury, prawda? Tak, ono opisuje np. zale\u017cno\u015b\u0107 mi\u0119dzy si\u0142\u0105 trz\u0119sienia ziemi, a cz\u0119stotliwo\u015bci\u0105 jego wyst\u0119powania. Ma\u0142e wstrz\u0105sy s\u0105 cz\u0119ste, katastrofalne trz\u0119sienia zdarzaj\u0105 si\u0119 rzadko, a wszystko to uk\u0142ada si\u0119 w g\u0142adk\u0105 matematyczn\u0105 krzyw\u0105. I okazuje si\u0119, \u017ce wydajno\u015b\u0107 modeli AI zachowuje si\u0119? W identyczny przewidywalny spos\u00f3b. A jak w og\u00f3le mierzymy t\u0119 wydajno\u015b\u0107? W pracy ci\u0105gle pojawia si\u0119 ten termin. Cross entropy loss. Najpro\u015bciej m\u00f3wi\u0105c, cross entropy loss to mia\u0142a tego, jak bardzo model jest zaskoczony kolejnym s\u0142owem w zdaniu. Czyli jak wynik w golfie i mniejszy tym lepiej. Dok\u0142adnie. Idealny model, kt\u00f3ry przewiduje wszystko z absolutn\u0105 pewno\u015bci\u0105, mia\u0142by loss r\u00f3wny zero. Nasze modele pr\u00f3buj\u0105 do tego zera d\u0105\u017cy\u0107. A prawa skali pokazuj\u0105, \u017ce ten wynik maleje w przewidywalny, pot\u0119gowy spos\u00f3b, gdy zwi\u0119kszamy jeden z trzech zasob\u00f3w. Czyli liczb\u0119 parametr\u00f3w modelu N. Ilo\u015b\u0107 danych treningowych D albo moc obliczeniow\u0105 C. A propos mocy pojawia si\u0119 tam jednostka PF-Days. Co to w\u0142a\u015bciwie jest? To jest taka jednostka czasu my\u015blenia dla superkomputera. Jeden petaflop to tysi\u0105c bilion\u00f3w operacji na sekund\u0119. To jest niewyobra\u017calna liczba. Czyli PF-Day oznacza, \u017ce taki potw\u00f3r obliczeniowy pracuje dla nas przez ta\u0142\u0105 dob\u0119. I to jest gigantyczny ko\u015b\u0107. A praca Kaplana pokaza\u0142a, \u017ce te g\u0142adkie krzywe przewidywalno\u015bci rozci\u0105gaj\u0105 si\u0119 na przestrzeni siedmiu rz\u0119du wielko\u015bci. To tak jakby ta sama zasada fizyki dzia\u0142a\u0142a dla, nie wiem, mr\u00f3wki i dla wieloryba. To nie mo\u017ce by\u0107 przypadek. Dok\u0142adnie. I to jest ten moment, w kt\u00f3rym budowanie AI przesz\u0142o z etapu powiedzmy alchemi do etapu chemii. Czyli koniec zmieszaniem sk\u0142adnik\u00f3w w laboratorium i liczeniem na szcz\u0119\u015bcie. Tak. Badacze dostali zestaw r\u00f3wna\u0144, kt\u00f3re m\u00f3wi\u0105. Je\u015bli zainwestujesz x milion\u00f3w dolar\u00f3w w moc obliczeniow\u0105, a y w powi\u0119kszenie modelu uzyskasz przybli\u017ceniu zet procent poprawy wydajno\u015bci. To pozwoli\u0142a na strategiczne planowanie i uzasadnienie tych gigantycznych bud\u017cet\u00f3w. Z du\u017c\u0105 doz\u0105pewno\u015bci. Nagle inwestorzy zobaczyli map\u0119 drogow\u0105 do coraz pot\u0119\u017cniejszej AI. Dobrze, wi\u0119c mamy map\u0119. Inwestuj w skale, a dostaniesz lepsze wyniki. Proste. Ale tutaj autorzy zadali jeszcze jedno, kluczowe pytanie, kt\u00f3re wywr\u00f3ci\u0142o wszystko do g\u00f3ry nogami. Mianowicie. Jak najlepiej wydawa\u0107 te pieni\u0105dze. I odpowied\u017a, kt\u00f3r\u0105 znale\u017ali przeczy wszystkie mu, czego uczono in\u017cynier\u00f3w AI przez lata. A tak. To jest chyba najbardziej szokuj\u0105cy i kontr intuicyjny wniosek z ca\u0142ej tej pracy. No bo standardowe podej\u015bcie by\u0142o jakie. By\u0142o takie. Trenujemy model tak d\u0142ugo, a\u017c jego krzywa uczenia si\u0119 wyp\u0142aszcze. Dajemy mu dane i patrzymy, jaki jego wynik w tym naszym golfie, czyli los, spada. I gdy przestaje spada\u0107? To znaczy, \u017ce model nauczy\u0142 si\u0119 wszystkiego, czego m\u00f3g\u0142 z tych danych. To si\u0119 nazywa osi\u0105gni\u0119cie konvergencji. I wydaje si\u0119 to absolutnie logiczne. A ta praca m\u00f3wi, \u017ce to? Marnotrawstwo zasob\u00f3w. Dok\u0142adnie tak. Autorzy wprowadzili poj\u0119cie compute efficient training. Czyli training optymalny pod wzgl\u0119dem obliczeniowym. Tak. Postawili pytanie. Maj\u0105c sta\u0142y bud\u017cet, powiedzmy milion dolar\u00f3w na serwery, jak go najlepiej wyda\u0107? Czy trenowa\u0107 ma\u0142y model do perfekcji, a\u017c wyci\u015bniemy z niego ostatnie soki? No i odpowied\u017a brzmi nie. Zdecydowanie nie. Okazuje si\u0119, \u017ce optymaln\u0105 strategi\u0105 jest zbudowanie najwi\u0119kszego mo\u017cliwego modelu, na jaki nas sta\u0107 i zatrzymanie treningu. Nad\u0142ugo przed tym, jak si\u0119 w pe\u0142ni naucz\u0119. To brzmi jak herezja. Dlaczego niedotrenowany, gigantyczny model ma by\u0107 lepszy ni\u017c w pe\u0142ni wytrenowany, ale mniejszy? Przecie\u017c on nie zd\u0105\u017cy\u0142 si\u0119 nauczy\u0107 wszystkiego. Kluczem jest poj\u0119cie sample efficiency. Efektywno\u015b\u0107 na pr\u00f3bce. Tak. Du\u017ce modele s\u0105 jak genialnie studenci. Ucz\u0105 si\u0119 znacznie szybciej z ka\u017cdego przyk\u0142adu. Ma\u0142y model jest jak przeci\u0119tny ucza\u0144. Potrzebuje wielu powt\u00f3rzek, \u017ceby zrozumie\u0107 ten sam materia\u0142. Aha. To, \u017ce w tej samej jednostce czasu i przy tym samym koszcie obliczeniowym, du\u017cy model robi znacznie wi\u0119ksze post\u0119py. Jego krzywa uczenia opada o wiele stromiej. Rozumiem. Czyli maj\u0105c ograniczony bud\u017cet. Lepiej jest wyda\u0107 go na szybk\u0105 i efektywn\u0105 nauk\u0119 tego giganta? Mhm. ni\u017c na powolne i \u017cmudne docieranie do granicy mo\u017cliwo\u015bci malucha. Czyli wracamy do naszej analogii z samochodem wy\u015bcigowym? Dok\u0142adnie. To jest w\u0142a\u015bnie ten moment. Zamiast dopieszcza\u0107 ma\u0142y silnik przez rok, \u017ceby wycisn\u0105\u0107 z niego, powiedzmy, 300 koni mechanicznych. Lepiej zbudowa\u0107 ogromny silnik V12, uruchomi\u0107 go na jeden dzie\u0144. I z \u0142atwo\u015bci\u0105 osi\u0105gn\u0105\u0107 500 koni. Nawet je\u015bli teoretycznie m\u00f3g\u0142by osi\u0105gn\u0105\u0107 1000. Bo ten du\u017cy silnik dochodzi do tych 500 koni po prostu znacznie szybciej i taniej. To jest idealne por\u00f3wnanie. A kiedy badacze prze\u0142o\u017cyli to na liczby i zasymulowali jak najlepiej wyda\u0107 za\u0142\u00f3\u017cmy miliard razy wi\u0119kszy bud\u017cet na kompiut, wniki by\u0142y szokuj\u0105ce. I co wysz\u0142o? Lwia cz\u0119\u015b\u0107 tych dodatkowych zasob\u00f3w powinna buj\u015b\u0107 na zwi\u0119kszenie rozmiaru modelu. Mniejsza cz\u0119\u015b\u0107 na zwi\u0119kszenie batch size, czyli liczby przyk\u0142ad\u00f3w przetwarzanych naraz, a tylko absolutnie znikomy u\u0142amek na wyd\u0142u\u017cenie czasu treningu. To ca\u0142kowicie odwr\u00f3ci\u0142o tradycyjn\u0105 intuicj\u0119. O 180 stopni. To jest prawdziwy moment aha. Dla zespo\u0142u badawczego z uniwersytetu czy startupu oznacza to, \u017ce nie powinien on m\u0119czy\u0107 jednego ma\u0142ego modelu przez wiele tygodni. Nie, powinien zbudowa\u0107 najwi\u0119kszy model na jakiego sta\u0107 i trenowa\u0107 go kr\u00f3cej. Nawet je\u015bli na wykresie wida\u0107, \u017ce model wci\u0105\u017c si\u0119 uczy. Tak. W momencie, gdy sko\u0144czy si\u0119 bud\u017cet ten niedotrenowany gigant b\u0119dzie mia\u0142 ni\u017c szilos. Czyli b\u0119dzie po prostu lepszy ni\u017c w pe\u0142ni zoptymalizowany maluch. I ta zasada sta\u0142a si\u0119 fundamentem strategii firm takich jak OpenAI, Anthropec czy Google. Oni wiedz\u0105, \u017ce aby osi\u0105gn\u0105\u0107 kolejny prze\u0142om nie wystarczy trenowa\u0107 d\u0142u\u017cej. Trzeba budowa\u0107 wi\u0119ksze modele. Ta praca da\u0142a im na to matematyczne dowody. W porz\u0105dku. To wszystko jest fascynuj\u0105ce z punktu widzenia laboratorium. Ale powiedzmy sobie szczerze. Dlaczego kogo\u015b, kto nie jest in\u017cynierem AI, mia\u0142oby to obchodzi\u0107? Dobre pytanie. Jak te abstrakcyjne prawa kszta\u0142tuj\u0105 \u015bwiat, w kt\u00f3rym \u017cyjemy? Kszta\u0142tuj\u0105 go w spos\u00f3b absolutnie fundamentalny. Po pierwsze ta praca uzasadnia gigantyczne wielomiliardowe inwestycje w centra danych i CIPAi. To ju\u017c nie jest \u015blepy wy\u015bcig zbroje\u0144? Nie. To nie jest przeczucie kilku wizjoner\u00f3w. To strategia oparta na twardych danych, kt\u00f3ra m\u00f3wi, \u017ce ka\u017cdy zainwestowany dolar w skal\u0119 przyniesie przewidywalny zwrot w postaci lepszej technologii. I dlatego widzimy tak\u0105 eksplozj\u0119 inwestycji w tej dziedzinie. A co z danymi? Zawsze s\u0142yszeli\u015bmy, \u017ce dane to nowa ropa. Czy ta praca to potwierdza? I tu jest kolejna bardzo ciekawa rzecz. Ta praca sugeruje, \u017ce has\u0142o powinno brzmie\u0107 raczej wielkie modele s\u0105 wa\u017cniejsze ni\u017c wielkie dane. Naprawd\u0119? Oczywi\u015bcie dane s\u0105 absolutnie niezb\u0119dne, ale zapotrzebowanie na nie ro\u015bnie wolniej ni\u017c optymalny rozmiar modelu. Czyli jak to wygl\u0105da w liczbach? Zgodnie z wyliczeniami, gdy o\u015bmiokrotnie zwi\u0119kszamy rozmiar modelu, \u017ceby zrobi\u0107 to optymalnie, b\u0119dziemy tylko pi\u0119ciokrotnie wi\u0119cej danych, a nie o\u015bmiokrotnie. Czyli zapotrzebowanie na moc, obliczeniow\u0105 i rozmiar modelu ro\u015bnie szybciej ni\u017c zapotrzebowanie na dane? Tak. I to jest w pewnym sensie dobra wiadomo\u015b\u0107, bo zaczynamy zderza\u0107 si\u0119 ze \u015bcian\u0105, je\u015bli chodzi o ilo\u015b\u0107 wysokiej jako\u015bci danych tekstowych w internecie. Zasoby s\u0105 sko\u0144czone. W\u0142a\u015bnie. Ta praca pokaza\u0142a, \u017ce to rozmiar modelu jest g\u0142\u00f3wnym motorem post\u0119pu. To przesun\u0119\u0142o punkt ci\u0119\u017cko\u015bci bada\u0144 w ca\u0142ej dziedzinie. Skupiono si\u0119 na metodach trenowania ogromnych sieci, jak model paralelizm i na projektowaniu specjalistycznego sprz\u0119tu. Ale to nie mo\u017ce trwa\u0107 wiecznie, prawda? Musi by\u0107 jaka\u015b \u015bciana, model nie mo\u017ce osi\u0105gn\u0105\u0107 zerowego los. Oczywi\u015bcie, \u017ce nie. Bo to by oznacza\u0142o, \u017ce jest w stanie przewidzie\u0107 wszystko. A j\u0119zyk naturalny ma w sobie co\u015b, co nazywamy niezerow\u0105 entropi\u0105. To zawsze b\u0119dzie w nim pewna doza nieprzewidywalno\u015bci, dwuznaczno\u015bci, kreatywno\u015bci. Nie da si\u0119 go w 100% skompresowa\u0107 do matematycznych wzorc\u00f3w. I sama praca to przewiduje. Tak. Sama praca przewiduje teoretyczny punkt za\u0142amania tych praw. Autorzy szacuj\u0105, \u017ce mo\u017ce on nast\u0105pi\u0107 przy modelach o rozmiarze bilion\u00f3w parametr\u00f3w. To wci\u0105\u017c wi\u0119cej ni\u017c mamy dzisiaj. Mhm. Ale jest to ju\u017c jaka\u015b widoczna na horyzoncie granica. A samo badanie ma charakter empiryczny. Pokazuje, co dzia\u0142a, ale nie do ko\u0144ca dlaczego. Tak. I autorzy s\u0105 tego w pe\u0142ni \u015bwiadomi. Sami przyrownoj\u0105 swoje odkrycia do termodynamiki. Opisuj\u0105 makroskopowe w\u0142a\u015bciwo\u015bci systemu, jak ci\u015bnienie i temperatura, bez wchodzenia w szczeg\u00f3\u0142y ruchu pojedynczych cz\u0105steczek. Co by\u0142oby zadaniem mechaniki statystycznej? W\u0142a\u015bnie. Wcz\u0105\u017c czekamy na g\u0142\u0119bsz\u0105 teori\u0119, kt\u00f3ra wyja\u015bni\u0142aby, dlaczego akurat te wyk\u0142adniki pot\u0119gowe, a nie inne, rz\u0105dz\u0105 procesem uczenia si\u0119 sieci neuronowych. Znamy prawa, ale nie znamy jeszcze w pe\u0142ni ich fundamentalnego pochodzenia. Dobrze. To podsumujmy. Czego si\u0119 dowiedzieli\u015bmy? Po pierwsze, skala jest wa\u017cniejsza ni\u017c kszta\u0142t. Liczba parametr\u00f3w m\u00f3zg modelu jest kluczowa, a nie finezyjna architektura. Mhm. Po drugie, wydajno\u015b\u0107 ro\u015bnie w przewidywalny matematyczny spos\u00f3b, zgodnie z prawami mocy. To zamieni\u0142o rozw\u00f3j AI ze zgadywanki w in\u017cynieri\u0119. Zdecydowanie. I po trzecie, co chyba najbardziej kontrointuicyjne. Maj\u0105c ograniczony but\u017cet, najefektywniejsze jest trenowa\u0107 ogromne modele, ale nie do samego ko\u0144ca. To jest doskona\u0142e podsumowanie. Te trzy zasady, cho\u0107 proste w swoim brzmieniu, zdefiniowa\u0142y ca\u0142\u0105 dekad\u0119 bada\u0144 nad du\u017cymi modelami j\u0119zykowymi i zaprowadzi\u0142y nas do miejsca, w kt\u00f3rym jeste\u015bmy dzisiaj. Na koniec zostawmy naszych s\u0142uchaczy z czym\u015b do przemy\u015blenia. Zastan\u00f3wmy si\u0119 nad tym przewidywanym punktem za\u0142amania praw skali. T\u0105 \u015bcian\u0105, do kt\u00f3rej zmierzamy. Tak. Czy ten punkt mo\u017ce oznaczy\u0107 co\u015b wi\u0119cej ni\u017c tylko techniczn\u0105 granic\u0119? By\u0107 mo\u017ce jest to fundamentalna granica tego, co mo\u017cna wydoby\u0107 z danych j\u0119zykowych, w spos\u00f3b czysto statystyczny i przewidywalny. Czyli pr\u00f3g, za kt\u00f3rym jest ju\u017c co\u015b innego. By\u0107 mo\u017ce. Pr\u00f3g, za kt\u00f3rym znajduje si\u0119 ju\u017c tylko ta nieredukowalna entropia, prawdziwa z\u0142o\u017cono\u015b\u0107, kreatywno\u015b\u0107 i nieprzewidywalno\u015b\u0107 ludzkiego j\u0119zyka, kt\u00f3rej nie da si\u0119 ju\u017c skompresowa\u0107 do prostszych wzorc\u00f3w. I co wtedy? No w\u0142a\u015bnie. Co si\u0119 stanie, gdy nasze modele dotr\u0105 do tej granicy? Jakiego rodzaju inteligencj\u0119 wtedy osi\u0105gn\u0105? Goro ca\u0142a ta \u0142atwa, statystyczna wiedza o \u015bwiecie zostanie ju\u017c przez nieprzyswojona. Czy to jest ten moment, w kt\u00f3rym skalowanie przestaje wystarcza\u0107 i do prawdziwego skoku w kierunku og\u00f3lnej inteligencji b\u0119dzie potrzebny zupe\u0142nie nowy paradygmat?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " W porz\u0105dku. Roz\u0142o\u017cmy to naczynniki pierwsze. Wyobra\u017amy sobie tak\u0105 sytuacj\u0119. Mamy powiedzmy ograniczony bud\u017cet na zbudowanie samochodu wy\u015bcigowego.", "tokens": [50364, 343, 1515, 23876, 5279, 13, 43313, 5249, 1427, 2226, 281, 297, 14691, 26384, 9850, 45994, 13, 14458, 24393, 10659, 2226, 13652, 31069, 28275, 29924, 13, 376, 7804, 27617, 2226, 34416, 282, 17946, 2526, 3265, 1427, 302, 1667, 710, 18281, 22028, 3247, 8997, 34873, 4628, 1788, 66, 328, 26576, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13197060635215357, "compression_ratio": 1.3401639344262295, "no_speech_prob": 0.07309634983539581}, {"id": 1, "seek": 0, "start": 10.0, "end": 22.0, "text": " Intuicja podpowiada\u0142aby, \u017ceby skonstruowa\u0107 mniejszy dopracowany silnik i perfekcyjnie go dostroi\u0107. Wycisn\u0105\u0107 z niego ostatnie soki, prawda?", "tokens": [50864, 5681, 84, 299, 2938, 2497, 14701, 39018, 1221, 2509, 11, 11316, 1110, 4068, 894, 11445, 39513, 7706, 360, 1424, 326, 23341, 3425, 13123, 741, 13826, 916, 42949, 2766, 352, 20568, 340, 12757, 13, 14458, 26720, 13113, 2162, 710, 49615, 32686, 2766, 370, 2984, 11, 43607, 30, 51464], "temperature": 0.0, "avg_logprob": -0.13197060635215357, "compression_ratio": 1.3401639344262295, "no_speech_prob": 0.07309634983539581}, {"id": 2, "seek": 0, "start": 22.0, "end": 24.0, "text": " No tak, to brzmi logicznie.", "tokens": [51464, 883, 991, 11, 281, 738, 89, 3057, 9952, 89, 2766, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13197060635215357, "compression_ratio": 1.3401639344262295, "no_speech_prob": 0.07309634983539581}, {"id": 3, "seek": 2400, "start": 24.0, "end": 37.0, "text": " A co je\u015bli badania pokaza\u0142yby, \u017ce znacznie, ale to znacznie lepszym pomys\u0142em jest zbudowanie ogromnego, pot\u0119\u017cnego silnika, ale uruchomienie go tylko na u\u0142amek jego mo\u017cliwo\u015bci?", "tokens": [50364, 316, 598, 25630, 1578, 5609, 13010, 12257, 6825, 2322, 11, 3561, 15397, 14875, 2766, 11, 6775, 281, 15397, 14875, 2766, 476, 1878, 26681, 12991, 749, 11126, 3492, 710, 18281, 22028, 34416, 298, 11858, 11, 1847, 1274, 1427, 11858, 3425, 77, 5439, 11, 6775, 4038, 625, 298, 27385, 352, 13219, 1667, 344, 1221, 529, 74, 26542, 30854, 36476, 30, 51014], "temperature": 0.0, "avg_logprob": -0.07339738664172944, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.3299035429954529}, {"id": 4, "seek": 2400, "start": 37.0, "end": 46.0, "text": " To jest w\u0142a\u015bnie to. Okazuje si\u0119, \u017ce dok\u0142adnie to odkryli badacze z OpenAI w pracy, kt\u00f3ra no c\u00f3\u017c, strz\u0105sn\u0119\u0142a posadami ca\u0142ego \u015bwiata AI.", "tokens": [51014, 1407, 3492, 14234, 281, 13, 3477, 43317, 3244, 11, 3561, 45864, 2766, 281, 3611, 43298, 2081, 1578, 326, 1381, 710, 7238, 48698, 261, 35591, 11, 19456, 572, 6333, 1427, 11, 1056, 8925, 18860, 1274, 5024, 1366, 345, 4526, 35224, 6308, 21485, 3274, 7318, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07339738664172944, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.3299035429954529}, {"id": 5, "seek": 2400, "start": 46.0, "end": 49.0, "text": " To by\u0142o jak podanie im jakiego\u015b kamienia z rozetty?", "tokens": [51464, 1407, 14811, 4207, 2497, 7155, 566, 4207, 12200, 1788, 9727, 18811, 710, 9544, 302, 874, 30, 51614], "temperature": 0.0, "avg_logprob": -0.07339738664172944, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.3299035429954529}, {"id": 6, "seek": 4900, "start": 49.0, "end": 60.0, "text": " Dok\u0142adnie. Nagle po latach b\u0142\u0105dzenia troch\u0119 po omacku, kierowania si\u0119 g\u0142\u00f3wnie intuicj\u0105, kto\u015b da\u0142 in\u017cynierom zestaw, no nie wiem, praw fizyki, kt\u00f3re rz\u0105dz\u0105 ich wszech\u015bwiatem.", "tokens": [50364, 29768, 10358, 2766, 13, 426, 15088, 714, 4465, 608, 272, 15926, 67, 14320, 24926, 714, 3406, 501, 84, 11, 38767, 21308, 3244, 18117, 812, 14215, 560, 84, 299, 8555, 11, 32982, 1120, 1221, 294, 1427, 2534, 811, 298, 37889, 1607, 11, 572, 2838, 26522, 11, 22508, 21000, 88, 2984, 11, 8864, 367, 23876, 8925, 1893, 37647, 19439, 1788, 6253, 26851, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08840321302413941, "compression_ratio": 1.45, "no_speech_prob": 0.5258719325065613}, {"id": 7, "seek": 4900, "start": 60.0, "end": 71.0, "text": " W\u0142a\u015bnie o to chodzi. Dzi\u015b analizujemy prac\u0119 naukow\u0105 zatytu\u0142owan\u0105 Scaling Laws for Neural Language Models autorstwa Jared Akaplana i jego zespo\u0142u.", "tokens": [50914, 343, 5024, 12221, 277, 281, 23998, 13, 413, 3992, 1788, 2624, 590, 21767, 22404, 1274, 35616, 74, 30297, 35802, 4328, 84, 1221, 37345, 1611, 2747, 4270, 7744, 82, 337, 1734, 1807, 24445, 6583, 1625, 19510, 372, 4151, 24160, 316, 2330, 564, 2095, 741, 26542, 710, 279, 2259, 24066, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08840321302413941, "compression_ratio": 1.45, "no_speech_prob": 0.5258719325065613}, {"id": 8, "seek": 4900, "start": 71.0, "end": 78.0, "text": " I to nie b\u0119dzie \u017cadna przesada, je\u015bli powiem, \u017ce to w\u0142a\u015bnie ten dokument da\u0142 zielone \u015bwiat\u0142o, dlatego ca\u0142ego wy\u015bcigu na gigantyczne modele.", "tokens": [51464, 286, 281, 2838, 10562, 39628, 629, 6541, 279, 1538, 11, 25630, 3388, 4907, 11, 3561, 281, 14234, 2064, 40858, 1120, 1221, 710, 1187, 546, 36425, 5249, 11, 32205, 35224, 6308, 4628, 1788, 66, 16397, 1667, 8741, 394, 17466, 716, 4391, 306, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08840321302413941, "compression_ratio": 1.45, "no_speech_prob": 0.5258719325065613}, {"id": 9, "seek": 7800, "start": 78.0, "end": 84.0, "text": " Tak, tego, kt\u00f3rego \u015bwiadkami jeste\u015bmy dzisiaj. Naszym celem jest wi\u0119c zrozumienie tych praw skali.", "tokens": [50364, 9118, 11, 8627, 11, 46951, 21485, 345, 48737, 35928, 25772, 13, 16151, 26681, 1769, 10386, 3492, 16677, 710, 27857, 449, 27385, 15180, 22508, 1110, 5103, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07702850371368172, "compression_ratio": 1.4682274247491638, "no_speech_prob": 0.07513406127691269}, {"id": 10, "seek": 7800, "start": 84.0, "end": 97.0, "text": " Dowiemy si\u0119, dlaczego prosta, brutalna si\u0142a okaza\u0142a si\u0119 wa\u017cniejsza ni\u017c jaka\u015b finezyjna in\u017cynieria i jak strategicznie alokowa\u0107 zasoby, \u017ceby budowa\u0107 coraz pot\u0119\u017cniejsze systemy AI.", "tokens": [50664, 413, 13998, 2226, 3244, 11, 37873, 39329, 582, 8638, 11, 17878, 629, 1511, 5024, 3133, 12257, 5024, 3244, 27777, 30295, 2394, 28502, 4207, 64, 1788, 2489, 1229, 73, 629, 294, 1427, 2534, 811, 654, 741, 4207, 10924, 89, 2766, 419, 453, 11445, 26530, 13944, 11, 11316, 3265, 11445, 25899, 1847, 1274, 1427, 44258, 1185, 88, 7318, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07702850371368172, "compression_ratio": 1.4682274247491638, "no_speech_prob": 0.07513406127691269}, {"id": 11, "seek": 7800, "start": 97.0, "end": 107.0, "text": " Innymi s\u0142owy spr\u00f3bujemy zrozumie\u0107, dlaczego strategia bigger is better to nie jest tylko marketingowy slogan, ale twarda matematyczna zasada.", "tokens": [51314, 682, 31813, 15116, 10089, 6103, 14216, 21767, 710, 27857, 449, 414, 2162, 11, 37873, 39329, 5464, 654, 3801, 307, 1101, 281, 2838, 3492, 13219, 6370, 10089, 33052, 11, 6775, 683, 19218, 3803, 8615, 17466, 629, 26530, 1538, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07702850371368172, "compression_ratio": 1.4682274247491638, "no_speech_prob": 0.07513406127691269}, {"id": 12, "seek": 10700, "start": 107.0, "end": 113.0, "text": " No w\u0142a\u015bnie, to zacznijmy od tego pierwszego fundamentalnego uderzenia w dotychczasowe przekonania.", "tokens": [50364, 883, 14234, 11, 281, 710, 14875, 77, 1718, 2226, 3611, 8627, 27623, 27725, 8088, 11858, 344, 1068, 14320, 261, 5893, 16384, 30989, 6880, 29785, 266, 5609, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08035485497836409, "compression_ratio": 1.3849206349206349, "no_speech_prob": 0.014289389364421368}, {"id": 13, "seek": 10700, "start": 113.0, "end": 114.0, "text": " Ok.", "tokens": [50664, 3477, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08035485497836409, "compression_ratio": 1.3849206349206349, "no_speech_prob": 0.014289389364421368}, {"id": 14, "seek": 10700, "start": 114.0, "end": 126.0, "text": " Przez lata ca\u0142e laboratoria, wiesz, chwali\u0142y si\u0119 swoimi unikalnymi, innowacyjnymi architekturami. A ten artyku\u0142 zdaje si\u0119 m\u00f3wi\u0107, \u017ce to wszystko detale.", "tokens": [50714, 2114, 1381, 89, 46722, 47631, 5938, 1639, 654, 11, 261, 15347, 11, 26237, 5103, 6825, 3244, 13291, 10121, 517, 41216, 31813, 11, 294, 3785, 31285, 31813, 3912, 642, 2320, 374, 4526, 13, 316, 2064, 594, 874, 5279, 1221, 16221, 11153, 3244, 13489, 12757, 11, 3561, 281, 22607, 1141, 1220, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08035485497836409, "compression_ratio": 1.3849206349206349, "no_speech_prob": 0.014289389364421368}, {"id": 15, "seek": 10700, "start": 126.0, "end": 130.0, "text": " Tak, detale, kt\u00f3re nie maj\u0105 wi\u0119kszego znaczenia.", "tokens": [51314, 9118, 11, 1141, 1220, 11, 8864, 2838, 26064, 29968, 27725, 15397, 326, 14320, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08035485497836409, "compression_ratio": 1.3849206349206349, "no_speech_prob": 0.014289389364421368}, {"id": 16, "seek": 10700, "start": 130.0, "end": 132.0, "text": " A liczy si\u0119 tylko jedno, skala.", "tokens": [51514, 316, 6169, 1229, 3244, 13219, 5232, 1771, 11, 1110, 5159, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08035485497836409, "compression_ratio": 1.3849206349206349, "no_speech_prob": 0.014289389364421368}, {"id": 17, "seek": 13200, "start": 132.0, "end": 134.0, "text": " To by\u0142o absolutnie rewolucyjne.", "tokens": [50364, 1407, 14811, 18757, 2766, 319, 48481, 1311, 88, 73, 716, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 18, "seek": 13200, "start": 134.0, "end": 142.0, "text": " Ja pami\u0119tam, jak na pocz\u0105tku kariery sp\u0119dza\u0142y\u015bmy ca\u0142e noce, pr\u00f3buj\u0105c wycisn\u0105\u0107 ostatni u\u0142amek procenta z modelu.", "tokens": [50464, 3530, 31088, 37323, 11, 4207, 1667, 43959, 7917, 811, 88, 637, 6298, 2394, 6825, 10513, 47631, 572, 384, 11, 8565, 65, 44733, 4628, 26720, 13113, 2162, 32686, 3722, 344, 1221, 529, 74, 38826, 64, 710, 2316, 84, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 19, "seek": 13200, "start": 142.0, "end": 144.0, "text": " Modyfikuj\u0105c architektury.", "tokens": [50864, 376, 843, 31230, 44733, 3912, 642, 2320, 2598, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 20, "seek": 13200, "start": 144.0, "end": 146.0, "text": " Tak, dodaj\u0105c warstwy tu, poszerzaj\u0105c je tam.", "tokens": [50964, 9118, 11, 13886, 38757, 1516, 372, 9726, 2604, 11, 1366, 4527, 89, 38757, 1506, 7677, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 21, "seek": 13200, "start": 146.0, "end": 150.0, "text": " A ta praca pokaza\u0142a, \u017ce w du\u017cej mierze gonili\u015bmy za duchami.", "tokens": [51064, 316, 1846, 582, 6628, 13010, 12257, 5024, 11, 3561, 261, 1581, 38493, 47448, 1381, 26307, 43912, 7949, 274, 625, 4526, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 22, "seek": 13200, "start": 150.0, "end": 153.0, "text": " Klucze nie jest sprytna konstrukcja.", "tokens": [51264, 16053, 1311, 1381, 2838, 3492, 637, 627, 83, 629, 34208, 25126, 34056, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 23, "seek": 13200, "start": 153.0, "end": 155.0, "text": " A czysta, surowa liczba parametr\u00f3w.", "tokens": [51414, 316, 6430, 9140, 11, 1022, 5528, 6169, 89, 4231, 6220, 27965, 3901, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 24, "seek": 13200, "start": 155.0, "end": 156.0, "text": " W\u0142a\u015bnie.", "tokens": [51514, 343, 5024, 12221, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 25, "seek": 13200, "start": 156.0, "end": 159.0, "text": " Czekaj, czekaj, bo to brzmi no zbyt prosto.", "tokens": [51564, 383, 19878, 1805, 11, 6472, 916, 1805, 11, 748, 281, 738, 89, 3057, 572, 710, 2322, 83, 10293, 78, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07428007414846709, "compression_ratio": 1.41, "no_speech_prob": 0.20378389954566956}, {"id": 26, "seek": 15900, "start": 159.0, "end": 166.0, "text": " Chcesz powiedzie\u0107, \u017ce ca\u0142a ta sztuka projektowania architektur, te wszystkie debaty, czy model powinien by\u0107 g\u0142\u0119bszy, czy szerszy.", "tokens": [50364, 761, 887, 89, 27886, 11, 3561, 1335, 5024, 1846, 262, 2682, 13599, 26261, 21308, 3912, 642, 2320, 374, 11, 535, 31723, 3001, 21398, 11, 6430, 2316, 27310, 1053, 15069, 18117, 1274, 929, 1229, 11, 6430, 7870, 433, 1229, 13, 50714], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 27, "seek": 15900, "start": 166.0, "end": 169.0, "text": " To wszystko w zasadzie nie ma wi\u0119kszego znaczenia.", "tokens": [50714, 1407, 22607, 261, 44585, 3283, 2838, 463, 29968, 27725, 15397, 326, 14320, 13, 50864], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 28, "seek": 15900, "start": 169.0, "end": 171.0, "text": " To si\u0119 wydaje a\u017c niewiarygodne.", "tokens": [50864, 1407, 3244, 49165, 48134, 43622, 29104, 21787, 716, 13, 50964], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 29, "seek": 15900, "start": 171.0, "end": 176.0, "text": " Wiem, wiem, \u017ce tak to brzmi, ale dane s\u0105 po prostu nieub\u0142agane.", "tokens": [50964, 343, 4907, 11, 26522, 11, 3561, 991, 281, 738, 89, 3057, 11, 6775, 49206, 9015, 714, 19518, 2838, 836, 1221, 559, 1929, 13, 51214], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 30, "seek": 15900, "start": 176.0, "end": 180.0, "text": " Oczywi\u015bcie m\u00f3wimy tu o szerokim, ale jednak ograniczonym zakresie.", "tokens": [51214, 42980, 13489, 13189, 2604, 277, 36160, 453, 332, 11, 6775, 25897, 34416, 282, 17946, 12732, 23810, 495, 414, 13, 51414], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 31, "seek": 15900, "start": 180.0, "end": 181.0, "text": " Jasne.", "tokens": [51414, 34023, 716, 13, 51464], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 32, "seek": 15900, "start": 181.0, "end": 185.0, "text": " Nie mo\u017cna zbudowa\u0107 modelu o jednej warstwie i oczekiwa\u0107 cud\u00f3w.", "tokens": [51464, 12016, 17790, 710, 18281, 11445, 2316, 84, 277, 5232, 11794, 1516, 372, 8699, 741, 277, 3689, 14753, 25234, 40287, 3901, 13, 51664], "temperature": 0.0, "avg_logprob": -0.049840303567739636, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.00903138518333435}, {"id": 33, "seek": 18500, "start": 185.0, "end": 187.0, "text": " Ale w granicach rozs\u0105dku tak.", "tokens": [50364, 9366, 261, 9370, 299, 608, 9544, 82, 18962, 5279, 991, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 34, "seek": 18500, "start": 187.0, "end": 189.0, "text": " Kszta\u0142t okaza\u0142 si\u0119 drugorz\u0119dny.", "tokens": [50464, 591, 15453, 46426, 83, 3133, 12257, 1221, 3244, 4110, 284, 89, 6298, 1634, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 35, "seek": 18500, "start": 189.0, "end": 191.0, "text": " Czyli jak por\u00f3wnali te modele?", "tokens": [50564, 37099, 4207, 1515, 812, 895, 5103, 535, 4391, 306, 30, 50664], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 36, "seek": 18500, "start": 191.0, "end": 196.0, "text": " Kiedy badacze por\u00f3wnali modele o tej samej liczbie parametr\u00f3w, ale zupe\u0142nie innej budowie.", "tokens": [50664, 591, 16446, 1578, 326, 1381, 1515, 812, 895, 5103, 4391, 306, 277, 12573, 912, 73, 6169, 89, 7392, 6220, 27965, 3901, 11, 6775, 49922, 294, 11794, 3265, 13998, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 37, "seek": 18500, "start": 196.0, "end": 202.0, "text": " Jeden by\u0142, powiedzmy, wysoki i w\u0105ski, jak wie\u017cowiec, a drugi niski i szeroki, jak supermarket.", "tokens": [50914, 508, 6876, 16673, 11, 27617, 2226, 11, 27062, 17056, 741, 261, 1611, 18020, 11, 4207, 3355, 1427, 13998, 66, 11, 257, 4110, 72, 297, 271, 2984, 741, 36160, 17056, 11, 4207, 25180, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 38, "seek": 18500, "start": 202.0, "end": 206.0, "text": " Mhm. To ich wydajno\u015b\u0107 by\u0142a prawie taka sama.", "tokens": [51214, 26272, 13, 1407, 1893, 25984, 1805, 23293, 23936, 3206, 8699, 28017, 17768, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 39, "seek": 18500, "start": 206.0, "end": 210.0, "text": " Niemal identyczna. R\u00f3\u017cnice by\u0142y na poziomie b\u0142\u0119du statystycznego.", "tokens": [51414, 12016, 5579, 2473, 17466, 629, 13, 497, 812, 1427, 77, 573, 26366, 1667, 38503, 40120, 272, 46564, 769, 2219, 38593, 17466, 11858, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08254370593384608, "compression_ratio": 1.4250871080139373, "no_speech_prob": 0.08570688962936401}, {"id": 40, "seek": 21000, "start": 211.0, "end": 213.0, "text": " Ale jest tam ten wa\u017cny szczeg\u00f3\u0142.", "tokens": [50414, 9366, 3492, 7677, 2064, 27777, 1634, 22090, 1146, 16181, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 41, "seek": 21000, "start": 213.0, "end": 216.0, "text": " W pracy jest mowa, \u017ce licz\u0105 si\u0119 parametry non-embedding.", "tokens": [50514, 343, 35591, 3492, 275, 5528, 11, 3561, 6169, 8925, 3244, 6220, 9889, 2107, 12, 443, 2883, 3584, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 42, "seek": 21000, "start": 216.0, "end": 220.0, "text": " To jest chyba kluczowe rozr\u00f3\u017cnienie. Jakby\u015bmy to mogli wyt\u0142umaczy\u0107.", "tokens": [50664, 1407, 3492, 31532, 9671, 1311, 89, 6880, 9544, 11721, 1427, 77, 27385, 13, 15029, 2322, 10513, 281, 13172, 2081, 261, 4328, 49166, 14691, 2162, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 43, "seek": 21000, "start": 220.0, "end": 224.0, "text": " Wyobra\u017amy sobie, \u017ce model j\u0119zykowy sk\u0142ada si\u0119 z dw\u00f3ch cz\u0119\u015bci.", "tokens": [50864, 14458, 24393, 10659, 2226, 13652, 11, 3561, 2316, 49055, 74, 10089, 1110, 46217, 3244, 710, 27379, 812, 339, 41314, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 44, "seek": 21000, "start": 224.0, "end": 225.0, "text": " Ok.", "tokens": [51064, 3477, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 45, "seek": 21000, "start": 225.0, "end": 228.0, "text": " Pierwsza to taki gigantyczny s\u0142ownik polskomaszynowy.", "tokens": [51114, 16676, 14358, 2394, 281, 20065, 8741, 394, 17466, 1634, 15116, 44895, 1180, 82, 20557, 296, 1229, 3785, 88, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 46, "seek": 21000, "start": 228.0, "end": 230.0, "text": " To s\u0105 w\u0142a\u015bnie parametry embedding.", "tokens": [51264, 1407, 9015, 14234, 6220, 9889, 12240, 3584, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 47, "seek": 21000, "start": 230.0, "end": 233.0, "text": " T\u0142umacz\u0105 s\u0142owa na j\u0119zyk komputera.", "tokens": [51364, 314, 49166, 326, 8925, 15116, 5528, 1667, 49055, 74, 5207, 2582, 1663, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 48, "seek": 21000, "start": 233.0, "end": 238.0, "text": " Dok\u0142adnie. T\u0142umacz\u0105 s\u0142owa jak kot czy biegnie na wektore liczb.", "tokens": [51514, 29768, 10358, 2766, 13, 314, 49166, 326, 8925, 15116, 5528, 4207, 43029, 6430, 272, 20408, 2766, 1667, 321, 2320, 418, 6169, 89, 65, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06600950349051997, "compression_ratio": 1.5034013605442176, "no_speech_prob": 0.5237111449241638}, {"id": 49, "seek": 23800, "start": 238.0, "end": 244.0, "text": " Druga cz\u0119\u015b\u0107 to w\u0142a\u015bciwy m\u00f3zg, kt\u00f3ry z tych przet\u0142umaczonych poj\u0119\u0107 buduje logiczne zdania.", "tokens": [50364, 2491, 19364, 47149, 281, 40112, 9726, 32515, 89, 70, 11, 9913, 710, 15180, 6541, 302, 49166, 14875, 2526, 339, 714, 11115, 2162, 3265, 13008, 9952, 43077, 16221, 5609, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 50, "seek": 23800, "start": 244.0, "end": 248.0, "text": " I rozumie kontekst. To s\u0105 parametry non-embedding.", "tokens": [50664, 286, 48797, 414, 14373, 916, 372, 13, 1407, 9015, 6220, 9889, 2107, 12, 443, 2883, 3584, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 51, "seek": 23800, "start": 248.0, "end": 251.0, "text": " I to w\u0142a\u015bnie wielko\u015b\u0107 tego m\u00f3zgu ma znaczenie?", "tokens": [50864, 286, 281, 14234, 20570, 4093, 7753, 8627, 32515, 89, 2794, 463, 15397, 326, 16778, 30, 51014], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 52, "seek": 23800, "start": 251.0, "end": 258.0, "text": " Tak. Ta praca pokaza\u0142a, \u017ce to wielko\u015b\u0107 tego m\u00f3zgu ma decyduj\u0105ce znaczenie, a nie wielko\u015b\u0107 s\u0142ownika.", "tokens": [51014, 9118, 13, 6551, 582, 6628, 13010, 12257, 5024, 11, 3561, 281, 20570, 4093, 7753, 8627, 32515, 89, 2794, 463, 979, 88, 769, 8555, 384, 15397, 326, 16778, 11, 257, 2838, 20570, 4093, 7753, 15116, 648, 5439, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 53, "seek": 23800, "start": 258.0, "end": 264.0, "text": " To troch\u0119 tak, jakby\u015bmy ocenia\u0107 pisarza po tym, jak g\u0142\u0119boko rozumie relacje mi\u0119dzy postaciami,", "tokens": [51364, 1407, 24926, 991, 11, 28976, 10513, 10409, 268, 654, 2162, 26584, 289, 2394, 714, 8107, 11, 4207, 18117, 1274, 65, 13704, 48797, 414, 1039, 29293, 33964, 2183, 326, 15568, 11, 51664], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 54, "seek": 23800, "start": 264.0, "end": 267.0, "text": " a nie po tym, jak gruby jest jego s\u0142ownik wyraz\u00f3w obcych.", "tokens": [51664, 257, 2838, 714, 8107, 11, 4207, 677, 836, 88, 3492, 26542, 15116, 44895, 4628, 30695, 3901, 1111, 31306, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05091596686321756, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.010801935568451881}, {"id": 55, "seek": 26700, "start": 267.0, "end": 269.0, "text": " Idealna analogia.", "tokens": [50364, 13090, 304, 629, 16660, 654, 13, 50464], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 56, "seek": 26700, "start": 269.0, "end": 272.0, "text": " A oni zrobili sprytny eksperyment, \u017ceby to udowodni\u0107, prawda?", "tokens": [50464, 316, 36317, 44399, 2312, 637, 627, 83, 1634, 30724, 610, 88, 518, 11, 11316, 281, 11727, 305, 378, 3722, 2162, 11, 43607, 30, 50614], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 57, "seek": 26700, "start": 272.0, "end": 275.0, "text": " Tak. To by\u0142o genialne w swojej prostocie.", "tokens": [50614, 9118, 13, 1407, 14811, 48228, 716, 261, 29489, 73, 10293, 905, 414, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 58, "seek": 26700, "start": 275.0, "end": 281.0, "text": " Na pocz\u0105tku, kiedy patrzyli na wyniki, wliczaj\u0105c wszystkie parametry, wydawa\u0142o si\u0119, \u017ce g\u0142\u0119bsze modele s\u0105 lepsze.", "tokens": [50764, 6056, 43959, 11, 18777, 1947, 13047, 2081, 1667, 31936, 9850, 11, 261, 1050, 89, 38757, 31723, 6220, 9889, 11, 25984, 10449, 5249, 3244, 11, 3561, 18117, 1274, 929, 1381, 4391, 306, 9015, 476, 1878, 1381, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 59, "seek": 26700, "start": 281.0, "end": 282.0, "text": " By\u0142 chaos.", "tokens": [51064, 3146, 1221, 14158, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 60, "seek": 26700, "start": 282.0, "end": 283.0, "text": " Ale to by\u0142a iluzja.", "tokens": [51114, 9366, 281, 23936, 1930, 3334, 2938, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 61, "seek": 26700, "start": 283.0, "end": 289.0, "text": " Ca\u0142kowita. Kiedy odfiltrowali te parametry s\u0142ownikowe, sta\u0142o si\u0119 co\u015b niezwyk\u0142ego.", "tokens": [51164, 7544, 1221, 74, 305, 2786, 13, 591, 16446, 3611, 69, 2352, 1892, 5103, 535, 6220, 9889, 15116, 44895, 6880, 11, 11135, 5249, 3244, 19241, 33511, 9726, 74, 1221, 6308, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 62, "seek": 26700, "start": 289.0, "end": 290.0, "text": " Co takiego?", "tokens": [51464, 3066, 32296, 30, 51514], "temperature": 0.0, "avg_logprob": -0.05406483582087925, "compression_ratio": 1.4, "no_speech_prob": 0.026263749226927757}, {"id": 63, "seek": 29000, "start": 291.0, "end": 292.0, "text": " Burza\u0142y obraz.", "tokens": [50414, 7031, 2394, 6825, 22798, 89, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 64, "seek": 29000, "start": 292.0, "end": 295.0, "text": " Nagle zobaczyli czysty, prosty trend.", "tokens": [50464, 426, 15088, 37273, 2081, 6430, 25134, 11, 10293, 88, 6028, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 65, "seek": 29000, "start": 295.0, "end": 299.0, "text": " Skala jest kr\u00f3lem, a kszta\u0142t to co najwy\u017cej dworzanin.", "tokens": [50614, 7324, 5159, 3492, 42366, 10386, 11, 257, 350, 15453, 46426, 83, 281, 598, 11212, 9726, 38493, 274, 28321, 21238, 259, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 66, "seek": 29000, "start": 299.0, "end": 304.0, "text": " Skoro ju\u017c wiemy, \u017ce liczy si\u0119 g\u0142\u00f3wnie rozmiar, to nasuwa si\u0119 pytanie.", "tokens": [50814, 7324, 10780, 10678, 3355, 2226, 11, 3561, 6169, 1229, 3244, 18117, 812, 14215, 9544, 3057, 289, 11, 281, 5382, 84, 4151, 3244, 36610, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 67, "seek": 29000, "start": 304.0, "end": 306.0, "text": " Czy ten post\u0119p jest chaotyczny?", "tokens": [51064, 19832, 2064, 2183, 18085, 3492, 6294, 6737, 3689, 1634, 30, 51164], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 68, "seek": 29000, "start": 306.0, "end": 311.0, "text": " Czy po prostu budujemy wi\u0119kszy model i, no wiesz, mamy nadziej\u0119, \u017ce zadzia\u0142a?", "tokens": [51164, 19832, 714, 19518, 3265, 21767, 29968, 1229, 2316, 741, 11, 572, 261, 15347, 11, 17335, 48881, 11, 3561, 42788, 89, 25605, 30, 51414], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 69, "seek": 29000, "start": 311.0, "end": 312.0, "text": " Dobre pytanie.", "tokens": [51414, 29679, 265, 36610, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 70, "seek": 29000, "start": 312.0, "end": 314.0, "text": " A mo\u017ce jest w tym jaka\u015b metoda?", "tokens": [51464, 316, 12034, 3492, 261, 8107, 4207, 64, 1788, 1131, 13449, 30, 51564], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 71, "seek": 29000, "start": 314.0, "end": 317.0, "text": " I tu dochodzimy do drugiego kluczowego punktu.", "tokens": [51564, 286, 2604, 9243, 378, 89, 13189, 360, 4110, 12200, 9671, 1311, 89, 26576, 39561, 84, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07379972523656385, "compression_ratio": 1.4316546762589928, "no_speech_prob": 0.1527933031320572}, {"id": 72, "seek": 31700, "start": 317.0, "end": 320.0, "text": " Ten post\u0119p jest szokuj\u0105co przewidywalny.", "tokens": [50364, 9380, 2183, 18085, 3492, 7870, 453, 13263, 1291, 39758, 327, 27112, 304, 1634, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 73, "seek": 31700, "start": 320.0, "end": 322.0, "text": " To jest w\u0142a\u015bnie sedno praw skalu.", "tokens": [50514, 1407, 3492, 14234, 9643, 1771, 22508, 1110, 4929, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 74, "seek": 31700, "start": 322.0, "end": 326.0, "text": " W artykule pojawia si\u0119 poj\u0119cie power law, czyli prawo pot\u0119gowe.", "tokens": [50614, 343, 594, 874, 74, 2271, 30655, 654, 3244, 714, 11115, 4260, 1347, 2101, 11, 16591, 3206, 6120, 1847, 1274, 70, 6880, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 75, "seek": 31700, "start": 326.0, "end": 328.0, "text": " Znamy je z natury, prawda?", "tokens": [50814, 1176, 5378, 88, 1506, 710, 2249, 2598, 11, 43607, 30, 50914], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 76, "seek": 31700, "start": 328.0, "end": 334.0, "text": " Tak, ono opisuje np. zale\u017cno\u015b\u0107 mi\u0119dzy si\u0142\u0105 trz\u0119sienia ziemi, a cz\u0119stotliwo\u015bci\u0105 jego wyst\u0119powania.", "tokens": [50914, 9118, 11, 322, 78, 45477, 13008, 33808, 13, 710, 45494, 23293, 33964, 1511, 15926, 504, 11052, 82, 18811, 16503, 3057, 11, 257, 18544, 372, 310, 2081, 36476, 1611, 26542, 48255, 1274, 14701, 5609, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 77, "seek": 31700, "start": 334.0, "end": 342.0, "text": " Ma\u0142e wstrz\u0105sy s\u0105 cz\u0119ste, katastrofalne trz\u0119sienia zdarzaj\u0105 si\u0119 rzadko, a wszystko to uk\u0142ada si\u0119 w g\u0142adk\u0105 matematyczn\u0105 krzyw\u0105.", "tokens": [51214, 4042, 19827, 261, 9733, 8925, 3187, 9015, 18544, 2941, 11, 16536, 525, 340, 36474, 716, 504, 11052, 82, 18811, 16221, 49763, 11133, 3244, 367, 89, 345, 4093, 11, 257, 22607, 281, 26769, 46217, 3244, 261, 290, 10358, 26304, 3803, 8615, 17466, 13113, 350, 13047, 86, 1611, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 78, "seek": 31700, "start": 342.0, "end": 346.0, "text": " I okazuje si\u0119, \u017ce wydajno\u015b\u0107 modeli AI zachowuje si\u0119?", "tokens": [51614, 286, 3133, 43317, 3244, 11, 3561, 25984, 1805, 23293, 2316, 72, 7318, 29303, 305, 13008, 3244, 30, 51814], "temperature": 0.0, "avg_logprob": -0.07280109902105387, "compression_ratio": 1.5126582278481013, "no_speech_prob": 0.12622889876365662}, {"id": 79, "seek": 34600, "start": 346.0, "end": 349.0, "text": " W identyczny przewidywalny spos\u00f3b.", "tokens": [50364, 343, 2473, 17466, 1634, 39758, 327, 27112, 304, 1634, 22904, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 80, "seek": 34600, "start": 349.0, "end": 351.0, "text": " A jak w og\u00f3le mierzymy t\u0119 wydajno\u015b\u0107?", "tokens": [50514, 316, 4207, 261, 29229, 47448, 1229, 2226, 32489, 25984, 1805, 23293, 30, 50614], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 81, "seek": 34600, "start": 351.0, "end": 353.0, "text": " W pracy ci\u0105gle pojawia si\u0119 ten termin.", "tokens": [50614, 343, 35591, 42398, 22631, 30655, 654, 3244, 2064, 10761, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 82, "seek": 34600, "start": 353.0, "end": 355.0, "text": " Cross entropy loss.", "tokens": [50714, 11623, 30867, 4470, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 83, "seek": 34600, "start": 355.0, "end": 364.0, "text": " Najpro\u015bciej m\u00f3wi\u0105c, cross entropy loss to mia\u0142a tego, jak bardzo model jest zaskoczony kolejnym s\u0142owem w zdaniu.", "tokens": [50814, 31576, 4318, 9815, 73, 46591, 66, 11, 3278, 30867, 4470, 281, 21290, 5024, 8627, 11, 4207, 9034, 2316, 3492, 710, 3863, 905, 44479, 23749, 12996, 15116, 305, 443, 261, 16221, 25849, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 84, "seek": 34600, "start": 364.0, "end": 367.0, "text": " Czyli jak wynik w golfie i mniejszy tym lepiej.", "tokens": [51264, 37099, 4207, 31936, 1035, 261, 12880, 414, 741, 39513, 7706, 8107, 476, 39699, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 85, "seek": 34600, "start": 367.0, "end": 374.0, "text": " Dok\u0142adnie. Idealny model, kt\u00f3ry przewiduje wszystko z absolutn\u0105 pewno\u015bci\u0105, mia\u0142by loss r\u00f3wny zero.", "tokens": [51414, 29768, 10358, 2766, 13, 13090, 304, 1634, 2316, 11, 9913, 39758, 327, 13008, 22607, 710, 18757, 13113, 33002, 50227, 11, 27989, 2322, 4470, 11416, 43682, 4018, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1003241463313027, "compression_ratio": 1.4452296819787986, "no_speech_prob": 0.019958501681685448}, {"id": 86, "seek": 37400, "start": 375.0, "end": 378.0, "text": " Nasze modele pr\u00f3buj\u0105 do tego zera d\u0105\u017cy\u0107.", "tokens": [50414, 16151, 1381, 4391, 306, 8565, 65, 13263, 360, 8627, 710, 1663, 274, 1611, 39687, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 87, "seek": 37400, "start": 378.0, "end": 386.0, "text": " A prawa skali pokazuj\u0105, \u017ce ten wynik maleje w przewidywalny, pot\u0119gowy spos\u00f3b, gdy zwi\u0119kszamy jeden z trzech zasob\u00f3w.", "tokens": [50564, 316, 3206, 4151, 1110, 5103, 13010, 921, 13263, 11, 3561, 2064, 31936, 1035, 7133, 2884, 261, 39758, 327, 27112, 304, 1634, 11, 1847, 1274, 70, 10089, 22904, 11, 28405, 11873, 5034, 1694, 89, 7804, 12906, 710, 504, 19439, 26530, 996, 3901, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 88, "seek": 37400, "start": 386.0, "end": 389.0, "text": " Czyli liczb\u0119 parametr\u00f3w modelu N.", "tokens": [50964, 37099, 6169, 89, 65, 1274, 6220, 27965, 3901, 2316, 84, 426, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 89, "seek": 37400, "start": 389.0, "end": 394.0, "text": " Ilo\u015b\u0107 danych treningowych D albo moc obliczeniow\u0105 C.", "tokens": [51114, 286, 752, 7753, 274, 34644, 2192, 773, 19605, 413, 22622, 34962, 1111, 1050, 42124, 30297, 383, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 90, "seek": 37400, "start": 394.0, "end": 399.0, "text": " A propos mocy pojawia si\u0119 tam jednostka PF-Days. Co to w\u0142a\u015bciwie jest?", "tokens": [51364, 316, 7532, 705, 1344, 30655, 654, 3244, 7677, 5232, 36414, 2330, 430, 37, 12, 35, 3772, 13, 3066, 281, 50108, 3492, 30, 51614], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 91, "seek": 37400, "start": 399.0, "end": 403.0, "text": " To jest taka jednostka czasu my\u015blenia dla superkomputera.", "tokens": [51614, 1407, 3492, 28017, 5232, 36414, 2330, 40860, 48633, 6698, 654, 12285, 1687, 20557, 2582, 1663, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08793231024258379, "compression_ratio": 1.3741258741258742, "no_speech_prob": 0.06437920778989792}, {"id": 92, "seek": 40300, "start": 403.0, "end": 409.0, "text": " Jeden petaflop to tysi\u0105c bilion\u00f3w operacji na sekund\u0119. To jest niewyobra\u017calna liczba.", "tokens": [50364, 508, 6876, 3817, 2792, 75, 404, 281, 38156, 11404, 66, 8588, 313, 3901, 2208, 13152, 1667, 17215, 997, 1274, 13, 1407, 3492, 43622, 88, 24393, 1427, 304, 629, 6169, 89, 4231, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08640898132324219, "compression_ratio": 1.3453815261044177, "no_speech_prob": 0.0027822344563901424}, {"id": 93, "seek": 40300, "start": 409.0, "end": 414.0, "text": " Czyli PF-Day oznacza, \u017ce taki potw\u00f3r obliczeniowy pracuje dla nas przez ta\u0142\u0105 dob\u0119.", "tokens": [50664, 37099, 430, 37, 12, 35, 320, 277, 22672, 326, 2394, 11, 3561, 20065, 1847, 86, 15614, 1111, 1050, 42124, 10089, 22404, 13008, 12285, 5382, 14064, 1846, 15926, 27082, 1274, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08640898132324219, "compression_ratio": 1.3453815261044177, "no_speech_prob": 0.0027822344563901424}, {"id": 94, "seek": 40300, "start": 414.0, "end": 417.0, "text": " I to jest gigantyczny ko\u015b\u0107.", "tokens": [50914, 286, 281, 3492, 8741, 394, 17466, 1634, 8384, 7753, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08640898132324219, "compression_ratio": 1.3453815261044177, "no_speech_prob": 0.0027822344563901424}, {"id": 95, "seek": 40300, "start": 417.0, "end": 425.0, "text": " A praca Kaplana pokaza\u0142a, \u017ce te g\u0142adkie krzywe przewidywalno\u015bci rozci\u0105gaj\u0105 si\u0119 na przestrzeni siedmiu rz\u0119du wielko\u015bci.", "tokens": [51064, 316, 582, 6628, 10988, 16554, 64, 13010, 12257, 5024, 11, 3561, 535, 290, 10358, 22872, 350, 13047, 826, 39758, 327, 27112, 304, 16438, 9544, 34381, 70, 11133, 3244, 1667, 44264, 81, 42124, 262, 1091, 3057, 84, 367, 11052, 769, 20570, 4093, 6199, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08640898132324219, "compression_ratio": 1.3453815261044177, "no_speech_prob": 0.0027822344563901424}, {"id": 96, "seek": 42500, "start": 426.0, "end": 434.0, "text": " To tak jakby ta sama zasada fizyki dzia\u0142a\u0142a dla, nie wiem, mr\u00f3wki i dla wieloryba. To nie mo\u017ce by\u0107 przypadek.", "tokens": [50414, 1407, 991, 28976, 1846, 17768, 26530, 1538, 21000, 88, 2984, 37903, 5024, 12285, 11, 2838, 26522, 11, 33660, 3901, 2984, 741, 12285, 20570, 827, 4231, 13, 1407, 2838, 12034, 15069, 41780, 762, 74, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09049751140453198, "compression_ratio": 1.4602076124567474, "no_speech_prob": 0.44223809242248535}, {"id": 97, "seek": 42500, "start": 434.0, "end": 441.0, "text": " Dok\u0142adnie. I to jest ten moment, w kt\u00f3rym budowanie AI przesz\u0142o z etapu powiedzmy alchemi do etapu chemii.", "tokens": [50814, 29768, 10358, 2766, 13, 286, 281, 3492, 2064, 1623, 11, 261, 30120, 3265, 22028, 7318, 6541, 10430, 5249, 710, 47634, 84, 27617, 2226, 419, 339, 13372, 360, 47634, 84, 4771, 5597, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09049751140453198, "compression_ratio": 1.4602076124567474, "no_speech_prob": 0.44223809242248535}, {"id": 98, "seek": 42500, "start": 441.0, "end": 445.0, "text": " Czyli koniec zmieszaniem sk\u0142adnik\u00f3w w laboratorium i liczeniem na szcz\u0119\u015bcie.", "tokens": [51164, 37099, 5897, 35733, 17020, 15347, 282, 4907, 1110, 10358, 47447, 261, 5938, 41679, 741, 6169, 2904, 4907, 1667, 22090, 1274, 9815, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09049751140453198, "compression_ratio": 1.4602076124567474, "no_speech_prob": 0.44223809242248535}, {"id": 99, "seek": 42500, "start": 445.0, "end": 452.0, "text": " Tak. Badacze dostali zestaw r\u00f3wna\u0144, kt\u00f3re m\u00f3wi\u0105. Je\u015bli zainwestujesz x milion\u00f3w dolar\u00f3w w moc obliczeniow\u0105,", "tokens": [51364, 9118, 13, 11523, 326, 1381, 20568, 5103, 37889, 1607, 367, 3901, 629, 5248, 11, 8864, 46591, 13, 37086, 710, 491, 8750, 4579, 10430, 2031, 1962, 313, 3901, 360, 2200, 3901, 261, 34962, 1111, 1050, 42124, 30297, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09049751140453198, "compression_ratio": 1.4602076124567474, "no_speech_prob": 0.44223809242248535}, {"id": 100, "seek": 45200, "start": 452.0, "end": 457.0, "text": " a y w powi\u0119kszenie modelu uzyskasz przybli\u017ceniu zet procent poprawy wydajno\u015bci.", "tokens": [50364, 257, 288, 261, 3388, 5034, 1694, 16778, 2316, 84, 16851, 749, 74, 19601, 6501, 32117, 24930, 5951, 710, 302, 38826, 1665, 5131, 88, 25984, 1805, 16438, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07020198524772346, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.08307787775993347}, {"id": 101, "seek": 45200, "start": 457.0, "end": 462.0, "text": " To pozwoli\u0142a na strategiczne planowanie i uzasadnienie tych gigantycznych bud\u017cet\u00f3w.", "tokens": [50614, 1407, 40557, 9384, 5024, 1667, 10924, 43077, 1393, 22028, 741, 16851, 296, 345, 77, 27385, 15180, 8741, 394, 17466, 9399, 3265, 1427, 302, 3901, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07020198524772346, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.08307787775993347}, {"id": 102, "seek": 45200, "start": 462.0, "end": 468.0, "text": " Z du\u017c\u0105 doz\u0105pewno\u015bci. Nagle inwestorzy zobaczyli map\u0119 drogow\u0105 do coraz pot\u0119\u017cniejszej AI.", "tokens": [50864, 1176, 21783, 1611, 360, 8925, 494, 20944, 6199, 13, 426, 15088, 294, 8750, 284, 1229, 37273, 2081, 4471, 1274, 3789, 70, 30297, 360, 25899, 1847, 1274, 1427, 30295, 16920, 7318, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07020198524772346, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.08307787775993347}, {"id": 103, "seek": 45200, "start": 468.0, "end": 474.0, "text": " Dobrze, wi\u0119c mamy map\u0119. Inwestuj w skale, a dostaniesz lepsze wyniki. Proste.", "tokens": [51164, 29679, 13503, 11, 16677, 17335, 4471, 1274, 13, 682, 8750, 4579, 261, 1110, 1220, 11, 257, 20568, 282, 15347, 476, 1878, 1381, 31936, 9850, 13, 2114, 555, 68, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07020198524772346, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.08307787775993347}, {"id": 104, "seek": 45200, "start": 474.0, "end": 481.0, "text": " Ale tutaj autorzy zadali jeszcze jedno, kluczowe pytanie, kt\u00f3re wywr\u00f3ci\u0142o wszystko do g\u00f3ry nogami.", "tokens": [51464, 9366, 12749, 19510, 1229, 42788, 5103, 14168, 5232, 1771, 11, 9671, 1311, 89, 6880, 36610, 11, 8864, 4628, 7449, 812, 537, 5249, 22607, 360, 290, 812, 627, 9638, 4526, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07020198524772346, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.08307787775993347}, {"id": 105, "seek": 48100, "start": 481.0, "end": 484.0, "text": " Mianowicie. Jak najlepiej wydawa\u0107 te pieni\u0105dze.", "tokens": [50364, 376, 952, 305, 28434, 13, 15029, 41903, 39699, 25984, 10449, 2162, 535, 26274, 11404, 67, 1381, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 106, "seek": 48100, "start": 484.0, "end": 490.0, "text": " I odpowied\u017a, kt\u00f3r\u0105 znale\u017ali przeczy wszystkie mu, czego uczono in\u017cynier\u00f3w AI przez lata.", "tokens": [50514, 286, 36574, 10659, 11, 37415, 15397, 1220, 10659, 2081, 8325, 6522, 31723, 2992, 11, 36559, 35403, 8957, 294, 1427, 2534, 811, 3901, 7318, 14064, 46722, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 107, "seek": 48100, "start": 490.0, "end": 496.0, "text": " A tak. To jest chyba najbardziej szokuj\u0105cy i kontr intuicyjny wniosek z ca\u0142ej tej pracy.", "tokens": [50814, 316, 991, 13, 1407, 3492, 31532, 41857, 7870, 453, 13263, 1344, 741, 14373, 81, 560, 84, 2632, 73, 1634, 261, 3722, 541, 74, 710, 47631, 73, 12573, 35591, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 108, "seek": 48100, "start": 496.0, "end": 498.0, "text": " No bo standardowe podej\u015bcie by\u0142o jakie.", "tokens": [51114, 883, 748, 3832, 6880, 7468, 73, 9815, 14811, 22124, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 109, "seek": 48100, "start": 498.0, "end": 503.0, "text": " By\u0142o takie. Trenujemy model tak d\u0142ugo, a\u017c jego krzywa uczenia si\u0119 wyp\u0142aszcze.", "tokens": [51214, 3146, 5249, 15963, 13, 314, 1095, 21767, 2316, 991, 44042, 20746, 11, 48134, 26542, 350, 13047, 4151, 344, 38517, 3244, 46392, 1221, 19601, 9680, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 110, "seek": 48100, "start": 503.0, "end": 508.0, "text": " Dajemy mu dane i patrzymy, jaki jego wynik w tym naszym golfie, czyli los, spada.", "tokens": [51464, 413, 1805, 3633, 2992, 49206, 741, 1947, 13047, 2226, 11, 24492, 26542, 31936, 1035, 261, 8107, 48094, 12880, 414, 11, 16591, 1750, 11, 637, 1538, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 111, "seek": 48100, "start": 508.0, "end": 510.0, "text": " I gdy przestaje spada\u0107?", "tokens": [51714, 286, 28405, 44264, 11153, 637, 1538, 2162, 30, 51814], "temperature": 0.0, "avg_logprob": -0.10378000538819915, "compression_ratio": 1.4108761329305135, "no_speech_prob": 0.15455162525177002}, {"id": 112, "seek": 51000, "start": 510.0, "end": 514.0, "text": " To znaczy, \u017ce model nauczy\u0142 si\u0119 wszystkiego, czego m\u00f3g\u0142 z tych danych.", "tokens": [50364, 1407, 36584, 11, 3561, 2316, 49103, 1229, 1221, 3244, 14615, 12200, 11, 36559, 275, 14047, 1221, 710, 15180, 274, 34644, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 113, "seek": 51000, "start": 514.0, "end": 519.0, "text": " To si\u0119 nazywa osi\u0105gni\u0119cie konvergencji. I wydaje si\u0119 to absolutnie logiczne.", "tokens": [50564, 1407, 3244, 20151, 88, 4151, 3003, 11404, 70, 35938, 4260, 5897, 331, 1766, 19649, 13, 286, 49165, 3244, 281, 18757, 2766, 9952, 43077, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 114, "seek": 51000, "start": 519.0, "end": 521.0, "text": " A ta praca m\u00f3wi, \u017ce to?", "tokens": [50814, 316, 1846, 582, 6628, 24592, 11, 3561, 281, 30, 50914], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 115, "seek": 51000, "start": 521.0, "end": 527.0, "text": " Marnotrawstwo zasob\u00f3w. Dok\u0142adnie tak. Autorzy wprowadzili poj\u0119cie compute efficient training.", "tokens": [50914, 376, 1083, 310, 5131, 372, 6120, 26530, 996, 3901, 13, 29768, 10358, 2766, 991, 13, 6049, 284, 1229, 46733, 89, 2312, 714, 11115, 4260, 14722, 7148, 3097, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 116, "seek": 51000, "start": 527.0, "end": 531.0, "text": " Czyli training optymalny pod wzgl\u0119dem obliczeniowym.", "tokens": [51214, 37099, 3097, 2427, 4199, 304, 1634, 2497, 48538, 6298, 443, 1111, 1050, 42124, 31691, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 117, "seek": 51000, "start": 531.0, "end": 536.0, "text": " Tak. Postawili pytanie. Maj\u0105c sta\u0142y bud\u017cet, powiedzmy milion dolar\u00f3w na serwery,", "tokens": [51414, 9118, 13, 10223, 1607, 2312, 36610, 13, 7048, 1611, 66, 11135, 6825, 3265, 1427, 302, 11, 27617, 2226, 1962, 313, 360, 2200, 3901, 1667, 816, 1554, 88, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08178140791200048, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.015056835487484932}, {"id": 118, "seek": 53600, "start": 536.0, "end": 543.0, "text": " jak go najlepiej wyda\u0107? Czy trenowa\u0107 ma\u0142y model do perfekcji, a\u017c wyci\u015bniemy z niego ostatnie soki?", "tokens": [50364, 4207, 352, 41903, 39699, 4628, 2675, 2162, 30, 19832, 23136, 11445, 463, 6825, 2316, 360, 13826, 916, 19649, 11, 48134, 4628, 537, 12221, 2226, 710, 49615, 32686, 2766, 370, 2984, 30, 50714], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 119, "seek": 53600, "start": 543.0, "end": 545.0, "text": " No i odpowied\u017a brzmi nie.", "tokens": [50714, 883, 741, 36574, 10659, 738, 89, 3057, 2838, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 120, "seek": 53600, "start": 545.0, "end": 551.0, "text": " Zdecydowanie nie. Okazuje si\u0119, \u017ce optymaln\u0105 strategi\u0105 jest zbudowanie najwi\u0119kszego mo\u017cliwego modelu,", "tokens": [50814, 1176, 1479, 1344, 67, 22028, 2838, 13, 3477, 43317, 3244, 11, 3561, 2427, 4199, 304, 13113, 5464, 11404, 3492, 710, 18281, 22028, 48636, 1694, 27725, 30854, 826, 1571, 2316, 84, 11, 51114], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 121, "seek": 53600, "start": 551.0, "end": 554.0, "text": " na jaki nas sta\u0107 i zatrzymanie treningu.", "tokens": [51114, 1667, 24492, 5382, 11135, 2162, 741, 35802, 13047, 1601, 414, 2192, 773, 84, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 122, "seek": 53600, "start": 554.0, "end": 557.0, "text": " Nad\u0142ugo przed tym, jak si\u0119 w pe\u0142ni naucz\u0119.", "tokens": [51264, 23269, 1221, 20746, 18334, 8107, 11, 4207, 3244, 261, 43205, 3722, 49103, 11052, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 123, "seek": 53600, "start": 557.0, "end": 565.0, "text": " To brzmi jak herezja. Dlaczego niedotrenowany, gigantyczny model ma by\u0107 lepszy ni\u017c w pe\u0142ni wytrenowany, ale mniejszy?", "tokens": [51414, 1407, 738, 89, 3057, 4207, 720, 4371, 2938, 13, 413, 75, 39329, 32488, 310, 1095, 23341, 11, 8741, 394, 17466, 1634, 2316, 463, 15069, 476, 1878, 1229, 28502, 261, 43205, 3722, 261, 4328, 1095, 23341, 11, 6775, 39513, 7706, 30, 51814], "temperature": 0.0, "avg_logprob": -0.08319826687083524, "compression_ratio": 1.505050505050505, "no_speech_prob": 0.011209170334041119}, {"id": 124, "seek": 56500, "start": 565.0, "end": 568.0, "text": " Przecie\u017c on nie zd\u0105\u017cy\u0142 si\u0119 nauczy\u0107 wszystkiego.", "tokens": [50364, 2114, 1381, 40082, 322, 2838, 16221, 1611, 7735, 1221, 3244, 49103, 27150, 14615, 12200, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 125, "seek": 56500, "start": 568.0, "end": 571.0, "text": " Kluczem jest poj\u0119cie sample efficiency.", "tokens": [50514, 16053, 1311, 24313, 3492, 714, 11115, 4260, 6889, 10493, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 126, "seek": 56500, "start": 571.0, "end": 573.0, "text": " Efektywno\u015b\u0107 na pr\u00f3bce.", "tokens": [50664, 31840, 916, 874, 20944, 7753, 1667, 8565, 65, 384, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 127, "seek": 56500, "start": 573.0, "end": 579.0, "text": " Tak. Du\u017ce modele s\u0105 jak genialnie studenci. Ucz\u0105 si\u0119 znacznie szybciej z ka\u017cdego przyk\u0142adu.", "tokens": [50764, 9118, 13, 5153, 2875, 4391, 306, 9015, 4207, 48228, 2766, 972, 30322, 13, 624, 3689, 1611, 3244, 15397, 14875, 2766, 36456, 4260, 73, 710, 21912, 67, 6308, 23144, 84, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 128, "seek": 56500, "start": 579.0, "end": 585.0, "text": " Ma\u0142y model jest jak przeci\u0119tny ucza\u0144. Potrzebuje wielu powt\u00f3rzek, \u017ceby zrozumie\u0107 ten sam materia\u0142.", "tokens": [51064, 4042, 6825, 2316, 3492, 4207, 39622, 46788, 1634, 35403, 64, 5248, 13, 9145, 13503, 6021, 2884, 40437, 3388, 4547, 81, 19878, 11, 11316, 710, 27857, 449, 414, 2162, 2064, 3247, 2389, 8908, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 129, "seek": 56500, "start": 585.0, "end": 586.0, "text": " Aha.", "tokens": [51364, 27448, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06814596109222948, "compression_ratio": 1.321285140562249, "no_speech_prob": 0.012895099818706512}, {"id": 130, "seek": 58600, "start": 586.0, "end": 595.0, "text": " To, \u017ce w tej samej jednostce czasu i przy tym samym koszcie obliczeniowym, du\u017cy model robi znacznie wi\u0119ksze post\u0119py.", "tokens": [50364, 1407, 11, 3561, 261, 12573, 912, 73, 5232, 36414, 384, 40860, 741, 6501, 8107, 3247, 4199, 19532, 89, 4260, 1111, 1050, 42124, 31691, 11, 1581, 7735, 2316, 47380, 15397, 14875, 2766, 29968, 1381, 2183, 1274, 8200, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 131, "seek": 58600, "start": 595.0, "end": 598.0, "text": " Jego krzywa uczenia opada o wiele stromiej.", "tokens": [50814, 508, 6308, 350, 13047, 4151, 344, 38517, 999, 1538, 277, 33137, 1056, 298, 7764, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 132, "seek": 58600, "start": 598.0, "end": 600.0, "text": " Rozumiem.", "tokens": [50964, 43313, 449, 4907, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 133, "seek": 58600, "start": 600.0, "end": 607.0, "text": " Czyli maj\u0105c ograniczony bud\u017cet. Lepiej jest wyda\u0107 go na szybk\u0105 i efektywn\u0105 nauk\u0119 tego giganta?", "tokens": [51064, 37099, 26064, 66, 34416, 282, 17946, 2526, 3265, 1427, 302, 13, 441, 595, 7764, 3492, 4628, 2675, 2162, 352, 1667, 36456, 26304, 741, 31482, 916, 874, 895, 1611, 35616, 15724, 8627, 8741, 5983, 30, 51414], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 134, "seek": 58600, "start": 607.0, "end": 608.0, "text": " Mhm.", "tokens": [51414, 26272, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 135, "seek": 58600, "start": 608.0, "end": 613.0, "text": " ni\u017c na powolne i \u017cmudne docieranie do granicy mo\u017cliwo\u015bci malucha.", "tokens": [51464, 28502, 1667, 3388, 401, 716, 741, 19625, 31916, 716, 360, 27674, 7155, 360, 9370, 2632, 30854, 36476, 2806, 26042, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11058699138580806, "compression_ratio": 1.3779527559055118, "no_speech_prob": 0.4895648956298828}, {"id": 136, "seek": 61300, "start": 613.0, "end": 616.0, "text": " Czyli wracamy do naszej analogii z samochodem wy\u015bcigowym?", "tokens": [50364, 37099, 928, 326, 7804, 360, 42946, 16660, 5597, 710, 3247, 8997, 378, 443, 4628, 1788, 66, 328, 31691, 30, 50514], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 137, "seek": 61300, "start": 616.0, "end": 617.0, "text": " Dok\u0142adnie.", "tokens": [50514, 29768, 10358, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 138, "seek": 61300, "start": 617.0, "end": 619.0, "text": " To jest w\u0142a\u015bnie ten moment.", "tokens": [50564, 1407, 3492, 14234, 2064, 1623, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 139, "seek": 61300, "start": 619.0, "end": 625.0, "text": " Zamiast dopieszcza\u0107 ma\u0142y silnik przez rok, \u017ceby wycisn\u0105\u0107 z niego, powiedzmy, 300 koni mechanicznych.", "tokens": [50664, 1176, 4526, 525, 21900, 15347, 66, 35873, 463, 6825, 3425, 13123, 14064, 35135, 11, 11316, 4628, 26720, 13113, 2162, 710, 49615, 11, 27617, 2226, 11, 6641, 5897, 72, 4236, 17946, 9399, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 140, "seek": 61300, "start": 625.0, "end": 630.0, "text": " Lepiej zbudowa\u0107 ogromny silnik V12, uruchomi\u0107 go na jeden dzie\u0144.", "tokens": [50964, 441, 595, 7764, 710, 18281, 11445, 34416, 298, 1634, 3425, 13123, 691, 4762, 11, 4038, 625, 9220, 2162, 352, 1667, 12906, 47568, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 141, "seek": 61300, "start": 630.0, "end": 636.0, "text": " I z \u0142atwo\u015bci\u0105 osi\u0105gn\u0105\u0107 500 koni. Nawet je\u015bli teoretycznie m\u00f3g\u0142by osi\u0105gn\u0105\u0107 1000.", "tokens": [51214, 286, 710, 47759, 36476, 1611, 3003, 11404, 4568, 36374, 5923, 5897, 72, 13, 40315, 302, 25630, 535, 418, 45586, 275, 14047, 34635, 3003, 11404, 4568, 36374, 9714, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 142, "seek": 61300, "start": 636.0, "end": 641.0, "text": " Bo ten du\u017cy silnik dochodzi do tych 500 koni po prostu znacznie szybciej i taniej.", "tokens": [51514, 3286, 2064, 1581, 7735, 3425, 13123, 9243, 14543, 360, 15180, 5923, 5897, 72, 714, 19518, 15397, 14875, 2766, 36456, 4260, 73, 741, 256, 7155, 73, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05744005178476309, "compression_ratio": 1.4376996805111821, "no_speech_prob": 0.049674760550260544}, {"id": 143, "seek": 64100, "start": 641.0, "end": 643.0, "text": " To jest idealne por\u00f3wnanie.", "tokens": [50364, 1407, 3492, 7157, 716, 1515, 812, 895, 7155, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 144, "seek": 64100, "start": 643.0, "end": 654.0, "text": " A kiedy badacze prze\u0142o\u017cyli to na liczby i zasymulowali jak najlepiej wyda\u0107 za\u0142\u00f3\u017cmy miliard razy wi\u0119kszy bud\u017cet na kompiut, wniki by\u0142y szokuj\u0105ce.", "tokens": [50464, 316, 18777, 1578, 326, 1381, 8325, 5249, 7735, 2081, 281, 1667, 6169, 89, 2322, 741, 710, 5871, 76, 425, 305, 5103, 4207, 41903, 39699, 4628, 2675, 2162, 7949, 1221, 812, 1427, 2226, 1962, 72, 515, 9639, 88, 29968, 1229, 3265, 1427, 302, 1667, 5207, 22630, 325, 11, 261, 77, 9850, 26366, 7870, 453, 13263, 384, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 145, "seek": 64100, "start": 654.0, "end": 655.0, "text": " I co wysz\u0142o?", "tokens": [51014, 286, 598, 261, 20589, 5249, 30, 51064], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 146, "seek": 64100, "start": 655.0, "end": 661.0, "text": " Lwia cz\u0119\u015b\u0107 tych dodatkowych zasob\u00f3w powinna buj\u015b\u0107 na zwi\u0119kszenie rozmiaru modelu.", "tokens": [51064, 441, 86, 654, 47149, 15180, 13886, 33525, 19605, 26530, 996, 3901, 27310, 629, 758, 44536, 1667, 11873, 5034, 1694, 16778, 9544, 3057, 16870, 2316, 84, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 147, "seek": 64100, "start": 661.0, "end": 666.0, "text": " Mniejsza cz\u0119\u015b\u0107 na zwi\u0119kszenie batch size, czyli liczby przyk\u0142ad\u00f3w przetwarzanych naraz,", "tokens": [51364, 376, 30295, 2394, 47149, 1667, 11873, 5034, 1694, 16778, 15245, 2744, 11, 16591, 6169, 89, 2322, 23144, 3901, 6541, 302, 31991, 34644, 6714, 921, 11, 51614], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 148, "seek": 64100, "start": 666.0, "end": 670.0, "text": " a tylko absolutnie znikomy u\u0142amek na wyd\u0142u\u017cenie czasu treningu.", "tokens": [51614, 257, 13219, 18757, 2766, 710, 13123, 8488, 344, 1221, 529, 74, 1667, 25984, 24066, 41118, 40860, 2192, 773, 84, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08595955066191845, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.26652052998542786}, {"id": 149, "seek": 67000, "start": 670.0, "end": 673.0, "text": " To ca\u0142kowicie odwr\u00f3ci\u0142o tradycyjn\u0105 intuicj\u0119.", "tokens": [50364, 1407, 35224, 74, 305, 28434, 3611, 7449, 812, 537, 5249, 504, 880, 42949, 13113, 560, 84, 299, 11115, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 150, "seek": 67000, "start": 673.0, "end": 675.0, "text": " O 180 stopni.", "tokens": [50514, 422, 11971, 1590, 3722, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 151, "seek": 67000, "start": 675.0, "end": 677.0, "text": " To jest prawdziwy moment aha.", "tokens": [50614, 1407, 3492, 41175, 3992, 9726, 1623, 47340, 13, 50714], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 152, "seek": 67000, "start": 677.0, "end": 686.0, "text": " Dla zespo\u0142u badawczego z uniwersytetu czy startupu oznacza to, \u017ce nie powinien on m\u0119czy\u0107 jednego ma\u0142ego modelu przez wiele tygodni.", "tokens": [50714, 413, 875, 710, 279, 2259, 24066, 272, 1538, 86, 3689, 6308, 710, 36435, 5364, 4328, 41236, 6430, 18578, 84, 277, 22672, 326, 2394, 281, 11, 3561, 2838, 27310, 1053, 322, 275, 1274, 33967, 5232, 11858, 463, 1221, 6308, 2316, 84, 14064, 33137, 1104, 21787, 3722, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 153, "seek": 67000, "start": 686.0, "end": 692.0, "text": " Nie, powinien zbudowa\u0107 najwi\u0119kszy model na jakiego sta\u0107 i trenowa\u0107 go kr\u00f3cej.", "tokens": [51164, 12016, 11, 27310, 1053, 710, 18281, 11445, 48636, 1694, 1229, 2316, 1667, 4207, 12200, 11135, 2162, 741, 23136, 11445, 352, 42366, 20811, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 154, "seek": 67000, "start": 692.0, "end": 695.0, "text": " Nawet je\u015bli na wykresie wida\u0107, \u017ce model wci\u0105\u017c si\u0119 uczy.", "tokens": [51464, 40315, 302, 25630, 1667, 39287, 495, 414, 261, 46898, 11, 3561, 2316, 261, 537, 27242, 3244, 344, 6522, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0671828184554826, "compression_ratio": 1.404494382022472, "no_speech_prob": 0.037431322038173676}, {"id": 155, "seek": 69500, "start": 695.0, "end": 702.0, "text": " Tak. W momencie, gdy sko\u0144czy si\u0119 bud\u017cet ten niedotrenowany gigant b\u0119dzie mia\u0142 ni\u017c szilos.", "tokens": [50364, 9118, 13, 343, 40883, 11, 28405, 1110, 78, 5248, 6522, 3244, 3265, 1427, 302, 2064, 32488, 310, 1095, 23341, 8741, 394, 10562, 27989, 28502, 7870, 6136, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 156, "seek": 69500, "start": 702.0, "end": 706.0, "text": " Czyli b\u0119dzie po prostu lepszy ni\u017c w pe\u0142ni zoptymalizowany maluch.", "tokens": [50714, 37099, 10562, 714, 19518, 476, 1878, 1229, 28502, 261, 43205, 3722, 710, 404, 874, 5579, 590, 23341, 2806, 625, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 157, "seek": 69500, "start": 706.0, "end": 713.0, "text": " I ta zasada sta\u0142a si\u0119 fundamentem strategii firm takich jak OpenAI, Anthropec czy Google.", "tokens": [50914, 286, 1846, 26530, 1538, 11135, 5024, 3244, 6073, 443, 5464, 5597, 6174, 29607, 4207, 7238, 48698, 11, 12727, 340, 494, 66, 6430, 3329, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 158, "seek": 69500, "start": 713.0, "end": 718.0, "text": " Oni wiedz\u0105, \u017ce aby osi\u0105gn\u0105\u0107 kolejny prze\u0142om nie wystarczy trenowa\u0107 d\u0142u\u017cej.", "tokens": [51264, 1282, 72, 46894, 8925, 11, 3561, 24457, 3003, 11404, 4568, 36374, 23749, 1634, 8325, 1221, 298, 2838, 4628, 9710, 6522, 23136, 11445, 274, 24066, 38493, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 159, "seek": 69500, "start": 718.0, "end": 720.0, "text": " Trzeba budowa\u0107 wi\u0119ksze modele.", "tokens": [51514, 1765, 1381, 4231, 3265, 11445, 29968, 1381, 4391, 306, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 160, "seek": 69500, "start": 720.0, "end": 723.0, "text": " Ta praca da\u0142a im na to matematyczne dowody.", "tokens": [51614, 6551, 582, 6628, 1120, 5024, 566, 1667, 281, 3803, 8615, 17466, 716, 9459, 843, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09350691823398366, "compression_ratio": 1.436426116838488, "no_speech_prob": 0.4710620939731598}, {"id": 161, "seek": 72300, "start": 724.0, "end": 728.0, "text": " W porz\u0105dku. To wszystko jest fascynuj\u0105ce z punktu widzenia laboratorium.", "tokens": [50414, 343, 1515, 23876, 5279, 13, 1407, 22607, 3492, 30632, 1344, 77, 13263, 384, 710, 39561, 84, 5274, 14320, 5938, 41679, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 162, "seek": 72300, "start": 728.0, "end": 734.0, "text": " Ale powiedzmy sobie szczerze. Dlaczego kogo\u015b, kto nie jest in\u017cynierem AI, mia\u0142oby to obchodzi\u0107?", "tokens": [50614, 9366, 27617, 2226, 13652, 22090, 260, 1381, 13, 413, 75, 39329, 350, 23515, 1788, 11, 23780, 2838, 3492, 294, 1427, 2534, 72, 7333, 7318, 11, 27989, 13944, 281, 1111, 34616, 2162, 30, 50914], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 163, "seek": 72300, "start": 734.0, "end": 736.0, "text": " Dobre pytanie.", "tokens": [50914, 29679, 265, 36610, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 164, "seek": 72300, "start": 736.0, "end": 739.0, "text": " Jak te abstrakcyjne prawa kszta\u0142tuj\u0105 \u015bwiat, w kt\u00f3rym \u017cyjemy?", "tokens": [51014, 15029, 535, 10823, 11272, 42949, 716, 3206, 4151, 350, 15453, 46426, 83, 13263, 36425, 11, 261, 30120, 16136, 73, 3633, 30, 51164], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 165, "seek": 72300, "start": 739.0, "end": 742.0, "text": " Kszta\u0142tuj\u0105 go w spos\u00f3b absolutnie fundamentalny.", "tokens": [51164, 591, 15453, 46426, 83, 13263, 352, 261, 22904, 18757, 2766, 8088, 1634, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 166, "seek": 72300, "start": 742.0, "end": 748.0, "text": " Po pierwsze ta praca uzasadnia gigantyczne wielomiliardowe inwestycje w centra danych i CIPAi.", "tokens": [51314, 6165, 45994, 1846, 582, 6628, 16851, 296, 345, 12679, 8741, 394, 17466, 716, 20570, 298, 2312, 515, 6880, 294, 86, 7819, 44261, 261, 1489, 424, 274, 34644, 741, 383, 9139, 32, 72, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 167, "seek": 72300, "start": 748.0, "end": 750.0, "text": " To ju\u017c nie jest \u015blepy wy\u015bcig zbroje\u0144?", "tokens": [51614, 1407, 10678, 2838, 3492, 8299, 306, 8200, 4628, 1788, 66, 328, 710, 9120, 2884, 5248, 30, 51714], "temperature": 0.0, "avg_logprob": -0.09128746008261657, "compression_ratio": 1.3918495297805642, "no_speech_prob": 0.08356347680091858}, {"id": 168, "seek": 75000, "start": 750.0, "end": 754.0, "text": " Nie. To nie jest przeczucie kilku wizjoner\u00f3w.", "tokens": [50364, 12016, 13, 1407, 2838, 3492, 8325, 3689, 1311, 414, 5128, 5279, 40808, 15735, 260, 3901, 13, 50564], "temperature": 0.0, "avg_logprob": -0.061877822119092186, "compression_ratio": 1.3828125, "no_speech_prob": 0.04577287286520004}, {"id": 169, "seek": 75000, "start": 754.0, "end": 761.0, "text": " To strategia oparta na twardych danych, kt\u00f3ra m\u00f3wi, \u017ce ka\u017cdy zainwestowany dolar w skal\u0119", "tokens": [50564, 1407, 5464, 654, 999, 19061, 1667, 683, 515, 16384, 274, 34644, 11, 19456, 24592, 11, 3561, 31615, 710, 491, 8750, 23341, 360, 2200, 261, 16890, 1274, 50914], "temperature": 0.0, "avg_logprob": -0.061877822119092186, "compression_ratio": 1.3828125, "no_speech_prob": 0.04577287286520004}, {"id": 170, "seek": 75000, "start": 761.0, "end": 765.0, "text": " przyniesie przewidywalny zwrot w postaci lepszej technologii.", "tokens": [50914, 6501, 40549, 414, 39758, 327, 27112, 304, 1634, 49111, 310, 261, 2183, 22086, 476, 1878, 16920, 1537, 1132, 5597, 13, 51114], "temperature": 0.0, "avg_logprob": -0.061877822119092186, "compression_ratio": 1.3828125, "no_speech_prob": 0.04577287286520004}, {"id": 171, "seek": 75000, "start": 765.0, "end": 769.0, "text": " I dlatego widzimy tak\u0105 eksplozj\u0119 inwestycji w tej dziedzinie.", "tokens": [51114, 286, 32205, 27486, 13189, 31069, 30724, 564, 15151, 11115, 294, 86, 7819, 19649, 261, 12573, 9758, 15338, 259, 414, 13, 51314], "temperature": 0.0, "avg_logprob": -0.061877822119092186, "compression_ratio": 1.3828125, "no_speech_prob": 0.04577287286520004}, {"id": 172, "seek": 75000, "start": 769.0, "end": 776.0, "text": " A co z danymi? Zawsze s\u0142yszeli\u015bmy, \u017ce dane to nowa ropa. Czy ta praca to potwierdza?", "tokens": [51314, 316, 598, 710, 274, 1325, 3057, 30, 1176, 28354, 15116, 20589, 10148, 10513, 11, 3561, 49206, 281, 586, 64, 744, 4306, 13, 19832, 1846, 582, 6628, 281, 1847, 40717, 67, 2394, 30, 51664], "temperature": 0.0, "avg_logprob": -0.061877822119092186, "compression_ratio": 1.3828125, "no_speech_prob": 0.04577287286520004}, {"id": 173, "seek": 77600, "start": 776.0, "end": 782.0, "text": " I tu jest kolejna bardzo ciekawa rzecz. Ta praca sugeruje, \u017ce has\u0142o powinno brzmie\u0107 raczej", "tokens": [50364, 286, 2604, 3492, 23749, 629, 9034, 46419, 10449, 36833, 13, 6551, 582, 6628, 459, 1321, 13008, 11, 3561, 575, 5249, 27310, 1771, 738, 89, 25210, 2162, 4129, 16920, 50664], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 174, "seek": 77600, "start": 782.0, "end": 785.0, "text": " wielkie modele s\u0105 wa\u017cniejsze ni\u017c wielkie dane.", "tokens": [50664, 20570, 22872, 4391, 306, 9015, 27777, 44258, 28502, 20570, 22872, 49206, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 175, "seek": 77600, "start": 785.0, "end": 786.0, "text": " Naprawd\u0119?", "tokens": [50814, 18287, 20098, 30, 50864], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 176, "seek": 77600, "start": 786.0, "end": 794.0, "text": " Oczywi\u015bcie dane s\u0105 absolutnie niezb\u0119dne, ale zapotrzebowanie na nie ro\u015bnie wolniej ni\u017c optymalny rozmiar modelu.", "tokens": [50864, 42980, 49206, 9015, 18757, 2766, 33511, 65, 6298, 716, 11, 6775, 14223, 310, 13503, 8202, 7155, 1667, 2838, 744, 12221, 20960, 10402, 28502, 2427, 4199, 304, 1634, 9544, 3057, 289, 2316, 84, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 177, "seek": 77600, "start": 794.0, "end": 796.0, "text": " Czyli jak to wygl\u0105da w liczbach?", "tokens": [51264, 37099, 4207, 281, 32015, 261, 6169, 89, 32096, 30, 51364], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 178, "seek": 77600, "start": 796.0, "end": 802.0, "text": " Zgodnie z wyliczeniami, gdy o\u015bmiokrotnie zwi\u0119kszamy rozmiar modelu, \u017ceby zrobi\u0107 to optymalnie,", "tokens": [51364, 1176, 21787, 2766, 710, 4628, 1050, 2904, 15568, 11, 28405, 277, 1788, 3057, 453, 10536, 2766, 11873, 5034, 1694, 89, 7804, 9544, 3057, 289, 2316, 84, 11, 11316, 31785, 281, 2427, 4199, 304, 2766, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06479490337087147, "compression_ratio": 1.4727272727272727, "no_speech_prob": 0.10564759373664856}, {"id": 179, "seek": 80200, "start": 802.0, "end": 806.0, "text": " b\u0119dziemy tylko pi\u0119ciokrotnie wi\u0119cej danych, a nie o\u015bmiokrotnie.", "tokens": [50364, 31966, 13219, 32677, 537, 453, 10536, 2766, 26004, 274, 34644, 11, 257, 2838, 277, 1788, 3057, 453, 10536, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 180, "seek": 80200, "start": 806.0, "end": 811.0, "text": " Czyli zapotrzebowanie na moc, obliczeniow\u0105 i rozmiar modelu ro\u015bnie szybciej ni\u017c zapotrzebowanie na dane?", "tokens": [50564, 37099, 14223, 310, 13503, 8202, 7155, 1667, 34962, 11, 1111, 1050, 42124, 30297, 741, 9544, 3057, 289, 2316, 84, 744, 12221, 36456, 4260, 73, 28502, 14223, 310, 13503, 8202, 7155, 1667, 49206, 30, 50814], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 181, "seek": 80200, "start": 811.0, "end": 812.0, "text": " Tak.", "tokens": [50814, 9118, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 182, "seek": 80200, "start": 812.0, "end": 817.0, "text": " I to jest w pewnym sensie dobra wiadomo\u015b\u0107, bo zaczynamy zderza\u0107 si\u0119 ze \u015bcian\u0105,", "tokens": [50864, 286, 281, 3492, 261, 47160, 4199, 2923, 414, 360, 6198, 26393, 40633, 7753, 11, 748, 43811, 5378, 88, 710, 1068, 35873, 3244, 5277, 220, 6199, 282, 1611, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 183, "seek": 80200, "start": 817.0, "end": 821.0, "text": " je\u015bli chodzi o ilo\u015b\u0107 wysokiej jako\u015bci danych tekstowych w internecie.", "tokens": [51114, 25630, 23998, 277, 1930, 78, 7753, 27062, 453, 7764, 17123, 6199, 274, 34644, 16624, 372, 19605, 261, 728, 716, 4260, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 184, "seek": 80200, "start": 821.0, "end": 823.0, "text": " Zasoby s\u0105 sko\u0144czone.", "tokens": [51314, 1176, 296, 13944, 9015, 1110, 78, 5248, 3689, 546, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 185, "seek": 80200, "start": 823.0, "end": 829.0, "text": " W\u0142a\u015bnie. Ta praca pokaza\u0142a, \u017ce to rozmiar modelu jest g\u0142\u00f3wnym motorem post\u0119pu.", "tokens": [51414, 343, 5024, 12221, 13, 6551, 582, 6628, 13010, 12257, 5024, 11, 3561, 281, 9544, 3057, 289, 2316, 84, 3492, 18117, 812, 895, 4199, 2184, 37956, 2183, 18085, 84, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07685133496170524, "compression_ratio": 1.5033557046979866, "no_speech_prob": 0.14702695608139038}, {"id": 186, "seek": 82900, "start": 829.0, "end": 832.0, "text": " To przesun\u0119\u0142o punkt ci\u0119\u017cko\u015bci bada\u0144 w ca\u0142ej dziedzinie.", "tokens": [50364, 1407, 6541, 279, 409, 1274, 5249, 39561, 35484, 1427, 4093, 6199, 272, 1538, 5248, 261, 47631, 73, 9758, 15338, 259, 414, 13, 50514], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 187, "seek": 82900, "start": 832.0, "end": 837.0, "text": " Skupiono si\u0119 na metodach trenowania ogromnych sieci, jak model paralelizm", "tokens": [50514, 7324, 1010, 49020, 3244, 1667, 1131, 378, 608, 23136, 21308, 34416, 298, 9399, 2804, 537, 11, 4207, 2316, 26009, 338, 590, 76, 50764], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 188, "seek": 82900, "start": 837.0, "end": 840.0, "text": " i na projektowaniu specjalistycznego sprz\u0119tu.", "tokens": [50764, 741, 1667, 26261, 305, 25849, 46433, 468, 17466, 11858, 6103, 11052, 9179, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 189, "seek": 82900, "start": 840.0, "end": 842.0, "text": " Ale to nie mo\u017ce trwa\u0107 wiecznie, prawda?", "tokens": [50914, 9366, 281, 2838, 12034, 504, 25234, 3355, 19923, 11, 43607, 30, 51014], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 190, "seek": 82900, "start": 842.0, "end": 846.0, "text": " Musi by\u0107 jaka\u015b \u015bciana, model nie mo\u017ce osi\u0105gn\u0105\u0107 zerowego los.", "tokens": [51014, 3569, 72, 15069, 4207, 64, 1788, 220, 6199, 2095, 11, 2316, 2838, 12034, 3003, 11404, 4568, 36374, 44746, 26576, 1750, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 191, "seek": 82900, "start": 846.0, "end": 847.0, "text": " Oczywi\u015bcie, \u017ce nie.", "tokens": [51214, 42980, 11, 3561, 2838, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 192, "seek": 82900, "start": 847.0, "end": 850.0, "text": " Bo to by oznacza\u0142o, \u017ce jest w stanie przewidzie\u0107 wszystko.", "tokens": [51264, 3286, 281, 538, 277, 22672, 326, 2394, 5249, 11, 3561, 3492, 261, 40013, 39758, 327, 21214, 22607, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 193, "seek": 82900, "start": 850.0, "end": 854.0, "text": " A j\u0119zyk naturalny ma w sobie co\u015b, co nazywamy niezerow\u0105 entropi\u0105.", "tokens": [51414, 316, 49055, 74, 3303, 1634, 463, 261, 13652, 19241, 11, 598, 20151, 27112, 7804, 2838, 4527, 30297, 948, 1513, 11404, 13, 51614], "temperature": 0.0, "avg_logprob": -0.05707023949023114, "compression_ratio": 1.4834437086092715, "no_speech_prob": 0.555751383304596}, {"id": 194, "seek": 85400, "start": 854.0, "end": 857.0, "text": " To zawsze b\u0119dzie w nim pewna doza nieprzewidywalno\u015bci,", "tokens": [50364, 1407, 30964, 10562, 261, 24887, 25889, 629, 360, 2394, 2838, 1424, 43551, 327, 27112, 304, 16438, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 195, "seek": 85400, "start": 857.0, "end": 859.0, "text": " dwuznaczno\u015bci, kreatywno\u015bci.", "tokens": [50514, 27379, 3334, 77, 14875, 16438, 11, 350, 620, 88, 20944, 6199, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 196, "seek": 85400, "start": 859.0, "end": 863.0, "text": " Nie da si\u0119 go w 100% skompresowa\u0107 do matematycznych wzorc\u00f3w.", "tokens": [50614, 12016, 1120, 3244, 352, 261, 2319, 4, 1110, 8586, 495, 11445, 360, 3803, 8615, 17466, 9399, 24809, 284, 29268, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 197, "seek": 85400, "start": 863.0, "end": 865.0, "text": " I sama praca to przewiduje.", "tokens": [50814, 286, 17768, 582, 6628, 281, 39758, 327, 13008, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 198, "seek": 85400, "start": 865.0, "end": 866.0, "text": " Tak.", "tokens": [50914, 9118, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 199, "seek": 85400, "start": 866.0, "end": 870.0, "text": " Sama praca przewiduje teoretyczny punkt za\u0142amania tych praw.", "tokens": [50964, 318, 2404, 582, 6628, 39758, 327, 13008, 535, 418, 874, 3689, 1634, 39561, 7949, 20177, 5609, 15180, 22508, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 200, "seek": 85400, "start": 870.0, "end": 875.0, "text": " Autorzy szacuj\u0105, \u017ce mo\u017ce on nast\u0105pi\u0107 przy modelach o rozmiarze bilion\u00f3w parametr\u00f3w.", "tokens": [51164, 6049, 284, 1229, 7870, 326, 13263, 11, 3561, 12034, 322, 26088, 1611, 79, 12757, 6501, 2316, 608, 277, 9544, 3057, 289, 1381, 8588, 313, 3901, 6220, 27965, 3901, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 201, "seek": 85400, "start": 875.0, "end": 877.0, "text": " To wci\u0105\u017c wi\u0119cej ni\u017c mamy dzisiaj.", "tokens": [51414, 1407, 261, 537, 27242, 26004, 28502, 17335, 25772, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 202, "seek": 85400, "start": 877.0, "end": 878.0, "text": " Mhm.", "tokens": [51514, 26272, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 203, "seek": 85400, "start": 878.0, "end": 881.0, "text": " Ale jest to ju\u017c jaka\u015b widoczna na horyzoncie granica.", "tokens": [51564, 9366, 3492, 281, 10678, 4207, 64, 1788, 5274, 905, 35458, 1667, 276, 827, 35296, 4260, 9370, 2262, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08343310925945546, "compression_ratio": 1.4485049833887043, "no_speech_prob": 0.5594674944877625}, {"id": 204, "seek": 88100, "start": 881.0, "end": 883.0, "text": " A samo badanie ma charakter empiryczny.", "tokens": [50364, 316, 36422, 1578, 7155, 463, 1290, 33557, 4012, 12781, 3689, 1634, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 205, "seek": 88100, "start": 883.0, "end": 886.0, "text": " Pokazuje, co dzia\u0142a, ale nie do ko\u0144ca dlaczego.", "tokens": [50464, 14958, 43317, 11, 598, 37903, 11, 6775, 2838, 360, 26470, 496, 37873, 39329, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 206, "seek": 88100, "start": 886.0, "end": 887.0, "text": " Tak.", "tokens": [50614, 9118, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 207, "seek": 88100, "start": 887.0, "end": 889.0, "text": " I autorzy s\u0105 tego w pe\u0142ni \u015bwiadomi.", "tokens": [50664, 286, 19510, 1229, 9015, 8627, 261, 43205, 3722, 21485, 345, 9220, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 208, "seek": 88100, "start": 889.0, "end": 892.0, "text": " Sami przyrownoj\u0105 swoje odkrycia do termodynamiki.", "tokens": [50764, 44029, 6501, 81, 648, 78, 8555, 29489, 3611, 43298, 2755, 360, 1433, 378, 5216, 9850, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 209, "seek": 88100, "start": 892.0, "end": 897.0, "text": " Opisuj\u0105 makroskopowe w\u0142a\u015bciwo\u015bci systemu, jak ci\u015bnienie i temperatura,", "tokens": [50914, 12011, 271, 13263, 963, 2635, 43855, 6880, 40112, 36476, 1185, 84, 11, 4207, 6983, 1788, 77, 27385, 741, 36903, 11, 51164], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 210, "seek": 88100, "start": 897.0, "end": 901.0, "text": " bez wchodzenia w szczeg\u00f3\u0142y ruchu pojedynczych cz\u0105steczek.", "tokens": [51164, 10782, 261, 29914, 14320, 261, 22090, 1146, 812, 6825, 367, 625, 84, 714, 40543, 2534, 6522, 339, 6472, 1611, 2941, 3689, 916, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 211, "seek": 88100, "start": 901.0, "end": 903.0, "text": " Co by\u0142oby zadaniem mechaniki statystycznej?", "tokens": [51364, 3066, 16673, 13944, 710, 11338, 4907, 4236, 9850, 2219, 38593, 17466, 11794, 30, 51464], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 212, "seek": 88100, "start": 903.0, "end": 904.0, "text": " W\u0142a\u015bnie.", "tokens": [51464, 343, 5024, 12221, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 213, "seek": 88100, "start": 904.0, "end": 907.0, "text": " Wcz\u0105\u017c czekamy na g\u0142\u0119bsz\u0105 teori\u0119, kt\u00f3ra wyja\u015bni\u0142aby,", "tokens": [51514, 343, 3689, 27242, 6472, 916, 7804, 1667, 18117, 1274, 929, 8925, 40238, 5034, 11, 19456, 4628, 2938, 1788, 3722, 1221, 2509, 11, 51664], "temperature": 0.0, "avg_logprob": -0.07494192123413086, "compression_ratio": 1.4129032258064516, "no_speech_prob": 0.021090485155582428}, {"id": 214, "seek": 90700, "start": 907.0, "end": 911.0, "text": " dlaczego akurat te wyk\u0142adniki pot\u0119gowe, a nie inne,", "tokens": [50364, 37873, 39329, 9308, 44108, 535, 4628, 15317, 77, 9850, 1847, 1274, 70, 6880, 11, 257, 2838, 24170, 11, 50564], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 215, "seek": 90700, "start": 911.0, "end": 914.0, "text": " rz\u0105dz\u0105 procesem uczenia si\u0119 sieci neuronowych.", "tokens": [50564, 367, 23876, 8925, 17565, 443, 344, 38517, 3244, 2804, 537, 34090, 19605, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 216, "seek": 90700, "start": 914.0, "end": 919.0, "text": " Znamy prawa, ale nie znamy jeszcze w pe\u0142ni ich fundamentalnego pochodzenia.", "tokens": [50714, 1176, 5378, 88, 3206, 4151, 11, 6775, 2838, 710, 5378, 88, 14168, 261, 43205, 3722, 1893, 8088, 11858, 714, 29914, 14320, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 217, "seek": 90700, "start": 919.0, "end": 920.0, "text": " Dobrze.", "tokens": [50964, 29679, 13503, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 218, "seek": 90700, "start": 920.0, "end": 921.0, "text": " To podsumujmy.", "tokens": [51014, 1407, 31925, 449, 4579, 2226, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 219, "seek": 90700, "start": 921.0, "end": 923.0, "text": " Czego si\u0119 dowiedzieli\u015bmy?", "tokens": [51064, 383, 27725, 3244, 9459, 15338, 23099, 10513, 30, 51164], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 220, "seek": 90700, "start": 923.0, "end": 927.0, "text": " Po pierwsze, skala jest wa\u017cniejsza ni\u017c kszta\u0142t.", "tokens": [51164, 6165, 45994, 11, 1110, 5159, 3492, 27777, 30295, 2394, 28502, 350, 15453, 46426, 83, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 221, "seek": 90700, "start": 927.0, "end": 932.0, "text": " Liczba parametr\u00f3w m\u00f3zg modelu jest kluczowa, a nie finezyjna architektura.", "tokens": [51364, 441, 17946, 4231, 6220, 27965, 3901, 32515, 89, 70, 2316, 84, 3492, 9671, 1311, 89, 5528, 11, 257, 2838, 2489, 1229, 73, 629, 3912, 642, 2320, 2991, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 222, "seek": 90700, "start": 932.0, "end": 933.0, "text": " Mhm.", "tokens": [51614, 26272, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06218482123480903, "compression_ratio": 1.3632958801498127, "no_speech_prob": 0.07893318682909012}, {"id": 223, "seek": 93300, "start": 933.0, "end": 937.0, "text": " Po drugie, wydajno\u015b\u0107 ro\u015bnie w przewidywalny matematyczny spos\u00f3b,", "tokens": [50364, 6165, 4110, 414, 11, 25984, 1805, 23293, 744, 12221, 261, 39758, 327, 27112, 304, 1634, 3803, 8615, 17466, 1634, 22904, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 224, "seek": 93300, "start": 937.0, "end": 939.0, "text": " zgodnie z prawami mocy.", "tokens": [50564, 710, 21787, 2766, 710, 22508, 4526, 705, 1344, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 225, "seek": 93300, "start": 939.0, "end": 943.0, "text": " To zamieni\u0142o rozw\u00f3j AI ze zgadywanki w in\u017cynieri\u0119.", "tokens": [50664, 1407, 19876, 35462, 5249, 9544, 86, 18999, 7318, 5277, 40948, 880, 86, 27203, 261, 294, 1427, 2534, 811, 5034, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 226, "seek": 93300, "start": 943.0, "end": 944.0, "text": " Zdecydowanie.", "tokens": [50864, 1176, 1479, 1344, 67, 22028, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 227, "seek": 93300, "start": 944.0, "end": 947.0, "text": " I po trzecie, co chyba najbardziej kontrointuicyjne.", "tokens": [50914, 286, 714, 22266, 4260, 11, 598, 31532, 41857, 14373, 340, 686, 84, 2632, 73, 716, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 228, "seek": 93300, "start": 947.0, "end": 949.0, "text": " Maj\u0105c ograniczony but\u017cet,", "tokens": [51064, 7048, 1611, 66, 34416, 282, 17946, 2526, 457, 1427, 302, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 229, "seek": 93300, "start": 949.0, "end": 954.0, "text": " najefektywniejsze jest trenowa\u0107 ogromne modele, ale nie do samego ko\u0144ca.", "tokens": [51164, 11212, 5666, 916, 874, 895, 7764, 82, 1381, 3492, 23136, 11445, 34416, 298, 716, 4391, 306, 11, 6775, 2838, 360, 912, 1571, 26470, 496, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 230, "seek": 93300, "start": 954.0, "end": 956.0, "text": " To jest doskona\u0142e podsumowanie.", "tokens": [51414, 1407, 3492, 4491, 74, 4037, 19827, 31925, 449, 22028, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 231, "seek": 93300, "start": 956.0, "end": 959.0, "text": " Te trzy zasady, cho\u0107 proste w swoim brzmieniu,", "tokens": [51514, 1989, 34573, 26530, 880, 11, 1586, 2162, 10293, 68, 261, 13291, 332, 738, 89, 76, 1053, 5951, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08436848567082332, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.08489023149013519}, {"id": 232, "seek": 95900, "start": 959.0, "end": 963.0, "text": " zdefiniowa\u0142y ca\u0142\u0105 dekad\u0119 bada\u0144 nad du\u017cymi modelami j\u0119zykowymi", "tokens": [50364, 710, 20595, 3812, 5528, 6825, 1335, 15926, 368, 34985, 1274, 272, 1538, 5248, 12617, 1581, 7735, 3057, 2316, 4526, 49055, 74, 10089, 3057, 50564], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 233, "seek": 95900, "start": 963.0, "end": 967.0, "text": " i zaprowadzi\u0142y nas do miejsca, w kt\u00f3rym jeste\u015bmy dzisiaj.", "tokens": [50564, 741, 14223, 1892, 345, 3992, 6825, 5382, 360, 18522, 44239, 11, 261, 30120, 35928, 25772, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 234, "seek": 95900, "start": 967.0, "end": 970.0, "text": " Na koniec zostawmy naszych s\u0142uchaczy z czym\u015b do przemy\u015blenia.", "tokens": [50764, 6056, 5897, 35733, 31873, 1607, 2226, 45002, 15116, 625, 14691, 710, 31466, 1788, 360, 6541, 3633, 1788, 6698, 654, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 235, "seek": 95900, "start": 970.0, "end": 974.0, "text": " Zastan\u00f3wmy si\u0119 nad tym przewidywanym punktem za\u0142amania praw skali.", "tokens": [50914, 1176, 525, 282, 3901, 2226, 3244, 12617, 8107, 39758, 327, 27112, 1325, 76, 39561, 443, 7949, 20177, 5609, 22508, 1110, 5103, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 236, "seek": 95900, "start": 974.0, "end": 976.0, "text": " T\u0105 \u015bcian\u0105, do kt\u00f3rej zmierzamy.", "tokens": [51114, 314, 1611, 220, 6199, 282, 1611, 11, 360, 36023, 17020, 34602, 7804, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 237, "seek": 95900, "start": 976.0, "end": 977.0, "text": " Tak.", "tokens": [51214, 9118, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 238, "seek": 95900, "start": 977.0, "end": 981.0, "text": " Czy ten punkt mo\u017ce oznaczy\u0107 co\u015b wi\u0119cej ni\u017c tylko techniczn\u0105 granic\u0119?", "tokens": [51264, 19832, 2064, 39561, 12034, 277, 22672, 14691, 2162, 19241, 26004, 28502, 13219, 1537, 17946, 13113, 9370, 299, 1274, 30, 51464], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 239, "seek": 95900, "start": 981.0, "end": 984.0, "text": " By\u0107 mo\u017ce jest to fundamentalna granica tego,", "tokens": [51464, 3146, 2162, 12034, 3492, 281, 8088, 629, 9370, 2262, 8627, 11, 51614], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 240, "seek": 95900, "start": 984.0, "end": 987.0, "text": " co mo\u017cna wydoby\u0107 z danych j\u0119zykowych,", "tokens": [51614, 598, 17790, 25984, 13944, 2162, 710, 274, 34644, 49055, 74, 19605, 11, 51764], "temperature": 0.0, "avg_logprob": -0.05380390263810943, "compression_ratio": 1.465625, "no_speech_prob": 0.0781429260969162}, {"id": 241, "seek": 98700, "start": 987.0, "end": 990.0, "text": " w spos\u00f3b czysto statystyczny i przewidywalny.", "tokens": [50364, 261, 22904, 6430, 20875, 2219, 38593, 17466, 1634, 741, 39758, 327, 27112, 304, 1634, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 242, "seek": 98700, "start": 990.0, "end": 993.0, "text": " Czyli pr\u00f3g, za kt\u00f3rym jest ju\u017c co\u015b innego.", "tokens": [50514, 37099, 8565, 70, 11, 7949, 30120, 3492, 10678, 19241, 294, 11858, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 243, "seek": 98700, "start": 993.0, "end": 994.0, "text": " By\u0107 mo\u017ce.", "tokens": [50664, 3146, 2162, 12034, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 244, "seek": 98700, "start": 994.0, "end": 998.0, "text": " Pr\u00f3g, za kt\u00f3rym znajduje si\u0119 ju\u017c tylko ta nieredukowalna entropia,", "tokens": [50714, 2114, 812, 70, 11, 7949, 30120, 47570, 2884, 3244, 10678, 13219, 1846, 297, 811, 292, 2034, 305, 304, 629, 948, 1513, 654, 11, 50914], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 245, "seek": 98700, "start": 998.0, "end": 1003.0, "text": " prawdziwa z\u0142o\u017cono\u015b\u0107, kreatywno\u015b\u0107 i nieprzewidywalno\u015b\u0107 ludzkiego j\u0119zyka,", "tokens": [50914, 41175, 3992, 4151, 710, 5249, 1427, 8957, 7753, 11, 350, 620, 88, 20944, 7753, 741, 2838, 1424, 43551, 327, 27112, 304, 23293, 15946, 30154, 12200, 42309, 40940, 11, 51164], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 246, "seek": 98700, "start": 1003.0, "end": 1006.0, "text": " kt\u00f3rej nie da si\u0119 ju\u017c skompresowa\u0107 do prostszych wzorc\u00f3w.", "tokens": [51164, 36023, 2838, 1120, 3244, 10678, 1110, 8586, 495, 11445, 360, 10293, 45021, 24809, 284, 29268, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 247, "seek": 98700, "start": 1006.0, "end": 1007.0, "text": " I co wtedy?", "tokens": [51314, 286, 598, 26959, 30, 51364], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 248, "seek": 98700, "start": 1007.0, "end": 1008.0, "text": " No w\u0142a\u015bnie.", "tokens": [51364, 883, 14234, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 249, "seek": 98700, "start": 1008.0, "end": 1012.0, "text": " Co si\u0119 stanie, gdy nasze modele dotr\u0105 do tej granicy?", "tokens": [51414, 3066, 3244, 40013, 11, 28405, 43394, 4391, 306, 5893, 32881, 360, 12573, 9370, 2632, 30, 51614], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 250, "seek": 98700, "start": 1012.0, "end": 1015.0, "text": " Jakiego rodzaju inteligencj\u0119 wtedy osi\u0105gn\u0105?", "tokens": [51614, 15029, 12200, 28607, 33166, 24777, 3213, 41960, 26959, 3003, 11404, 4568, 1611, 30, 51764], "temperature": 0.0, "avg_logprob": -0.06183823001000189, "compression_ratio": 1.5067114093959733, "no_speech_prob": 0.03781117871403694}, {"id": 251, "seek": 101500, "start": 1015.0, "end": 1020.0, "text": " Goro ca\u0142a ta \u0142atwa, statystyczna wiedza o \u015bwiecie zostanie ju\u017c przez nieprzyswojona.", "tokens": [50364, 460, 10780, 1335, 5024, 1846, 47759, 4151, 11, 2219, 38593, 17466, 629, 46894, 2394, 277, 40078, 4260, 31873, 7155, 10678, 14064, 2838, 1424, 89, 749, 6120, 73, 4037, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09854829458542812, "compression_ratio": 1.3195876288659794, "no_speech_prob": 0.3520701825618744}, {"id": 252, "seek": 101500, "start": 1020.0, "end": 1024.0, "text": " Czy to jest ten moment, w kt\u00f3rym skalowanie przestaje wystarcza\u0107", "tokens": [50614, 19832, 281, 3492, 2064, 1623, 11, 261, 30120, 16890, 22028, 44264, 11153, 4628, 9710, 66, 35873, 50814], "temperature": 0.0, "avg_logprob": -0.09854829458542812, "compression_ratio": 1.3195876288659794, "no_speech_prob": 0.3520701825618744}, {"id": 253, "seek": 101500, "start": 1024.0, "end": 1027.0, "text": " i do prawdziwego skoku w kierunku og\u00f3lnej inteligencji", "tokens": [50814, 741, 360, 41175, 3992, 826, 1571, 1110, 13275, 261, 38767, 49910, 5360, 15741, 11794, 24777, 3213, 19649, 50964], "temperature": 0.0, "avg_logprob": -0.09854829458542812, "compression_ratio": 1.3195876288659794, "no_speech_prob": 0.3520701825618744}, {"id": 254, "seek": 101500, "start": 1027.0, "end": 1030.0, "text": " b\u0119dzie potrzebny zupe\u0142nie nowy paradygmat?", "tokens": [50964, 10562, 37595, 1634, 49922, 586, 88, 13480, 18103, 15677, 30, 51114], "temperature": 0.0, "avg_logprob": -0.09854829458542812, "compression_ratio": 1.3195876288659794, "no_speech_prob": 0.3520701825618744}], "language": "pl"}