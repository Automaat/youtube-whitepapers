{"text": " Co by by\u0142o, gdyby\u015bmy mogli trenowa\u0107 modele AI o skali, powiedzmy, biliona parametr\u00f3w? I to na sprz\u0119cie, kt\u00f3re mamy dzi\u015b. Brzmi jak science fiction, prawda? A jednak to jest dok\u0142adnie to pytanie, kt\u00f3re postawili sobie badacze z Microsoftu. Kiedy my\u015blimy o trenowaniu wielkich modeli, no to pierwsze, co przychodzi do g\u0142owy, to gigantyczna moc obliczeniowa. Ale jest jeszcze jedna, chyba bardziej podst\u0119pna bariera. Pami\u0119\u0107. We\u017amy taki przyk\u0142ad z artyku\u0142u. Model GPT-2, ten o wielko\u015bci 1,5 miliarda parametr\u00f3w, sam plik z wagami modelu zajmuje, wiesz, jakie\u015b 3 GB. Ale \u017ceby go trenowa\u0107, potrzeba ponad 24 GB pami\u0119ci, na jednej karcie graficznej. To jest o\u015bmiokrotnie wi\u0119cej. Gdzie Ulicha podziewa si\u0119 ca\u0142a reszta? I w\u0142a\u015bnie t\u0119 zagadk\u0119 rozwi\u0105zuje praca, kt\u00f3r\u0105 dzi\u015b bierzemy pod lup\u0119. Praca wprowadzaj\u0105ca technologi\u0119 o nazwie zero. Zero redundancy optimizer. Dok\u0142adnie. A naszym celem dzisiaj jest nie tylko zrozumie\u0107 jak zero to robi, ale te\u017c dlaczego to by\u0142o tak rewolucyjne. Bo to nie jest jaka\u015b tam kolejna, drobna optymalizacja. To jest fundamentalna zmiana sposobu my\u015blenia o zasobach. Dlatego nasz\u0105 rozmow\u0119 podzielimy na trzy cz\u0119\u015bci. Najpierw dok\u0142adnie zdiagnozujemy, co jest tym niewidzialnym balastem, kt\u00f3ry po\u017cera ca\u0142\u0105 pami\u0119\u0107 GPU. Potem krok po kroku prze\u015bledzimy t\u0119 genialn\u0105 w swojej prostocie logik\u0119 zero. Czyli bezlitosn\u0105 eliminacj\u0119 redundancji. A na koniec sprawdzimy, czy to wszystko w og\u00f3le zadzia\u0142a\u0142o w praktyce i jakie drzwi otworzy\u0142o. A otworzy\u0142o i to z hookiem drzwi do stworzenia jednego z najwi\u0119kszych w\u00f3wczas modeli j\u0119zykowych. Turing NLG. To jest naprawd\u0119 niesamowite, \u017ce model zajmuje 3 Giga, a training 24. Musimy wi\u0119c zacz\u0105\u0107 od tego niewidzialnego balastu. Gdzie tak naprawd\u0119 ucieka ca\u0142a ta pami\u0119\u0107? Najpopularniejszym podej\u015bciem do skalowania treningu jest od lat Data Parallelizm. Dlaczego ono, mimo \u017ce jest takie proste, nagle przesta\u0142o wystarcza\u0107. Data Parallelizm w skr\u00f3cie DP jest genialne w swojej prostocie. Mamy wiele kart graficznych, wi\u0119c na ka\u017cd\u0105 z nich wysy\u0142amy pe\u0142n\u0105 kopi\u0119 modelu i ka\u017cda mieli inn\u0105 porcj\u0119 danych. Na koniec synchronizujemy wyniki. Proste. I to dzia\u0142a \u015bwietnie dop\u00f3ki model mie\u015bci si\u0119 w pami\u0119ci pojedynczej karty. Problem pojawia si\u0119, gdy model ro\u015bnie, bo w DP ka\u017cda karta graficzna, powiedzmy, \u017ce mamy ich 64, przechowuje identyczn\u0105 pe\u0142n\u0105 kopi\u0119 wszystkiego. Nie tylko parametr\u00f3w modelu, ale te\u017c gradient\u00f3w i stan\u00f3w optymalizatora. Masz wi\u0119c 64 identyczne kopie tych samych gigantycznych zbior\u00f3w danych. To jest po prostu definicja redundacji i marnotrastwa. Ok, czyli to jest tak. Jak by\u015bmy chcieli zbudowa\u0107 64 identyczne samochody i zamiast jednej fabryki, budujemy 64 ma\u0142e fabryczki i ka\u017cda z nich ma pe\u0142en zestaw cz\u0119\u015bci do ca\u0142ego samochodu, czyli mo\u017ce sk\u0142ada tylko jedne drzwi. Brzmi absurdalnie. A co z alternatyw\u0105, czyli model paralelizm? Tam przecie\u017c dzielimy model, a nie dane. Dok\u0142adnie. Model paralelizm. MP. Na papierze wydaje si\u0119 idealnym rozwi\u0105zaniem. Kroimy model na kawa\u0142ki i ka\u017cdy kawa\u0142ek umieszczamy na innej karcie graficznej. Problem w tym, \u017ce to jest logistyczny koszmar. Wyobra\u017a sobie, \u017ce kroisz tort na 16 kawa\u0142k\u00f3w i ka\u017cdy kawa\u0142ek wys\u0142asz kurrierem do innego miasta, \u017ceby go tam udekorowano. A potem te kawa\u0142ki musz\u0105 si\u0119 mi\u0119dzy sob\u0105 wymienia\u0107, bo dekoracja jednego zale\u017cy od drugiego. Ilo\u015b\u0107 komunikacji i tej ca\u0142ej synchronizacji mi\u0119dzy tymi kawa\u0142kami ro\u015bnie lawinowo. Autorzy prac\u0119 podaj\u0105 brutalny przyk\u0142ad. Pr\u00f3ba trenowania modelu o 40 miliardach parametr\u00f3w z u\u017cyciem MP na dw\u00f3ch, pot\u0119\u017cnych serwerach sprawi\u0142a, \u017ce wydajno\u015b\u0107 spad\u0142a do mniej ni\u017c 5% teoretycznej mocy obliczeniowej GPU. Tak, to znaczy, \u017ce przez 95% czasu karty graficzne po prostu czeka\u0142y na dane. To jest \u015blepa uliczka. Rozumiem. Czyli DPI jest proste, ale marnotrawne pami\u0119ciowo, a MP oszcz\u0119dza pami\u0119\u0107, ale zabija wydajno\u015b\u0107 przez komunikacj\u0119. Mamy pad. I tu w\u0142a\u015bnie wchodzi zero. Zanim przejdziemy do samego rozwi\u0105zania, rozbijmy jeszcze tego g\u0142\u00f3wnego po\u017ceracza pami\u0119ci naczynniki pierwsze. Wspomnia\u0142e\u015b o parametrach, gradientach i stanach optymalizatora. Tak, ta codziewi z u\u017cycie pami\u0119ci na dwie kategorie. Pierwsza i absolutnie kluczowa to s\u0105 model states. W jej sk\u0142ad wchodz\u0105 trzy elementy. Same parametry modelu, parameters, gradienty, gradients, czyli te pochodne m\u00f3wi\u0105ce jak aktualizowa\u0107 parametry, no i stan\u0119 optymalizatora, optimizer states. I to jest ten cichwy zab\u00f3jca. Je\u015bli u\u017cywamy popularnego optymalizatora Adam, to do ka\u017cdego parametru musi on przechowywa\u0107 dwie dodatkowe warto\u015bci. Pent, czyli momentum i wariancie variance. Je\u015bli dodamy do tego trening w mixed precision, kt\u00f3ry te\u017c wymaga przechowywania kopii pewnych danych, to dochodzimy do szokuj\u0105cej liczby, kt\u00f3r\u0105 podaj\u0105 autorzy. Na ka\u017cdy jeden parametr modelu przypada 16 bite\u00f3w pami\u0119ci zu\u017cywanej przez model states. A\u017c 16? Tak. Czyli model o miliardzie parametr\u00f3w potrzebuje 16 gigabyte\u00f3w i to jest g\u0142\u00f3wny winowajca. A ta druga ta teoria? Druga to residual states. To jest ca\u0142a lepszta aktywacje, activations, kt\u00f3re trzeba trzyma\u0107 w pami\u0119cie, \u017ceby obliczy\u0107 gradienty, jakie\u015b tymczasowe bufory do operacji, temporary buffers i pofragmentowana pami\u0119\u0107. To te\u017c jest problem, ale znacznie mniejszy. Zero zajmuje si\u0119 obiema kategoriami, ale prawdziwa rewolucja zaczyna si\u0119 od model states. Ok, czyli mamy zdiagnozowanego g\u0142\u00f3wnego winowajce i tu dochodzimy do tego momentu, aha. Kluczowy wgl\u0105d autor\u00f3w zero jest po prostu genialny. Te wszystkie stany modelu nie s\u0105 potrzebne przez ca\u0142y czas na ka\u017cdym GPU jednocze\u015bnie. I to jest sedno. U\u017cyjmy twojej analogii z kucharzami i wielkim daniem. W standardowym DP ka\u017cdy kucharz dostaje na start pe\u0142n\u0105 list\u0119 sk\u0142adnik\u00f3w na ca\u0142y przepis i trzyma je przy sobie przez ca\u0142y czas. Zero DP m\u00f3wi stop. Kucharz numer jeden potrzebuje teraz tylko m\u0105ki i jajek, \u017ceby zrobi\u0107 ciasto. Dajmy mu tylko to. Gdy sko\u0144czy, przeka\u017ce ciasto kucharzowi numer dwa, kt\u00f3ry potrzebuje tylko cukru i owoc\u00f3w. Dajmy mu tylko to. Chodzi o to, by dostarcza\u0107 zasoby dynamicznie, dok\u0142adnie wtedy i tam, gdzie s\u0105 potrzebne. A nie replikowa\u0107 wszystko wsz\u0119dzie na wszelki wypadek. I nad tej zasadzie opiera si\u0119 z serce tej technologii. Zero DP. I z tego, co czytam, podzielili to na trzy etapy. Zacznijmy od pierwszego. Etap pierwszy to optimizer state partitioning. W skr\u00f3cie pos. Zamiast replikowa\u0107 stany optimalizatora na ka\u017cdym GPU, po prostu dzielimy je r\u00f3wno pomi\u0119dzy wszystkie procesy. Je\u015bli mamy osiem kart graficznych, ka\u017cda przechowuje i aktualizuje tylko jedn\u0105 usm\u0105 tych stan\u00f3w. Proste. Ale efekt jest pot\u0119\u017cny. Autorzy podaj\u0105, \u017ce to ju\u017c na starcie daje czterokrotn\u0105 redukcj\u0119 zu\u017cycia pami\u0119ci. Czekaj, czterokrotna redukcja to jest ogromny zysk. Ale co najwa\u017cniejsze, oni pisz\u0105, \u017ce to nie generuje \u017cadnych dodatkowych koszt\u00f3w komunikacji w por\u00f3wnaniu do standardowego DP. Jak to w og\u00f3le mo\u017cliwe? To jest \u015bwietne pytanie. Dzieje si\u0119 tak, poniewa\u017c w standardowym DP i tak musisz na koniec zebra\u0107 wszystkie gradienty ze wszystkich kart i je u\u015bredni\u0107 za pomoc\u0105 operacji All Reduce. In\u017cynierowie Zero wpadli na pomys\u0142, \u017ceby po\u0142\u0105czy\u0107 t\u0119 operacj\u0119 z dystrybucj\u0105 odpowiednich fragment\u00f3w stan\u00f3w optimalizatora. Zamiast robi\u0107 dwie osobne operacje, robi\u0105 jedn\u0105 sprytniejsz\u0105, kt\u00f3ra osi\u0105ga oba cele za jednym zamachem. Dlatego zysk pami\u0119ci jest, mo\u017cna powiedzie\u0107, darmowy z perspektywy komunikacji. Rozumiem, czyli to ju\u017c jest imponuj\u0105ce. Ale wci\u0105\u017c mamy zreplikowane gradienty i parametry, kt\u00f3re te\u017c s\u0105 ogromne. Domy\u015blam si\u0119, \u017ce to jest cel drugiego etapu. Dok\u0142adnie tak. I do tego samego wniosku doszli autorzy. Dlatego wprowadzili etap dwa. Gradient Partitioning, oznaczany jako POS plus G. Tutaj, opr\u00f3cz stan\u00f3w optimalizatora, dzielimy r\u00f3wnie\u017c gradienty. Ka\u017cdy proces GPU jest odpowiedziany tylko za aktualizacj\u0119 swojej cz\u0119\u015bci parametr\u00f3w. Wi\u0119c potrzebuje tylko tych gradient\u00f3w, kt\u00f3re odpowiadaj\u0105 tej cz\u0119\u015bci. Reszty nie musi przechowywa\u0107. Chwila, czyli znowu dzielimy wi\u0119cej danych. Ale w artykule czytam, \u017ce wolumen komunikacji wci\u0105\u017c pozostaje taki sam jak w standardowym DP. To brzmu jak czarna magia. Gdzie jest haczyk? Jak mo\u017cna oszcz\u0119dzi\u0107 dwa razy wi\u0119cej pami\u0119ci, ale koszt komunikacji w og\u00f3le nie ro\u015bnie? To nie magia. Tylko bardzo sprytna in\u017cynieria komunikacji. Zamiast standardowej operacji AllReduce, kt\u00f3ra wysy\u0142a wszystkie gradienty do wszystkich, u\u017cywaj\u0105 operacji Reduce Scatter. Ka\u017cdy GPU oblicza swoj\u0105 porcj\u0119 gradient\u00f3w, a potem ta operacja redukuje je, na przyk\u0142ad sumuje, i od razu rozsiewa, czyli Scatters, odpowiednie ju\u017c zsumowane fragmenty do w\u0142a\u015bciwych procesor\u00f3w. Ka\u017cdy dostaje tylko to, co jest mu potrzebne. Okazuje si\u0119, \u017ce ca\u0142kowita ilo\u015b\u0107 danych przesy\u0142anych przez sie\u0107 jest identyczna jak w AllReduce. Czyli haczyka nie ma? Nie ma. Efekt jest taki, \u017ce uzyskujemy ju\u017c o\u015bmiokrotn\u0105 redukcj\u0119 zu\u017cycia pami\u0119ci wci\u0105\u017c bez dodatkowego narzutu komunikacyjnego. To jest absolutnie genialne, czyli po dw\u00f3ch etapach mamy o\u015bmiokrotnie mniejsze zapotrzebowanie na pami\u0119\u0107, ale wci\u0105\u017c na ka\u017cdej karcie siedzi pe\u0142na kopia parametr\u00f3w modelu. I to prowadzi nas do etapu trzeciego, tego ostatecznego. Tak, etap 3, Parameter Partitioning, czyli POS plus G plus P. Na koniec dzielimy same parametry modelu. To jest najbardziej radykalny krok. Wyobra\u017amy sobie, \u017ce ka\u017cda karta GPU w danym momencie widzi tylko t\u0119 cz\u0119\u015b\u0107 modelu, nad kt\u00f3r\u0105 akurat pracuje. A reszta jest dla niej niewidoczna, dop\u00f3ki nie b\u0119dzie potrzebna. Kiedy przychodzi czas na obliczenia w danej warstwie sieci, odpowiednie parametry s\u0105 dynamicznie przesy\u0142ane w locie do wszystkich kart za pomoc\u0105 operacji AllGather. Po wykonaniu oblicze\u0144 s\u0105 one zwalniane z pami\u0119ci. Efekt ko\u0144cowy. Redukcja pami\u0119ci staje si\u0119 liniowo zale\u017cna od liczby u\u017cywanych GPU. Je\u015bli mamy 64 karty, teoretyczna redukcja jest 64-krotna. No dobrze, ale tu ju\u017c musi by\u0107 jaki\u015b koszt. Przesy\u0142anie parametr\u00f3w w prz\u00f3d i w ty\u0142 przy ka\u017cdej warstwie brzmi jak ogromny narzut. Autorzy sami przyznaj\u0105, \u017ce og\u00f3lna komunikacja wzrasta o 50%. Czy ten wzrost nie staje si\u0119 w\u0105skim gard\u0142em przy naprawd\u0119 du\u017cej skali, powiedzmy na tysi\u0105cach GPU? Czy zysk z pami\u0119\u0107 nie jest niwelowany przez czas oczekiwania na dane? To jest kluczowa obawa i autorzy \u015bwietnie j\u0105 adresuj\u0105. Po pierwsze, ten 50% wzrost to jest ca\u0142kowita obj\u0119to\u015b\u0107 danych. Te operacje s\u0105 jednak zaimplementowane tak, by maksymalnie nak\u0142ada\u0107 komunikacj\u0119 z obliczeniami. Nowoczesne, szybkie interkonekty jak InfiniBend czy Enfulink s\u0105 zaprojektowane do takich zada\u0144. Ale co wa\u017cniejsze jest drugi, bardziej subtelny efekt. Uwolniona pami\u0119\u0107 pozwala na u\u017cycie znacznie wi\u0119kszych batch sizes, czyli jednorazowych porcji danych treningowych. A im wi\u0119kszy batch size, tym bardziej efektywnie pracuje samo GPU. Koszt komunikacji jest amortyzowany przez znacznie wi\u0119ksz\u0105 ilo\u015b\u0107 u\u017cytecznych oblicze\u0144. W praktyce dla bardzo du\u017cych modeli ten kompromis jest niezwykle op\u0142acalny. Dzi\u0119ki temu jak podaj\u0105 w pracy model o bilionie parametr\u00f3w mie\u015bci si\u0119 na 1024 kartach GPU. To otwiera zupe\u0142nie nowe horyzonty. Ok, czyli poskromili\u015bmy smoka zwanego model states, ale m\u00f3wi\u0142e\u015b, \u017ce s\u0105 jeszcze te mniejsze denerwuj\u0105ce problemy, czyli residual states. Po takiej optymizacji to one pewnie staj\u0105 si\u0119 nowym w\u0105skim gard\u0142em. Co zrobiono z aktywacjami? Dok\u0142adnie. Gdy wyeliminujesz g\u0142\u00f3wny problem, te drugorz\u0119dne wychodz\u0105 na pierwszy plan. I tu wkracza 0R. Radzi sobie z tym na kilka sposob\u00f3w. Pierwsza technika to Partition Activation Checkpointing. Checkpointing aktywacji to znana technika. Trzyma\u0107 wszystkie aktywacje w pami\u0119ci zapami\u0119tujemy je co kilka warstw, a w razie potrzeby przeliczamy na nowo. Zero idzie okrok dalej. Dzieli nawet te zapami\u0119tane aktywacje mi\u0119dzy r\u00f3\u017cne GPU. A je\u015bli to wci\u0105\u017c za ma\u0142o, mo\u017ce je nawet zrzuci\u0107 do pami\u0119ci RAM procesora, czyli zrobi\u0107 tzw. offload. Ale zrzucanie danych z superszytkiej pami\u0119ci GPU do znacznie wolniejszej pami\u0119ci RAM procesora to nie brzmi jak dobry pomys\u0142 na wydajno\u015b\u0107. Czy to nie spowalnia wszystkiego do \u015blimaczego tempa? Intuicyjnie tak, ale w przypadku gigantycznych modeli okazuje si\u0119 to zaskakuj\u0105co efektywne. Dzieje si\u0119 tak, poniewa\u017c te modele s\u0105 tak bardzo compute bound, czyli ilo\u015b\u0107 oblicze\u0144 jest tak du\u017ca w stosunku do ilo\u015bci danych, \u017ce ten transfer do i z CPU mo\u017cna niemal ca\u0142kowicie ukry\u0107 za czasem, kt\u00f3ry GPU i tak sp\u0119dza na mieleniu liczb. To kolejny przyk\u0142ad my\u015blenia o ca\u0142ym systemie, a nie tylko o jednym komponencie. Opr\u00f3cz tego 0R wprowadza jeszcze dwie techniki. Constant size buffers, \u017ceby bufory tymczasowe nie ros\u0142y razem z modelem. Oraz memory defragmentation, czyli aktywne zarz\u0105dzanie pami\u0119ci\u0105, by unika\u0107 b\u0142\u0119d\u00f3w out of memory nawet gdy teoretycznie jest jeszcze wolne miejsce. Takie inteligentne sprz\u0105tanie. W\u0142a\u015bnie, inteligentne sprz\u0105tanie, kt\u00f3re zapobiega katastrofie. Wszystko to brzmi genialnie na papierze, ale jak wiemy, w \u015bwiecie wielkich oblicze\u0144 diabe\u0142 tkwi w szczeg\u00f3\u0142ach. Czy autorom uda\u0142o si\u0119 udowodni\u0107, \u017ce te wszystkie sprytne sztuczki faktycznie przek\u0142adaj\u0105 si\u0119 na realny wzrost wydajno\u015bci? Jak wypad\u0142y w testach? I to jest chyba najbardziej satysfakcjonuj\u0105ca cz\u0119\u015b\u0107 tej pracy. Wyniki s\u0105 powalaj\u0105ce. W artykule jest wykres por\u00f3wnuj\u0105cy wydajno\u015b\u0107 zero z \u00f3wczesnym stanem wiedzy dla du\u017cych modeli, czyli Megatron LM. Dla modeli powy\u017cej 40 miliard\u00f3w parametr\u00f3w zero osi\u0105ga znacznie wy\u017csz\u0105 przepustowo\u015b\u0107, mierzon\u0105 w Tiflopsach. Przy 100 miliardach parametr\u00f3w m\u00f3wimy o r\u00f3\u017cnicy si\u0119gaj\u0105cej nawet o\u015bniu czy 10 razy. Wow. To nie jest przyrost o kilka procent, to jest skok o rz\u0105d wielko\u015bci. W tej pracy pojawia si\u0119 te\u017c fascynuj\u0105ce zjawisko, kt\u00f3re nazywaj\u0105 superliniarna skalowalno\u015b\u0107. To brzmi troch\u0119 jak z\u0142amanie praw fizyki. M\u00f3wi, \u017ce podwojenie liczby kart GPU daje wi\u0119cej ni\u017c podwojenie wydajno\u015bci. Jak to w og\u00f3le jest mo\u017cliwe? To jest bezpo\u015bredni efekt tego, o czym m\u00f3wili\u015bmy przy okazji koszt\u00f3w komunikacji. Wyja\u015bnijmy to na prostym przyk\u0142adzie. Za\u0142\u00f3\u017cmy, \u017ce na 16 kartach GPU z powodu ogranicze\u0144 pami\u0119ci mo\u017cesz u\u017cy\u0107 batch size o wielko\u015bci 1 na ka\u017cdej karcie. Ca\u0142kowyty batch size dla ca\u0142ego systemu wynosi 16. Ok. Teraz podwajasz liczb\u0119 kart do 32. W starym \u015bwiecie twoja wydajno\u015b\u0107 by si\u0119 podwoi\u0142a, a ca\u0142kowyty batch size wyni\u00f3s\u0142 by 32. Ale z 0 dzi\u0119ki ogromnej oszcz\u0119dno\u015bci pami\u0119ci na ka\u017cdej z tych 32 kart mo\u017cesz teraz zmie\u015bci\u0107 powiedzmy batch size o wielko\u015bci 4. Aha. Tw\u00f3j ca\u0142kowyty batch size to teraz 32x4, czyli 128. Ka\u017cde GPU wykonuje znacznie wi\u0119cej u\u017cytecznej pracy na sekund\u0119, bo wi\u0119ksze wsady lepiej je wysycaj\u0105. W efekcie podwajaj\u0105c liczb\u0119 kart zwi\u0119kszy\u0142a\u015b wydajno\u015b\u0107 nie dwu, a o\u015bmiokrotnie. To jest w\u0142a\u015bnie superliniowa skalowalno\u015b\u0107. Czyli implikacje s\u0105 ogromy. Nie chodzi tylko o to, \u017ceby trenowa\u0107 jeszcze wi\u0119ksze modele, ale te\u017c o to, kto mo\u017ce je trenowa\u0107. W artykule jest mowa o demokratyzacji. Tak. I to jest by\u0107 mo\u017ce najwa\u017cniejsze, d\u0142ugofalowy skutek. Zero w ni\u017cszych stadiach optymalizacji np. tylko popius, plus G, pozwala trenowa\u0107 modele do 13 miliard\u00f3w parametr\u00f3w, bez konieczno\u015bci stosowania skomplikowanego model paralelizmy. A to w\u0142a\u015bnie MP wymaga\u0142o od naukowc\u00f3w g\u0142\u0119bokich modyfikacji w kodzie samego modelu, co by\u0142o ogromn\u0105 barier\u0105 wej\u015bcia. W praktyce oznacza\u0142o to, \u017ce grupa badawcza na uniwersytecie, dysponuj\u0105ca nawet kilkoma serwerami, mog\u0142a nagle zacz\u0105\u0107 prowadzi\u0107 badania, kt\u00f3re wcze\u015bniej by\u0142y zarezerwowane wy\u0142\u0105cznie dla gigant\u00f3w technologicznych z w\u0142asnymi centrami danych. To prawdziwa zmiana regu\u0142 gry, a ostatecznym dowodem, \u017ce to wszystko dzia\u0142a, by\u0142o stworzenie konkretnego modelu. Prawda? Oczywi\u015bcie. Teoria i benchmarki s\u0105 wa\u017cne, ale nic nie przemawia do wyobra\u017ani tak, jak dzia\u0142aj\u0105cy produkt. Dzi\u0119ki Zero zesp\u00f3\u0142 Microsoftu wytrenowa\u0142 model Turing NLG. Mia\u0142 17 miliard\u00f3w parametr\u00f3w, co w tamtym czasie czyni\u0142o go najwi\u0119kszym modelem na \u015bwiecie. I osi\u0105gn\u0105\u0142 rekordow\u0105 dok\u0142adno\u015b\u0107 w wielu zadaniach j\u0119zykowych. To by\u0142 ostateczny dow\u00f3d na to, \u017ce Zero nie tylko dzia\u0142a, ale te\u017c przynosi realne, prze\u0142omowe rezultaty naukowe. Reasumuj\u0105c t\u0119 cz\u0119\u015b\u0107, Zero to nie jest tylko kolejna optymalizacja, to jest fundamentalna zmiana paradygmatu. Zamiast podej\u015bcia opartego na brutalnej sile, czyli dok\u0142adaniu coraz pot\u0119\u017cniejszego i dro\u017cszego sprz\u0119tu z wi\u0119ksz\u0105 ilo\u015bci\u0105 pami\u0119ci, proponuje inteligentne, niemal finezyjne zarz\u0105dzanie zasobami poprzez systematyczn\u0105 eliminacj\u0119 redundancji na ka\u017cdym kroku. Dok\u0142adnie. Ale co czy kaw\u0119? I to pokazuje klas\u0119 autor\u00f3w. W podsumowaniu sami przyznaj\u0105, \u017ce rozwi\u0105zali tylko jeden, cho\u0107 ogromny problem. Stworzyli narz\u0119dzie do walki z barier\u0105 pami\u0119ci, ale na horyzoncie pojawi\u0142a si\u0119 kolejna, r\u00f3wnie wielka przeszkoda. Nazywaj\u0105 j\u0105 luk\u0105 w mocy obliczeniowej, Compute Power Gap. Obliczyli, \u017ce nawet z wydajno\u015bci\u0105, jak on daje zero, wytrenowanie modelu o bilionie parametr\u00f3w na \u00f3wczesnym sprz\u0119cie wci\u0105\u017c wymaga\u0142oby ponad roku nieprzerwanych oblicze\u0144. To prowadzi nas do ko\u0144cowej my\u015bli, kt\u00f3r\u0105 warto podrzuci\u0107 osobom, kt\u00f3re nas s\u0142uchaj\u0105. Tak. Skoro zero i podobne technologie pokaza\u0142y, \u017ce pami\u0119\u0107 musi by\u0107 ju\u017c ostateczn\u0105 barier\u0105 i mo\u017cna j\u0105 obej\u015b\u0107 za pomoc\u0105 sprytnego oprogramowania, to gdzie le\u017cy kolejna granica innowacji? Czy nast\u0119pny prze\u0142om b\u0119dzie polega\u0142 na budowie jeszcze pot\u0119\u017cniejszych superkomputer\u00f3w na jeszcze bardziej egzotycznym sprz\u0119cie i skracaniu tego roku do miesi\u0119cy, a potem tygodni? Czy mo\u017ce prawdziwe prze\u0142om nadejdzie zube\u0142nie innej strony od odkrycia nowych architektur modeli lub algorytm\u00f3w treningowych, kt\u00f3re pozwol\u0105 osi\u0105gn\u0105\u0107 te same rezultaty przy fundamentalnie mniejszym zapotrzebowaniu nadczyste obliczenia? Innymi s\u0142owy. Czy przysz\u0142o\u015b\u0107 to wi\u0119ksze silniki, czy mo\u017ce kaliwo?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.7, "text": " Co by by\u0142o, gdyby\u015bmy mogli trenowa\u0107 modele AI o skali, powiedzmy, biliona parametr\u00f3w?", "tokens": [50364, 3066, 538, 14811, 11, 28405, 2322, 10513, 13172, 2081, 23136, 11445, 4391, 306, 7318, 277, 1110, 5103, 11, 27617, 2226, 11, 8588, 21758, 6220, 27965, 3901, 30, 50749], "temperature": 0.0, "avg_logprob": -0.17127641509560979, "compression_ratio": 1.4403973509933774, "no_speech_prob": 0.013513713143765926}, {"id": 1, "seek": 0, "start": 7.7, "end": 11.9, "text": " I to na sprz\u0119cie, kt\u00f3re mamy dzi\u015b. Brzmi jak science fiction, prawda?", "tokens": [50749, 286, 281, 1667, 6103, 11052, 4260, 11, 8864, 17335, 31981, 1788, 13, 1603, 89, 3057, 4207, 3497, 13266, 11, 43607, 30, 50959], "temperature": 0.0, "avg_logprob": -0.17127641509560979, "compression_ratio": 1.4403973509933774, "no_speech_prob": 0.013513713143765926}, {"id": 2, "seek": 0, "start": 11.9, "end": 17.3, "text": " A jednak to jest dok\u0142adnie to pytanie, kt\u00f3re postawili sobie badacze z Microsoftu.", "tokens": [50959, 316, 25897, 281, 3492, 45864, 2766, 281, 36610, 11, 8864, 2183, 1607, 2312, 13652, 1578, 326, 1381, 710, 8116, 84, 13, 51229], "temperature": 0.0, "avg_logprob": -0.17127641509560979, "compression_ratio": 1.4403973509933774, "no_speech_prob": 0.013513713143765926}, {"id": 3, "seek": 0, "start": 17.3, "end": 23.8, "text": " Kiedy my\u015blimy o trenowaniu wielkich modeli, no to pierwsze, co przychodzi do g\u0142owy, to gigantyczna moc obliczeniowa.", "tokens": [51229, 591, 16446, 48633, 4197, 88, 277, 23136, 305, 25849, 20570, 48349, 2316, 72, 11, 572, 281, 45994, 11, 598, 6501, 34616, 360, 18117, 10089, 11, 281, 8741, 394, 17466, 629, 34962, 1111, 1050, 42124, 5528, 13, 51554], "temperature": 0.0, "avg_logprob": -0.17127641509560979, "compression_ratio": 1.4403973509933774, "no_speech_prob": 0.013513713143765926}, {"id": 4, "seek": 0, "start": 23.8, "end": 28.1, "text": " Ale jest jeszcze jedna, chyba bardziej podst\u0119pna bariera. Pami\u0119\u0107.", "tokens": [51554, 9366, 3492, 14168, 5232, 629, 11, 31532, 27209, 2497, 372, 18085, 629, 2159, 10609, 13, 430, 23806, 2162, 13, 51769], "temperature": 0.0, "avg_logprob": -0.17127641509560979, "compression_ratio": 1.4403973509933774, "no_speech_prob": 0.013513713143765926}, {"id": 5, "seek": 2810, "start": 28.200000000000003, "end": 34.5, "text": " We\u017amy taki przyk\u0142ad z artyku\u0142u. Model GPT-2, ten o wielko\u015bci 1,5 miliarda parametr\u00f3w,", "tokens": [50369, 492, 10659, 2226, 20065, 23144, 710, 594, 874, 5279, 24066, 13, 17105, 26039, 51, 12, 17, 11, 2064, 277, 20570, 4093, 6199, 502, 11, 20, 1962, 72, 19218, 6220, 27965, 3901, 11, 50684], "temperature": 0.0, "avg_logprob": -0.1285606718411411, "compression_ratio": 1.3205574912891986, "no_speech_prob": 0.04788842052221298}, {"id": 6, "seek": 2810, "start": 34.5, "end": 39.5, "text": " sam plik z wagami modelu zajmuje, wiesz, jakie\u015b 3 GB.", "tokens": [50684, 3247, 499, 1035, 710, 36854, 4526, 2316, 84, 33729, 76, 13008, 11, 261, 15347, 11, 31163, 805, 26809, 13, 50934], "temperature": 0.0, "avg_logprob": -0.1285606718411411, "compression_ratio": 1.3205574912891986, "no_speech_prob": 0.04788842052221298}, {"id": 7, "seek": 2810, "start": 39.5, "end": 46.3, "text": " Ale \u017ceby go trenowa\u0107, potrzeba ponad 24 GB pami\u0119ci, na jednej karcie graficznej.", "tokens": [50934, 9366, 11316, 352, 23136, 11445, 11, 28577, 4231, 9224, 345, 4022, 26809, 31088, 537, 11, 1667, 5232, 11794, 7917, 4260, 1295, 1786, 89, 11794, 13, 51274], "temperature": 0.0, "avg_logprob": -0.1285606718411411, "compression_ratio": 1.3205574912891986, "no_speech_prob": 0.04788842052221298}, {"id": 8, "seek": 2810, "start": 46.3, "end": 50.3, "text": " To jest o\u015bmiokrotnie wi\u0119cej. Gdzie Ulicha podziewa si\u0119 ca\u0142a reszta?", "tokens": [51274, 1407, 3492, 277, 1788, 3057, 453, 10536, 2766, 26004, 13, 460, 13096, 24853, 48710, 2497, 89, 1093, 64, 3244, 1335, 5024, 725, 89, 1328, 30, 51474], "temperature": 0.0, "avg_logprob": -0.1285606718411411, "compression_ratio": 1.3205574912891986, "no_speech_prob": 0.04788842052221298}, {"id": 9, "seek": 2810, "start": 50.3, "end": 54.6, "text": " I w\u0142a\u015bnie t\u0119 zagadk\u0119 rozwi\u0105zuje praca, kt\u00f3r\u0105 dzi\u015b bierzemy pod lup\u0119.", "tokens": [51474, 286, 14234, 32489, 27001, 345, 15724, 9544, 18234, 11728, 2884, 582, 6628, 11, 37415, 31981, 1788, 272, 34602, 3633, 2497, 287, 1010, 1274, 13, 51689], "temperature": 0.0, "avg_logprob": -0.1285606718411411, "compression_ratio": 1.3205574912891986, "no_speech_prob": 0.04788842052221298}, {"id": 10, "seek": 5460, "start": 54.7, "end": 60.4, "text": " Praca wprowadzaj\u0105ca technologi\u0119 o nazwie zero. Zero redundancy optimizer.", "tokens": [50369, 2114, 6628, 46733, 89, 11133, 496, 1537, 1132, 5034, 277, 20151, 8699, 4018, 13, 17182, 27830, 6717, 5028, 6545, 13, 50654], "temperature": 0.0, "avg_logprob": -0.11631586592076189, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00239102216437459}, {"id": 11, "seek": 5460, "start": 60.4, "end": 70.0, "text": " Dok\u0142adnie. A naszym celem dzisiaj jest nie tylko zrozumie\u0107 jak zero to robi, ale te\u017c dlaczego to by\u0142o tak rewolucyjne.", "tokens": [50654, 29768, 10358, 2766, 13, 316, 48094, 1769, 10386, 25772, 3492, 2838, 13219, 710, 27857, 449, 414, 2162, 4207, 4018, 281, 47380, 11, 6775, 9516, 37873, 39329, 281, 14811, 991, 319, 48481, 1311, 88, 73, 716, 13, 51134], "temperature": 0.0, "avg_logprob": -0.11631586592076189, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00239102216437459}, {"id": 12, "seek": 5460, "start": 70.0, "end": 73.3, "text": " Bo to nie jest jaka\u015b tam kolejna, drobna optymalizacja.", "tokens": [51134, 3286, 281, 2838, 3492, 4207, 64, 1788, 7677, 23749, 629, 11, 3789, 65, 629, 2427, 4199, 304, 590, 23395, 13, 51299], "temperature": 0.0, "avg_logprob": -0.11631586592076189, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00239102216437459}, {"id": 13, "seek": 5460, "start": 73.3, "end": 77.4, "text": " To jest fundamentalna zmiana sposobu my\u015blenia o zasobach.", "tokens": [51299, 1407, 3492, 8088, 629, 17020, 8497, 20443, 996, 84, 48633, 6698, 654, 277, 26530, 996, 608, 13, 51504], "temperature": 0.0, "avg_logprob": -0.11631586592076189, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00239102216437459}, {"id": 14, "seek": 5460, "start": 77.4, "end": 80.2, "text": " Dlatego nasz\u0105 rozmow\u0119 podzielimy na trzy cz\u0119\u015bci.", "tokens": [51504, 47184, 5382, 8925, 35234, 305, 1274, 2497, 42280, 13189, 1667, 34573, 41314, 13, 51644], "temperature": 0.0, "avg_logprob": -0.11631586592076189, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00239102216437459}, {"id": 15, "seek": 8020, "start": 80.2, "end": 87.3, "text": " Najpierw dok\u0142adnie zdiagnozujemy, co jest tym niewidzialnym balastem, kt\u00f3ry po\u017cera ca\u0142\u0105 pami\u0119\u0107 GPU.", "tokens": [50364, 31576, 45119, 86, 45864, 2766, 710, 4504, 559, 1771, 89, 21767, 11, 598, 3492, 8107, 43622, 327, 17787, 12996, 3119, 525, 443, 11, 9913, 714, 1427, 1663, 1335, 15926, 31088, 2162, 18407, 13, 50719], "temperature": 0.0, "avg_logprob": -0.09843166878348902, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.0093671390786767}, {"id": 16, "seek": 8020, "start": 87.3, "end": 93.2, "text": " Potem krok po kroku prze\u015bledzimy t\u0119 genialn\u0105 w swojej prostocie logik\u0119 zero.", "tokens": [50719, 9145, 443, 350, 31621, 714, 45909, 5279, 8325, 1788, 1493, 89, 13189, 32489, 48228, 13113, 261, 29489, 73, 10293, 905, 414, 3565, 1035, 1274, 4018, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09843166878348902, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.0093671390786767}, {"id": 17, "seek": 8020, "start": 93.2, "end": 96.6, "text": " Czyli bezlitosn\u0105 eliminacj\u0119 redundancji.", "tokens": [51014, 37099, 10782, 75, 11343, 13113, 7892, 29924, 27830, 4463, 4013, 13, 51184], "temperature": 0.0, "avg_logprob": -0.09843166878348902, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.0093671390786767}, {"id": 18, "seek": 8020, "start": 96.6, "end": 102.5, "text": " A na koniec sprawdzimy, czy to wszystko w og\u00f3le zadzia\u0142a\u0142o w praktyce i jakie drzwi otworzy\u0142o.", "tokens": [51184, 316, 1667, 5897, 35733, 46192, 89, 13189, 11, 6430, 281, 22607, 261, 29229, 42788, 89, 25605, 5249, 261, 3206, 74, 874, 384, 741, 22124, 1224, 89, 6253, 4337, 28321, 1229, 5249, 13, 51479], "temperature": 0.0, "avg_logprob": -0.09843166878348902, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.0093671390786767}, {"id": 19, "seek": 8020, "start": 102.5, "end": 109.4, "text": " A otworzy\u0142o i to z hookiem drzwi do stworzenia jednego z najwi\u0119kszych w\u00f3wczas modeli j\u0119zykowych. Turing NLG.", "tokens": [51479, 316, 4337, 28321, 1229, 5249, 741, 281, 710, 6328, 4907, 1224, 89, 6253, 360, 342, 28321, 14320, 5232, 11858, 710, 48636, 1694, 28051, 261, 3901, 30989, 2316, 72, 49055, 74, 19605, 13, 314, 1345, 426, 43, 38, 13, 51824], "temperature": 0.0, "avg_logprob": -0.09843166878348902, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.0093671390786767}, {"id": 20, "seek": 10940, "start": 109.4, "end": 115.30000000000001, "text": " To jest naprawd\u0119 niesamowite, \u017ce model zajmuje 3 Giga, a training 24.", "tokens": [50364, 1407, 3492, 20970, 48100, 335, 305, 642, 11, 3561, 2316, 33729, 76, 13008, 805, 460, 9900, 11, 257, 3097, 4022, 13, 50659], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 21, "seek": 10940, "start": 115.30000000000001, "end": 118.60000000000001, "text": " Musimy wi\u0119c zacz\u0105\u0107 od tego niewidzialnego balastu.", "tokens": [50659, 3569, 13189, 16677, 34430, 8925, 2162, 3611, 8627, 43622, 327, 17787, 11858, 3119, 525, 84, 13, 50824], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 22, "seek": 10940, "start": 118.60000000000001, "end": 121.4, "text": " Gdzie tak naprawd\u0119 ucieka ca\u0142a ta pami\u0119\u0107?", "tokens": [50824, 460, 13096, 991, 20970, 344, 4260, 2330, 1335, 5024, 1846, 31088, 2162, 30, 50964], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 23, "seek": 10940, "start": 121.4, "end": 126.2, "text": " Najpopularniejszym podej\u015bciem do skalowania treningu jest od lat Data Parallelizm.", "tokens": [50964, 31576, 42376, 10402, 7706, 76, 7468, 73, 9815, 76, 360, 16890, 21308, 2192, 773, 84, 3492, 3611, 4465, 11888, 3457, 336, 338, 590, 76, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 24, "seek": 10940, "start": 126.2, "end": 130.8, "text": " Dlaczego ono, mimo \u017ce jest takie proste, nagle przesta\u0142o wystarcza\u0107.", "tokens": [51204, 413, 75, 39329, 322, 78, 11, 275, 6934, 3561, 3492, 15963, 10293, 68, 11, 297, 15088, 6541, 7841, 5249, 4628, 9710, 66, 35873, 13, 51434], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 25, "seek": 10940, "start": 130.8, "end": 136.0, "text": " Data Parallelizm w skr\u00f3cie DP jest genialne w swojej prostocie.", "tokens": [51434, 11888, 3457, 336, 338, 590, 76, 261, 1110, 11721, 4260, 42796, 3492, 48228, 716, 261, 29489, 73, 10293, 905, 414, 13, 51694], "temperature": 0.0, "avg_logprob": -0.11176139916946638, "compression_ratio": 1.4464944649446494, "no_speech_prob": 0.002038652542978525}, {"id": 26, "seek": 13600, "start": 136.0, "end": 143.7, "text": " Mamy wiele kart graficznych, wi\u0119c na ka\u017cd\u0105 z nich wysy\u0142amy pe\u0142n\u0105 kopi\u0119 modelu i ka\u017cda mieli inn\u0105 porcj\u0119 danych.", "tokens": [50364, 376, 7804, 33137, 29120, 1295, 1786, 89, 9399, 11, 16677, 1667, 21912, 67, 1611, 710, 25570, 27062, 88, 1221, 7804, 43205, 13113, 28920, 5034, 2316, 84, 741, 21912, 2675, 41214, 7714, 1611, 1515, 41960, 274, 34644, 13, 50749], "temperature": 0.0, "avg_logprob": -0.08954848060312197, "compression_ratio": 1.4943396226415093, "no_speech_prob": 0.032317668199539185}, {"id": 27, "seek": 13600, "start": 143.7, "end": 146.8, "text": " Na koniec synchronizujemy wyniki. Proste.", "tokens": [50749, 6056, 5897, 35733, 19331, 590, 21767, 31936, 9850, 13, 2114, 555, 68, 13, 50904], "temperature": 0.0, "avg_logprob": -0.08954848060312197, "compression_ratio": 1.4943396226415093, "no_speech_prob": 0.032317668199539185}, {"id": 28, "seek": 13600, "start": 146.8, "end": 151.6, "text": " I to dzia\u0142a \u015bwietnie dop\u00f3ki model mie\u015bci si\u0119 w pami\u0119ci pojedynczej karty.", "tokens": [50904, 286, 281, 37903, 8299, 39083, 2766, 21900, 812, 2984, 2316, 12597, 6199, 3244, 261, 31088, 537, 714, 40543, 2534, 9680, 73, 29120, 88, 13, 51144], "temperature": 0.0, "avg_logprob": -0.08954848060312197, "compression_ratio": 1.4943396226415093, "no_speech_prob": 0.032317668199539185}, {"id": 29, "seek": 13600, "start": 151.6, "end": 158.2, "text": " Problem pojawia si\u0119, gdy model ro\u015bnie, bo w DP ka\u017cda karta graficzna, powiedzmy, \u017ce mamy ich 64,", "tokens": [51144, 11676, 30655, 654, 3244, 11, 28405, 2316, 744, 12221, 11, 748, 261, 42796, 21912, 2675, 350, 19061, 1295, 1786, 35458, 11, 27617, 2226, 11, 3561, 17335, 1893, 12145, 11, 51474], "temperature": 0.0, "avg_logprob": -0.08954848060312197, "compression_ratio": 1.4943396226415093, "no_speech_prob": 0.032317668199539185}, {"id": 30, "seek": 13600, "start": 158.2, "end": 161.8, "text": " przechowuje identyczn\u0105 pe\u0142n\u0105 kopi\u0119 wszystkiego.", "tokens": [51474, 8325, 339, 305, 13008, 2473, 17466, 13113, 43205, 13113, 28920, 5034, 14615, 12200, 13, 51654], "temperature": 0.0, "avg_logprob": -0.08954848060312197, "compression_ratio": 1.4943396226415093, "no_speech_prob": 0.032317668199539185}, {"id": 31, "seek": 16180, "start": 161.8, "end": 167.20000000000002, "text": " Nie tylko parametr\u00f3w modelu, ale te\u017c gradient\u00f3w i stan\u00f3w optymalizatora.", "tokens": [50364, 12016, 13219, 6220, 27965, 3901, 2316, 84, 11, 6775, 9516, 16235, 3901, 741, 27984, 3901, 2427, 4199, 304, 590, 1639, 64, 13, 50634], "temperature": 0.0, "avg_logprob": -0.09328530247050121, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0017280698521062732}, {"id": 32, "seek": 16180, "start": 167.20000000000002, "end": 172.70000000000002, "text": " Masz wi\u0119c 64 identyczne kopie tych samych gigantycznych zbior\u00f3w danych.", "tokens": [50634, 5224, 89, 16677, 12145, 2473, 17466, 716, 28920, 414, 15180, 3247, 16384, 8741, 394, 17466, 9399, 710, 33362, 3901, 274, 34644, 13, 50909], "temperature": 0.0, "avg_logprob": -0.09328530247050121, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0017280698521062732}, {"id": 33, "seek": 16180, "start": 172.70000000000002, "end": 176.4, "text": " To jest po prostu definicja redundacji i marnotrastwa.", "tokens": [50909, 1407, 3492, 714, 19518, 1561, 299, 2938, 2182, 997, 13152, 741, 275, 1083, 310, 4148, 4151, 13, 51094], "temperature": 0.0, "avg_logprob": -0.09328530247050121, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0017280698521062732}, {"id": 34, "seek": 16180, "start": 176.4, "end": 183.60000000000002, "text": " Ok, czyli to jest tak. Jak by\u015bmy chcieli zbudowa\u0107 64 identyczne samochody i zamiast jednej fabryki,", "tokens": [51094, 3477, 11, 16591, 281, 3492, 991, 13, 15029, 538, 10513, 417, 537, 10148, 710, 18281, 11445, 12145, 2473, 17466, 716, 3247, 8997, 843, 741, 710, 4526, 525, 5232, 11794, 5355, 627, 2984, 11, 51454], "temperature": 0.0, "avg_logprob": -0.09328530247050121, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0017280698521062732}, {"id": 35, "seek": 16180, "start": 183.60000000000002, "end": 190.20000000000002, "text": " budujemy 64 ma\u0142e fabryczki i ka\u017cda z nich ma pe\u0142en zestaw cz\u0119\u015bci do ca\u0142ego samochodu,", "tokens": [51454, 3265, 21767, 12145, 463, 19827, 5355, 627, 3689, 2984, 741, 21912, 2675, 710, 25570, 463, 43205, 268, 37889, 1607, 41314, 360, 35224, 6308, 3247, 8997, 34873, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09328530247050121, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0017280698521062732}, {"id": 36, "seek": 19020, "start": 190.2, "end": 194.79999999999998, "text": " czyli mo\u017ce sk\u0142ada tylko jedne drzwi. Brzmi absurdalnie.", "tokens": [50364, 16591, 12034, 1110, 46217, 13219, 5232, 716, 1224, 89, 6253, 13, 1603, 89, 3057, 19774, 304, 2766, 13, 50594], "temperature": 0.0, "avg_logprob": -0.11266856193542481, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03780064359307289}, {"id": 37, "seek": 19020, "start": 194.79999999999998, "end": 200.2, "text": " A co z alternatyw\u0105, czyli model paralelizm? Tam przecie\u017c dzielimy model, a nie dane.", "tokens": [50594, 316, 598, 710, 5400, 21398, 86, 1611, 11, 16591, 2316, 26009, 338, 590, 76, 30, 8540, 8325, 40082, 9758, 1187, 13189, 2316, 11, 257, 2838, 49206, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11266856193542481, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03780064359307289}, {"id": 38, "seek": 19020, "start": 200.2, "end": 206.79999999999998, "text": " Dok\u0142adnie. Model paralelizm. MP. Na papierze wydaje si\u0119 idealnym rozwi\u0105zaniem.", "tokens": [50864, 29768, 10358, 2766, 13, 17105, 26009, 338, 590, 76, 13, 14146, 13, 6056, 37410, 1381, 49165, 3244, 7157, 12996, 9544, 18234, 21238, 4907, 13, 51194], "temperature": 0.0, "avg_logprob": -0.11266856193542481, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03780064359307289}, {"id": 39, "seek": 19020, "start": 206.79999999999998, "end": 212.0, "text": " Kroimy model na kawa\u0142ki i ka\u017cdy kawa\u0142ek umieszczamy na innej karcie graficznej.", "tokens": [51194, 591, 340, 13189, 2316, 1667, 350, 10449, 1221, 2984, 741, 31615, 350, 10449, 1221, 916, 1105, 15347, 3689, 7804, 1667, 294, 11794, 7917, 4260, 1295, 1786, 89, 11794, 13, 51454], "temperature": 0.0, "avg_logprob": -0.11266856193542481, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03780064359307289}, {"id": 40, "seek": 19020, "start": 212.0, "end": 217.39999999999998, "text": " Problem w tym, \u017ce to jest logistyczny koszmar. Wyobra\u017a sobie, \u017ce kroisz tort na 16 kawa\u0142k\u00f3w", "tokens": [51454, 11676, 261, 8107, 11, 3561, 281, 3492, 3565, 468, 17466, 1634, 19532, 89, 6209, 13, 14458, 24393, 10659, 13652, 11, 3561, 45909, 23848, 10806, 1667, 3165, 350, 10449, 1221, 23849, 51724], "temperature": 0.0, "avg_logprob": -0.11266856193542481, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.03780064359307289}, {"id": 41, "seek": 21740, "start": 217.4, "end": 221.6, "text": " i ka\u017cdy kawa\u0142ek wys\u0142asz kurrierem do innego miasta, \u017ceby go tam udekorowano.", "tokens": [50364, 741, 31615, 350, 10449, 1221, 916, 27062, 1221, 19601, 10072, 470, 7333, 360, 294, 11858, 2752, 12468, 11, 11316, 352, 7677, 11727, 916, 284, 305, 3730, 13, 50574], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 42, "seek": 21740, "start": 221.6, "end": 226.3, "text": " A potem te kawa\u0142ki musz\u0105 si\u0119 mi\u0119dzy sob\u0105 wymienia\u0107, bo dekoracja jednego zale\u017cy od drugiego.", "tokens": [50574, 316, 36513, 535, 350, 10449, 1221, 2984, 1038, 8925, 3244, 33964, 18253, 1611, 29764, 18811, 2162, 11, 748, 368, 19339, 23395, 5232, 11858, 710, 37169, 3611, 4110, 12200, 13, 50809], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 43, "seek": 21740, "start": 226.3, "end": 231.3, "text": " Ilo\u015b\u0107 komunikacji i tej ca\u0142ej synchronizacji mi\u0119dzy tymi kawa\u0142kami ro\u015bnie lawinowo.", "tokens": [50809, 286, 752, 7753, 45359, 1035, 13152, 741, 12573, 47631, 73, 19331, 590, 13152, 33964, 1104, 3057, 350, 10449, 1221, 48737, 744, 12221, 2101, 259, 19941, 13, 51059], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 44, "seek": 21740, "start": 231.3, "end": 236.6, "text": " Autorzy prac\u0119 podaj\u0105 brutalny przyk\u0142ad. Pr\u00f3ba trenowania modelu o 40 miliardach parametr\u00f3w", "tokens": [51059, 6049, 284, 1229, 22404, 1274, 2497, 11133, 17878, 1634, 23144, 13, 2114, 812, 4231, 23136, 21308, 2316, 84, 277, 3356, 1962, 72, 515, 608, 6220, 27965, 3901, 51324], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 45, "seek": 21740, "start": 236.6, "end": 243.3, "text": " z u\u017cyciem MP na dw\u00f3ch, pot\u0119\u017cnych serwerach sprawi\u0142a, \u017ce wydajno\u015b\u0107 spad\u0142a do mniej ni\u017c 5%", "tokens": [51324, 710, 34097, 4260, 76, 14146, 1667, 27379, 812, 339, 11, 1847, 1274, 1427, 9399, 816, 1554, 608, 22734, 72, 5024, 11, 3561, 25984, 1805, 23293, 637, 345, 5024, 360, 39513, 28502, 1025, 4, 51659], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 46, "seek": 21740, "start": 243.3, "end": 245.6, "text": " teoretycznej mocy obliczeniowej GPU.", "tokens": [51659, 535, 418, 874, 3689, 11794, 705, 1344, 1111, 1050, 42124, 21091, 18407, 13, 51774], "temperature": 0.0, "avg_logprob": -0.09962598811945267, "compression_ratio": 1.446685878962536, "no_speech_prob": 0.05263778567314148}, {"id": 47, "seek": 24560, "start": 246.6, "end": 252.0, "text": " Tak, to znaczy, \u017ce przez 95% czasu karty graficzne po prostu czeka\u0142y na dane.", "tokens": [50414, 9118, 11, 281, 36584, 11, 3561, 14064, 13420, 4, 40860, 29120, 88, 1295, 1786, 43077, 714, 19518, 6472, 36361, 6825, 1667, 49206, 13, 50684], "temperature": 0.0, "avg_logprob": -0.1626087509038794, "compression_ratio": 1.3892857142857142, "no_speech_prob": 0.07574590295553207}, {"id": 48, "seek": 24560, "start": 252.0, "end": 253.5, "text": " To jest \u015blepa uliczka.", "tokens": [50684, 1407, 3492, 8299, 306, 4306, 344, 1050, 89, 2330, 13, 50759], "temperature": 0.0, "avg_logprob": -0.1626087509038794, "compression_ratio": 1.3892857142857142, "no_speech_prob": 0.07574590295553207}, {"id": 49, "seek": 24560, "start": 253.5, "end": 261.0, "text": " Rozumiem. Czyli DPI jest proste, ale marnotrawne pami\u0119ciowo, a MP oszcz\u0119dza pami\u0119\u0107,", "tokens": [50759, 43313, 449, 4907, 13, 37099, 413, 31701, 3492, 10293, 68, 11, 6775, 275, 1083, 310, 5131, 716, 31088, 537, 19941, 11, 257, 14146, 3003, 43771, 6298, 2394, 31088, 2162, 11, 51134], "temperature": 0.0, "avg_logprob": -0.1626087509038794, "compression_ratio": 1.3892857142857142, "no_speech_prob": 0.07574590295553207}, {"id": 50, "seek": 24560, "start": 261.0, "end": 267.0, "text": " ale zabija wydajno\u015b\u0107 przez komunikacj\u0119. Mamy pad. I tu w\u0142a\u015bnie wchodzi zero.", "tokens": [51134, 6775, 24838, 20642, 25984, 1805, 23293, 14064, 45359, 1035, 29924, 13, 376, 7804, 6887, 13, 286, 2604, 14234, 261, 34616, 4018, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1626087509038794, "compression_ratio": 1.3892857142857142, "no_speech_prob": 0.07574590295553207}, {"id": 51, "seek": 24560, "start": 267.0, "end": 274.0, "text": " Zanim przejdziemy do samego rozwi\u0105zania, rozbijmy jeszcze tego g\u0142\u00f3wnego po\u017ceracza pami\u0119ci naczynniki pierwsze.", "tokens": [51434, 1176, 17869, 8325, 73, 13096, 2226, 360, 912, 1571, 9544, 22620, 5609, 11, 9544, 30418, 2226, 14168, 8627, 18117, 3901, 11858, 714, 1427, 260, 326, 2394, 31088, 537, 297, 14691, 26384, 9850, 45994, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1626087509038794, "compression_ratio": 1.3892857142857142, "no_speech_prob": 0.07574590295553207}, {"id": 52, "seek": 27400, "start": 274.0, "end": 278.4, "text": " Wspomnia\u0142e\u015b o parametrach, gradientach i stanach optymalizatora.", "tokens": [50364, 343, 4952, 38131, 8908, 68, 1788, 277, 6220, 27965, 608, 11, 16235, 608, 741, 27984, 608, 2427, 4199, 304, 590, 1639, 64, 13, 50584], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 53, "seek": 27400, "start": 278.4, "end": 282.1, "text": " Tak, ta codziewi z u\u017cycie pami\u0119ci na dwie kategorie.", "tokens": [50584, 9118, 11, 1846, 17656, 89, 1093, 72, 710, 34097, 4260, 31088, 537, 1667, 274, 8699, 350, 2968, 17473, 13, 50769], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 54, "seek": 27400, "start": 282.1, "end": 286.0, "text": " Pierwsza i absolutnie kluczowa to s\u0105 model states.", "tokens": [50769, 16676, 14358, 2394, 741, 18757, 2766, 9671, 1311, 89, 5528, 281, 9015, 2316, 4368, 13, 50964], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 55, "seek": 27400, "start": 286.0, "end": 292.4, "text": " W jej sk\u0142ad wchodz\u0105 trzy elementy. Same parametry modelu, parameters, gradienty, gradients,", "tokens": [50964, 343, 28924, 1110, 10358, 261, 29914, 8925, 34573, 4478, 88, 13, 10635, 6220, 9889, 2316, 84, 11, 9834, 11, 16235, 88, 11, 2771, 2448, 11, 51284], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 56, "seek": 27400, "start": 292.4, "end": 299.0, "text": " czyli te pochodne m\u00f3wi\u0105ce jak aktualizowa\u0107 parametry, no i stan\u0119 optymalizatora, optimizer states.", "tokens": [51284, 16591, 535, 714, 29914, 716, 46591, 384, 4207, 13680, 901, 590, 11445, 6220, 9889, 11, 572, 741, 27984, 1274, 2427, 4199, 304, 590, 1639, 64, 11, 5028, 6545, 4368, 13, 51614], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 57, "seek": 27400, "start": 299.0, "end": 301.3, "text": " I to jest ten cichwy zab\u00f3jca.", "tokens": [51614, 286, 281, 3492, 2064, 269, 480, 9726, 24838, 18999, 496, 13, 51729], "temperature": 0.0, "avg_logprob": -0.174996522221252, "compression_ratio": 1.5305343511450382, "no_speech_prob": 0.04134221002459526}, {"id": 58, "seek": 30130, "start": 301.40000000000003, "end": 308.5, "text": " Je\u015bli u\u017cywamy popularnego optymalizatora Adam, to do ka\u017cdego parametru musi on przechowywa\u0107 dwie dodatkowe warto\u015bci.", "tokens": [50369, 37086, 34097, 86, 7804, 3743, 11858, 2427, 4199, 304, 590, 1639, 64, 7938, 11, 281, 360, 21912, 67, 6308, 6220, 302, 894, 37587, 322, 8325, 339, 10089, 25234, 274, 8699, 13886, 33525, 6880, 31830, 6199, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 59, "seek": 30130, "start": 308.5, "end": 311.90000000000003, "text": " Pent, czyli momentum i wariancie variance.", "tokens": [50724, 20165, 11, 16591, 11244, 741, 1516, 952, 4260, 21977, 13, 50894], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 60, "seek": 30130, "start": 311.90000000000003, "end": 317.2, "text": " Je\u015bli dodamy do tego trening w mixed precision, kt\u00f3ry te\u017c wymaga przechowywania kopii pewnych danych,", "tokens": [50894, 37086, 13886, 7804, 360, 8627, 2192, 773, 261, 7467, 18356, 11, 9913, 9516, 29764, 9286, 8325, 339, 10089, 86, 5609, 28920, 5597, 47160, 16384, 274, 34644, 11, 51159], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 61, "seek": 30130, "start": 317.2, "end": 320.2, "text": " to dochodzimy do szokuj\u0105cej liczby, kt\u00f3r\u0105 podaj\u0105 autorzy.", "tokens": [51159, 281, 9243, 378, 89, 13189, 360, 7870, 453, 13263, 20811, 6169, 89, 2322, 11, 37415, 2497, 11133, 19510, 1229, 13, 51309], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 62, "seek": 30130, "start": 320.2, "end": 325.90000000000003, "text": " Na ka\u017cdy jeden parametr modelu przypada 16 bite\u00f3w pami\u0119ci zu\u017cywanej przez model states.", "tokens": [51309, 6056, 31615, 12906, 6220, 27965, 2316, 84, 41780, 1538, 3165, 7988, 3901, 31088, 537, 2164, 7735, 86, 1929, 73, 14064, 2316, 4368, 13, 51594], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 63, "seek": 30130, "start": 325.90000000000003, "end": 327.3, "text": " A\u017c 16?", "tokens": [51594, 316, 1427, 3165, 30, 51664], "temperature": 0.0, "avg_logprob": -0.1374902440540826, "compression_ratio": 1.4810996563573884, "no_speech_prob": 0.0013268070761114359}, {"id": 64, "seek": 32730, "start": 327.3, "end": 334.1, "text": " Tak. Czyli model o miliardzie parametr\u00f3w potrzebuje 16 gigabyte\u00f3w i to jest g\u0142\u00f3wny winowajca.", "tokens": [50364, 9118, 13, 37099, 2316, 277, 1962, 72, 515, 3283, 6220, 27965, 3901, 28577, 6021, 2884, 3165, 8741, 34529, 3901, 741, 281, 3492, 18117, 812, 43682, 1942, 305, 1805, 496, 13, 50704], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 65, "seek": 32730, "start": 334.1, "end": 335.7, "text": " A ta druga ta teoria?", "tokens": [50704, 316, 1846, 4110, 64, 1846, 535, 8172, 30, 50784], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 66, "seek": 32730, "start": 335.7, "end": 339.2, "text": " Druga to residual states.", "tokens": [50784, 2491, 19364, 281, 27980, 4368, 13, 50959], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 67, "seek": 32730, "start": 339.2, "end": 344.7, "text": " To jest ca\u0142a lepszta aktywacje, activations, kt\u00f3re trzeba trzyma\u0107 w pami\u0119cie,", "tokens": [50959, 1407, 3492, 1335, 5024, 476, 1878, 89, 1328, 9308, 874, 86, 29293, 11, 2430, 763, 11, 8864, 25860, 34573, 1696, 2162, 261, 31088, 4260, 11, 51234], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 68, "seek": 32730, "start": 344.7, "end": 352.3, "text": " \u017ceby obliczy\u0107 gradienty, jakie\u015b tymczasowe bufory do operacji, temporary buffers i pofragmentowana pami\u0119\u0107.", "tokens": [51234, 11316, 1111, 1050, 27150, 16235, 88, 11, 31163, 8107, 30989, 6880, 758, 69, 827, 360, 2208, 13152, 11, 13413, 9204, 433, 741, 714, 69, 3731, 518, 40458, 31088, 2162, 13, 51614], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 69, "seek": 32730, "start": 352.3, "end": 354.90000000000003, "text": " To te\u017c jest problem, ale znacznie mniejszy.", "tokens": [51614, 1407, 9516, 3492, 1154, 11, 6775, 15397, 14875, 2766, 39513, 7706, 13, 51744], "temperature": 0.0, "avg_logprob": -0.15946029663085937, "compression_ratio": 1.3963636363636365, "no_speech_prob": 0.0062012155540287495}, {"id": 70, "seek": 35490, "start": 355.0, "end": 360.59999999999997, "text": " Zero zajmuje si\u0119 obiema kategoriami, ale prawdziwa rewolucja zaczyna si\u0119 od model states.", "tokens": [50369, 17182, 33729, 76, 13008, 3244, 1111, 414, 1696, 350, 2968, 284, 15568, 11, 6775, 41175, 3992, 4151, 319, 48481, 1311, 2938, 43811, 629, 3244, 3611, 2316, 4368, 13, 50649], "temperature": 0.0, "avg_logprob": -0.11063567973949291, "compression_ratio": 1.4148936170212767, "no_speech_prob": 0.0024868331383913755}, {"id": 71, "seek": 35490, "start": 360.59999999999997, "end": 367.2, "text": " Ok, czyli mamy zdiagnozowanego g\u0142\u00f3wnego winowajce i tu dochodzimy do tego momentu, aha.", "tokens": [50649, 3477, 11, 16591, 17335, 710, 4504, 559, 1771, 89, 37345, 6308, 18117, 3901, 11858, 1942, 305, 1805, 384, 741, 2604, 9243, 378, 89, 13189, 360, 8627, 1623, 84, 11, 47340, 13, 50979], "temperature": 0.0, "avg_logprob": -0.11063567973949291, "compression_ratio": 1.4148936170212767, "no_speech_prob": 0.0024868331383913755}, {"id": 72, "seek": 35490, "start": 367.2, "end": 372.0, "text": " Kluczowy wgl\u0105d autor\u00f3w zero jest po prostu genialny.", "tokens": [50979, 16053, 1311, 89, 10089, 261, 7191, 18962, 19510, 3901, 4018, 3492, 714, 19518, 48228, 1634, 13, 51219], "temperature": 0.0, "avg_logprob": -0.11063567973949291, "compression_ratio": 1.4148936170212767, "no_speech_prob": 0.0024868331383913755}, {"id": 73, "seek": 35490, "start": 372.0, "end": 377.9, "text": " Te wszystkie stany modelu nie s\u0105 potrzebne przez ca\u0142y czas na ka\u017cdym GPU jednocze\u015bnie.", "tokens": [51219, 1989, 31723, 342, 1325, 2316, 84, 2838, 9015, 37595, 716, 14064, 35226, 13190, 1667, 31615, 76, 18407, 5232, 26694, 1381, 12221, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11063567973949291, "compression_ratio": 1.4148936170212767, "no_speech_prob": 0.0024868331383913755}, {"id": 74, "seek": 35490, "start": 377.9, "end": 383.09999999999997, "text": " I to jest sedno. U\u017cyjmy twojej analogii z kucharzami i wielkim daniem.", "tokens": [51514, 286, 281, 3492, 9643, 1771, 13, 624, 7735, 73, 2226, 732, 2884, 73, 16660, 5597, 710, 350, 31084, 89, 4526, 741, 20570, 25112, 3277, 4907, 13, 51774], "temperature": 0.0, "avg_logprob": -0.11063567973949291, "compression_ratio": 1.4148936170212767, "no_speech_prob": 0.0024868331383913755}, {"id": 75, "seek": 38310, "start": 383.1, "end": 391.5, "text": " W standardowym DP ka\u017cdy kucharz dostaje na start pe\u0142n\u0105 list\u0119 sk\u0142adnik\u00f3w na ca\u0142y przepis i trzyma je przy sobie przez ca\u0142y czas.", "tokens": [50364, 343, 3832, 31691, 42796, 31615, 350, 31084, 89, 20568, 11153, 1667, 722, 43205, 13113, 1329, 1274, 1110, 10358, 47447, 1667, 35226, 30829, 271, 741, 34573, 1696, 1506, 6501, 13652, 14064, 35226, 13190, 13, 50784], "temperature": 0.0, "avg_logprob": -0.09559010797076756, "compression_ratio": 1.564625850340136, "no_speech_prob": 0.014879227615892887}, {"id": 76, "seek": 38310, "start": 391.5, "end": 393.90000000000003, "text": " Zero DP m\u00f3wi stop.", "tokens": [50784, 17182, 42796, 24592, 1590, 13, 50904], "temperature": 0.0, "avg_logprob": -0.09559010797076756, "compression_ratio": 1.564625850340136, "no_speech_prob": 0.014879227615892887}, {"id": 77, "seek": 38310, "start": 393.90000000000003, "end": 399.8, "text": " Kucharz numer jeden potrzebuje teraz tylko m\u0105ki i jajek, \u017ceby zrobi\u0107 ciasto. Dajmy mu tylko to.", "tokens": [50904, 591, 31084, 89, 7866, 12906, 28577, 6021, 2884, 16854, 13219, 275, 1611, 2984, 741, 361, 1805, 916, 11, 11316, 31785, 6983, 33869, 13, 413, 1805, 2226, 2992, 13219, 281, 13, 51199], "temperature": 0.0, "avg_logprob": -0.09559010797076756, "compression_ratio": 1.564625850340136, "no_speech_prob": 0.014879227615892887}, {"id": 78, "seek": 38310, "start": 399.8, "end": 406.20000000000005, "text": " Gdy sko\u0144czy, przeka\u017ce ciasto kucharzowi numer dwa, kt\u00f3ry potrzebuje tylko cukru i owoc\u00f3w. Dajmy mu tylko to.", "tokens": [51199, 460, 3173, 1110, 78, 5248, 6522, 11, 29785, 64, 2875, 6983, 33869, 350, 31084, 89, 24503, 7866, 35045, 11, 9913, 28577, 6021, 2884, 13219, 37485, 894, 741, 11492, 905, 3901, 13, 413, 1805, 2226, 2992, 13219, 281, 13, 51519], "temperature": 0.0, "avg_logprob": -0.09559010797076756, "compression_ratio": 1.564625850340136, "no_speech_prob": 0.014879227615892887}, {"id": 79, "seek": 38310, "start": 406.20000000000005, "end": 411.8, "text": " Chodzi o to, by dostarcza\u0107 zasoby dynamicznie, dok\u0142adnie wtedy i tam, gdzie s\u0105 potrzebne.", "tokens": [51519, 761, 14543, 277, 281, 11, 538, 20568, 40088, 35873, 26530, 13944, 8546, 89, 2766, 11, 45864, 2766, 26959, 741, 7677, 11, 18922, 9015, 37595, 716, 13, 51799], "temperature": 0.0, "avg_logprob": -0.09559010797076756, "compression_ratio": 1.564625850340136, "no_speech_prob": 0.014879227615892887}, {"id": 80, "seek": 41180, "start": 411.8, "end": 418.90000000000003, "text": " A nie replikowa\u0107 wszystko wsz\u0119dzie na wszelki wypadek. I nad tej zasadzie opiera si\u0119 z serce tej technologii. Zero DP.", "tokens": [50364, 316, 2838, 3248, 1035, 11445, 22607, 38322, 42643, 1667, 37647, 12971, 2984, 46392, 762, 74, 13, 286, 12617, 12573, 44585, 3283, 999, 10609, 3244, 710, 816, 384, 12573, 1537, 1132, 5597, 13, 17182, 42796, 13, 50719], "temperature": 0.0, "avg_logprob": -0.09894866302233785, "compression_ratio": 1.4724409448818898, "no_speech_prob": 0.004156686831265688}, {"id": 81, "seek": 41180, "start": 418.90000000000003, "end": 423.3, "text": " I z tego, co czytam, podzielili to na trzy etapy. Zacznijmy od pierwszego.", "tokens": [50719, 286, 710, 8627, 11, 598, 6430, 37323, 11, 2497, 42280, 2312, 281, 1667, 34573, 47634, 88, 13, 1176, 14875, 77, 1718, 2226, 3611, 27623, 27725, 13, 50939], "temperature": 0.0, "avg_logprob": -0.09894866302233785, "compression_ratio": 1.4724409448818898, "no_speech_prob": 0.004156686831265688}, {"id": 82, "seek": 41180, "start": 423.3, "end": 428.90000000000003, "text": " Etap pierwszy to optimizer state partitioning. W skr\u00f3cie pos.", "tokens": [50939, 3790, 569, 34016, 281, 5028, 6545, 1785, 24808, 278, 13, 343, 1110, 11721, 4260, 1366, 13, 51219], "temperature": 0.0, "avg_logprob": -0.09894866302233785, "compression_ratio": 1.4724409448818898, "no_speech_prob": 0.004156686831265688}, {"id": 83, "seek": 41180, "start": 428.90000000000003, "end": 436.3, "text": " Zamiast replikowa\u0107 stany optimalizatora na ka\u017cdym GPU, po prostu dzielimy je r\u00f3wno pomi\u0119dzy wszystkie procesy.", "tokens": [51219, 1176, 4526, 525, 3248, 1035, 11445, 342, 1325, 2427, 10650, 590, 1639, 64, 1667, 31615, 76, 18407, 11, 714, 19518, 9758, 1187, 13189, 1506, 11416, 20944, 12991, 49485, 31723, 17565, 88, 13, 51589], "temperature": 0.0, "avg_logprob": -0.09894866302233785, "compression_ratio": 1.4724409448818898, "no_speech_prob": 0.004156686831265688}, {"id": 84, "seek": 43630, "start": 436.3, "end": 443.40000000000003, "text": " Je\u015bli mamy osiem kart graficznych, ka\u017cda przechowuje i aktualizuje tylko jedn\u0105 usm\u0105 tych stan\u00f3w. Proste.", "tokens": [50364, 37086, 17335, 3003, 4907, 29120, 1295, 1786, 89, 9399, 11, 21912, 2675, 8325, 339, 305, 13008, 741, 13680, 901, 590, 13008, 13219, 5232, 13113, 505, 76, 1611, 15180, 27984, 3901, 13, 2114, 555, 68, 13, 50719], "temperature": 0.0, "avg_logprob": -0.0945042948569021, "compression_ratio": 1.4758842443729903, "no_speech_prob": 0.015300658531486988}, {"id": 85, "seek": 43630, "start": 443.40000000000003, "end": 450.8, "text": " Ale efekt jest pot\u0119\u017cny. Autorzy podaj\u0105, \u017ce to ju\u017c na starcie daje czterokrotn\u0105 redukcj\u0119 zu\u017cycia pami\u0119ci.", "tokens": [50719, 9366, 31482, 8192, 3492, 1847, 1274, 1427, 1634, 13, 6049, 284, 1229, 2497, 11133, 11, 3561, 281, 10678, 1667, 3543, 4260, 1120, 2884, 6472, 391, 453, 10536, 13113, 2783, 74, 41960, 2164, 7735, 2755, 31088, 537, 13, 51089], "temperature": 0.0, "avg_logprob": -0.0945042948569021, "compression_ratio": 1.4758842443729903, "no_speech_prob": 0.015300658531486988}, {"id": 86, "seek": 43630, "start": 450.8, "end": 461.8, "text": " Czekaj, czterokrotna redukcja to jest ogromny zysk. Ale co najwa\u017cniejsze, oni pisz\u0105, \u017ce to nie generuje \u017cadnych dodatkowych koszt\u00f3w komunikacji w por\u00f3wnaniu do standardowego DP.", "tokens": [51089, 383, 19878, 1805, 11, 6472, 391, 453, 10536, 629, 2783, 74, 34056, 281, 3492, 34416, 298, 1634, 710, 749, 74, 13, 9366, 598, 11212, 27111, 44258, 11, 36317, 26584, 8925, 11, 3561, 281, 2838, 1337, 13008, 39628, 9399, 13886, 33525, 19605, 19532, 2682, 3901, 45359, 1035, 13152, 261, 1515, 812, 895, 25849, 360, 3832, 26576, 42796, 13, 51639], "temperature": 0.0, "avg_logprob": -0.0945042948569021, "compression_ratio": 1.4758842443729903, "no_speech_prob": 0.015300658531486988}, {"id": 87, "seek": 43630, "start": 461.8, "end": 463.5, "text": " Jak to w og\u00f3le mo\u017cliwe?", "tokens": [51639, 15029, 281, 261, 29229, 30854, 826, 30, 51724], "temperature": 0.0, "avg_logprob": -0.0945042948569021, "compression_ratio": 1.4758842443729903, "no_speech_prob": 0.015300658531486988}, {"id": 88, "seek": 43630, "start": 463.5, "end": 465.90000000000003, "text": " To jest \u015bwietne pytanie.", "tokens": [51724, 1407, 3492, 8299, 39083, 716, 36610, 13, 51844], "temperature": 0.0, "avg_logprob": -0.0945042948569021, "compression_ratio": 1.4758842443729903, "no_speech_prob": 0.015300658531486988}, {"id": 89, "seek": 46590, "start": 465.9, "end": 477.2, "text": " Dzieje si\u0119 tak, poniewa\u017c w standardowym DP i tak musisz na koniec zebra\u0107 wszystkie gradienty ze wszystkich kart i je u\u015bredni\u0107 za pomoc\u0105 operacji All Reduce.", "tokens": [50364, 413, 3283, 2884, 3244, 991, 11, 32426, 261, 3832, 31691, 42796, 741, 991, 1038, 23848, 1667, 5897, 35733, 47060, 2162, 31723, 16235, 88, 5277, 34234, 29120, 741, 1506, 344, 1788, 986, 3722, 2162, 7949, 48962, 1611, 2208, 13152, 1057, 4477, 4176, 13, 50929], "temperature": 0.0, "avg_logprob": -0.08774069213867187, "compression_ratio": 1.4448398576512456, "no_speech_prob": 0.01668037660419941}, {"id": 90, "seek": 46590, "start": 477.2, "end": 485.2, "text": " In\u017cynierowie Zero wpadli na pomys\u0142, \u017ceby po\u0142\u0105czy\u0107 t\u0119 operacj\u0119 z dystrybucj\u0105 odpowiednich fragment\u00f3w stan\u00f3w optimalizatora.", "tokens": [50929, 682, 1427, 2534, 811, 13998, 17182, 261, 13647, 2081, 1667, 12991, 39508, 11, 11316, 714, 15926, 33967, 32489, 2208, 29924, 710, 14584, 372, 627, 65, 1311, 8555, 36574, 77, 480, 26424, 3901, 27984, 3901, 2427, 10650, 590, 1639, 64, 13, 51329], "temperature": 0.0, "avg_logprob": -0.08774069213867187, "compression_ratio": 1.4448398576512456, "no_speech_prob": 0.01668037660419941}, {"id": 91, "seek": 46590, "start": 485.2, "end": 491.79999999999995, "text": " Zamiast robi\u0107 dwie osobne operacje, robi\u0105 jedn\u0105 sprytniejsz\u0105, kt\u00f3ra osi\u0105ga oba cele za jednym zamachem.", "tokens": [51329, 1176, 4526, 525, 46900, 274, 8699, 41518, 716, 2208, 29293, 11, 3870, 11404, 5232, 13113, 637, 627, 83, 30295, 8925, 11, 19456, 3003, 11404, 3680, 1111, 64, 43165, 7949, 5232, 12996, 19876, 608, 443, 13, 51659], "temperature": 0.0, "avg_logprob": -0.08774069213867187, "compression_ratio": 1.4448398576512456, "no_speech_prob": 0.01668037660419941}, {"id": 92, "seek": 49180, "start": 491.8, "end": 496.7, "text": " Dlatego zysk pami\u0119ci jest, mo\u017cna powiedzie\u0107, darmowy z perspektywy komunikacji.", "tokens": [50364, 47184, 710, 749, 74, 31088, 537, 3492, 11, 17790, 27886, 11, 4072, 76, 10089, 710, 868, 32659, 874, 9726, 45359, 1035, 13152, 13, 50609], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 93, "seek": 49180, "start": 496.7, "end": 504.1, "text": " Rozumiem, czyli to ju\u017c jest imponuj\u0105ce. Ale wci\u0105\u017c mamy zreplikowane gradienty i parametry, kt\u00f3re te\u017c s\u0105 ogromne.", "tokens": [50609, 43313, 449, 4907, 11, 16591, 281, 10678, 3492, 704, 266, 13263, 384, 13, 9366, 261, 537, 27242, 17335, 710, 265, 564, 1035, 23066, 16235, 88, 741, 6220, 9889, 11, 8864, 9516, 9015, 34416, 298, 716, 13, 50979], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 94, "seek": 49180, "start": 504.1, "end": 506.6, "text": " Domy\u015blam si\u0119, \u017ce to jest cel drugiego etapu.", "tokens": [50979, 413, 8488, 1788, 4326, 3244, 11, 3561, 281, 3492, 9277, 4110, 12200, 47634, 84, 13, 51104], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 95, "seek": 49180, "start": 506.6, "end": 512.3, "text": " Dok\u0142adnie tak. I do tego samego wniosku doszli autorzy. Dlatego wprowadzili etap dwa.", "tokens": [51104, 29768, 10358, 2766, 991, 13, 286, 360, 8627, 912, 1571, 45368, 2717, 5279, 4491, 89, 2081, 19510, 1229, 13, 47184, 46733, 89, 2312, 47634, 35045, 13, 51389], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 96, "seek": 49180, "start": 512.3, "end": 516.6, "text": " Gradient Partitioning, oznaczany jako POS plus G.", "tokens": [51389, 16710, 1196, 4100, 849, 278, 11, 277, 22672, 14875, 1325, 17123, 430, 4367, 1804, 460, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 97, "seek": 49180, "start": 516.6, "end": 521.2, "text": " Tutaj, opr\u00f3cz stan\u00f3w optimalizatora, dzielimy r\u00f3wnie\u017c gradienty.", "tokens": [51604, 41819, 11, 999, 11721, 3689, 27984, 3901, 2427, 10650, 590, 1639, 64, 11, 9758, 1187, 13189, 20532, 16235, 88, 13, 51834], "temperature": 0.0, "avg_logprob": -0.10138394673665364, "compression_ratio": 1.4294670846394983, "no_speech_prob": 0.043560612946748734}, {"id": 98, "seek": 52120, "start": 521.2, "end": 526.9000000000001, "text": " Ka\u017cdy proces GPU jest odpowiedziany tylko za aktualizacj\u0119 swojej cz\u0119\u015bci parametr\u00f3w.", "tokens": [50364, 10988, 1427, 3173, 17565, 18407, 3492, 24314, 15338, 952, 88, 13219, 7949, 13680, 901, 590, 29924, 29489, 73, 41314, 6220, 27965, 3901, 13, 50649], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 99, "seek": 52120, "start": 526.9000000000001, "end": 532.0, "text": " Wi\u0119c potrzebuje tylko tych gradient\u00f3w, kt\u00f3re odpowiadaj\u0105 tej cz\u0119\u015bci.", "tokens": [50649, 32508, 28577, 6021, 2884, 13219, 15180, 16235, 3901, 11, 8864, 24314, 39018, 8555, 12573, 41314, 13, 50904], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 100, "seek": 52120, "start": 532.0, "end": 534.0, "text": " Reszty nie musi przechowywa\u0107.", "tokens": [50904, 5015, 89, 874, 2838, 37587, 8325, 339, 10089, 25234, 13, 51004], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 101, "seek": 52120, "start": 534.0, "end": 537.2, "text": " Chwila, czyli znowu dzielimy wi\u0119cej danych.", "tokens": [51004, 761, 86, 7371, 11, 16591, 710, 3785, 84, 9758, 1187, 13189, 26004, 274, 34644, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 102, "seek": 52120, "start": 537.2, "end": 543.6, "text": " Ale w artykule czytam, \u017ce wolumen komunikacji wci\u0105\u017c pozostaje taki sam jak w standardowym DP.", "tokens": [51164, 9366, 261, 594, 874, 74, 2271, 6430, 37323, 11, 3561, 20960, 16988, 45359, 1035, 13152, 261, 537, 27242, 21281, 555, 11153, 20065, 3247, 4207, 261, 3832, 31691, 42796, 13, 51484], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 103, "seek": 52120, "start": 543.6, "end": 547.2, "text": " To brzmu jak czarna magia. Gdzie jest haczyk?", "tokens": [51484, 1407, 738, 89, 20140, 4207, 6472, 21394, 2258, 654, 13, 460, 13096, 3492, 324, 6522, 74, 30, 51664], "temperature": 0.0, "avg_logprob": -0.11136958675999795, "compression_ratio": 1.3691756272401434, "no_speech_prob": 0.0009419511188752949}, {"id": 104, "seek": 54720, "start": 547.2, "end": 552.5, "text": " Jak mo\u017cna oszcz\u0119dzi\u0107 dwa razy wi\u0119cej pami\u0119ci, ale koszt komunikacji w og\u00f3le nie ro\u015bnie?", "tokens": [50364, 15029, 17790, 3003, 43771, 6298, 28496, 35045, 9639, 88, 26004, 31088, 537, 11, 6775, 19532, 2682, 45359, 1035, 13152, 261, 29229, 2838, 744, 12221, 30, 50629], "temperature": 0.0, "avg_logprob": -0.11302571418957832, "compression_ratio": 1.41635687732342, "no_speech_prob": 0.03966452181339264}, {"id": 105, "seek": 54720, "start": 552.5, "end": 557.8000000000001, "text": " To nie magia. Tylko bardzo sprytna in\u017cynieria komunikacji.", "tokens": [50629, 1407, 2838, 2258, 654, 13, 49286, 4093, 9034, 637, 627, 83, 629, 294, 1427, 2534, 811, 654, 45359, 1035, 13152, 13, 50894], "temperature": 0.0, "avg_logprob": -0.11302571418957832, "compression_ratio": 1.41635687732342, "no_speech_prob": 0.03966452181339264}, {"id": 106, "seek": 54720, "start": 557.8000000000001, "end": 564.1, "text": " Zamiast standardowej operacji AllReduce, kt\u00f3ra wysy\u0142a wszystkie gradienty do wszystkich,", "tokens": [50894, 1176, 4526, 525, 3832, 21091, 2208, 13152, 1057, 20544, 4176, 11, 19456, 27062, 88, 5024, 31723, 16235, 88, 360, 34234, 11, 51209], "temperature": 0.0, "avg_logprob": -0.11302571418957832, "compression_ratio": 1.41635687732342, "no_speech_prob": 0.03966452181339264}, {"id": 107, "seek": 54720, "start": 564.1, "end": 568.1, "text": " u\u017cywaj\u0105 operacji Reduce Scatter.", "tokens": [51209, 34097, 86, 11133, 2208, 13152, 4477, 4176, 2747, 1161, 13, 51409], "temperature": 0.0, "avg_logprob": -0.11302571418957832, "compression_ratio": 1.41635687732342, "no_speech_prob": 0.03966452181339264}, {"id": 108, "seek": 54720, "start": 568.1, "end": 574.7, "text": " Ka\u017cdy GPU oblicza swoj\u0105 porcj\u0119 gradient\u00f3w, a potem ta operacja redukuje je, na przyk\u0142ad sumuje,", "tokens": [51409, 10988, 1427, 3173, 18407, 1111, 1050, 2394, 49194, 1515, 41960, 16235, 3901, 11, 257, 36513, 1846, 2208, 23395, 2783, 5279, 2884, 1506, 11, 1667, 23144, 2408, 13008, 11, 51739], "temperature": 0.0, "avg_logprob": -0.11302571418957832, "compression_ratio": 1.41635687732342, "no_speech_prob": 0.03966452181339264}, {"id": 109, "seek": 57470, "start": 574.7, "end": 582.5, "text": " i od razu rozsiewa, czyli Scatters, odpowiednie ju\u017c zsumowane fragmenty do w\u0142a\u015bciwych procesor\u00f3w.", "tokens": [50364, 741, 3611, 367, 8813, 9544, 82, 1093, 64, 11, 16591, 2747, 37690, 11, 36574, 2766, 10678, 710, 82, 449, 23066, 26424, 88, 360, 40112, 9726, 339, 17565, 284, 3901, 13, 50754], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 110, "seek": 57470, "start": 582.5, "end": 586.1, "text": " Ka\u017cdy dostaje tylko to, co jest mu potrzebne.", "tokens": [50754, 10988, 1427, 3173, 20568, 11153, 13219, 281, 11, 598, 3492, 2992, 37595, 716, 13, 50934], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 111, "seek": 57470, "start": 586.1, "end": 592.0, "text": " Okazuje si\u0119, \u017ce ca\u0142kowita ilo\u015b\u0107 danych przesy\u0142anych przez sie\u0107 jest identyczna jak w AllReduce.", "tokens": [50934, 3477, 43317, 3244, 11, 3561, 35224, 74, 305, 2786, 1930, 78, 7753, 274, 34644, 6541, 17823, 1221, 34644, 14064, 2804, 2162, 3492, 2473, 17466, 629, 4207, 261, 1057, 20544, 4176, 13, 51229], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 112, "seek": 57470, "start": 592.0, "end": 593.5, "text": " Czyli haczyka nie ma?", "tokens": [51229, 37099, 324, 6522, 2330, 2838, 463, 30, 51304], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 113, "seek": 57470, "start": 593.5, "end": 594.5, "text": " Nie ma.", "tokens": [51304, 12016, 463, 13, 51354], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 114, "seek": 57470, "start": 594.5, "end": 602.1, "text": " Efekt jest taki, \u017ce uzyskujemy ju\u017c o\u015bmiokrotn\u0105 redukcj\u0119 zu\u017cycia pami\u0119ci wci\u0105\u017c bez dodatkowego narzutu komunikacyjnego.", "tokens": [51354, 31840, 8192, 3492, 20065, 11, 3561, 16851, 749, 74, 21767, 10678, 277, 1788, 3057, 453, 10536, 13113, 2783, 74, 41960, 2164, 7735, 2755, 31088, 537, 261, 537, 27242, 10782, 13886, 33525, 26576, 6714, 89, 325, 84, 45359, 1035, 31285, 11858, 13, 51734], "temperature": 0.0, "avg_logprob": -0.07501090594700405, "compression_ratio": 1.4006849315068493, "no_speech_prob": 0.002601775573566556}, {"id": 115, "seek": 60210, "start": 602.2, "end": 608.6, "text": " To jest absolutnie genialne, czyli po dw\u00f3ch etapach mamy o\u015bmiokrotnie mniejsze zapotrzebowanie na pami\u0119\u0107,", "tokens": [50369, 1407, 3492, 18757, 2766, 48228, 716, 11, 16591, 714, 27379, 812, 339, 47634, 608, 17335, 277, 1788, 3057, 453, 10536, 2766, 275, 44258, 14223, 310, 13503, 8202, 7155, 1667, 31088, 2162, 11, 50689], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 116, "seek": 60210, "start": 608.6, "end": 613.1, "text": " ale wci\u0105\u017c na ka\u017cdej karcie siedzi pe\u0142na kopia parametr\u00f3w modelu.", "tokens": [50689, 6775, 261, 537, 27242, 1667, 21912, 1479, 73, 7917, 4260, 262, 1091, 3992, 43205, 629, 28920, 654, 6220, 27965, 3901, 2316, 84, 13, 50914], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 117, "seek": 60210, "start": 613.1, "end": 616.7, "text": " I to prowadzi nas do etapu trzeciego, tego ostatecznego.", "tokens": [50914, 286, 281, 36590, 3992, 5382, 360, 47634, 84, 22266, 4260, 1571, 11, 8627, 277, 15406, 3689, 11858, 13, 51094], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 118, "seek": 60210, "start": 616.7, "end": 623.7, "text": " Tak, etap 3, Parameter Partitioning, czyli POS plus G plus P.", "tokens": [51094, 9118, 11, 47634, 805, 11, 34882, 2398, 4100, 849, 278, 11, 16591, 430, 4367, 1804, 460, 1804, 430, 13, 51444], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 119, "seek": 60210, "start": 623.7, "end": 627.0, "text": " Na koniec dzielimy same parametry modelu.", "tokens": [51444, 6056, 5897, 35733, 9758, 1187, 13189, 912, 6220, 9889, 2316, 84, 13, 51609], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 120, "seek": 60210, "start": 627.0, "end": 629.2, "text": " To jest najbardziej radykalny krok.", "tokens": [51609, 1407, 3492, 41857, 367, 880, 19990, 1634, 350, 31621, 13, 51719], "temperature": 0.0, "avg_logprob": -0.12850075960159302, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.0023678774014115334}, {"id": 121, "seek": 62920, "start": 629.2, "end": 637.1, "text": " Wyobra\u017amy sobie, \u017ce ka\u017cda karta GPU w danym momencie widzi tylko t\u0119 cz\u0119\u015b\u0107 modelu, nad kt\u00f3r\u0105 akurat pracuje.", "tokens": [50364, 14458, 24393, 10659, 2226, 13652, 11, 3561, 21912, 2675, 350, 19061, 18407, 261, 274, 1325, 76, 40883, 5274, 3992, 13219, 32489, 47149, 2316, 84, 11, 12617, 37415, 9308, 44108, 22404, 13008, 13, 50759], "temperature": 0.0, "avg_logprob": -0.0709068603515625, "compression_ratio": 1.397923875432526, "no_speech_prob": 0.0013041956117376685}, {"id": 122, "seek": 62920, "start": 637.1, "end": 641.3000000000001, "text": " A reszta jest dla niej niewidoczna, dop\u00f3ki nie b\u0119dzie potrzebna.", "tokens": [50759, 316, 725, 89, 1328, 3492, 12285, 2838, 73, 43622, 327, 905, 35458, 11, 21900, 812, 2984, 2838, 10562, 37595, 629, 13, 50969], "temperature": 0.0, "avg_logprob": -0.0709068603515625, "compression_ratio": 1.397923875432526, "no_speech_prob": 0.0013041956117376685}, {"id": 123, "seek": 62920, "start": 641.3000000000001, "end": 644.5, "text": " Kiedy przychodzi czas na obliczenia w danej warstwie sieci,", "tokens": [50969, 591, 16446, 6501, 34616, 13190, 1667, 1111, 1050, 14320, 261, 49206, 73, 1516, 372, 8699, 2804, 537, 11, 51129], "temperature": 0.0, "avg_logprob": -0.0709068603515625, "compression_ratio": 1.397923875432526, "no_speech_prob": 0.0013041956117376685}, {"id": 124, "seek": 62920, "start": 644.5, "end": 651.1, "text": " odpowiednie parametry s\u0105 dynamicznie przesy\u0142ane w locie do wszystkich kart za pomoc\u0105 operacji AllGather.", "tokens": [51129, 36574, 2766, 6220, 9889, 9015, 8546, 89, 2766, 6541, 17823, 1221, 1929, 261, 1628, 414, 360, 34234, 29120, 7949, 48962, 1611, 2208, 13152, 1057, 38, 1172, 13, 51459], "temperature": 0.0, "avg_logprob": -0.0709068603515625, "compression_ratio": 1.397923875432526, "no_speech_prob": 0.0013041956117376685}, {"id": 125, "seek": 62920, "start": 651.1, "end": 654.3000000000001, "text": " Po wykonaniu oblicze\u0144 s\u0105 one zwalniane z pami\u0119ci.", "tokens": [51459, 6165, 46702, 25849, 1111, 1050, 49689, 9015, 472, 11873, 39980, 21133, 710, 31088, 537, 13, 51619], "temperature": 0.0, "avg_logprob": -0.0709068603515625, "compression_ratio": 1.397923875432526, "no_speech_prob": 0.0013041956117376685}, {"id": 126, "seek": 65430, "start": 654.4, "end": 655.8, "text": " Efekt ko\u0144cowy.", "tokens": [50369, 31840, 8192, 26470, 66, 10089, 13, 50439], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 127, "seek": 65430, "start": 655.8, "end": 660.4, "text": " Redukcja pami\u0119ci staje si\u0119 liniowo zale\u017cna od liczby u\u017cywanych GPU.", "tokens": [50439, 4477, 2034, 34056, 31088, 537, 342, 11153, 3244, 287, 3812, 19941, 710, 45494, 629, 3611, 6169, 89, 2322, 34097, 86, 34644, 18407, 13, 50669], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 128, "seek": 65430, "start": 660.4, "end": 665.6999999999999, "text": " Je\u015bli mamy 64 karty, teoretyczna redukcja jest 64-krotna.", "tokens": [50669, 37086, 17335, 12145, 29120, 88, 11, 535, 418, 874, 3689, 629, 2783, 74, 34056, 3492, 12145, 12, 74, 10536, 629, 13, 50934], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 129, "seek": 65430, "start": 665.6999999999999, "end": 668.9, "text": " No dobrze, ale tu ju\u017c musi by\u0107 jaki\u015b koszt.", "tokens": [50934, 883, 28335, 11, 6775, 2604, 10678, 37587, 15069, 34721, 19532, 2682, 13, 51094], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 130, "seek": 65430, "start": 668.9, "end": 674.4, "text": " Przesy\u0142anie parametr\u00f3w w prz\u00f3d i w ty\u0142 przy ka\u017cdej warstwie brzmi jak ogromny narzut.", "tokens": [51094, 2114, 12214, 88, 1221, 7155, 6220, 27965, 3901, 261, 6541, 17081, 741, 261, 1104, 1221, 6501, 21912, 1479, 73, 1516, 372, 8699, 738, 89, 3057, 4207, 34416, 298, 1634, 6714, 89, 325, 13, 51369], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 131, "seek": 65430, "start": 674.4, "end": 679.5999999999999, "text": " Autorzy sami przyznaj\u0105, \u017ce og\u00f3lna komunikacja wzrasta o 50%.", "tokens": [51369, 6049, 284, 1229, 3247, 72, 6501, 35458, 8555, 11, 3561, 5360, 15741, 629, 45359, 1035, 23395, 24809, 4148, 64, 277, 2625, 6856, 51629], "temperature": 0.0, "avg_logprob": -0.082843613078576, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.005089933983981609}, {"id": 132, "seek": 67960, "start": 679.6, "end": 686.5, "text": " Czy ten wzrost nie staje si\u0119 w\u0105skim gard\u0142em przy naprawd\u0119 du\u017cej skali, powiedzmy na tysi\u0105cach GPU?", "tokens": [50364, 19832, 2064, 24809, 27494, 2838, 342, 11153, 3244, 261, 1611, 5161, 332, 5628, 11126, 6501, 20970, 1581, 38493, 1110, 5103, 11, 27617, 2226, 1667, 38156, 11404, 66, 608, 18407, 30, 50709], "temperature": 0.0, "avg_logprob": -0.0624210617759011, "compression_ratio": 1.4119718309859155, "no_speech_prob": 0.012266566976904869}, {"id": 133, "seek": 67960, "start": 686.5, "end": 690.8000000000001, "text": " Czy zysk z pami\u0119\u0107 nie jest niwelowany przez czas oczekiwania na dane?", "tokens": [50709, 19832, 710, 749, 74, 710, 31088, 2162, 2838, 3492, 3867, 45512, 23341, 14064, 13190, 277, 3689, 14753, 86, 5609, 1667, 49206, 30, 50924], "temperature": 0.0, "avg_logprob": -0.0624210617759011, "compression_ratio": 1.4119718309859155, "no_speech_prob": 0.012266566976904869}, {"id": 134, "seek": 67960, "start": 690.8000000000001, "end": 695.2, "text": " To jest kluczowa obawa i autorzy \u015bwietnie j\u0105 adresuj\u0105.", "tokens": [50924, 1407, 3492, 9671, 1311, 89, 5528, 1111, 10449, 741, 19510, 1229, 8299, 39083, 2766, 35692, 614, 495, 13263, 13, 51144], "temperature": 0.0, "avg_logprob": -0.0624210617759011, "compression_ratio": 1.4119718309859155, "no_speech_prob": 0.012266566976904869}, {"id": 135, "seek": 67960, "start": 695.2, "end": 700.6, "text": " Po pierwsze, ten 50% wzrost to jest ca\u0142kowita obj\u0119to\u015b\u0107 danych.", "tokens": [51144, 6165, 45994, 11, 2064, 2625, 4, 24809, 27494, 281, 3492, 35224, 74, 305, 2786, 1111, 11115, 1353, 7753, 274, 34644, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0624210617759011, "compression_ratio": 1.4119718309859155, "no_speech_prob": 0.012266566976904869}, {"id": 136, "seek": 67960, "start": 700.6, "end": 706.6, "text": " Te operacje s\u0105 jednak zaimplementowane tak, by maksymalnie nak\u0142ada\u0107 komunikacj\u0119 z obliczeniami.", "tokens": [51414, 1989, 2208, 29293, 9015, 25897, 7949, 332, 43704, 23066, 991, 11, 538, 963, 3187, 5579, 2766, 20332, 46217, 2162, 45359, 1035, 29924, 710, 1111, 1050, 2904, 15568, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0624210617759011, "compression_ratio": 1.4119718309859155, "no_speech_prob": 0.012266566976904869}, {"id": 137, "seek": 70660, "start": 706.6, "end": 712.9, "text": " Nowoczesne, szybkie interkonekty jak InfiniBend czy Enfulink s\u0105 zaprojektowane do takich zada\u0144.", "tokens": [50364, 823, 905, 12214, 716, 11, 36456, 22872, 728, 74, 546, 74, 874, 4207, 11537, 3812, 33, 521, 6430, 2193, 906, 475, 9015, 14223, 340, 14930, 23066, 360, 29607, 710, 1538, 5248, 13, 50679], "temperature": 0.0, "avg_logprob": -0.09857986955081716, "compression_ratio": 1.4982698961937717, "no_speech_prob": 0.03718231990933418}, {"id": 138, "seek": 70660, "start": 712.9, "end": 716.6, "text": " Ale co wa\u017cniejsze jest drugi, bardziej subtelny efekt.", "tokens": [50679, 9366, 598, 27777, 44258, 3492, 4110, 72, 11, 27209, 7257, 338, 1634, 31482, 8192, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09857986955081716, "compression_ratio": 1.4982698961937717, "no_speech_prob": 0.03718231990933418}, {"id": 139, "seek": 70660, "start": 716.6, "end": 724.9, "text": " Uwolniona pami\u0119\u0107 pozwala na u\u017cycie znacznie wi\u0119kszych batch sizes, czyli jednorazowych porcji danych treningowych.", "tokens": [50864, 624, 48481, 77, 21758, 31088, 2162, 40557, 5159, 1667, 34097, 4260, 15397, 14875, 2766, 29968, 28051, 15245, 11602, 11, 16591, 5232, 19048, 921, 19605, 1515, 19649, 274, 34644, 2192, 773, 19605, 13, 51279], "temperature": 0.0, "avg_logprob": -0.09857986955081716, "compression_ratio": 1.4982698961937717, "no_speech_prob": 0.03718231990933418}, {"id": 140, "seek": 70660, "start": 724.9, "end": 729.6, "text": " A im wi\u0119kszy batch size, tym bardziej efektywnie pracuje samo GPU.", "tokens": [51279, 316, 566, 29968, 1229, 15245, 2744, 11, 8107, 27209, 31482, 916, 874, 14215, 22404, 13008, 36422, 18407, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09857986955081716, "compression_ratio": 1.4982698961937717, "no_speech_prob": 0.03718231990933418}, {"id": 141, "seek": 70660, "start": 729.6, "end": 734.8000000000001, "text": " Koszt komunikacji jest amortyzowany przez znacznie wi\u0119ksz\u0105 ilo\u015b\u0107 u\u017cytecznych oblicze\u0144.", "tokens": [51514, 36909, 2682, 45359, 1035, 13152, 3492, 669, 477, 37433, 23341, 14064, 15397, 14875, 2766, 29968, 8925, 1930, 78, 7753, 34097, 975, 3689, 9399, 1111, 1050, 49689, 13, 51774], "temperature": 0.0, "avg_logprob": -0.09857986955081716, "compression_ratio": 1.4982698961937717, "no_speech_prob": 0.03718231990933418}, {"id": 142, "seek": 73480, "start": 734.8, "end": 739.8, "text": " W praktyce dla bardzo du\u017cych modeli ten kompromis jest niezwykle op\u0142acalny.", "tokens": [50364, 343, 3206, 74, 874, 384, 12285, 9034, 1581, 7735, 339, 2316, 72, 2064, 5207, 28722, 271, 3492, 33511, 9726, 14677, 999, 1221, 326, 304, 1634, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12473215255062137, "compression_ratio": 1.3682170542635659, "no_speech_prob": 0.011679715476930141}, {"id": 143, "seek": 73480, "start": 739.8, "end": 747.8, "text": " Dzi\u0119ki temu jak podaj\u0105 w pracy model o bilionie parametr\u00f3w mie\u015bci si\u0119 na 1024 kartach GPU.", "tokens": [50614, 413, 34546, 33346, 4207, 2497, 11133, 261, 35591, 2316, 277, 8588, 313, 414, 6220, 27965, 3901, 12597, 6199, 3244, 1667, 1266, 7911, 29120, 608, 18407, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12473215255062137, "compression_ratio": 1.3682170542635659, "no_speech_prob": 0.011679715476930141}, {"id": 144, "seek": 73480, "start": 747.8, "end": 750.3, "text": " To otwiera zupe\u0142nie nowe horyzonty.", "tokens": [51014, 1407, 4337, 86, 10609, 49922, 586, 68, 276, 827, 89, 896, 88, 13, 51139], "temperature": 0.0, "avg_logprob": -0.12473215255062137, "compression_ratio": 1.3682170542635659, "no_speech_prob": 0.011679715476930141}, {"id": 145, "seek": 73480, "start": 750.3, "end": 759.8, "text": " Ok, czyli poskromili\u015bmy smoka zwanego model states, ale m\u00f3wi\u0142e\u015b, \u017ce s\u0105 jeszcze te mniejsze denerwuj\u0105ce problemy, czyli residual states.", "tokens": [51139, 3477, 11, 16591, 1366, 74, 4397, 43912, 899, 15289, 710, 7916, 6308, 2316, 4368, 11, 6775, 24592, 19827, 1788, 11, 3561, 9015, 14168, 535, 275, 44258, 1441, 260, 86, 13263, 384, 1154, 88, 11, 16591, 27980, 4368, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12473215255062137, "compression_ratio": 1.3682170542635659, "no_speech_prob": 0.011679715476930141}, {"id": 146, "seek": 75980, "start": 760.3, "end": 765.8, "text": " Po takiej optymizacji to one pewnie staj\u0105 si\u0119 nowym w\u0105skim gard\u0142em. Co zrobiono z aktywacjami?", "tokens": [50389, 6165, 38941, 2427, 4199, 590, 13152, 281, 472, 520, 14215, 342, 11133, 3244, 586, 4199, 261, 1611, 5161, 332, 5628, 11126, 13, 3066, 44399, 49020, 710, 9308, 874, 86, 326, 73, 4526, 30, 50664], "temperature": 0.0, "avg_logprob": -0.0993171408156718, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.05341131612658501}, {"id": 147, "seek": 75980, "start": 765.8, "end": 771.8, "text": " Dok\u0142adnie. Gdy wyeliminujesz g\u0142\u00f3wny problem, te drugorz\u0119dne wychodz\u0105 na pierwszy plan.", "tokens": [50664, 29768, 10358, 2766, 13, 460, 3173, 4628, 338, 4395, 4579, 10430, 18117, 812, 43682, 1154, 11, 535, 4110, 284, 89, 6298, 716, 4628, 29914, 8925, 1667, 34016, 1393, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0993171408156718, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.05341131612658501}, {"id": 148, "seek": 75980, "start": 771.8, "end": 776.8, "text": " I tu wkracza 0R. Radzi sobie z tym na kilka sposob\u00f3w.", "tokens": [50964, 286, 2604, 261, 74, 12080, 2394, 1958, 49, 13, 9654, 3992, 13652, 710, 8107, 1667, 36466, 20443, 996, 3901, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0993171408156718, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.05341131612658501}, {"id": 149, "seek": 75980, "start": 776.8, "end": 780.8, "text": " Pierwsza technika to Partition Activation Checkpointing.", "tokens": [51214, 16676, 14358, 2394, 1537, 5439, 281, 4100, 849, 28550, 399, 6881, 6053, 278, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0993171408156718, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.05341131612658501}, {"id": 150, "seek": 75980, "start": 780.8, "end": 783.8, "text": " Checkpointing aktywacji to znana technika.", "tokens": [51414, 6881, 6053, 278, 9308, 874, 86, 13152, 281, 15397, 2095, 1537, 5439, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0993171408156718, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.05341131612658501}, {"id": 151, "seek": 78380, "start": 783.8, "end": 790.8, "text": " Trzyma\u0107 wszystkie aktywacje w pami\u0119ci zapami\u0119tujemy je co kilka warstw, a w razie potrzeby przeliczamy na nowo.", "tokens": [50364, 1765, 1229, 1696, 2162, 31723, 9308, 874, 86, 29293, 261, 31088, 537, 14223, 23806, 83, 21767, 1506, 598, 36466, 1516, 372, 86, 11, 257, 261, 9639, 414, 28577, 2322, 6541, 338, 17946, 7804, 1667, 586, 78, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09470977783203124, "compression_ratio": 1.3766816143497758, "no_speech_prob": 0.12497343868017197}, {"id": 152, "seek": 78380, "start": 790.8, "end": 796.8, "text": " Zero idzie okrok dalej. Dzieli nawet te zapami\u0119tane aktywacje mi\u0119dzy r\u00f3\u017cne GPU.", "tokens": [50714, 17182, 4496, 3283, 3133, 31621, 34257, 13, 39448, 23099, 22696, 535, 14223, 23806, 83, 1929, 9308, 874, 86, 29293, 33964, 47760, 18407, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09470977783203124, "compression_ratio": 1.3766816143497758, "no_speech_prob": 0.12497343868017197}, {"id": 153, "seek": 78380, "start": 796.8, "end": 804.8, "text": " A je\u015bli to wci\u0105\u017c za ma\u0142o, mo\u017ce je nawet zrzuci\u0107 do pami\u0119ci RAM procesora, czyli zrobi\u0107 tzw. offload.", "tokens": [51014, 316, 25630, 281, 261, 537, 27242, 7949, 463, 5249, 11, 12034, 1506, 22696, 710, 81, 11728, 39162, 360, 31088, 537, 14561, 17565, 3252, 11, 16591, 31785, 256, 14406, 13, 766, 2907, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09470977783203124, "compression_ratio": 1.3766816143497758, "no_speech_prob": 0.12497343868017197}, {"id": 154, "seek": 80480, "start": 804.8, "end": 813.8, "text": " Ale zrzucanie danych z superszytkiej pami\u0119ci GPU do znacznie wolniejszej pami\u0119ci RAM procesora to nie brzmi jak dobry pomys\u0142 na wydajno\u015b\u0107.", "tokens": [50364, 9366, 710, 19390, 1311, 7155, 274, 34644, 710, 1687, 7706, 83, 45145, 31088, 537, 18407, 360, 15397, 14875, 2766, 20960, 30295, 16920, 31088, 537, 14561, 17565, 3252, 281, 2838, 738, 89, 3057, 4207, 35884, 12991, 39508, 1667, 25984, 1805, 23293, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06443037103723596, "compression_ratio": 1.4557823129251701, "no_speech_prob": 0.1376759558916092}, {"id": 155, "seek": 80480, "start": 813.8, "end": 816.8, "text": " Czy to nie spowalnia wszystkiego do \u015blimaczego tempa?", "tokens": [50814, 19832, 281, 2838, 637, 305, 304, 12679, 14615, 12200, 360, 8299, 4197, 14875, 6308, 1383, 4306, 30, 50964], "temperature": 0.0, "avg_logprob": -0.06443037103723596, "compression_ratio": 1.4557823129251701, "no_speech_prob": 0.1376759558916092}, {"id": 156, "seek": 80480, "start": 816.8, "end": 822.8, "text": " Intuicyjnie tak, ale w przypadku gigantycznych modeli okazuje si\u0119 to zaskakuj\u0105co efektywne.", "tokens": [50964, 5681, 84, 2632, 73, 2766, 991, 11, 6775, 261, 41955, 8741, 394, 17466, 9399, 2316, 72, 3133, 43317, 3244, 281, 710, 3863, 514, 13263, 1291, 31482, 916, 874, 86, 716, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06443037103723596, "compression_ratio": 1.4557823129251701, "no_speech_prob": 0.1376759558916092}, {"id": 157, "seek": 80480, "start": 822.8, "end": 830.8, "text": " Dzieje si\u0119 tak, poniewa\u017c te modele s\u0105 tak bardzo compute bound, czyli ilo\u015b\u0107 oblicze\u0144 jest tak du\u017ca w stosunku do ilo\u015bci danych,", "tokens": [51264, 413, 3283, 2884, 3244, 991, 11, 32426, 535, 4391, 306, 9015, 991, 9034, 14722, 5472, 11, 16591, 1930, 78, 7753, 1111, 1050, 49689, 3492, 991, 21783, 64, 261, 43581, 49910, 360, 1930, 44468, 274, 34644, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06443037103723596, "compression_ratio": 1.4557823129251701, "no_speech_prob": 0.1376759558916092}, {"id": 158, "seek": 83080, "start": 830.8, "end": 837.8, "text": " \u017ce ten transfer do i z CPU mo\u017cna niemal ca\u0142kowicie ukry\u0107 za czasem, kt\u00f3ry GPU i tak sp\u0119dza na mieleniu liczb.", "tokens": [50364, 3561, 2064, 5003, 360, 741, 710, 13199, 17790, 2838, 5579, 35224, 74, 305, 28434, 26769, 627, 2162, 7949, 13190, 443, 11, 9913, 18407, 741, 991, 637, 6298, 2394, 1667, 275, 12844, 5951, 6169, 89, 65, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09086893055890058, "compression_ratio": 1.4367469879518073, "no_speech_prob": 0.29381126165390015}, {"id": 159, "seek": 83080, "start": 837.8, "end": 841.8, "text": " To kolejny przyk\u0142ad my\u015blenia o ca\u0142ym systemie, a nie tylko o jednym komponencie.", "tokens": [50714, 1407, 23749, 1634, 23144, 48633, 6698, 654, 277, 35224, 4199, 1185, 414, 11, 257, 2838, 13219, 277, 5232, 12996, 5207, 79, 266, 36220, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09086893055890058, "compression_ratio": 1.4367469879518073, "no_speech_prob": 0.29381126165390015}, {"id": 160, "seek": 83080, "start": 841.8, "end": 844.8, "text": " Opr\u00f3cz tego 0R wprowadza jeszcze dwie techniki.", "tokens": [50914, 422, 1424, 812, 3689, 8627, 1958, 49, 46733, 2394, 14168, 274, 8699, 1537, 9850, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09086893055890058, "compression_ratio": 1.4367469879518073, "no_speech_prob": 0.29381126165390015}, {"id": 161, "seek": 83080, "start": 844.8, "end": 849.8, "text": " Constant size buffers, \u017ceby bufory tymczasowe nie ros\u0142y razem z modelem.", "tokens": [51064, 37413, 2744, 9204, 433, 11, 11316, 758, 69, 827, 8107, 30989, 6880, 2838, 18953, 6825, 40225, 710, 4391, 10386, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09086893055890058, "compression_ratio": 1.4367469879518073, "no_speech_prob": 0.29381126165390015}, {"id": 162, "seek": 83080, "start": 849.8, "end": 857.8, "text": " Oraz memory defragmentation, czyli aktywne zarz\u0105dzanie pami\u0119ci\u0105, by unika\u0107 b\u0142\u0119d\u00f3w out of memory nawet gdy teoretycznie jest jeszcze wolne miejsce.", "tokens": [51314, 422, 30695, 4675, 1060, 3731, 19631, 11, 16591, 9308, 874, 86, 716, 22675, 23876, 89, 7155, 31088, 34381, 11, 538, 517, 5439, 2162, 272, 1221, 6298, 3901, 484, 295, 4675, 22696, 28405, 535, 418, 45586, 3492, 14168, 20960, 716, 38122, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09086893055890058, "compression_ratio": 1.4367469879518073, "no_speech_prob": 0.29381126165390015}, {"id": 163, "seek": 85780, "start": 857.8, "end": 859.8, "text": " Takie inteligentne sprz\u0105tanie.", "tokens": [50364, 9118, 414, 24777, 25002, 716, 6103, 8925, 83, 7155, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 164, "seek": 85780, "start": 859.8, "end": 862.8, "text": " W\u0142a\u015bnie, inteligentne sprz\u0105tanie, kt\u00f3re zapobiega katastrofie.", "tokens": [50464, 343, 5024, 12221, 11, 24777, 25002, 716, 6103, 8925, 83, 7155, 11, 8864, 14223, 996, 414, 3680, 16536, 525, 340, 69, 414, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 165, "seek": 85780, "start": 862.8, "end": 869.8, "text": " Wszystko to brzmi genialnie na papierze, ale jak wiemy, w \u015bwiecie wielkich oblicze\u0144 diabe\u0142 tkwi w szczeg\u00f3\u0142ach.", "tokens": [50614, 343, 10424, 4093, 281, 738, 89, 3057, 48228, 2766, 1667, 37410, 1381, 11, 6775, 4207, 3355, 2226, 11, 261, 40078, 4260, 20570, 48349, 1111, 1050, 49689, 1026, 4488, 1221, 256, 74, 6253, 261, 22090, 1146, 16181, 608, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 166, "seek": 85780, "start": 869.8, "end": 876.8, "text": " Czy autorom uda\u0142o si\u0119 udowodni\u0107, \u017ce te wszystkie sprytne sztuczki faktycznie przek\u0142adaj\u0105 si\u0119 na realny wzrost wydajno\u015bci?", "tokens": [50964, 19832, 19510, 298, 44544, 5249, 3244, 11727, 305, 378, 3722, 2162, 11, 3561, 535, 31723, 637, 627, 83, 716, 262, 2682, 1311, 89, 2984, 33647, 45586, 29785, 46217, 8555, 3244, 1667, 957, 1634, 24809, 27494, 25984, 1805, 16438, 30, 51314], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 167, "seek": 85780, "start": 876.8, "end": 878.8, "text": " Jak wypad\u0142y w testach?", "tokens": [51314, 15029, 4628, 13647, 6825, 261, 1500, 608, 30, 51414], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 168, "seek": 85780, "start": 878.8, "end": 883.8, "text": " I to jest chyba najbardziej satysfakcjonuj\u0105ca cz\u0119\u015b\u0107 tej pracy. Wyniki s\u0105 powalaj\u0105ce.", "tokens": [51414, 286, 281, 3492, 31532, 41857, 3227, 749, 69, 514, 45677, 13263, 496, 47149, 12573, 35591, 13, 343, 2534, 9850, 9015, 3388, 304, 11133, 384, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06498505051728266, "compression_ratio": 1.4711538461538463, "no_speech_prob": 0.0739581286907196}, {"id": 169, "seek": 88380, "start": 883.8, "end": 890.8, "text": " W artykule jest wykres por\u00f3wnuj\u0105cy wydajno\u015b\u0107 zero z \u00f3wczesnym stanem wiedzy dla du\u017cych modeli, czyli Megatron LM.", "tokens": [50364, 343, 594, 874, 74, 2271, 3492, 39287, 495, 1515, 812, 895, 13263, 1344, 25984, 1805, 23293, 4018, 710, 11857, 86, 3689, 279, 12996, 27984, 443, 46894, 1229, 12285, 1581, 7735, 339, 2316, 72, 11, 16591, 9986, 267, 2044, 46529, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08447529872258504, "compression_ratio": 1.4275618374558303, "no_speech_prob": 0.057519346475601196}, {"id": 170, "seek": 88380, "start": 890.8, "end": 897.8, "text": " Dla modeli powy\u017cej 40 miliard\u00f3w parametr\u00f3w zero osi\u0105ga znacznie wy\u017csz\u0105 przepustowo\u015b\u0107, mierzon\u0105 w Tiflopsach.", "tokens": [50714, 413, 875, 2316, 72, 3388, 88, 38493, 3356, 1962, 72, 515, 3901, 6220, 27965, 3901, 4018, 3003, 11404, 3680, 15397, 14875, 2766, 4628, 1427, 82, 8925, 30829, 381, 19941, 7753, 11, 47448, 35296, 1611, 261, 314, 351, 75, 3370, 608, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08447529872258504, "compression_ratio": 1.4275618374558303, "no_speech_prob": 0.057519346475601196}, {"id": 171, "seek": 88380, "start": 897.8, "end": 903.8, "text": " Przy 100 miliardach parametr\u00f3w m\u00f3wimy o r\u00f3\u017cnicy si\u0119gaj\u0105cej nawet o\u015bniu czy 10 razy.", "tokens": [51064, 39590, 2319, 1962, 72, 515, 608, 6220, 27965, 3901, 13489, 13189, 277, 19637, 77, 2632, 3244, 70, 11133, 20811, 22696, 277, 1788, 3722, 84, 6430, 1266, 9639, 88, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08447529872258504, "compression_ratio": 1.4275618374558303, "no_speech_prob": 0.057519346475601196}, {"id": 172, "seek": 88380, "start": 903.8, "end": 904.8, "text": " Wow.", "tokens": [51364, 3153, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08447529872258504, "compression_ratio": 1.4275618374558303, "no_speech_prob": 0.057519346475601196}, {"id": 173, "seek": 88380, "start": 904.8, "end": 908.8, "text": " To nie jest przyrost o kilka procent, to jest skok o rz\u0105d wielko\u015bci.", "tokens": [51414, 1407, 2838, 3492, 6501, 27494, 277, 36466, 38826, 11, 281, 3492, 1110, 453, 277, 367, 23876, 20570, 4093, 6199, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08447529872258504, "compression_ratio": 1.4275618374558303, "no_speech_prob": 0.057519346475601196}, {"id": 174, "seek": 90880, "start": 908.8, "end": 914.8, "text": " W tej pracy pojawia si\u0119 te\u017c fascynuj\u0105ce zjawisko, kt\u00f3re nazywaj\u0105 superliniarna skalowalno\u015b\u0107.", "tokens": [50364, 343, 12573, 35591, 30655, 654, 3244, 9516, 30632, 1344, 77, 13263, 384, 710, 22199, 43442, 11, 8864, 20151, 27112, 11133, 1687, 5045, 9448, 629, 16890, 305, 304, 23293, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 175, "seek": 90880, "start": 914.8, "end": 917.8, "text": " To brzmi troch\u0119 jak z\u0142amanie praw fizyki.", "tokens": [50664, 1407, 738, 89, 3057, 24926, 4207, 31614, 6147, 414, 22508, 21000, 88, 2984, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 176, "seek": 90880, "start": 917.8, "end": 923.8, "text": " M\u00f3wi, \u017ce podwojenie liczby kart GPU daje wi\u0119cej ni\u017c podwojenie wydajno\u015bci. Jak to w og\u00f3le jest mo\u017cliwe?", "tokens": [50814, 376, 3901, 72, 11, 3561, 2497, 6120, 15378, 414, 6169, 89, 2322, 29120, 18407, 1120, 2884, 26004, 28502, 2497, 6120, 15378, 414, 25984, 1805, 16438, 13, 15029, 281, 261, 29229, 3492, 30854, 826, 30, 51114], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 177, "seek": 90880, "start": 923.8, "end": 928.8, "text": " To jest bezpo\u015bredni efekt tego, o czym m\u00f3wili\u015bmy przy okazji koszt\u00f3w komunikacji.", "tokens": [51114, 1407, 3492, 10782, 2259, 1788, 986, 3722, 31482, 8192, 8627, 11, 277, 31466, 13489, 43912, 6501, 3133, 921, 4013, 19532, 2682, 3901, 45359, 1035, 13152, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 178, "seek": 90880, "start": 928.8, "end": 930.8, "text": " Wyja\u015bnijmy to na prostym przyk\u0142adzie.", "tokens": [51364, 14458, 2938, 1788, 77, 1718, 2226, 281, 1667, 10293, 4199, 23144, 3283, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 179, "seek": 90880, "start": 930.8, "end": 937.8, "text": " Za\u0142\u00f3\u017cmy, \u017ce na 16 kartach GPU z powodu ogranicze\u0144 pami\u0119ci mo\u017cesz u\u017cy\u0107 batch size o wielko\u015bci 1 na ka\u017cdej karcie.", "tokens": [51464, 31440, 1221, 812, 1427, 2226, 11, 3561, 1667, 3165, 29120, 608, 18407, 710, 3388, 34873, 34416, 30732, 49689, 31088, 537, 10697, 10430, 34097, 2162, 15245, 2744, 277, 20570, 4093, 6199, 502, 1667, 21912, 1479, 73, 7917, 4260, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05046576545352027, "compression_ratio": 1.44, "no_speech_prob": 0.08499053120613098}, {"id": 180, "seek": 93780, "start": 937.8, "end": 941.8, "text": " Ca\u0142kowyty batch size dla ca\u0142ego systemu wynosi 16.", "tokens": [50364, 7544, 1221, 74, 10089, 874, 15245, 2744, 12285, 35224, 6308, 1185, 84, 31936, 21521, 3165, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 181, "seek": 93780, "start": 941.8, "end": 942.8, "text": " Ok.", "tokens": [50564, 3477, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 182, "seek": 93780, "start": 942.8, "end": 945.8, "text": " Teraz podwajasz liczb\u0119 kart do 32.", "tokens": [50614, 41810, 2497, 86, 1805, 19601, 6169, 89, 65, 1274, 29120, 360, 8858, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 183, "seek": 93780, "start": 945.8, "end": 951.8, "text": " W starym \u015bwiecie twoja wydajno\u015b\u0107 by si\u0119 podwoi\u0142a, a ca\u0142kowyty batch size wyni\u00f3s\u0142 by 32.", "tokens": [50764, 343, 342, 822, 76, 40078, 4260, 732, 2938, 25984, 1805, 23293, 538, 3244, 2497, 6120, 72, 5024, 11, 257, 35224, 74, 10089, 874, 15245, 2744, 31936, 7138, 82, 1221, 538, 8858, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 184, "seek": 93780, "start": 951.8, "end": 961.8, "text": " Ale z 0 dzi\u0119ki ogromnej oszcz\u0119dno\u015bci pami\u0119ci na ka\u017cdej z tych 32 kart mo\u017cesz teraz zmie\u015bci\u0107 powiedzmy batch size o wielko\u015bci 4.", "tokens": [51064, 9366, 710, 1958, 45003, 34416, 298, 11794, 3003, 43771, 6298, 16438, 31088, 537, 1667, 21912, 1479, 73, 710, 15180, 8858, 29120, 10697, 10430, 16854, 17020, 414, 6199, 2162, 27617, 2226, 15245, 2744, 277, 20570, 4093, 6199, 1017, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 185, "seek": 93780, "start": 961.8, "end": 962.8, "text": " Aha.", "tokens": [51564, 27448, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 186, "seek": 93780, "start": 962.8, "end": 966.8, "text": " Tw\u00f3j ca\u0142kowyty batch size to teraz 32x4, czyli 128.", "tokens": [51614, 2574, 18999, 35224, 74, 10089, 874, 15245, 2744, 281, 16854, 8858, 87, 19, 11, 16591, 29810, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09188378558439367, "compression_ratio": 1.4826254826254825, "no_speech_prob": 0.010692078620195389}, {"id": 187, "seek": 96680, "start": 966.8, "end": 972.8, "text": " Ka\u017cde GPU wykonuje znacznie wi\u0119cej u\u017cytecznej pracy na sekund\u0119, bo wi\u0119ksze wsady lepiej je wysycaj\u0105.", "tokens": [50364, 10988, 1427, 1479, 18407, 46702, 13008, 15397, 14875, 2766, 26004, 34097, 975, 3689, 11794, 35591, 1667, 17215, 997, 1274, 11, 748, 29968, 1381, 37647, 880, 476, 39699, 1506, 27062, 88, 496, 8555, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 188, "seek": 96680, "start": 972.8, "end": 978.8, "text": " W efekcie podwajaj\u0105c liczb\u0119 kart zwi\u0119kszy\u0142a\u015b wydajno\u015b\u0107 nie dwu, a o\u015bmiokrotnie.", "tokens": [50664, 343, 31482, 916, 4260, 2497, 86, 1805, 38757, 6169, 89, 65, 1274, 29120, 11873, 5034, 1694, 1229, 5024, 1788, 25984, 1805, 23293, 2838, 27379, 84, 11, 257, 277, 1788, 3057, 453, 10536, 2766, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 189, "seek": 96680, "start": 978.8, "end": 981.8, "text": " To jest w\u0142a\u015bnie superliniowa skalowalno\u015b\u0107.", "tokens": [50964, 1407, 3492, 14234, 1687, 5045, 72, 5528, 16890, 305, 304, 23293, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 190, "seek": 96680, "start": 981.8, "end": 983.8, "text": " Czyli implikacje s\u0105 ogromy.", "tokens": [51114, 37099, 8484, 1035, 29293, 9015, 34416, 8488, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 191, "seek": 96680, "start": 983.8, "end": 989.8, "text": " Nie chodzi tylko o to, \u017ceby trenowa\u0107 jeszcze wi\u0119ksze modele, ale te\u017c o to, kto mo\u017ce je trenowa\u0107.", "tokens": [51214, 12016, 23998, 13219, 277, 281, 11, 11316, 23136, 11445, 14168, 29968, 1381, 4391, 306, 11, 6775, 9516, 277, 281, 11, 23780, 12034, 1506, 23136, 11445, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 192, "seek": 96680, "start": 989.8, "end": 991.8, "text": " W artykule jest mowa o demokratyzacji.", "tokens": [51514, 343, 594, 874, 74, 2271, 3492, 275, 5528, 277, 1371, 453, 81, 21398, 89, 13152, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 193, "seek": 96680, "start": 991.8, "end": 992.8, "text": " Tak.", "tokens": [51614, 9118, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 194, "seek": 96680, "start": 992.8, "end": 995.8, "text": " I to jest by\u0107 mo\u017ce najwa\u017cniejsze, d\u0142ugofalowy skutek.", "tokens": [51664, 286, 281, 3492, 15069, 12034, 11212, 27111, 44258, 11, 274, 34077, 2670, 304, 10089, 1110, 325, 916, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07987261675075143, "compression_ratio": 1.498422712933754, "no_speech_prob": 0.028243010863661766}, {"id": 195, "seek": 99580, "start": 995.8, "end": 1003.8, "text": " Zero w ni\u017cszych stadiach optymalizacji np. tylko popius, plus G, pozwala trenowa\u0107 modele do 13 miliard\u00f3w parametr\u00f3w,", "tokens": [50364, 17182, 261, 28502, 45021, 38408, 72, 608, 2427, 4199, 304, 590, 13152, 33808, 13, 13219, 1665, 4872, 11, 1804, 460, 11, 40557, 5159, 23136, 11445, 4391, 306, 360, 3705, 1962, 72, 515, 3901, 6220, 27965, 3901, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08263839021021006, "compression_ratio": 1.3966101694915254, "no_speech_prob": 0.0812382847070694}, {"id": 196, "seek": 99580, "start": 1003.8, "end": 1007.8, "text": " bez konieczno\u015bci stosowania skomplikowanego model paralelizmy.", "tokens": [50764, 10782, 5897, 414, 3689, 16438, 43581, 21308, 1110, 298, 564, 1035, 37345, 6308, 2316, 26009, 338, 590, 2226, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08263839021021006, "compression_ratio": 1.3966101694915254, "no_speech_prob": 0.0812382847070694}, {"id": 197, "seek": 99580, "start": 1007.8, "end": 1014.8, "text": " A to w\u0142a\u015bnie MP wymaga\u0142o od naukowc\u00f3w g\u0142\u0119bokich modyfikacji w kodzie samego modelu, co by\u0142o ogromn\u0105 barier\u0105 wej\u015bcia.", "tokens": [50964, 316, 281, 14234, 14146, 29764, 9286, 5249, 3611, 35616, 74, 305, 29268, 18117, 1274, 21666, 480, 275, 843, 31230, 13152, 261, 350, 378, 3283, 912, 1571, 2316, 84, 11, 598, 14811, 34416, 298, 13113, 2159, 811, 1611, 321, 73, 1788, 2755, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08263839021021006, "compression_ratio": 1.3966101694915254, "no_speech_prob": 0.0812382847070694}, {"id": 198, "seek": 99580, "start": 1014.8, "end": 1019.8, "text": " W praktyce oznacza\u0142o to, \u017ce grupa badawcza na uniwersytecie, dysponuj\u0105ca nawet kilkoma serwerami,", "tokens": [51314, 343, 3206, 74, 874, 384, 277, 22672, 326, 2394, 5249, 281, 11, 3561, 12740, 64, 272, 1538, 86, 41524, 1667, 36435, 5364, 88, 975, 4260, 11, 15243, 79, 266, 13263, 496, 22696, 5128, 74, 6440, 816, 1554, 4526, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08263839021021006, "compression_ratio": 1.3966101694915254, "no_speech_prob": 0.0812382847070694}, {"id": 199, "seek": 101980, "start": 1019.8, "end": 1026.8, "text": " mog\u0142a nagle zacz\u0105\u0107 prowadzi\u0107 badania, kt\u00f3re wcze\u015bniej by\u0142y zarezerwowane wy\u0142\u0105cznie dla gigant\u00f3w technologicznych z w\u0142asnymi centrami danych.", "tokens": [50364, 13172, 5024, 297, 15088, 34430, 8925, 2162, 36590, 28496, 1578, 5609, 11, 8864, 40785, 26366, 710, 543, 4527, 86, 23066, 4628, 15926, 19923, 12285, 8741, 394, 3901, 1537, 1132, 17946, 9399, 710, 43572, 31813, 1489, 2356, 72, 274, 34644, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07626769889114249, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.4300079643726349}, {"id": 200, "seek": 101980, "start": 1026.8, "end": 1032.8, "text": " To prawdziwa zmiana regu\u0142 gry, a ostatecznym dowodem, \u017ce to wszystko dzia\u0142a, by\u0142o stworzenie konkretnego modelu.", "tokens": [50714, 1407, 41175, 3992, 4151, 17020, 8497, 1121, 84, 1221, 41974, 11, 257, 277, 15406, 3689, 12996, 9459, 378, 443, 11, 3561, 281, 22607, 37903, 11, 14811, 342, 28321, 16778, 36500, 11858, 2316, 84, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07626769889114249, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.4300079643726349}, {"id": 201, "seek": 101980, "start": 1032.8, "end": 1033.8, "text": " Prawda?", "tokens": [51014, 430, 5131, 2675, 30, 51064], "temperature": 0.0, "avg_logprob": -0.07626769889114249, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.4300079643726349}, {"id": 202, "seek": 101980, "start": 1033.8, "end": 1040.8, "text": " Oczywi\u015bcie. Teoria i benchmarki s\u0105 wa\u017cne, ale nic nie przemawia do wyobra\u017ani tak, jak dzia\u0142aj\u0105cy produkt.", "tokens": [51064, 42980, 13, 1989, 8172, 741, 18927, 72, 9015, 46110, 11, 6775, 6201, 2838, 6541, 443, 34953, 360, 4628, 24393, 10659, 3722, 991, 11, 4207, 27121, 11133, 1344, 42816, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07626769889114249, "compression_ratio": 1.4057971014492754, "no_speech_prob": 0.4300079643726349}, {"id": 203, "seek": 104080, "start": 1040.8, "end": 1050.8, "text": " Dzi\u0119ki Zero zesp\u00f3\u0142 Microsoftu wytrenowa\u0142 model Turing NLG. Mia\u0142 17 miliard\u00f3w parametr\u00f3w, co w tamtym czasie czyni\u0142o go najwi\u0119kszym modelem na \u015bwiecie.", "tokens": [50364, 413, 34546, 17182, 710, 13361, 16181, 8116, 84, 261, 4328, 1095, 30105, 2316, 314, 1345, 426, 43, 38, 13, 376, 8908, 3282, 1962, 72, 515, 3901, 6220, 27965, 3901, 11, 598, 261, 7677, 874, 76, 42667, 6430, 3722, 5249, 352, 48636, 1694, 26681, 4391, 10386, 1667, 40078, 4260, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06552103346427984, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.46475115418434143}, {"id": 204, "seek": 104080, "start": 1050.8, "end": 1055.8, "text": " I osi\u0105gn\u0105\u0142 rekordow\u0105 dok\u0142adno\u015b\u0107 w wielu zadaniach j\u0119zykowych.", "tokens": [50864, 286, 3003, 11404, 4568, 1611, 1221, 33881, 765, 30297, 45864, 23293, 261, 40437, 42788, 3782, 608, 49055, 74, 19605, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06552103346427984, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.46475115418434143}, {"id": 205, "seek": 104080, "start": 1055.8, "end": 1062.8, "text": " To by\u0142 ostateczny dow\u00f3d na to, \u017ce Zero nie tylko dzia\u0142a, ale te\u017c przynosi realne, prze\u0142omowe rezultaty naukowe.", "tokens": [51114, 1407, 16673, 277, 15406, 3689, 1634, 9459, 17081, 1667, 281, 11, 3561, 17182, 2838, 13219, 37903, 11, 6775, 9516, 6501, 16751, 72, 957, 716, 11, 8325, 1221, 298, 6880, 48060, 723, 21398, 35616, 74, 6880, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06552103346427984, "compression_ratio": 1.3132075471698113, "no_speech_prob": 0.46475115418434143}, {"id": 206, "seek": 106280, "start": 1063.8, "end": 1070.8, "text": " Reasumuj\u0105c t\u0119 cz\u0119\u015b\u0107, Zero to nie jest tylko kolejna optymalizacja, to jest fundamentalna zmiana paradygmatu.", "tokens": [50414, 1300, 296, 449, 44733, 32489, 47149, 11, 17182, 281, 2838, 3492, 13219, 23749, 629, 2427, 4199, 304, 590, 23395, 11, 281, 3492, 8088, 629, 17020, 8497, 13480, 18103, 15677, 84, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08091913964137558, "compression_ratio": 1.4452830188679244, "no_speech_prob": 0.5322932004928589}, {"id": 207, "seek": 106280, "start": 1070.8, "end": 1079.8, "text": " Zamiast podej\u015bcia opartego na brutalnej sile, czyli dok\u0142adaniu coraz pot\u0119\u017cniejszego i dro\u017cszego sprz\u0119tu z wi\u0119ksz\u0105 ilo\u015bci\u0105 pami\u0119ci,", "tokens": [50764, 1176, 4526, 525, 7468, 73, 1788, 2755, 999, 446, 6308, 1667, 17878, 11794, 262, 794, 11, 16591, 45864, 25849, 25899, 1847, 1274, 1427, 10402, 15453, 6308, 741, 3789, 1427, 15453, 6308, 6103, 11052, 9179, 710, 29968, 8925, 1930, 44468, 1611, 31088, 537, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08091913964137558, "compression_ratio": 1.4452830188679244, "no_speech_prob": 0.5322932004928589}, {"id": 208, "seek": 106280, "start": 1079.8, "end": 1087.8, "text": " proponuje inteligentne, niemal finezyjne zarz\u0105dzanie zasobami poprzez systematyczn\u0105 eliminacj\u0119 redundancji na ka\u017cdym kroku.", "tokens": [51214, 2365, 266, 13008, 24777, 25002, 716, 11, 2838, 5579, 2489, 1229, 73, 716, 22675, 23876, 89, 7155, 26530, 996, 4526, 1665, 13503, 89, 1185, 267, 17466, 13113, 7892, 29924, 2182, 997, 4463, 4013, 1667, 31615, 76, 45909, 5279, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08091913964137558, "compression_ratio": 1.4452830188679244, "no_speech_prob": 0.5322932004928589}, {"id": 209, "seek": 108780, "start": 1087.8, "end": 1091.8, "text": " Dok\u0142adnie. Ale co czy kaw\u0119? I to pokazuje klas\u0119 autor\u00f3w.", "tokens": [50364, 29768, 10358, 2766, 13, 9366, 598, 6430, 350, 1607, 1274, 30, 286, 281, 13010, 43317, 350, 7743, 1274, 19510, 3901, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1006310068327805, "compression_ratio": 1.310483870967742, "no_speech_prob": 0.23592330515384674}, {"id": 210, "seek": 108780, "start": 1091.8, "end": 1096.8, "text": " W podsumowaniu sami przyznaj\u0105, \u017ce rozwi\u0105zali tylko jeden, cho\u0107 ogromny problem.", "tokens": [50564, 343, 31925, 449, 305, 25849, 3247, 72, 6501, 35458, 8555, 11, 3561, 9544, 22620, 5103, 13219, 12906, 11, 1586, 2162, 34416, 298, 1634, 1154, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1006310068327805, "compression_ratio": 1.310483870967742, "no_speech_prob": 0.23592330515384674}, {"id": 211, "seek": 108780, "start": 1096.8, "end": 1103.8, "text": " Stworzyli narz\u0119dzie do walki z barier\u0105 pami\u0119ci, ale na horyzoncie pojawi\u0142a si\u0119 kolejna, r\u00f3wnie wielka przeszkoda.", "tokens": [50814, 745, 28321, 1229, 2081, 6714, 89, 42643, 360, 1792, 72, 710, 2159, 811, 1611, 31088, 537, 11, 6775, 1667, 276, 827, 35296, 4260, 30655, 72, 5024, 3244, 23749, 629, 11, 11416, 14215, 20570, 2330, 6541, 10430, 74, 13449, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1006310068327805, "compression_ratio": 1.310483870967742, "no_speech_prob": 0.23592330515384674}, {"id": 212, "seek": 108780, "start": 1103.8, "end": 1108.8, "text": " Nazywaj\u0105 j\u0105 luk\u0105 w mocy obliczeniowej, Compute Power Gap.", "tokens": [51164, 11870, 27112, 11133, 35692, 287, 2034, 1611, 261, 705, 1344, 1111, 1050, 42124, 21091, 11, 6620, 1169, 7086, 460, 569, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1006310068327805, "compression_ratio": 1.310483870967742, "no_speech_prob": 0.23592330515384674}, {"id": 213, "seek": 110880, "start": 1109.8, "end": 1119.8, "text": " Obliczyli, \u017ce nawet z wydajno\u015bci\u0105, jak on daje zero, wytrenowanie modelu o bilionie parametr\u00f3w na \u00f3wczesnym sprz\u0119cie wci\u0105\u017c wymaga\u0142oby ponad roku nieprzerwanych oblicze\u0144.", "tokens": [50414, 4075, 1050, 1229, 2081, 11, 3561, 22696, 710, 25984, 1805, 16438, 1611, 11, 4207, 322, 1120, 2884, 4018, 11, 261, 4328, 1095, 22028, 2316, 84, 277, 8588, 313, 414, 6220, 27965, 3901, 1667, 11857, 86, 3689, 279, 12996, 6103, 11052, 4260, 261, 537, 27242, 29764, 9286, 1221, 13944, 9224, 345, 19451, 2838, 1424, 4527, 86, 34644, 1111, 1050, 49689, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06534275110217108, "compression_ratio": 1.4395973154362416, "no_speech_prob": 0.4596421718597412}, {"id": 214, "seek": 110880, "start": 1119.8, "end": 1123.8, "text": " To prowadzi nas do ko\u0144cowej my\u015bli, kt\u00f3r\u0105 warto podrzuci\u0107 osobom, kt\u00f3re nas s\u0142uchaj\u0105.", "tokens": [50914, 1407, 36590, 3992, 5382, 360, 26470, 66, 21091, 452, 15350, 11, 37415, 31830, 2497, 81, 11728, 39162, 41518, 298, 11, 8864, 5382, 15116, 625, 11133, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06534275110217108, "compression_ratio": 1.4395973154362416, "no_speech_prob": 0.4596421718597412}, {"id": 215, "seek": 110880, "start": 1123.8, "end": 1134.8, "text": " Tak. Skoro zero i podobne technologie pokaza\u0142y, \u017ce pami\u0119\u0107 musi by\u0107 ju\u017c ostateczn\u0105 barier\u0105 i mo\u017cna j\u0105 obej\u015b\u0107 za pomoc\u0105 sprytnego oprogramowania,", "tokens": [51114, 9118, 13, 7324, 10780, 4018, 741, 43024, 716, 1537, 20121, 13010, 12257, 6825, 11, 3561, 31088, 2162, 37587, 15069, 10678, 277, 15406, 3689, 13113, 2159, 811, 1611, 741, 17790, 35692, 36346, 44536, 7949, 48962, 1611, 637, 627, 83, 11858, 999, 340, 1342, 21308, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06534275110217108, "compression_ratio": 1.4395973154362416, "no_speech_prob": 0.4596421718597412}, {"id": 216, "seek": 113480, "start": 1134.8, "end": 1137.8, "text": " to gdzie le\u017cy kolejna granica innowacji?", "tokens": [50364, 281, 18922, 476, 7735, 23749, 629, 9370, 2262, 294, 3785, 13152, 30, 50514], "temperature": 0.0, "avg_logprob": -0.0688467886712816, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.0635211244225502}, {"id": 217, "seek": 113480, "start": 1137.8, "end": 1148.8, "text": " Czy nast\u0119pny prze\u0142om b\u0119dzie polega\u0142 na budowie jeszcze pot\u0119\u017cniejszych superkomputer\u00f3w na jeszcze bardziej egzotycznym sprz\u0119cie i skracaniu tego roku do miesi\u0119cy, a potem tygodni?", "tokens": [50514, 19832, 39662, 1634, 8325, 1221, 298, 10562, 13208, 3680, 1221, 1667, 3265, 13998, 14168, 1847, 1274, 1427, 10402, 45021, 1687, 20557, 13849, 3901, 1667, 14168, 27209, 24263, 89, 6737, 3689, 12996, 6103, 11052, 4260, 741, 1110, 12080, 25849, 8627, 19451, 360, 41543, 47303, 11, 257, 36513, 1104, 21787, 3722, 30, 51064], "temperature": 0.0, "avg_logprob": -0.0688467886712816, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.0635211244225502}, {"id": 218, "seek": 113480, "start": 1148.8, "end": 1156.8, "text": " Czy mo\u017ce prawdziwe prze\u0142om nadejdzie zube\u0142nie innej strony od odkrycia nowych architektur modeli lub algorytm\u00f3w treningowych,", "tokens": [51064, 19832, 12034, 41175, 3992, 826, 8325, 1221, 298, 297, 762, 73, 13096, 710, 1977, 1221, 2766, 294, 11794, 32406, 3611, 3611, 43298, 2755, 586, 16384, 3912, 642, 2320, 374, 2316, 72, 15980, 3501, 827, 83, 76, 3901, 2192, 773, 19605, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0688467886712816, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.0635211244225502}, {"id": 219, "seek": 113480, "start": 1156.8, "end": 1162.8, "text": " kt\u00f3re pozwol\u0105 osi\u0105gn\u0105\u0107 te same rezultaty przy fundamentalnie mniejszym zapotrzebowaniu nadczyste obliczenia?", "tokens": [51464, 8864, 40557, 401, 1611, 3003, 11404, 4568, 36374, 535, 912, 48060, 723, 21398, 6501, 8088, 2766, 39513, 7706, 76, 14223, 310, 13503, 8202, 25849, 12617, 6522, 2941, 1111, 1050, 14320, 30, 51764], "temperature": 0.0, "avg_logprob": -0.0688467886712816, "compression_ratio": 1.5015873015873016, "no_speech_prob": 0.0635211244225502}, {"id": 220, "seek": 116280, "start": 1162.8, "end": 1167.8, "text": " Innymi s\u0142owy. Czy przysz\u0142o\u015b\u0107 to wi\u0119ksze silniki, czy mo\u017ce kaliwo?", "tokens": [50364, 682, 31813, 15116, 10089, 13, 19832, 44018, 44742, 281, 29968, 1381, 3425, 77, 9850, 11, 6430, 12034, 7788, 72, 6120, 30, 50614], "temperature": 0.0, "avg_logprob": -0.11478999257087708, "compression_ratio": 0.9102564102564102, "no_speech_prob": 0.40102607011795044}], "language": "pl"}