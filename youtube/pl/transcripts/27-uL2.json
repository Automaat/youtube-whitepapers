{"text": " Co by by\u0142o, gdyby zamiast ca\u0142ej skrzynki z narz\u0119dziami, gdzie, wiesz, ka\u017cde s\u0142u\u017c\u0119 do czego\u015b innego, mo\u017cna by mie\u0107 jedno takie uniwersalne narz\u0119dzie. Taki scyzoryk, kt\u00f3ry zast\u0105pi\u0142by m\u0142otek, \u015brubokr\u0119ty, kombinerki. Dok\u0142adnie. A w \u015bwiecie sztucznej inteligencji, a konkretnie modeli j\u0119zykowych przez d\u0142ugi czas byli\u015bmy skazani w\u0142a\u015bnie na tak\u0105 specjalistyczn\u0105 skrzynk\u0119. Mieli\u015bmy ca\u0142e takie powiedzmy ZO modeli. No w\u0142a\u015bnie, ZO, idealne okre\u015blenie. Jeden model, jak GPT, to by\u0142 powiedzmy genialny poeta. \u015awietny w generowaniu p\u0142ynnego, kreatywnego tekstu. A drugi, na przyk\u0142ad T5, by\u0142 bardziej analitykiem. Mistrzem w rozumieniu j\u0119zyka, odpowiadaniu na pytania, streszczaniu. I programista musia\u0142 za ka\u017cdym razem wybiera\u0107 odpowiednie zwierz\u0119 do konkretnego zadania. I takie ZO jest, no c\u00f3\u017c, bardzo drogie w utrzymaniu. Ka\u017cdy model to osobny kosztowny trening, osobne zasoby. I osobny b\u00f3l g\u0142owy przy wyborze. To by\u0142 ten fundamentalny kompromis. Chcesz generowa\u0107 tekst, czego rozumie\u0107. Musisz wybra\u0107. Musisz. A dzisiaj przyjrzymy si\u0119 pracy naukowej, kt\u00f3ra rzuca temu wszystkiemu wyzwanie. Mamy przed sob\u0105 artyku\u0142 z Google Brain, zatytu\u0142owany UL2. Unifying Language Learning Paradigms. Nasza misja na dzi\u015b zrozumie\u0107, jak autorzy tej pracy pr\u00f3buj\u0105 stworzy\u0107 w\u0142a\u015bnie taki uniwersalny scyzoryk dla EI. Zastanowmy si\u0119, czy to w og\u00f3le mo\u017cliwe, \u017ceby jeden model by\u0142 jednocze\u015bnie i poet\u0105 i analitykiem. Wspomnieli\u015bmy ju\u017c o tym dyle macie. Generowanie kontrarozumienie. Wi\u0119kszo\u015b\u0107 badaczy przyjmowa\u0142a to za pewnik. To troch\u0119 jak w sporcie, prawda? Albo jeste\u015b marato\u0144czykiem albo sprinterem. Ci\u0119\u017cko by\u0107 mistrzem w obu naraz dok\u0142adnie. I autorzy UL2 podwa\u017cyli dogmat, kt\u00f3ry m\u00f3wi\u0142, \u017ce spos\u00f3b w jaki trenujemy model na samym pocz\u0105tku, ten tak zwany pre-training, musi by\u0107 \u015bci\u015ble dopasowany do jego przysz\u0142ych zada\u0144. Czyli je\u015bli chcesz, \u017ceby model strzeszcza\u0142, to od pocz\u0105tku trenujesz go w okre\u015blony spos\u00f3b. A oni zapytali, a co je\u015bli to b\u0142\u0105d? No w\u0142a\u015bnie, postawili odwa\u017cne pytanie. Dlaczego nie spr\u00f3bowa\u0107 stworzy\u0107 jednego modelu, kt\u00f3ry od samego pocz\u0105tku uczy si\u0119 wszystkiego? I b\u0119dzie r\u00f3wnie dobry wiesz w zadaniach na rozumienie, jak testy w superglu, i w zadaniach czysto generatywnych, jak strzeszczenia w X-sum. To naprawd\u0119 odwa\u017cna teza podwa\u017cy\u0107 co\u015b, co wydawa\u0142o si\u0119 fundamentem, w takim razie co zaproponowali. Jaka jest ich alternatywa? Ich pomys\u0142 jest w swojej prostocie genialny. Zauwa\u017cyli, \u017ce niemal ka\u017cde zadanie j\u0119zykowe, niewa\u017cne jakie, mo\u017cna sprowadzi\u0107 do jednego schematu. Input to target. Input to target, czyli wej\u015bcie i wej\u015bcie. Dok\u0142adnie. Dajesz modelowi jaki\u015b input i oczekujesz, \u017ce wygeneruje target. Uzupe\u0142nianie luki w zdaniu to input to target, t\u0142umaczenie. To samo. Czyli sprowadzili te wszystkie skomplikowane zadania do wsp\u00f3lnego mianownika. To pozwoli\u0142o im traktowa\u0107 jej jednolicie. W\u0142a\u015bnie tak. I na tym fundamentie zbudowali swoj\u0105 g\u0142\u00f3wn\u0105 innowacj\u0119. Metod\u0119 treningow\u0105 nazwan\u0105 Mixture of the Noisers. W skr\u00f3cie mod. Czyli to nie jest nowa architektura, nowy silnik? Nie. To raczej rewolucyjne paliwo. Spos\u00f3b trenowania. Mo\u017cna to por\u00f3wna\u0107 tak jak m\u00f3wi\u0142a\u015b do wszechstronnego planu treningowego dla sportowca. Kt\u00f3ry chce by\u0107 dobry i w maratonie i w spryncie. Ok, to roz\u0142\u00f3\u017cmy ten plan treningowy na czynniki pierwsze. Z jakich \u0107wicze\u0144 on si\u0119 sk\u0142ada? Mamy trzy g\u0142\u00f3wne typy. Pierwszy to Air the Noiser od Regular. To s\u0105 takie powiedzmy podstawowe \u0107wiczenia si\u0142owe, budowanie fundamentu. Jak to wygl\u0105da w praktyce? Bierzemy tekst i losowo go uszkadziamy. Wymazujemy kilka s\u0142\u00f3w tu i uwdzie. A zadaniem modelu jest odtworzenie tych brakuj\u0105cych, kr\u00f3tkich luk. Aha, czyli to taka praca u podstaw. Upewnienie si\u0119, \u017ce model za\u0142apa\u0142 gramatyk\u0119 i podstawowy zwi\u0105zki mi\u0119dzy s\u0142owami, zanim ka\u017cemy mu pisa\u0107 wiersze. Dok\u0142adnie tak. To go zmusza do ci\u0105g\u0142ego rozumienia najbli\u017cszego kontekstu i buduje solidne j\u0119zykowe podstawy. Bardzo podobnie trenuje si\u0119 model T5, czyli naszego analityka. Ok, mamy solidne fundamenty. Co jest drugim elementem? Drugi to S the Noiser, czyli Sequential. To ju\u017c jest trening sprinterski. Dajemy modelowi pocz\u0105tek zdania, a jego zadaniem jest doko\u0144czenie go w sp\u00f3jny i logiczny spos\u00f3b. Czyli to jest ta umiej\u0119tno\u015b\u0107, z kt\u00f3rej s\u0142yn\u0105 modele typu GPT, nasi poeci, ucz\u0105 si\u0119 kontynuowa\u0107 my\u015bl. Zglaza si\u0119. To rozwija zdolno\u015bci czysto generatywne. Ale autorzy dodali jeszcze trzeci, chyba najciekawszy element. X the Noiser od Extreme. Brzmi intensywnie. Bo to jest trening ekstremalny. Wyobra\u017a sobie, \u017ce usuwamy z tekstu nie kilka s\u0142\u00f3w, ale po\u0142ow\u0119. I to w jednym, d\u0142ugim bloku. Model dostaje tylko pierwsz\u0105 i ostatni\u0105 cz\u0119\u015b\u0107, a musi zrekonstruowa\u0107 ca\u0142y \u015brodek. To brzmi niewiarygodnie trudno. Jak pr\u00f3ba odtworzenia ca\u0142ej strony z ksi\u0105\u017cki maj\u0105c tylko pierwsze i ostatnie zdanie. Po co co\u015b takiego? Bo to uczy go niesamowitej elastyczno\u015bci. I rozumienia szerszego kontekstu. Musi nie tylko zna\u0107 gramatyk\u0119, nie tylko kontynuowa\u0107 my\u015bl, ale te\u017c potrafi\u0107 zrekonstruowa\u0107 z\u0142o\u017con\u0105 struktur\u0119 na podstawie bardzo ograniczonych informacji. To jest co\u015b pomi\u0119dzy metod\u0105 R i S. I tu dochodzimy do sedna. Kluczem nie jest \u017cadne z tych pojedynczych \u0107wicze\u0144, tylko ich po\u0142\u0105czenie, prawda? Dok\u0142adnie. Magiad kwi w mieszance. W trakcie jednego procesu treningowego model robi wszystkie trzy typy \u0107wicze\u0144. Raz uzupe\u0142nia kr\u00f3tkie luki, za chwil\u0119 doka\u0144cza zdania, a potem mierzy si\u0119 z t\u0105 ekstremaln\u0105 rekonstrukcj\u0105. Aha. W artykule jest nawet podkre\u015blione, \u017ce sam X-D Noiser w izolacji nie dzia\u0142a\u0142by dobrze. To potwierdzaj\u0105 te\u017c wcze\u015bniejsze badania. Dopiero synergi\u0119 tych trzech pozornie r\u00f3\u017cnych zada\u0144 tworzy wszechstronnego sportowca. Ta koncepcja mieszanki treningowej jest naprawd\u0119 klarowna, ale nasuwa si\u0119 pytanie. Praktyczne. Skoro model nauczy si\u0119 wszystkiego na raz, to jak on potem wie, kt\u00f3rej umiej\u0119tno\u015bci ma u\u017cy\u0107? \u015awietne pytanie. No bo przecie\u017c nie mo\u017ce zgadywa\u0107, czy ma analizowa\u0107 dane, czy pisa\u0107 kreatywnie. I autorzy maj\u0105 na to bardzo sprytne rozwi\u0105zanie, kt\u00f3re nazywaj\u0105 mode switching. Pomy\u015bl o naszym sportowcu. Sk\u0105d on wie, czy teraz ma biec spr\u0119t, czy podnosi\u0107 ci\u0119\u017cary? Trener mu m\u00f3wi. No w\u0142a\u015bnie. I oni zrobili to samo z modelem. Ale jak? Przecie\u017c nie da si\u0119 z nim porozmawia\u0107, prawie. Podczas treningu na pocz\u0105tku ka\u017cdego przyk\u0142adu podawali modelowi specjalny token. R, S albo X. A, czyli takie komendy. Dok\u0142adnie, komendy. Daj\u0105c mu R m\u00f3wili OK, teraz skup si\u0119 na uzupe\u0142nianiu ma\u0142ych luk, daj\u0105c S m\u00f3wili teraz czas na generowanie. Model nauczy\u0142 si\u0119 kojarzy\u0107 te tokeny z odpowiednim trybem pracy. Zaraz, zaraz. Czyli p\u00f3\u017aniej ju\u017c po treningu mo\u017cna u\u017cy\u0107 tych token\u00f3w jako takiego prze\u0142\u0105cznika tryb\u00f3w. Je\u015bli chce, \u017ceby napisa\u0142 mi opowiadanie, to na pocz\u0105tku polecenia daje mu token S i on wierze ma wej\u015b\u0107 w tryb kreatywny. Dok\u0142adnie tak. I to nie jest tylko teoria, to ma realny, mierzalny wp\u0142yw. W artykule jest eksperyment, w kt\u00f3rym prosili model o strychczenie tekstu ze zbioru exum. I co? Kiedy u\u017cyli odpowiedniego tokena podpowiedzi, wynik by\u0142 dramatycznie lepszy. R\u00f3\u017cnica wydajno\u015bci mi\u0119dzy u\u017cyciem dobrego a z\u0142ego trybu to by\u0142o uwaga a\u017c 48%. Wow, to dow\u00f3d, \u017ce model naprawd\u0119 nauczy\u0142 si\u0119 tych r\u00f3\u017cnych osobowo\u015bci i potrafi si\u0119 mi\u0119dzy nimi prze\u0142\u0105cza\u0107 na \u017c\u0105danie. Teoria brzmi fantastycznie, ale przejd\u017amy do najwa\u017cniejszego. Jakie s\u0105 wyniki? Czy ten scyzoryk faktycznie jest ostry, czy mo\u017ce jest po prostu przeci\u0119tny we wszystkim? Wyniki s\u0105 delikatnie m\u00f3wi\u0105c imponuj\u0105ce. Zacznijmy od ma\u0142ej skali. W bezpo\u015brednich por\u00f3wnaniach z modelami o podobnej wielko\u015bci trenowanymi w stylu T5 albo GPT mniejsza wersja UL2 konsekwentnie wygrywa\u0142a. I to nie w jednym czy dw\u00f3ch zadaniach. By\u0142a lepsza na 9 z 9 r\u00f3\u017cnych test\u00f3w. Na wszystkich? Na wszystkich. Znormalizowany og\u00f3lny wzrost wydajno\u015bci wynios ponad 76% w por\u00f3wnaniu do modelu w stylu GPT. To pokazuje, \u017ce to nie jest kompromis. Ten model jest po prostu lepszy w ca\u0142\u0105 spektrum zada\u0144. OK, czyli w ma\u0142ej skali to dzia\u0142a. Ale w \u015bwiecie AI cz\u0119sto m\u00f3wi si\u0119, \u017ce prawdziwa magia pojawia si\u0119 przy skalowaniu. Co si\u0119 sta\u0142o, gdy go powi\u0119kszyli? Wtedy sta\u0142o si\u0119 co\u015b jeszcze ciekawszego. Stworzyli wersj\u0119 z 20 miliardami parametr\u00f3w. UL2 20B. I ten model osi\u0105gn\u0105\u0142 State of the Art, czyli najlepsze znane wyniki, na ponad 50 r\u00f3\u017cnych zadaniach NLP. 50? A mo\u017cesz poda\u0107 jaki\u015b przyk\u0142ad? Pewnie. Na przyk\u0142ad streszczanie wielu wiadomo\u015bci naraz na zbiorze Multinius. To wymaga syntezy informacji z r\u00f3\u017cnych \u017ar\u00f3de\u0142. Albo odpowiadania na pytania z Twittera w testie tweet QA, gdzie j\u0119zyk jest wiesz, nieformalny, pe\u0142en b\u0142\u0119d\u00f3w. Slangu. Dok\u0142adnie. Albo rozumowanie oparte na zdrowym rozs\u0105dku w benchmarku SIQA. A nawet analiza bardzo d\u0142ugich dokument\u00f3w w scrolls, co jest ogromnym wyzwaniem dla wi\u0119kszo\u015bci modeli. We wszystkich tych obszarach UL2 20B ustanowi\u0142 nowe rekordy. Te wyniki s\u0105 naprawd\u0119 mocne, ale s\u0142ysza\u0142am, \u017ce w artykule kryje si\u0119 jedna prawdziwa bomba, co\u015b, co naprawd\u0119 wstrz\u0105sne\u0142o ca\u0142\u0105 spo\u0142eczno\u015bci\u0105. Tak. Najwi\u0119kszym zaskoczeniem jest bezpo\u015brednie starcie UL2 20B z modelem GPT-3. OK. Przypomnijmy. GPT-3 ma 175 miliard\u00f3w parametr\u00f3w. Jest prawie 9 razy wi\u0119kszy. Postawiono je naprzeciwko siebie w zadaniu Super Glue. Poczekaj, musimy to wyja\u015bni\u0107. Czym jest Super Glue? Super Glue to taki link wistyczny wielob\u00f3j dla AI. Zestaw bardzo trudnych zada\u0144, kt\u00f3re sprawdzaj\u0105 wszystko. Od logiki przez rozumienie przyczyn i skutk\u00f3w, po wy\u0142apywanie niuans\u00f3w w tek\u015bcie. To naprawd\u0119 ci\u0119\u017cki test. I mniejszy model UL2 stan\u0105\u0142 do walki z tym gigantem? I wygra\u0142. I co najwa\u017cniejsze, zrobi\u0142 to w trybie zero shot. Czyli bez \u017cadnych podpowiedzi? Bez \u017cadnej \u015bci\u0105gi. Bez przyk\u0142ad\u00f3w. Po prostu rzucono mu wyzwanie na zimno, a on poradzi\u0142 sobie lepiej ni\u017c znacznie wi\u0119kszy, dro\u017cszy i bardziej zasobo\u017cerny konkurent. To by\u0142o ogromne osi\u0105gni\u0119cie. Lepsze wyniki mniejszy model. To przepis na rewolucj\u0119. Ale z tego co wiem, to nie koniec. UL2 20B ma jeszcze jedn\u0105 prze\u0142omow\u0105 zdolno\u015b\u0107, kt\u00f3ra wcze\u015bniej by\u0142a zarezerwowana tylko dla najwi\u0119kszych niedost\u0119pnych modeli. Mowa o zdolno\u015bci do rozmowania krok po kroku, czyli Chain of Thought Prompting. To jest absolutny prze\u0142om. Polega to na tym, \u017ce zamiast od razu podawa\u0107 odpowied\u017a, model najpierw jakby my\u015bli na g\u0142os. Opisuje sw\u00f3j tok rozumowania. Dok\u0142adnie. Generuje opis krok\u00f3w, kt\u00f3re doprowadzi\u0142y go do wniosku. To nie tylko daje lepsze wyniki w zadaniach logicznych, ale te\u017c czyni proces my\u015blowy AI bardziej przejrzystym. I do tej pory ta zdolno\u015b\u0107 by\u0142a widziana tylko w zamkni\u0119tych, gigantycznych modelach, jak PLM od Google. UL2 20B to pierwszy publicznie dost\u0119pny model, kt\u00f3ry to potrafi. Co to wszystko oznacza w praktyce? Podsumujmy. Jakie s\u0105 implikacje dla, no, dla ca\u0142ej bran\u017cy AI? Po pierwsze, to ogromny krok w stron\u0119 bardziej efektywnej sztucznej inteligencji. Zamiast utrzybywa\u0107 to ca\u0142e kosztowne zoomodeli, mo\u017cemy potencjalnie mie\u0107 jeden wszechstronny model, kt\u00f3ry radzi sobie ze wszystkim. To gigantyczna oszcz\u0119dno\u015b\u0107 zasob\u00f3w w czasu pieni\u0119dzy. Ogromna. A to z kolei prowadzi do demokratyzacji, prawda? Mniejszy uniwersytet, kt\u00f3ry nie ma bud\u017cetu na superkomputery, mo\u017ce teraz pobra\u0107 ten jeden stosunkowo niedu\u017cy model i prowadzi\u0107 badania, kt\u00f3re do tej pory by\u0142y zarezerwowane dla garstki gigant\u00f3w. To jest drugi, niezwykle wa\u017cny wniosek. Udost\u0119pnienie publicznie modelu 20B, kt\u00f3ry potrasznie robi\u0107 Chain of Thought, to prawdziwa zmiana regu\u0142 gry dla ca\u0142ej spo\u0142eczno\u015bci bodawczej. Daje im to dost\u0119p do narz\u0119dzi, o kt\u00f3rych do tej pory mogli tylko czyta\u0107. To fascynuj\u0105ce, \u017ce ta metoda dzia\u0142a na tak r\u00f3\u017cnych architekturach, bo testowali j\u0105 i na modelach Encoder Decoder jak T5 i Decoder Only jak GPT. Czy to sugeruje, \u017ce mogli\u015bmy si\u0119 skupia\u0107 na niew\u0142a\u015bciwym aspekcie, buduj\u0105c coraz nowsze silniki podczas gdy prze\u0142omd kwi\u0142\u0142 w paliwie? My\u015bl\u0119, \u017ce to jest najwa\u017cniejszy wniosek naukowy z tej pracy. Autorzy pokazuj\u0105, \u017ce cel treningowy, ta sprytna mixture of the noisers, mo\u017ce by\u0107 wa\u017cniejsze ni\u017c sama architektura. Mhm. To pot\u0119\u017cna wskaz\u00f3wka, kt\u00f3ra m\u00f3wi by\u0107 mo\u017ce najwi\u0119ksze zyski nie kryj\u0105 si\u0119 w projektowaniu coraz bardziej skomplikowanych sieci, ale w m\u0105drzejszym ich trenowaniu. Wr\u00f3\u0107my wi\u0119c do naszej analogii. Wygl\u0105da na to, \u017ce ten scyzorek jest nie tylko uniwersalny, ale w wielu zadaniach ostrzejszy ni\u017c dedykowane narz\u0119dzia. Dzi\u0119ki tej innowatorskiej metodzie treningu, UL2 rzuca wyzwanie idei, \u017ce modele AI musz\u0105 by\u0107 w\u0105sko specjalizowane. Pokazuje, \u017ce wszechstronno\u015b\u0107 jest nie tylko mo\u017cliwa, ale i niezwykle skuteczna. Tak. Co wi\u0119cej, jest jeszcze jeden aspekt. Autorzy sami przyznaj\u0105, \u017ce ich proces treningowy nie by\u0142 idealny. W jego trakcie zdarza\u0142y si\u0119 problemy techniczne, pewne skoki w funkcji straty. Naprawd\u0119? Tak. Co wi\u0119cej, trenowali ten 20 miliardowy model tylko na jednym og\u00f3lnodost\u0119pnym zbiorze danych C4, kt\u00f3ry, szczerze m\u00f3wi\u0105c, nie jest uwa\u017cany za najlepszy z mo\u017cliwych. Chcesz powiedzie\u0107, \u017ce te wszystkie rewelacyjne, rekordowe wyniki, o kt\u00f3rych m\u00f3wi\u0142y\u015bmy, zosta\u0142y osi\u0105gni\u0119te w nie do ko\u0144ca optymalnych warunkach. Dok\u0142adnie. To wszystko sugeruje, \u017ce te imponuj\u0105ce rezultaty mog\u0105 by\u0107 w rzeczywisto\u015bci niedoszacowaniem prawdziwego potencja\u0142u tej metody. Wow. A to prowadzi do prowokuj\u0105cego pytania, pytania do zastanowienia. Jakie mo\u017cliwo\u015bci otworzy\u0142by idealnie wytrenowany model UL2 uczony na jeszcze lepszych, bardziej zr\u00f3\u017cnicowanych i czystszych danych? By\u0107 mo\u017ce to, co zobaczyli\u015bmy, to dopiero wierzcho\u0142ek g\u00f3r\u0119 lodowej.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.4, "text": " Co by by\u0142o, gdyby zamiast ca\u0142ej skrzynki z narz\u0119dziami, gdzie, wiesz, ka\u017cde s\u0142u\u017c\u0119 do czego\u015b innego,", "tokens": [50364, 3066, 538, 14811, 11, 28405, 2322, 710, 4526, 525, 47631, 73, 1110, 13047, 77, 2984, 710, 6714, 89, 6298, 89, 15568, 11, 18922, 11, 261, 15347, 11, 21912, 1479, 48459, 1427, 1274, 360, 36559, 1788, 294, 11858, 11, 50684], "temperature": 0.0, "avg_logprob": -0.18925399780273439, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.004027428105473518}, {"id": 1, "seek": 0, "start": 6.4, "end": 10.88, "text": " mo\u017cna by mie\u0107 jedno takie uniwersalne narz\u0119dzie.", "tokens": [50684, 17790, 538, 35612, 5232, 1771, 15963, 36435, 5364, 304, 716, 6714, 89, 42643, 13, 50908], "temperature": 0.0, "avg_logprob": -0.18925399780273439, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.004027428105473518}, {"id": 2, "seek": 0, "start": 10.88, "end": 15.24, "text": " Taki scyzoryk, kt\u00f3ry zast\u0105pi\u0142by m\u0142otek, \u015brubokr\u0119ty, kombinerki.", "tokens": [50908, 314, 7421, 795, 37433, 827, 74, 11, 9913, 36746, 1611, 22630, 34635, 40770, 310, 916, 11, 8299, 81, 836, 453, 81, 1274, 874, 11, 42925, 4564, 2984, 13, 51126], "temperature": 0.0, "avg_logprob": -0.18925399780273439, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.004027428105473518}, {"id": 3, "seek": 0, "start": 15.24, "end": 25.44, "text": " Dok\u0142adnie. A w \u015bwiecie sztucznej inteligencji, a konkretnie modeli j\u0119zykowych przez d\u0142ugi czas byli\u015bmy skazani w\u0142a\u015bnie na tak\u0105 specjalistyczn\u0105 skrzynk\u0119.", "tokens": [51126, 29768, 10358, 2766, 13, 316, 261, 40078, 4260, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 11, 257, 36500, 2766, 2316, 72, 49055, 74, 19605, 14064, 44042, 24780, 13190, 538, 38452, 1110, 921, 3782, 14234, 1667, 31069, 46433, 468, 17466, 13113, 1110, 13047, 77, 15724, 13, 51636], "temperature": 0.0, "avg_logprob": -0.18925399780273439, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.004027428105473518}, {"id": 4, "seek": 0, "start": 25.44, "end": 28.16, "text": " Mieli\u015bmy ca\u0142e takie powiedzmy ZO modeli.", "tokens": [51636, 376, 23099, 10513, 47631, 15963, 27617, 2226, 1176, 46, 2316, 72, 13, 51772], "temperature": 0.0, "avg_logprob": -0.18925399780273439, "compression_ratio": 1.4451827242524917, "no_speech_prob": 0.004027428105473518}, {"id": 5, "seek": 2816, "start": 28.16, "end": 35.32, "text": " No w\u0142a\u015bnie, ZO, idealne okre\u015blenie. Jeden model, jak GPT, to by\u0142 powiedzmy genialny poeta.", "tokens": [50364, 883, 14234, 11, 1176, 46, 11, 7157, 716, 3133, 265, 1788, 6698, 414, 13, 508, 6876, 2316, 11, 4207, 26039, 51, 11, 281, 16673, 27617, 2226, 48228, 1634, 714, 7664, 13, 50722], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 6, "seek": 2816, "start": 35.32, "end": 38.96, "text": " \u015awietny w generowaniu p\u0142ynnego, kreatywnego tekstu.", "tokens": [50722, 27933, 39083, 1634, 261, 1337, 305, 25849, 28695, 2534, 11858, 11, 350, 620, 27112, 11858, 16624, 372, 84, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 7, "seek": 2816, "start": 38.96, "end": 42.519999999999996, "text": " A drugi, na przyk\u0142ad T5, by\u0142 bardziej analitykiem.", "tokens": [50904, 316, 4110, 72, 11, 1667, 23144, 314, 20, 11, 16673, 27209, 364, 1860, 26116, 13, 51082], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 8, "seek": 2816, "start": 42.519999999999996, "end": 46.760000000000005, "text": " Mistrzem w rozumieniu j\u0119zyka, odpowiadaniu na pytania, streszczaniu.", "tokens": [51082, 20166, 19390, 443, 261, 48797, 1053, 5951, 42309, 40940, 11, 24314, 38069, 25849, 1667, 25878, 5609, 11, 342, 495, 89, 3689, 25849, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 9, "seek": 2816, "start": 46.760000000000005, "end": 52.44, "text": " I programista musia\u0142 za ka\u017cdym razem wybiera\u0107 odpowiednie zwierz\u0119 do konkretnego zadania.", "tokens": [51294, 286, 1461, 5236, 1038, 8908, 7949, 31615, 76, 40225, 45780, 10609, 2162, 36574, 2766, 11873, 811, 11052, 360, 36500, 11858, 42788, 5609, 13, 51578], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 10, "seek": 2816, "start": 52.44, "end": 56.04, "text": " I takie ZO jest, no c\u00f3\u017c, bardzo drogie w utrzymaniu.", "tokens": [51578, 286, 15963, 1176, 46, 3492, 11, 572, 6333, 1427, 11, 9034, 3789, 9997, 261, 2839, 13047, 1601, 5951, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1563862164815267, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.013958225958049297}, {"id": 11, "seek": 5604, "start": 56.16, "end": 59.96, "text": " Ka\u017cdy model to osobny kosztowny trening, osobne zasoby.", "tokens": [50370, 10988, 1427, 3173, 2316, 281, 41518, 1634, 19532, 2682, 648, 88, 2192, 773, 11, 41518, 716, 26530, 13944, 13, 50560], "temperature": 0.0, "avg_logprob": -0.15552671253681183, "compression_ratio": 1.358695652173913, "no_speech_prob": 0.015133279375731945}, {"id": 12, "seek": 5604, "start": 59.96, "end": 64.96, "text": " I osobny b\u00f3l g\u0142owy przy wyborze. To by\u0142 ten fundamentalny kompromis.", "tokens": [50560, 286, 41518, 1634, 272, 15741, 18117, 10089, 6501, 4628, 3918, 1381, 13, 1407, 16673, 2064, 8088, 1634, 5207, 28722, 271, 13, 50810], "temperature": 0.0, "avg_logprob": -0.15552671253681183, "compression_ratio": 1.358695652173913, "no_speech_prob": 0.015133279375731945}, {"id": 13, "seek": 5604, "start": 64.96, "end": 69.03999999999999, "text": " Chcesz generowa\u0107 tekst, czego rozumie\u0107. Musisz wybra\u0107.", "tokens": [50810, 761, 887, 89, 1337, 11445, 16624, 372, 11, 36559, 48797, 414, 2162, 13, 3569, 23848, 4628, 6198, 2162, 13, 51014], "temperature": 0.0, "avg_logprob": -0.15552671253681183, "compression_ratio": 1.358695652173913, "no_speech_prob": 0.015133279375731945}, {"id": 14, "seek": 5604, "start": 69.03999999999999, "end": 74.88, "text": " Musisz. A dzisiaj przyjrzymy si\u0119 pracy naukowej, kt\u00f3ra rzuca temu wszystkiemu wyzwanie.", "tokens": [51014, 3569, 23848, 13, 316, 25772, 6501, 73, 13047, 2226, 3244, 35591, 35616, 74, 21091, 11, 19456, 367, 11728, 496, 33346, 14615, 4907, 84, 4628, 14406, 7155, 13, 51306], "temperature": 0.0, "avg_logprob": -0.15552671253681183, "compression_ratio": 1.358695652173913, "no_speech_prob": 0.015133279375731945}, {"id": 15, "seek": 5604, "start": 74.88, "end": 82.48, "text": " Mamy przed sob\u0105 artyku\u0142 z Google Brain, zatytu\u0142owany UL2. Unifying Language Learning Paradigms.", "tokens": [51306, 376, 7804, 18334, 18253, 1611, 594, 874, 5279, 1221, 710, 3329, 29783, 11, 35802, 4328, 84, 1221, 23341, 624, 43, 17, 13, 1156, 5489, 24445, 15205, 28527, 328, 2592, 13, 51686], "temperature": 0.0, "avg_logprob": -0.15552671253681183, "compression_ratio": 1.358695652173913, "no_speech_prob": 0.015133279375731945}, {"id": 16, "seek": 8248, "start": 82.52000000000001, "end": 91.12, "text": " Nasza misja na dzi\u015b zrozumie\u0107, jak autorzy tej pracy pr\u00f3buj\u0105 stworzy\u0107 w\u0142a\u015bnie taki uniwersalny scyzoryk dla EI.", "tokens": [50366, 16151, 2394, 3346, 2938, 1667, 31981, 1788, 710, 27857, 449, 414, 2162, 11, 4207, 19510, 1229, 12573, 35591, 8565, 65, 13263, 342, 28321, 27150, 14234, 20065, 36435, 5364, 304, 1634, 795, 37433, 827, 74, 12285, 462, 40, 13, 50796], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 17, "seek": 8248, "start": 91.12, "end": 97.2, "text": " Zastanowmy si\u0119, czy to w og\u00f3le mo\u017cliwe, \u017ceby jeden model by\u0142 jednocze\u015bnie i poet\u0105 i analitykiem.", "tokens": [50796, 1176, 525, 282, 305, 2226, 3244, 11, 6430, 281, 261, 29229, 30854, 826, 11, 11316, 12906, 2316, 16673, 5232, 26694, 1381, 12221, 741, 20874, 1611, 741, 364, 1860, 26116, 13, 51100], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 18, "seek": 8248, "start": 97.2, "end": 101.56, "text": " Wspomnieli\u015bmy ju\u017c o tym dyle macie. Generowanie kontrarozumienie.", "tokens": [51100, 343, 4952, 38131, 23099, 10513, 10678, 277, 8107, 274, 2072, 7912, 414, 13, 15409, 22028, 14373, 5352, 15151, 449, 27385, 13, 51318], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 19, "seek": 8248, "start": 101.56, "end": 105.12, "text": " Wi\u0119kszo\u015b\u0107 badaczy przyjmowa\u0142a to za pewnik.", "tokens": [51318, 30127, 1694, 4765, 7753, 1578, 14691, 6501, 35195, 5528, 5024, 281, 7949, 47160, 1035, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 20, "seek": 8248, "start": 105.12, "end": 109.28, "text": " To troch\u0119 jak w sporcie, prawda? Albo jeste\u015b marato\u0144czykiem albo sprinterem.", "tokens": [51496, 1407, 24926, 4207, 261, 43729, 4260, 11, 43607, 30, 967, 1763, 25255, 1788, 1849, 2513, 5248, 6522, 26116, 22622, 25075, 7333, 13, 51704], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 21, "seek": 8248, "start": 109.28, "end": 112.44, "text": " Ci\u0119\u017cko by\u0107 mistrzem w obu naraz dok\u0142adnie.", "tokens": [51704, 383, 5034, 1427, 4093, 15069, 3544, 19390, 443, 261, 1111, 84, 6714, 921, 45864, 2766, 13, 51862], "temperature": 0.0, "avg_logprob": -0.11017353106767704, "compression_ratio": 1.4133738601823709, "no_speech_prob": 0.013352150097489357}, {"id": 22, "seek": 11244, "start": 112.44, "end": 121.0, "text": " I autorzy UL2 podwa\u017cyli dogmat, kt\u00f3ry m\u00f3wi\u0142, \u017ce spos\u00f3b w jaki trenujemy model na samym pocz\u0105tku, ten tak zwany pre-training,", "tokens": [50364, 286, 19510, 1229, 624, 43, 17, 2497, 4151, 7735, 2081, 3000, 15677, 11, 9913, 24592, 1221, 11, 3561, 22904, 261, 24492, 23136, 21767, 2316, 1667, 3247, 4199, 43959, 11, 2064, 991, 11873, 1325, 659, 12, 17227, 1760, 11, 50792], "temperature": 0.0, "avg_logprob": -0.11202512582143148, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.0058034732937812805}, {"id": 23, "seek": 11244, "start": 121.0, "end": 124.92, "text": " musi by\u0107 \u015bci\u015ble dopasowany do jego przysz\u0142ych zada\u0144.", "tokens": [50792, 37587, 15069, 220, 6199, 1788, 306, 360, 20990, 23341, 360, 26542, 44018, 47655, 710, 1538, 5248, 13, 50988], "temperature": 0.0, "avg_logprob": -0.11202512582143148, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.0058034732937812805}, {"id": 24, "seek": 11244, "start": 124.92, "end": 131.12, "text": " Czyli je\u015bli chcesz, \u017ceby model strzeszcza\u0142, to od pocz\u0105tku trenujesz go w okre\u015blony spos\u00f3b.", "tokens": [50988, 37099, 25630, 417, 887, 89, 11, 11316, 2316, 1056, 89, 10430, 41524, 1221, 11, 281, 3611, 43959, 23136, 4579, 10430, 352, 261, 3133, 265, 19212, 2526, 22904, 13, 51298], "temperature": 0.0, "avg_logprob": -0.11202512582143148, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.0058034732937812805}, {"id": 25, "seek": 11244, "start": 131.12, "end": 135.88, "text": " A oni zapytali, a co je\u015bli to b\u0142\u0105d?", "tokens": [51298, 316, 36317, 14223, 4328, 5103, 11, 257, 598, 25630, 281, 272, 15926, 67, 30, 51536], "temperature": 0.0, "avg_logprob": -0.11202512582143148, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.0058034732937812805}, {"id": 26, "seek": 11244, "start": 135.88, "end": 138.72, "text": " No w\u0142a\u015bnie, postawili odwa\u017cne pytanie.", "tokens": [51536, 883, 14234, 11, 2183, 1607, 2312, 3611, 27111, 716, 36610, 13, 51678], "temperature": 0.0, "avg_logprob": -0.11202512582143148, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.0058034732937812805}, {"id": 27, "seek": 13872, "start": 138.72, "end": 144.88, "text": " Dlaczego nie spr\u00f3bowa\u0107 stworzy\u0107 jednego modelu, kt\u00f3ry od samego pocz\u0105tku uczy si\u0119 wszystkiego?", "tokens": [50364, 413, 75, 39329, 2838, 6103, 14216, 11445, 342, 28321, 27150, 5232, 11858, 2316, 84, 11, 9913, 3611, 912, 1571, 43959, 344, 6522, 3244, 14615, 12200, 30, 50672], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 28, "seek": 13872, "start": 144.88, "end": 149.52, "text": " I b\u0119dzie r\u00f3wnie dobry wiesz w zadaniach na rozumienie, jak testy w superglu,", "tokens": [50672, 286, 10562, 11416, 14215, 35884, 261, 15347, 261, 42788, 3782, 608, 1667, 48797, 27385, 11, 4207, 1500, 88, 261, 1687, 7191, 84, 11, 50904], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 29, "seek": 13872, "start": 149.52, "end": 153.28, "text": " i w zadaniach czysto generatywnych, jak strzeszczenia w X-sum.", "tokens": [50904, 741, 261, 42788, 3782, 608, 6430, 20875, 1337, 21398, 895, 16384, 11, 4207, 1056, 89, 10430, 38517, 261, 1783, 12, 82, 449, 13, 51092], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 30, "seek": 13872, "start": 153.28, "end": 160.36, "text": " To naprawd\u0119 odwa\u017cna teza podwa\u017cy\u0107 co\u015b, co wydawa\u0142o si\u0119 fundamentem, w takim razie co zaproponowali.", "tokens": [51092, 1407, 20970, 3611, 27111, 629, 535, 2394, 2497, 4151, 39687, 19241, 11, 598, 25984, 10449, 5249, 3244, 6073, 443, 11, 261, 31732, 9639, 414, 598, 14223, 1513, 266, 305, 5103, 13, 51446], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 31, "seek": 13872, "start": 160.36, "end": 161.96, "text": " Jaka jest ich alternatywa?", "tokens": [51446, 508, 7849, 3492, 1893, 5400, 21398, 4151, 30, 51526], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 32, "seek": 13872, "start": 161.96, "end": 165.2, "text": " Ich pomys\u0142 jest w swojej prostocie genialny.", "tokens": [51526, 3141, 12991, 39508, 3492, 261, 29489, 73, 10293, 905, 414, 48228, 1634, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11733992203422215, "compression_ratio": 1.4452054794520548, "no_speech_prob": 0.006122155115008354}, {"id": 33, "seek": 16520, "start": 165.23999999999998, "end": 168.32, "text": " Zauwa\u017cyli, \u017ce niemal ka\u017cde zadanie j\u0119zykowe,", "tokens": [50366, 1176, 1459, 4151, 7735, 2081, 11, 3561, 2838, 5579, 21912, 1479, 42788, 7155, 49055, 74, 6880, 11, 50520], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 34, "seek": 16520, "start": 168.32, "end": 171.95999999999998, "text": " niewa\u017cne jakie, mo\u017cna sprowadzi\u0107 do jednego schematu.", "tokens": [50520, 297, 27806, 716, 22124, 11, 17790, 637, 1892, 345, 28496, 360, 5232, 11858, 956, 8615, 84, 13, 50702], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 35, "seek": 16520, "start": 171.95999999999998, "end": 173.51999999999998, "text": " Input to target.", "tokens": [50702, 682, 2582, 281, 3779, 13, 50780], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 36, "seek": 16520, "start": 173.51999999999998, "end": 176.79999999999998, "text": " Input to target, czyli wej\u015bcie i wej\u015bcie.", "tokens": [50780, 682, 2582, 281, 3779, 11, 16591, 321, 73, 9815, 741, 321, 73, 9815, 13, 50944], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 37, "seek": 16520, "start": 176.79999999999998, "end": 177.88, "text": " Dok\u0142adnie.", "tokens": [50944, 29768, 10358, 2766, 13, 50998], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 38, "seek": 16520, "start": 177.88, "end": 182.12, "text": " Dajesz modelowi jaki\u015b input i oczekujesz, \u017ce wygeneruje target.", "tokens": [50998, 413, 1805, 10430, 2316, 24503, 34721, 4846, 741, 277, 3689, 916, 4579, 10430, 11, 3561, 4628, 21848, 13008, 3779, 13, 51210], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 39, "seek": 16520, "start": 182.12, "end": 186.07999999999998, "text": " Uzupe\u0142nianie luki w zdaniu to input to target, t\u0142umaczenie.", "tokens": [51210, 624, 11728, 31457, 77, 952, 414, 287, 11788, 261, 16221, 25849, 281, 4846, 281, 3779, 11, 256, 49166, 326, 16778, 13, 51408], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 40, "seek": 16520, "start": 186.07999999999998, "end": 186.92, "text": " To samo.", "tokens": [51408, 1407, 36422, 13, 51450], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 41, "seek": 16520, "start": 186.92, "end": 191.51999999999998, "text": " Czyli sprowadzili te wszystkie skomplikowane zadania do wsp\u00f3lnego mianownika.", "tokens": [51450, 37099, 637, 1892, 345, 89, 2312, 535, 31723, 1110, 298, 564, 1035, 23066, 42788, 5609, 360, 47148, 11858, 275, 952, 648, 5439, 13, 51680], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 42, "seek": 16520, "start": 191.51999999999998, "end": 194.92, "text": " To pozwoli\u0142o im traktowa\u0107 jej jednolicie.", "tokens": [51680, 1407, 40557, 9384, 5249, 566, 944, 2320, 11445, 28924, 5232, 77, 7940, 414, 13, 51850], "temperature": 0.0, "avg_logprob": -0.11190991401672364, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.018266446888446808}, {"id": 43, "seek": 19492, "start": 194.95999999999998, "end": 196.04, "text": " W\u0142a\u015bnie tak.", "tokens": [50366, 343, 5024, 12221, 991, 13, 50420], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 44, "seek": 19492, "start": 196.04, "end": 200.04, "text": " I na tym fundamentie zbudowali swoj\u0105 g\u0142\u00f3wn\u0105 innowacj\u0119.", "tokens": [50420, 286, 1667, 8107, 6073, 414, 710, 18281, 305, 5103, 49194, 18117, 812, 895, 1611, 294, 3785, 29924, 13, 50620], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 45, "seek": 19492, "start": 200.04, "end": 203.48, "text": " Metod\u0119 treningow\u0105 nazwan\u0105 Mixture of the Noisers.", "tokens": [50620, 6377, 378, 1274, 2192, 773, 30297, 20151, 7916, 1611, 10204, 8890, 295, 264, 883, 271, 433, 13, 50792], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 46, "seek": 19492, "start": 203.48, "end": 205.07999999999998, "text": " W skr\u00f3cie mod.", "tokens": [50792, 343, 1110, 11721, 4260, 1072, 13, 50872], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 47, "seek": 19492, "start": 205.07999999999998, "end": 208.0, "text": " Czyli to nie jest nowa architektura, nowy silnik?", "tokens": [50872, 37099, 281, 2838, 3492, 586, 64, 3912, 642, 2320, 2991, 11, 586, 88, 3425, 13123, 30, 51018], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 48, "seek": 19492, "start": 208.0, "end": 210.83999999999997, "text": " Nie. To raczej rewolucyjne paliwo.", "tokens": [51018, 12016, 13, 1407, 4129, 16920, 319, 48481, 1311, 88, 73, 716, 3984, 72, 6120, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 49, "seek": 19492, "start": 210.83999999999997, "end": 212.32, "text": " Spos\u00f3b trenowania.", "tokens": [51160, 1738, 329, 14216, 23136, 21308, 13, 51234], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 50, "seek": 19492, "start": 212.32, "end": 216.72, "text": " Mo\u017cna to por\u00f3wna\u0107 tak jak m\u00f3wi\u0142a\u015b do wszechstronnego planu treningowego dla sportowca.", "tokens": [51234, 44736, 629, 281, 1515, 3901, 629, 2162, 991, 4207, 24592, 5024, 1788, 360, 37647, 19439, 372, 2044, 11858, 1393, 84, 2192, 773, 26576, 12285, 7282, 305, 496, 13, 51454], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 51, "seek": 19492, "start": 216.72, "end": 219.6, "text": " Kt\u00f3ry chce by\u0107 dobry i w maratonie i w spryncie.", "tokens": [51454, 591, 4547, 627, 28928, 15069, 35884, 741, 261, 1849, 25781, 414, 741, 261, 6103, 2534, 4260, 13, 51598], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 52, "seek": 19492, "start": 219.6, "end": 223.64, "text": " Ok, to roz\u0142\u00f3\u017cmy ten plan treningowy na czynniki pierwsze.", "tokens": [51598, 3477, 11, 281, 9544, 1221, 812, 1427, 2226, 2064, 1393, 2192, 773, 10089, 1667, 6430, 26384, 9850, 45994, 13, 51800], "temperature": 0.0, "avg_logprob": -0.12735817136143793, "compression_ratio": 1.438095238095238, "no_speech_prob": 0.0012622029753401875}, {"id": 53, "seek": 22364, "start": 223.72, "end": 226.07999999999998, "text": " Z jakich \u0107wicze\u0144 on si\u0119 sk\u0142ada?", "tokens": [50368, 1176, 4207, 480, 45854, 22295, 49689, 322, 3244, 1110, 46217, 30, 50486], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 54, "seek": 22364, "start": 226.07999999999998, "end": 228.0, "text": " Mamy trzy g\u0142\u00f3wne typy.", "tokens": [50486, 376, 7804, 34573, 18117, 3901, 716, 2125, 88, 13, 50582], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 55, "seek": 22364, "start": 228.0, "end": 231.23999999999998, "text": " Pierwszy to Air the Noiser od Regular.", "tokens": [50582, 16676, 30012, 281, 5774, 264, 883, 6694, 3611, 45659, 13, 50744], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 56, "seek": 22364, "start": 231.23999999999998, "end": 235.35999999999999, "text": " To s\u0105 takie powiedzmy podstawowe \u0107wiczenia si\u0142owe, budowanie fundamentu.", "tokens": [50744, 1407, 9015, 15963, 27617, 2226, 43443, 6880, 45854, 22295, 14320, 1511, 1221, 6880, 11, 3265, 22028, 6073, 84, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 57, "seek": 22364, "start": 235.35999999999999, "end": 236.95999999999998, "text": " Jak to wygl\u0105da w praktyce?", "tokens": [50950, 15029, 281, 32015, 261, 3206, 74, 874, 384, 30, 51030], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 58, "seek": 22364, "start": 236.95999999999998, "end": 239.79999999999998, "text": " Bierzemy tekst i losowo go uszkadziamy.", "tokens": [51030, 363, 34602, 3633, 16624, 372, 741, 1750, 19941, 352, 505, 30154, 345, 89, 2918, 88, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 59, "seek": 22364, "start": 239.79999999999998, "end": 242.39999999999998, "text": " Wymazujemy kilka s\u0142\u00f3w tu i uwdzie.", "tokens": [51172, 343, 4199, 921, 21767, 36466, 15116, 3901, 2604, 741, 23147, 13096, 13, 51302], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 60, "seek": 22364, "start": 242.39999999999998, "end": 246.48, "text": " A zadaniem modelu jest odtworzenie tych brakuj\u0105cych, kr\u00f3tkich luk.", "tokens": [51302, 316, 710, 11338, 4907, 2316, 84, 3492, 3611, 20270, 284, 16778, 15180, 1548, 74, 13263, 31306, 11, 42366, 83, 48349, 287, 2034, 13, 51506], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 61, "seek": 22364, "start": 246.48, "end": 250.0, "text": " Aha, czyli to taka praca u podstaw.", "tokens": [51506, 27448, 11, 16591, 281, 28017, 582, 6628, 344, 43443, 13, 51682], "temperature": 0.0, "avg_logprob": -0.1451919747771119, "compression_ratio": 1.375, "no_speech_prob": 0.12392916530370712}, {"id": 62, "seek": 25000, "start": 250.04, "end": 255.6, "text": " Upewnienie si\u0119, \u017ce model za\u0142apa\u0142 gramatyk\u0119 i podstawowy zwi\u0105zki mi\u0119dzy s\u0142owami,", "tokens": [50366, 624, 494, 895, 27385, 3244, 11, 3561, 2316, 7949, 1221, 7961, 1221, 21353, 21398, 15724, 741, 43443, 10089, 27741, 2984, 33964, 15116, 305, 4526, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 63, "seek": 25000, "start": 255.6, "end": 257.96, "text": " zanim ka\u017cemy mu pisa\u0107 wiersze.", "tokens": [50644, 710, 17869, 6799, 1427, 3633, 2992, 280, 3837, 2162, 261, 4890, 1381, 13, 50762], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 64, "seek": 25000, "start": 257.96, "end": 259.68, "text": " Dok\u0142adnie tak.", "tokens": [50762, 29768, 10358, 2766, 991, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 65, "seek": 25000, "start": 259.68, "end": 263.4, "text": " To go zmusza do ci\u0105g\u0142ego rozumienia najbli\u017cszego kontekstu", "tokens": [50848, 1407, 352, 17020, 301, 2394, 360, 42398, 70, 1221, 6308, 48797, 18811, 11212, 32117, 1427, 15453, 6308, 14373, 916, 372, 84, 51034], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 66, "seek": 25000, "start": 263.4, "end": 266.28, "text": " i buduje solidne j\u0119zykowe podstawy.", "tokens": [51034, 741, 3265, 13008, 5100, 716, 49055, 74, 6880, 43443, 88, 13, 51178], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 67, "seek": 25000, "start": 266.28, "end": 270.48, "text": " Bardzo podobnie trenuje si\u0119 model T5, czyli naszego analityka.", "tokens": [51178, 38559, 43024, 2766, 23136, 13008, 3244, 2316, 314, 20, 11, 16591, 44517, 364, 1860, 2330, 13, 51388], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 68, "seek": 25000, "start": 270.48, "end": 273.0, "text": " Ok, mamy solidne fundamenty.", "tokens": [51388, 3477, 11, 17335, 5100, 716, 6073, 88, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 69, "seek": 25000, "start": 273.0, "end": 274.8, "text": " Co jest drugim elementem?", "tokens": [51514, 3066, 3492, 4110, 332, 4478, 443, 30, 51604], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 70, "seek": 25000, "start": 274.8, "end": 278.68, "text": " Drugi to S the Noiser, czyli Sequential.", "tokens": [51604, 2491, 24780, 281, 318, 264, 883, 6694, 11, 16591, 46859, 2549, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1272922322370004, "compression_ratio": 1.4259927797833936, "no_speech_prob": 0.10000906139612198}, {"id": 71, "seek": 27868, "start": 278.68, "end": 280.64, "text": " To ju\u017c jest trening sprinterski.", "tokens": [50364, 1407, 10678, 3492, 2192, 773, 6103, 35388, 2984, 13, 50462], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 72, "seek": 27868, "start": 280.64, "end": 282.68, "text": " Dajemy modelowi pocz\u0105tek zdania,", "tokens": [50462, 413, 1805, 3633, 2316, 24503, 34397, 916, 16221, 5609, 11, 50564], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 73, "seek": 27868, "start": 282.68, "end": 286.6, "text": " a jego zadaniem jest doko\u0144czenie go w sp\u00f3jny i logiczny spos\u00f3b.", "tokens": [50564, 257, 26542, 710, 11338, 4907, 3492, 360, 4093, 5248, 39043, 352, 261, 637, 18999, 1634, 741, 9952, 89, 1634, 22904, 13, 50760], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 74, "seek": 27868, "start": 286.6, "end": 293.88, "text": " Czyli to jest ta umiej\u0119tno\u015b\u0107, z kt\u00f3rej s\u0142yn\u0105 modele typu GPT, nasi poeci,", "tokens": [50760, 37099, 281, 3492, 1846, 1105, 7764, 46788, 23293, 11, 710, 36023, 15116, 2534, 1611, 4391, 306, 2125, 84, 26039, 51, 11, 5382, 72, 714, 68, 537, 11, 51124], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 75, "seek": 27868, "start": 293.88, "end": 296.04, "text": " ucz\u0105 si\u0119 kontynuowa\u0107 my\u015bl.", "tokens": [51124, 35403, 1611, 3244, 5897, 874, 16241, 11445, 452, 19212, 13, 51232], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 76, "seek": 27868, "start": 296.04, "end": 297.04, "text": " Zglaza si\u0119.", "tokens": [51232, 1176, 70, 875, 2394, 3244, 13, 51282], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 77, "seek": 27868, "start": 297.04, "end": 299.88, "text": " To rozwija zdolno\u015bci czysto generatywne.", "tokens": [51282, 1407, 9544, 86, 20642, 16221, 401, 16438, 6430, 20875, 1337, 21398, 86, 716, 13, 51424], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 78, "seek": 27868, "start": 299.88, "end": 304.04, "text": " Ale autorzy dodali jeszcze trzeci, chyba najciekawszy element.", "tokens": [51424, 9366, 19510, 1229, 13886, 5103, 14168, 22266, 537, 11, 31532, 11212, 4260, 74, 1607, 7706, 4478, 13, 51632], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 79, "seek": 27868, "start": 304.04, "end": 306.32, "text": " X the Noiser od Extreme.", "tokens": [51632, 1783, 264, 883, 6694, 3611, 39525, 13, 51746], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 80, "seek": 27868, "start": 306.32, "end": 308.16, "text": " Brzmi intensywnie.", "tokens": [51746, 1603, 89, 3057, 14056, 88, 14215, 13, 51838], "temperature": 0.0, "avg_logprob": -0.11707322438557943, "compression_ratio": 1.3657718120805369, "no_speech_prob": 0.0024752216413617134}, {"id": 81, "seek": 30816, "start": 308.16, "end": 311.16, "text": " Bo to jest trening ekstremalny.", "tokens": [50364, 3286, 281, 3492, 2192, 773, 13359, 372, 2579, 304, 1634, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 82, "seek": 30816, "start": 311.16, "end": 316.48, "text": " Wyobra\u017a sobie, \u017ce usuwamy z tekstu nie kilka s\u0142\u00f3w, ale po\u0142ow\u0119.", "tokens": [50514, 14458, 24393, 10659, 13652, 11, 3561, 32247, 86, 7804, 710, 16624, 372, 84, 2838, 36466, 15116, 3901, 11, 6775, 714, 1221, 305, 1274, 13, 50780], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 83, "seek": 30816, "start": 316.48, "end": 318.96000000000004, "text": " I to w jednym, d\u0142ugim bloku.", "tokens": [50780, 286, 281, 261, 5232, 12996, 11, 274, 34077, 332, 888, 13275, 13, 50904], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 84, "seek": 30816, "start": 318.96000000000004, "end": 322.36, "text": " Model dostaje tylko pierwsz\u0105 i ostatni\u0105 cz\u0119\u015b\u0107,", "tokens": [50904, 17105, 20568, 11153, 13219, 27623, 8925, 741, 32686, 3722, 1611, 47149, 11, 51074], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 85, "seek": 30816, "start": 322.36, "end": 325.24, "text": " a musi zrekonstruowa\u0107 ca\u0142y \u015brodek.", "tokens": [51074, 257, 37587, 710, 20012, 4068, 894, 11445, 35226, 28580, 916, 13, 51218], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 86, "seek": 30816, "start": 325.24, "end": 327.32000000000005, "text": " To brzmi niewiarygodnie trudno.", "tokens": [51218, 1407, 738, 89, 3057, 43622, 29104, 21787, 2766, 32007, 1771, 13, 51322], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 87, "seek": 30816, "start": 327.32000000000005, "end": 332.84000000000003, "text": " Jak pr\u00f3ba odtworzenia ca\u0142ej strony z ksi\u0105\u017cki maj\u0105c tylko pierwsze i ostatnie zdanie.", "tokens": [51322, 15029, 8565, 4231, 3611, 20270, 284, 14320, 47631, 73, 32406, 710, 39311, 2984, 26064, 66, 13219, 45994, 741, 32686, 2766, 16221, 7155, 13, 51598], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 88, "seek": 30816, "start": 332.84000000000003, "end": 334.28000000000003, "text": " Po co co\u015b takiego?", "tokens": [51598, 6165, 598, 19241, 32296, 30, 51670], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 89, "seek": 30816, "start": 334.28000000000003, "end": 337.8, "text": " Bo to uczy go niesamowitej elastyczno\u015bci.", "tokens": [51670, 3286, 281, 344, 6522, 352, 48100, 335, 305, 642, 73, 806, 9820, 3689, 16438, 13, 51846], "temperature": 0.0, "avg_logprob": -0.09859987762239245, "compression_ratio": 1.4013840830449826, "no_speech_prob": 0.002002138178795576}, {"id": 90, "seek": 33780, "start": 337.84000000000003, "end": 340.12, "text": " I rozumienia szerszego kontekstu.", "tokens": [50366, 286, 48797, 18811, 7870, 433, 27725, 14373, 916, 372, 84, 13, 50480], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 91, "seek": 33780, "start": 340.12, "end": 344.12, "text": " Musi nie tylko zna\u0107 gramatyk\u0119, nie tylko kontynuowa\u0107 my\u015bl,", "tokens": [50480, 3569, 72, 2838, 13219, 710, 629, 2162, 21353, 21398, 15724, 11, 2838, 13219, 5897, 874, 16241, 11445, 452, 19212, 11, 50680], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 92, "seek": 33780, "start": 344.12, "end": 347.72, "text": " ale te\u017c potrafi\u0107 zrekonstruowa\u0107 z\u0142o\u017con\u0105 struktur\u0119", "tokens": [50680, 6775, 9516, 1847, 10437, 12757, 710, 20012, 4068, 894, 11445, 710, 5249, 1427, 266, 1611, 342, 31543, 1274, 50860], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 93, "seek": 33780, "start": 347.72, "end": 351.48, "text": " na podstawie bardzo ograniczonych informacji.", "tokens": [50860, 1667, 43443, 414, 9034, 34416, 282, 17946, 2526, 339, 1356, 13152, 13, 51048], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 94, "seek": 33780, "start": 351.48, "end": 354.76, "text": " To jest co\u015b pomi\u0119dzy metod\u0105 R i S.", "tokens": [51048, 1407, 3492, 19241, 12991, 49485, 1131, 378, 1611, 497, 741, 318, 13, 51212], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 95, "seek": 33780, "start": 354.76, "end": 356.52, "text": " I tu dochodzimy do sedna.", "tokens": [51212, 286, 2604, 9243, 378, 89, 13189, 360, 9643, 629, 13, 51300], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 96, "seek": 33780, "start": 356.52, "end": 359.6, "text": " Kluczem nie jest \u017cadne z tych pojedynczych \u0107wicze\u0144,", "tokens": [51300, 16053, 1311, 24313, 2838, 3492, 39628, 716, 710, 15180, 714, 40543, 2534, 6522, 339, 45854, 22295, 49689, 11, 51454], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 97, "seek": 33780, "start": 359.6, "end": 361.40000000000003, "text": " tylko ich po\u0142\u0105czenie, prawda?", "tokens": [51454, 13219, 1893, 714, 15926, 39043, 11, 43607, 30, 51544], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 98, "seek": 33780, "start": 361.40000000000003, "end": 362.52, "text": " Dok\u0142adnie.", "tokens": [51544, 29768, 10358, 2766, 13, 51600], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 99, "seek": 33780, "start": 362.52, "end": 364.64, "text": " Magiad kwi w mieszance.", "tokens": [51600, 6395, 38069, 350, 6253, 261, 33039, 719, 13, 51706], "temperature": 0.0, "avg_logprob": -0.13372820073908026, "compression_ratio": 1.3985507246376812, "no_speech_prob": 0.06569911539554596}, {"id": 100, "seek": 36464, "start": 364.64, "end": 369.08, "text": " W trakcie jednego procesu treningowego model robi wszystkie trzy typy \u0107wicze\u0144.", "tokens": [50364, 343, 944, 74, 4260, 5232, 11858, 17565, 84, 2192, 773, 26576, 2316, 47380, 31723, 34573, 2125, 88, 45854, 22295, 49689, 13, 50586], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 101, "seek": 36464, "start": 369.08, "end": 372.96, "text": " Raz uzupe\u0142nia kr\u00f3tkie luki, za chwil\u0119 doka\u0144cza zdania,", "tokens": [50586, 29051, 344, 11728, 31457, 12679, 42366, 83, 22872, 287, 11788, 11, 7949, 41941, 1274, 360, 2330, 5248, 41524, 16221, 5609, 11, 50780], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 102, "seek": 36464, "start": 372.96, "end": 376.24, "text": " a potem mierzy si\u0119 z t\u0105 ekstremaln\u0105 rekonstrukcj\u0105.", "tokens": [50780, 257, 36513, 47448, 1229, 3244, 710, 32294, 13359, 372, 2579, 304, 13113, 33881, 4068, 25126, 66, 8555, 13, 50944], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 103, "seek": 36464, "start": 376.24, "end": 377.08, "text": " Aha.", "tokens": [50944, 27448, 13, 50986], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 104, "seek": 36464, "start": 377.08, "end": 383.47999999999996, "text": " W artykule jest nawet podkre\u015blione, \u017ce sam X-D Noiser w izolacji nie dzia\u0142a\u0142by dobrze.", "tokens": [50986, 343, 594, 874, 74, 2271, 3492, 22696, 2497, 27885, 19212, 5328, 11, 3561, 3247, 1783, 12, 35, 883, 6694, 261, 14736, 401, 13152, 2838, 37903, 34635, 28335, 13, 51306], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 105, "seek": 36464, "start": 383.47999999999996, "end": 386.03999999999996, "text": " To potwierdzaj\u0105 te\u017c wcze\u015bniejsze badania.", "tokens": [51306, 1407, 1847, 40717, 28168, 11133, 9516, 38533, 1788, 44258, 1578, 5609, 13, 51434], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 106, "seek": 36464, "start": 386.03999999999996, "end": 390.96, "text": " Dopiero synergi\u0119 tych trzech pozornie r\u00f3\u017cnych zada\u0144 tworzy wszechstronnego sportowca.", "tokens": [51434, 42657, 12030, 33781, 70, 5034, 15180, 504, 19439, 21281, 1865, 414, 42602, 710, 1538, 5248, 46288, 1229, 37647, 19439, 372, 2044, 11858, 7282, 305, 496, 13, 51680], "temperature": 0.0, "avg_logprob": -0.14507251315646702, "compression_ratio": 1.3980263157894737, "no_speech_prob": 0.06450597196817398}, {"id": 107, "seek": 39096, "start": 391.0, "end": 395.0, "text": " Ta koncepcja mieszanki treningowej jest naprawd\u0119 klarowna,", "tokens": [50366, 6551, 5897, 27493, 34056, 33039, 27203, 2192, 773, 21091, 3492, 20970, 14743, 305, 629, 11, 50566], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 108, "seek": 39096, "start": 395.0, "end": 396.59999999999997, "text": " ale nasuwa si\u0119 pytanie.", "tokens": [50566, 6775, 5382, 84, 4151, 3244, 36610, 13, 50646], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 109, "seek": 39096, "start": 396.59999999999997, "end": 397.52, "text": " Praktyczne.", "tokens": [50646, 430, 11272, 874, 38491, 13, 50692], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 110, "seek": 39096, "start": 397.52, "end": 400.28, "text": " Skoro model nauczy si\u0119 wszystkiego na raz,", "tokens": [50692, 7324, 10780, 2316, 49103, 1229, 3244, 14615, 12200, 1667, 9639, 11, 50830], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 111, "seek": 39096, "start": 400.28, "end": 403.35999999999996, "text": " to jak on potem wie, kt\u00f3rej umiej\u0119tno\u015bci ma u\u017cy\u0107?", "tokens": [50830, 281, 4207, 322, 36513, 3355, 11, 36023, 1105, 7764, 46788, 16438, 463, 34097, 2162, 30, 50984], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 112, "seek": 39096, "start": 403.35999999999996, "end": 404.28, "text": " \u015awietne pytanie.", "tokens": [50984, 27933, 39083, 716, 36610, 13, 51030], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 113, "seek": 39096, "start": 404.28, "end": 406.28, "text": " No bo przecie\u017c nie mo\u017ce zgadywa\u0107,", "tokens": [51030, 883, 748, 8325, 40082, 2838, 12034, 40948, 880, 25234, 11, 51130], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 114, "seek": 39096, "start": 406.28, "end": 409.32, "text": " czy ma analizowa\u0107 dane, czy pisa\u0107 kreatywnie.", "tokens": [51130, 6430, 463, 2624, 590, 11445, 49206, 11, 6430, 280, 3837, 2162, 350, 620, 88, 14215, 13, 51282], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 115, "seek": 39096, "start": 409.32, "end": 411.88, "text": " I autorzy maj\u0105 na to bardzo sprytne rozwi\u0105zanie,", "tokens": [51282, 286, 19510, 1229, 26064, 1667, 281, 9034, 637, 627, 83, 716, 9544, 22620, 7155, 11, 51410], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 116, "seek": 39096, "start": 411.88, "end": 414.32, "text": " kt\u00f3re nazywaj\u0105 mode switching.", "tokens": [51410, 8864, 20151, 27112, 11133, 4391, 16493, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 117, "seek": 39096, "start": 414.32, "end": 415.96, "text": " Pomy\u015bl o naszym sportowcu.", "tokens": [51532, 430, 8488, 19212, 277, 48094, 7282, 305, 12032, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 118, "seek": 39096, "start": 415.96, "end": 420.32, "text": " Sk\u0105d on wie, czy teraz ma biec spr\u0119t, czy podnosi\u0107 ci\u0119\u017cary?", "tokens": [51614, 7324, 18962, 322, 3355, 11, 6430, 16854, 463, 272, 35733, 6103, 1274, 83, 11, 6430, 2497, 16751, 12757, 35484, 1427, 822, 30, 51832], "temperature": 0.0, "avg_logprob": -0.13952840325291171, "compression_ratio": 1.5031645569620253, "no_speech_prob": 0.055607523769140244}, {"id": 119, "seek": 42032, "start": 420.32, "end": 421.24, "text": " Trener mu m\u00f3wi.", "tokens": [50364, 8648, 1193, 2992, 24592, 13, 50410], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 120, "seek": 42032, "start": 421.24, "end": 422.2, "text": " No w\u0142a\u015bnie.", "tokens": [50410, 883, 14234, 13, 50458], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 121, "seek": 42032, "start": 422.2, "end": 424.12, "text": " I oni zrobili to samo z modelem.", "tokens": [50458, 286, 36317, 44399, 2312, 281, 36422, 710, 4391, 10386, 13, 50554], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 122, "seek": 42032, "start": 424.12, "end": 424.68, "text": " Ale jak?", "tokens": [50554, 9366, 4207, 30, 50582], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 123, "seek": 42032, "start": 424.68, "end": 427.04, "text": " Przecie\u017c nie da si\u0119 z nim porozmawia\u0107, prawie.", "tokens": [50582, 2114, 1381, 40082, 2838, 1120, 3244, 710, 24887, 1515, 15151, 76, 34953, 2162, 11, 3206, 8699, 13, 50700], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 124, "seek": 42032, "start": 427.04, "end": 430.0, "text": " Podczas treningu na pocz\u0105tku ka\u017cdego przyk\u0142adu", "tokens": [50700, 12646, 30989, 2192, 773, 84, 1667, 43959, 21912, 67, 6308, 23144, 84, 50848], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 125, "seek": 42032, "start": 430.0, "end": 432.64, "text": " podawali modelowi specjalny token.", "tokens": [50848, 2497, 1607, 5103, 2316, 24503, 46433, 1634, 14862, 13, 50980], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 126, "seek": 42032, "start": 432.64, "end": 435.0, "text": " R, S albo X.", "tokens": [50980, 497, 11, 318, 22622, 1783, 13, 51098], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 127, "seek": 42032, "start": 435.0, "end": 436.44, "text": " A, czyli takie komendy.", "tokens": [51098, 316, 11, 16591, 15963, 5207, 18642, 13, 51170], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 128, "seek": 42032, "start": 436.44, "end": 437.8, "text": " Dok\u0142adnie, komendy.", "tokens": [51170, 29768, 10358, 2766, 11, 5207, 18642, 13, 51238], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 129, "seek": 42032, "start": 437.8, "end": 442.68, "text": " Daj\u0105c mu R m\u00f3wili OK, teraz skup si\u0119 na uzupe\u0142nianiu ma\u0142ych luk,", "tokens": [51238, 413, 38757, 2992, 497, 13489, 2312, 2264, 11, 16854, 1110, 1010, 3244, 1667, 344, 11728, 31457, 77, 952, 5951, 463, 47655, 287, 2034, 11, 51482], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 130, "seek": 42032, "start": 442.68, "end": 445.92, "text": " daj\u0105c S m\u00f3wili teraz czas na generowanie.", "tokens": [51482, 1120, 8555, 66, 318, 13489, 2312, 16854, 13190, 1667, 1337, 22028, 13, 51644], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 131, "seek": 42032, "start": 445.92, "end": 449.6, "text": " Model nauczy\u0142 si\u0119 kojarzy\u0107 te tokeny z odpowiednim trybem pracy.", "tokens": [51644, 17105, 49103, 1229, 1221, 3244, 8384, 10150, 27150, 535, 14862, 88, 710, 36574, 39223, 853, 65, 443, 35591, 13, 51828], "temperature": 0.0, "avg_logprob": -0.17185778676727673, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.05209680274128914}, {"id": 132, "seek": 44960, "start": 449.64000000000004, "end": 451.68, "text": " Zaraz, zaraz.", "tokens": [50366, 41580, 921, 11, 22675, 921, 13, 50468], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 133, "seek": 44960, "start": 451.68, "end": 455.16, "text": " Czyli p\u00f3\u017aniej ju\u017c po treningu mo\u017cna u\u017cy\u0107 tych token\u00f3w", "tokens": [50468, 37099, 36968, 10678, 714, 2192, 773, 84, 17790, 34097, 2162, 15180, 14862, 3901, 50642], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 134, "seek": 44960, "start": 455.16, "end": 457.20000000000005, "text": " jako takiego prze\u0142\u0105cznika tryb\u00f3w.", "tokens": [50642, 17123, 32296, 8325, 43558, 77, 5439, 853, 65, 3901, 13, 50744], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 135, "seek": 44960, "start": 457.20000000000005, "end": 459.56, "text": " Je\u015bli chce, \u017ceby napisa\u0142 mi opowiadanie,", "tokens": [50744, 37086, 28928, 11, 11316, 9296, 3837, 1221, 2752, 999, 24503, 345, 7155, 11, 50862], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 136, "seek": 44960, "start": 459.56, "end": 462.32000000000005, "text": " to na pocz\u0105tku polecenia daje mu token S", "tokens": [50862, 281, 1667, 43959, 13208, 13037, 654, 1120, 2884, 2992, 14862, 318, 51000], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 137, "seek": 44960, "start": 462.32000000000005, "end": 464.6, "text": " i on wierze ma wej\u015b\u0107 w tryb kreatywny.", "tokens": [51000, 741, 322, 261, 811, 1381, 463, 321, 44536, 261, 853, 65, 350, 620, 88, 43682, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 138, "seek": 44960, "start": 464.6, "end": 465.68, "text": " Dok\u0142adnie tak.", "tokens": [51114, 29768, 10358, 2766, 991, 13, 51168], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 139, "seek": 44960, "start": 465.68, "end": 469.16, "text": " I to nie jest tylko teoria, to ma realny, mierzalny wp\u0142yw.", "tokens": [51168, 286, 281, 2838, 3492, 13219, 535, 8172, 11, 281, 463, 957, 1634, 11, 47448, 89, 304, 1634, 32444, 6825, 86, 13, 51342], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 140, "seek": 44960, "start": 469.16, "end": 471.96000000000004, "text": " W artykule jest eksperyment, w kt\u00f3rym prosili model", "tokens": [51342, 343, 594, 874, 74, 2271, 3492, 30724, 610, 88, 518, 11, 261, 30120, 6267, 2312, 2316, 51482], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 141, "seek": 44960, "start": 471.96000000000004, "end": 475.0, "text": " o strychczenie tekstu ze zbioru exum.", "tokens": [51482, 277, 1056, 16384, 39043, 16624, 372, 84, 5277, 710, 33362, 84, 454, 449, 13, 51634], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 142, "seek": 44960, "start": 475.0, "end": 476.0, "text": " I co?", "tokens": [51634, 286, 598, 30, 51684], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 143, "seek": 44960, "start": 476.0, "end": 478.40000000000003, "text": " Kiedy u\u017cyli odpowiedniego tokena podpowiedzi,", "tokens": [51684, 591, 16446, 34097, 2081, 36574, 2766, 1571, 14862, 64, 2497, 14701, 1091, 3992, 11, 51804], "temperature": 0.0, "avg_logprob": -0.13860494749886648, "compression_ratio": 1.4585987261146496, "no_speech_prob": 0.0011483397101983428}, {"id": 144, "seek": 47840, "start": 478.44, "end": 480.59999999999997, "text": " wynik by\u0142 dramatycznie lepszy.", "tokens": [50366, 31936, 1035, 16673, 42749, 17466, 2766, 476, 1878, 1229, 13, 50474], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 145, "seek": 47840, "start": 480.59999999999997, "end": 484.52, "text": " R\u00f3\u017cnica wydajno\u015bci mi\u0119dzy u\u017cyciem dobrego a z\u0142ego trybu", "tokens": [50474, 497, 812, 1427, 32687, 25984, 1805, 16438, 33964, 34097, 4260, 76, 41959, 1571, 257, 31614, 6308, 853, 6021, 50670], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 146, "seek": 47840, "start": 484.52, "end": 487.88, "text": " to by\u0142o uwaga a\u017c 48%.", "tokens": [50670, 281, 14811, 23147, 9286, 48134, 11174, 6856, 50838], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 147, "seek": 47840, "start": 487.88, "end": 492.96, "text": " Wow, to dow\u00f3d, \u017ce model naprawd\u0119 nauczy\u0142 si\u0119 tych r\u00f3\u017cnych osobowo\u015bci", "tokens": [50838, 3153, 11, 281, 9459, 17081, 11, 3561, 2316, 20970, 49103, 1229, 1221, 3244, 15180, 42602, 19116, 8202, 44468, 51092], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 148, "seek": 47840, "start": 492.96, "end": 496.2, "text": " i potrafi si\u0119 mi\u0119dzy nimi prze\u0142\u0105cza\u0107 na \u017c\u0105danie.", "tokens": [51092, 741, 1847, 10437, 72, 3244, 33964, 297, 10121, 8325, 15926, 66, 35873, 1667, 19625, 18962, 7155, 13, 51254], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 149, "seek": 47840, "start": 496.2, "end": 499.71999999999997, "text": " Teoria brzmi fantastycznie, ale przejd\u017amy do najwa\u017cniejszego.", "tokens": [51254, 1989, 8172, 738, 89, 3057, 4115, 9820, 19923, 11, 6775, 8325, 37109, 10659, 2226, 360, 11212, 27111, 10402, 15453, 6308, 13, 51430], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 150, "seek": 47840, "start": 499.71999999999997, "end": 501.23999999999995, "text": " Jakie s\u0105 wyniki?", "tokens": [51430, 15029, 414, 9015, 31936, 9850, 30, 51506], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 151, "seek": 47840, "start": 501.23999999999995, "end": 503.79999999999995, "text": " Czy ten scyzoryk faktycznie jest ostry,", "tokens": [51506, 19832, 2064, 795, 37433, 827, 74, 33647, 45586, 3492, 32946, 627, 11, 51634], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 152, "seek": 47840, "start": 503.79999999999995, "end": 507.4, "text": " czy mo\u017ce jest po prostu przeci\u0119tny we wszystkim?", "tokens": [51634, 6430, 12034, 3492, 714, 19518, 39622, 46788, 1634, 321, 30481, 30, 51814], "temperature": 0.0, "avg_logprob": -0.10524161202566965, "compression_ratio": 1.414715719063545, "no_speech_prob": 0.0018944793846458197}, {"id": 153, "seek": 50740, "start": 507.4, "end": 511.08, "text": " Wyniki s\u0105 delikatnie m\u00f3wi\u0105c imponuj\u0105ce.", "tokens": [50364, 343, 2534, 9850, 9015, 1103, 36300, 2766, 46591, 66, 704, 266, 13263, 384, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 154, "seek": 50740, "start": 511.08, "end": 513.12, "text": " Zacznijmy od ma\u0142ej skali.", "tokens": [50548, 1176, 14875, 77, 1718, 2226, 3611, 463, 19827, 73, 1110, 5103, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 155, "seek": 50740, "start": 513.12, "end": 516.64, "text": " W bezpo\u015brednich por\u00f3wnaniach z modelami o podobnej wielko\u015bci", "tokens": [50650, 343, 10782, 2259, 1788, 986, 77, 480, 1515, 812, 895, 3782, 608, 710, 2316, 4526, 277, 43024, 11794, 20570, 4093, 6199, 50826], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 156, "seek": 50740, "start": 516.64, "end": 520.48, "text": " trenowanymi w stylu T5 albo GPT", "tokens": [50826, 23136, 23341, 3057, 261, 7952, 2781, 314, 20, 22622, 26039, 51, 51018], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 157, "seek": 50740, "start": 520.48, "end": 524.72, "text": " mniejsza wersja UL2 konsekwentnie wygrywa\u0142a.", "tokens": [51018, 275, 30295, 2394, 261, 433, 2938, 624, 43, 17, 47020, 74, 34798, 2766, 4628, 70, 627, 4151, 5024, 13, 51230], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 158, "seek": 50740, "start": 524.72, "end": 526.72, "text": " I to nie w jednym czy dw\u00f3ch zadaniach.", "tokens": [51230, 286, 281, 2838, 261, 5232, 12996, 6430, 27379, 812, 339, 42788, 3782, 608, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 159, "seek": 50740, "start": 526.72, "end": 529.4, "text": " By\u0142a lepsza na 9 z 9 r\u00f3\u017cnych test\u00f3w.", "tokens": [51330, 3146, 5024, 476, 1878, 2394, 1667, 1722, 710, 1722, 42602, 1500, 3901, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 160, "seek": 50740, "start": 529.4, "end": 530.3199999999999, "text": " Na wszystkich?", "tokens": [51464, 6056, 34234, 30, 51510], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 161, "seek": 50740, "start": 530.3199999999999, "end": 531.52, "text": " Na wszystkich.", "tokens": [51510, 6056, 34234, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 162, "seek": 50740, "start": 531.52, "end": 534.1999999999999, "text": " Znormalizowany og\u00f3lny wzrost wydajno\u015bci", "tokens": [51570, 1176, 23157, 590, 23341, 5360, 15741, 1634, 24809, 27494, 25984, 1805, 16438, 51704], "temperature": 0.0, "avg_logprob": -0.1012623045179579, "compression_ratio": 1.3670411985018727, "no_speech_prob": 0.06328465789556503}, {"id": 163, "seek": 53420, "start": 534.2, "end": 539.2, "text": " wynios ponad 76% w por\u00f3wnaniu do modelu w stylu GPT.", "tokens": [50364, 31936, 2717, 9224, 345, 24733, 4, 261, 1515, 812, 895, 25849, 360, 2316, 84, 261, 7952, 2781, 26039, 51, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 164, "seek": 53420, "start": 539.2, "end": 540.9200000000001, "text": " To pokazuje, \u017ce to nie jest kompromis.", "tokens": [50614, 1407, 13010, 43317, 11, 3561, 281, 2838, 3492, 5207, 28722, 271, 13, 50700], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 165, "seek": 53420, "start": 540.9200000000001, "end": 544.36, "text": " Ten model jest po prostu lepszy w ca\u0142\u0105 spektrum zada\u0144.", "tokens": [50700, 9380, 2316, 3492, 714, 19518, 476, 1878, 1229, 261, 1335, 15926, 768, 2320, 6247, 710, 1538, 5248, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 166, "seek": 53420, "start": 544.36, "end": 546.76, "text": " OK, czyli w ma\u0142ej skali to dzia\u0142a.", "tokens": [50872, 2264, 11, 16591, 261, 463, 19827, 73, 1110, 5103, 281, 37903, 13, 50992], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 167, "seek": 53420, "start": 546.76, "end": 549.2, "text": " Ale w \u015bwiecie AI cz\u0119sto m\u00f3wi si\u0119,", "tokens": [50992, 9366, 261, 40078, 4260, 7318, 34369, 24592, 3244, 11, 51114], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 168, "seek": 53420, "start": 549.2, "end": 552.1600000000001, "text": " \u017ce prawdziwa magia pojawia si\u0119 przy skalowaniu.", "tokens": [51114, 3561, 41175, 3992, 4151, 2258, 654, 30655, 654, 3244, 6501, 16890, 305, 25849, 13, 51262], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 169, "seek": 53420, "start": 552.1600000000001, "end": 554.5600000000001, "text": " Co si\u0119 sta\u0142o, gdy go powi\u0119kszyli?", "tokens": [51262, 3066, 3244, 11135, 5249, 11, 28405, 352, 3388, 5034, 1694, 1229, 2081, 30, 51382], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 170, "seek": 53420, "start": 554.5600000000001, "end": 557.32, "text": " Wtedy sta\u0142o si\u0119 co\u015b jeszcze ciekawszego.", "tokens": [51382, 343, 83, 6038, 11135, 5249, 3244, 19241, 14168, 46419, 1607, 15453, 6308, 13, 51520], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 171, "seek": 53420, "start": 557.32, "end": 560.44, "text": " Stworzyli wersj\u0119 z 20 miliardami parametr\u00f3w.", "tokens": [51520, 745, 28321, 1229, 2081, 261, 433, 11115, 710, 945, 1962, 72, 515, 4526, 6220, 27965, 3901, 13, 51676], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 172, "seek": 53420, "start": 560.44, "end": 563.0400000000001, "text": " UL2 20B.", "tokens": [51676, 624, 43, 17, 945, 33, 13, 51806], "temperature": 0.0, "avg_logprob": -0.11569816638261844, "compression_ratio": 1.4143835616438356, "no_speech_prob": 0.05924126133322716}, {"id": 173, "seek": 56304, "start": 563.04, "end": 565.76, "text": " I ten model osi\u0105gn\u0105\u0142 State of the Art,", "tokens": [50364, 286, 2064, 2316, 3003, 11404, 4568, 1611, 1221, 4533, 295, 264, 5735, 11, 50500], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 174, "seek": 56304, "start": 565.76, "end": 567.68, "text": " czyli najlepsze znane wyniki,", "tokens": [50500, 16591, 41903, 1878, 1381, 15397, 1929, 31936, 9850, 11, 50596], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 175, "seek": 56304, "start": 567.68, "end": 570.4399999999999, "text": " na ponad 50 r\u00f3\u017cnych zadaniach NLP.", "tokens": [50596, 1667, 9224, 345, 2625, 42602, 42788, 3782, 608, 426, 45196, 13, 50734], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 176, "seek": 56304, "start": 570.4399999999999, "end": 571.8, "text": " 50?", "tokens": [50734, 2625, 30, 50802], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 177, "seek": 56304, "start": 571.8, "end": 573.5999999999999, "text": " A mo\u017cesz poda\u0107 jaki\u015b przyk\u0142ad?", "tokens": [50802, 316, 10697, 10430, 2497, 43379, 34721, 23144, 30, 50892], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 178, "seek": 56304, "start": 573.5999999999999, "end": 574.36, "text": " Pewnie.", "tokens": [50892, 2396, 14215, 13, 50930], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 179, "seek": 56304, "start": 574.36, "end": 576.52, "text": " Na przyk\u0142ad streszczanie wielu wiadomo\u015bci", "tokens": [50930, 6056, 23144, 342, 495, 89, 3689, 7155, 40437, 26393, 40633, 6199, 51038], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 180, "seek": 56304, "start": 576.52, "end": 578.5999999999999, "text": " naraz na zbiorze Multinius.", "tokens": [51038, 6714, 921, 1667, 710, 33362, 1381, 14665, 3812, 301, 13, 51142], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 181, "seek": 56304, "start": 578.5999999999999, "end": 581.56, "text": " To wymaga syntezy informacji z r\u00f3\u017cnych \u017ar\u00f3de\u0142.", "tokens": [51142, 1407, 29764, 9286, 943, 9358, 1229, 1356, 13152, 710, 42602, 50212, 11721, 1479, 1221, 13, 51290], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 182, "seek": 56304, "start": 581.56, "end": 585.4, "text": " Albo odpowiadania na pytania z Twittera w testie tweet QA,", "tokens": [51290, 967, 1763, 24314, 38069, 5609, 1667, 25878, 5609, 710, 5794, 64, 261, 1500, 414, 15258, 1249, 32, 11, 51482], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 183, "seek": 56304, "start": 585.4, "end": 588.56, "text": " gdzie j\u0119zyk jest wiesz, nieformalny, pe\u0142en b\u0142\u0119d\u00f3w.", "tokens": [51482, 18922, 49055, 74, 3492, 261, 15347, 11, 2838, 837, 304, 1634, 11, 43205, 268, 272, 1221, 6298, 3901, 13, 51640], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 184, "seek": 56304, "start": 588.56, "end": 589.4, "text": " Slangu.", "tokens": [51640, 6187, 656, 84, 13, 51682], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 185, "seek": 56304, "start": 589.4, "end": 590.56, "text": " Dok\u0142adnie.", "tokens": [51682, 29768, 10358, 2766, 13, 51740], "temperature": 0.0, "avg_logprob": -0.17830896685200354, "compression_ratio": 1.3663366336633664, "no_speech_prob": 0.056197572499513626}, {"id": 186, "seek": 59056, "start": 590.5999999999999, "end": 593.1199999999999, "text": " Albo rozumowanie oparte na zdrowym rozs\u0105dku", "tokens": [50366, 967, 1763, 48797, 22028, 999, 11026, 1667, 49745, 4199, 9544, 82, 18962, 5279, 50492], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 187, "seek": 59056, "start": 593.1199999999999, "end": 595.3599999999999, "text": " w benchmarku SIQA.", "tokens": [50492, 261, 18927, 84, 29083, 48, 32, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 188, "seek": 59056, "start": 595.3599999999999, "end": 598.4799999999999, "text": " A nawet analiza bardzo d\u0142ugich dokument\u00f3w w scrolls,", "tokens": [50604, 316, 22696, 2624, 13427, 9034, 274, 34077, 480, 40858, 3901, 261, 11369, 82, 11, 50760], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 189, "seek": 59056, "start": 598.4799999999999, "end": 601.5999999999999, "text": " co jest ogromnym wyzwaniem dla wi\u0119kszo\u015bci modeli.", "tokens": [50760, 598, 3492, 34416, 298, 12996, 4628, 89, 7916, 4907, 12285, 29968, 4765, 6199, 2316, 72, 13, 50916], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 190, "seek": 59056, "start": 601.5999999999999, "end": 606.04, "text": " We wszystkich tych obszarach UL2 20B ustanowi\u0142 nowe rekordy.", "tokens": [50916, 492, 34234, 15180, 3181, 26236, 608, 624, 43, 17, 945, 33, 26189, 282, 24503, 1221, 586, 68, 33881, 765, 88, 13, 51138], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 191, "seek": 59056, "start": 606.04, "end": 609.1199999999999, "text": " Te wyniki s\u0105 naprawd\u0119 mocne, ale s\u0142ysza\u0142am,", "tokens": [51138, 1989, 31936, 9850, 9015, 20970, 34962, 716, 11, 6775, 15116, 749, 2394, 20177, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 192, "seek": 59056, "start": 609.1199999999999, "end": 612.56, "text": " \u017ce w artykule kryje si\u0119 jedna prawdziwa bomba,", "tokens": [51292, 3561, 261, 594, 874, 74, 2271, 34847, 2884, 3244, 5232, 629, 41175, 3992, 4151, 7851, 64, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 193, "seek": 59056, "start": 612.56, "end": 616.28, "text": " co\u015b, co naprawd\u0119 wstrz\u0105sne\u0142o ca\u0142\u0105 spo\u0142eczno\u015bci\u0105.", "tokens": [51464, 19241, 11, 598, 20970, 261, 9733, 8925, 82, 716, 5249, 1335, 15926, 36851, 89, 16438, 1611, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 194, "seek": 59056, "start": 616.28, "end": 617.16, "text": " Tak.", "tokens": [51650, 9118, 13, 51694], "temperature": 0.0, "avg_logprob": -0.1428154613954801, "compression_ratio": 1.3754385964912281, "no_speech_prob": 0.028717927634716034}, {"id": 195, "seek": 61716, "start": 617.16, "end": 622.92, "text": " Najwi\u0119kszym zaskoczeniem jest bezpo\u015brednie starcie UL2 20B", "tokens": [50364, 31576, 22423, 1694, 26681, 710, 3863, 905, 2904, 4907, 3492, 10782, 2259, 1788, 986, 2766, 3543, 4260, 624, 43, 17, 945, 33, 50652], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 196, "seek": 61716, "start": 622.92, "end": 624.8399999999999, "text": " z modelem GPT-3.", "tokens": [50652, 710, 4391, 10386, 26039, 51, 12, 18, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 197, "seek": 61716, "start": 624.8399999999999, "end": 625.64, "text": " OK.", "tokens": [50748, 2264, 13, 50788], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 198, "seek": 61716, "start": 625.64, "end": 626.64, "text": " Przypomnijmy.", "tokens": [50788, 39590, 79, 38131, 1718, 2226, 13, 50838], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 199, "seek": 61716, "start": 626.64, "end": 630.28, "text": " GPT-3 ma 175 miliard\u00f3w parametr\u00f3w.", "tokens": [50838, 26039, 51, 12, 18, 463, 41165, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 200, "seek": 61716, "start": 630.28, "end": 633.04, "text": " Jest prawie 9 razy wi\u0119kszy.", "tokens": [51020, 24918, 3206, 8699, 1722, 9639, 88, 29968, 1229, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 201, "seek": 61716, "start": 633.04, "end": 636.6, "text": " Postawiono je naprzeciwko siebie w zadaniu Super Glue.", "tokens": [51158, 10223, 1607, 49020, 1506, 9296, 13503, 537, 86, 4093, 39137, 261, 42788, 25849, 4548, 49832, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 202, "seek": 61716, "start": 636.6, "end": 638.6, "text": " Poczekaj, musimy to wyja\u015bni\u0107.", "tokens": [51336, 430, 905, 19878, 1805, 11, 43449, 281, 4628, 2938, 1788, 3722, 2162, 13, 51436], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 203, "seek": 61716, "start": 638.6, "end": 640.28, "text": " Czym jest Super Glue?", "tokens": [51436, 19832, 76, 3492, 4548, 49832, 30, 51520], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 204, "seek": 61716, "start": 640.28, "end": 644.72, "text": " Super Glue to taki link wistyczny wielob\u00f3j dla AI.", "tokens": [51520, 4548, 49832, 281, 20065, 2113, 261, 468, 17466, 1634, 20570, 996, 18999, 12285, 7318, 13, 51742], "temperature": 0.0, "avg_logprob": -0.1183410730577053, "compression_ratio": 1.3251028806584362, "no_speech_prob": 0.012809188105165958}, {"id": 205, "seek": 64472, "start": 644.72, "end": 648.4, "text": " Zestaw bardzo trudnych zada\u0144, kt\u00f3re sprawdzaj\u0105 wszystko.", "tokens": [50364, 1176, 377, 1607, 9034, 32007, 9399, 710, 1538, 5248, 11, 8864, 46192, 89, 11133, 22607, 13, 50548], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 206, "seek": 64472, "start": 648.4, "end": 651.48, "text": " Od logiki przez rozumienie przyczyn i skutk\u00f3w,", "tokens": [50548, 12210, 3565, 9850, 14064, 48797, 27385, 6501, 6522, 77, 741, 1110, 325, 23849, 11, 50702], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 207, "seek": 64472, "start": 651.48, "end": 653.76, "text": " po wy\u0142apywanie niuans\u00f3w w tek\u015bcie.", "tokens": [50702, 714, 4628, 1221, 569, 27112, 7155, 3867, 84, 599, 3901, 261, 16624, 9815, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 208, "seek": 64472, "start": 653.76, "end": 655.1600000000001, "text": " To naprawd\u0119 ci\u0119\u017cki test.", "tokens": [50816, 1407, 20970, 35484, 1427, 2984, 1500, 13, 50886], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 209, "seek": 64472, "start": 655.1600000000001, "end": 659.1600000000001, "text": " I mniejszy model UL2 stan\u0105\u0142 do walki z tym gigantem?", "tokens": [50886, 286, 39513, 7706, 2316, 624, 43, 17, 27984, 1611, 1221, 360, 1792, 72, 710, 8107, 8741, 394, 443, 30, 51086], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 210, "seek": 64472, "start": 659.1600000000001, "end": 660.12, "text": " I wygra\u0142.", "tokens": [51086, 286, 4628, 20735, 1221, 13, 51134], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 211, "seek": 64472, "start": 660.12, "end": 662.88, "text": " I co najwa\u017cniejsze, zrobi\u0142 to w trybie zero shot.", "tokens": [51134, 286, 598, 11212, 27111, 44258, 11, 24483, 1221, 281, 261, 853, 7392, 4018, 3347, 13, 51272], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 212, "seek": 64472, "start": 662.88, "end": 665.0400000000001, "text": " Czyli bez \u017cadnych podpowiedzi?", "tokens": [51272, 37099, 10782, 39628, 9399, 2497, 14701, 1091, 3992, 30, 51380], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 213, "seek": 64472, "start": 665.0400000000001, "end": 666.64, "text": " Bez \u017cadnej \u015bci\u0105gi.", "tokens": [51380, 879, 89, 39628, 11794, 220, 50227, 7834, 13, 51460], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 214, "seek": 64472, "start": 666.64, "end": 667.8000000000001, "text": " Bez przyk\u0142ad\u00f3w.", "tokens": [51460, 879, 89, 23144, 3901, 13, 51518], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 215, "seek": 64472, "start": 667.8000000000001, "end": 670.1600000000001, "text": " Po prostu rzucono mu wyzwanie na zimno,", "tokens": [51518, 6165, 19518, 367, 89, 1311, 8957, 2992, 4628, 14406, 7155, 1667, 710, 332, 1771, 11, 51636], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 216, "seek": 64472, "start": 670.1600000000001, "end": 672.88, "text": " a on poradzi\u0142 sobie lepiej ni\u017c znacznie wi\u0119kszy,", "tokens": [51636, 257, 322, 1515, 345, 3992, 1221, 13652, 476, 39699, 28502, 15397, 14875, 2766, 29968, 1229, 11, 51772], "temperature": 0.0, "avg_logprob": -0.11054042387290819, "compression_ratio": 1.421875, "no_speech_prob": 0.22846893966197968}, {"id": 217, "seek": 67288, "start": 672.92, "end": 676.0, "text": " dro\u017cszy i bardziej zasobo\u017cerny konkurent.", "tokens": [50366, 3789, 1427, 7706, 741, 27209, 26530, 996, 78, 1427, 1248, 88, 21428, 540, 580, 13, 50520], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 218, "seek": 67288, "start": 676.0, "end": 677.88, "text": " To by\u0142o ogromne osi\u0105gni\u0119cie.", "tokens": [50520, 1407, 14811, 34416, 298, 716, 3003, 11404, 70, 35938, 4260, 13, 50614], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 219, "seek": 67288, "start": 677.88, "end": 680.24, "text": " Lepsze wyniki mniejszy model.", "tokens": [50614, 441, 10653, 1381, 31936, 9850, 39513, 7706, 2316, 13, 50732], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 220, "seek": 67288, "start": 680.24, "end": 681.92, "text": " To przepis na rewolucj\u0119.", "tokens": [50732, 1407, 30829, 271, 1667, 319, 48481, 1311, 11115, 13, 50816], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 221, "seek": 67288, "start": 681.92, "end": 683.68, "text": " Ale z tego co wiem, to nie koniec.", "tokens": [50816, 9366, 710, 8627, 598, 26522, 11, 281, 2838, 5897, 35733, 13, 50904], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 222, "seek": 67288, "start": 683.68, "end": 687.88, "text": " UL2 20B ma jeszcze jedn\u0105 prze\u0142omow\u0105 zdolno\u015b\u0107,", "tokens": [50904, 624, 43, 17, 945, 33, 463, 14168, 5232, 13113, 8325, 1221, 298, 30297, 16221, 401, 23293, 11, 51114], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 223, "seek": 67288, "start": 687.88, "end": 689.68, "text": " kt\u00f3ra wcze\u015bniej by\u0142a zarezerwowana", "tokens": [51114, 19456, 40785, 23936, 710, 543, 4527, 86, 40458, 51204], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 224, "seek": 67288, "start": 689.68, "end": 693.04, "text": " tylko dla najwi\u0119kszych niedost\u0119pnych modeli.", "tokens": [51204, 13219, 12285, 48636, 1694, 28051, 32488, 555, 18085, 9399, 2316, 72, 13, 51372], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 225, "seek": 67288, "start": 693.04, "end": 695.96, "text": " Mowa o zdolno\u015bci do rozmowania krok po kroku,", "tokens": [51372, 376, 5528, 277, 16221, 401, 16438, 360, 35234, 21308, 350, 31621, 714, 45909, 5279, 11, 51518], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 226, "seek": 67288, "start": 695.96, "end": 697.92, "text": " czyli Chain of Thought Prompting.", "tokens": [51518, 16591, 33252, 295, 23058, 15833, 662, 278, 13, 51616], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 227, "seek": 67288, "start": 697.92, "end": 699.6, "text": " To jest absolutny prze\u0142om.", "tokens": [51616, 1407, 3492, 18757, 1634, 8325, 1221, 298, 13, 51700], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 228, "seek": 67288, "start": 699.6, "end": 702.56, "text": " Polega to na tym, \u017ce zamiast od razu podawa\u0107 odpowied\u017a,", "tokens": [51700, 34212, 3680, 281, 1667, 8107, 11, 3561, 710, 4526, 525, 3611, 367, 8813, 2497, 10449, 2162, 36574, 10659, 11, 51848], "temperature": 0.0, "avg_logprob": -0.12172731899079822, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.07676837593317032}, {"id": 229, "seek": 70256, "start": 702.5999999999999, "end": 705.1999999999999, "text": " model najpierw jakby my\u015bli na g\u0142os.", "tokens": [50366, 2316, 11212, 45119, 86, 28976, 452, 15350, 1667, 43767, 13, 50496], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 230, "seek": 70256, "start": 705.1999999999999, "end": 707.16, "text": " Opisuje sw\u00f3j tok rozumowania.", "tokens": [50496, 12011, 271, 13008, 1693, 18999, 19164, 48797, 21308, 13, 50594], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 231, "seek": 70256, "start": 707.16, "end": 708.1199999999999, "text": " Dok\u0142adnie.", "tokens": [50594, 29768, 10358, 2766, 13, 50642], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 232, "seek": 70256, "start": 708.1199999999999, "end": 711.88, "text": " Generuje opis krok\u00f3w, kt\u00f3re doprowadzi\u0142y go do wniosku.", "tokens": [50642, 15409, 13008, 45477, 45909, 23849, 11, 8864, 360, 35019, 3992, 6825, 352, 360, 45368, 2717, 5279, 13, 50830], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 233, "seek": 70256, "start": 711.88, "end": 714.88, "text": " To nie tylko daje lepsze wyniki w zadaniach logicznych,", "tokens": [50830, 1407, 2838, 13219, 1120, 2884, 476, 1878, 1381, 31936, 9850, 261, 42788, 3782, 608, 9952, 89, 9399, 11, 50980], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 234, "seek": 70256, "start": 714.88, "end": 718.9599999999999, "text": " ale te\u017c czyni proces my\u015blowy AI bardziej przejrzystym.", "tokens": [50980, 6775, 9516, 6430, 3722, 17565, 452, 19212, 10089, 7318, 27209, 8325, 73, 13047, 372, 4199, 13, 51184], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 235, "seek": 70256, "start": 718.9599999999999, "end": 721.4799999999999, "text": " I do tej pory ta zdolno\u015b\u0107 by\u0142a widziana", "tokens": [51184, 286, 360, 12573, 280, 827, 1846, 16221, 401, 23293, 23936, 27486, 8497, 51310], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 236, "seek": 70256, "start": 721.4799999999999, "end": 724.64, "text": " tylko w zamkni\u0119tych, gigantycznych modelach,", "tokens": [51310, 13219, 261, 19876, 74, 35938, 874, 339, 11, 8741, 394, 17466, 9399, 2316, 608, 11, 51468], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 237, "seek": 70256, "start": 724.64, "end": 726.52, "text": " jak PLM od Google.", "tokens": [51468, 4207, 6999, 44, 3611, 3329, 13, 51562], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 238, "seek": 70256, "start": 726.52, "end": 730.1199999999999, "text": " UL2 20B to pierwszy publicznie dost\u0119pny model,", "tokens": [51562, 624, 43, 17, 945, 33, 281, 34016, 1908, 89, 2766, 48209, 1634, 2316, 11, 51742], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 239, "seek": 70256, "start": 730.1199999999999, "end": 731.1199999999999, "text": " kt\u00f3ry to potrafi.", "tokens": [51742, 9913, 281, 1847, 10437, 72, 13, 51792], "temperature": 0.0, "avg_logprob": -0.12298986927562991, "compression_ratio": 1.4, "no_speech_prob": 0.0016056449385359883}, {"id": 240, "seek": 73112, "start": 731.12, "end": 733.5600000000001, "text": " Co to wszystko oznacza w praktyce?", "tokens": [50364, 3066, 281, 22607, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 30, 50486], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 241, "seek": 73112, "start": 733.5600000000001, "end": 734.96, "text": " Podsumujmy.", "tokens": [50486, 12646, 82, 449, 4579, 2226, 13, 50556], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 242, "seek": 73112, "start": 734.96, "end": 740.16, "text": " Jakie s\u0105 implikacje dla, no, dla ca\u0142ej bran\u017cy AI?", "tokens": [50556, 15029, 414, 9015, 8484, 1035, 29293, 12285, 11, 572, 11, 12285, 47631, 73, 12029, 7735, 7318, 30, 50816], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 243, "seek": 73112, "start": 740.16, "end": 743.0, "text": " Po pierwsze, to ogromny krok w stron\u0119", "tokens": [50816, 6165, 45994, 11, 281, 34416, 298, 1634, 350, 31621, 261, 45766, 1274, 50958], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 244, "seek": 73112, "start": 743.0, "end": 746.04, "text": " bardziej efektywnej sztucznej inteligencji.", "tokens": [50958, 27209, 31482, 916, 874, 86, 11794, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 13, 51110], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 245, "seek": 73112, "start": 746.04, "end": 749.5600000000001, "text": " Zamiast utrzybywa\u0107 to ca\u0142e kosztowne zoomodeli,", "tokens": [51110, 1176, 4526, 525, 2839, 13047, 2322, 25234, 281, 47631, 19532, 2682, 648, 68, 5721, 298, 378, 10148, 11, 51286], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 246, "seek": 73112, "start": 749.5600000000001, "end": 752.72, "text": " mo\u017cemy potencjalnie mie\u0107 jeden wszechstronny model,", "tokens": [51286, 26500, 1847, 22660, 22600, 2766, 35612, 12906, 37647, 19439, 372, 2044, 1634, 2316, 11, 51444], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 247, "seek": 73112, "start": 752.72, "end": 754.16, "text": " kt\u00f3ry radzi sobie ze wszystkim.", "tokens": [51444, 9913, 2843, 3992, 13652, 5277, 30481, 13, 51516], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 248, "seek": 73112, "start": 754.16, "end": 757.8, "text": " To gigantyczna oszcz\u0119dno\u015b\u0107 zasob\u00f3w w czasu pieni\u0119dzy.", "tokens": [51516, 1407, 8741, 394, 17466, 629, 3003, 43771, 6298, 23293, 26530, 996, 3901, 261, 40860, 26274, 49485, 13, 51698], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 249, "seek": 73112, "start": 757.8, "end": 758.8, "text": " Ogromna.", "tokens": [51698, 422, 861, 298, 629, 13, 51748], "temperature": 0.0, "avg_logprob": -0.14492189067683808, "compression_ratio": 1.3920863309352518, "no_speech_prob": 0.008608447387814522}, {"id": 250, "seek": 75880, "start": 758.8, "end": 762.0799999999999, "text": " A to z kolei prowadzi do demokratyzacji, prawda?", "tokens": [50364, 316, 281, 710, 18303, 72, 36590, 3992, 360, 1371, 453, 81, 21398, 89, 13152, 11, 43607, 30, 50528], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 251, "seek": 75880, "start": 762.0799999999999, "end": 766.4799999999999, "text": " Mniejszy uniwersytet, kt\u00f3ry nie ma bud\u017cetu na superkomputery,", "tokens": [50528, 376, 10402, 7706, 36435, 5364, 4328, 302, 11, 9913, 2838, 463, 3265, 1427, 41236, 1667, 1687, 20557, 2582, 2109, 11, 50748], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 252, "seek": 75880, "start": 766.4799999999999, "end": 770.4, "text": " mo\u017ce teraz pobra\u0107 ten jeden stosunkowo niedu\u017cy model", "tokens": [50748, 12034, 16854, 714, 6198, 2162, 2064, 12906, 43581, 3197, 19941, 32488, 84, 7735, 2316, 50944], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 253, "seek": 75880, "start": 770.4, "end": 773.3599999999999, "text": " i prowadzi\u0107 badania, kt\u00f3re do tej pory by\u0142y zarezerwowane", "tokens": [50944, 741, 36590, 28496, 1578, 5609, 11, 8864, 360, 12573, 280, 827, 26366, 710, 543, 4527, 86, 23066, 51092], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 254, "seek": 75880, "start": 773.3599999999999, "end": 775.12, "text": " dla garstki gigant\u00f3w.", "tokens": [51092, 12285, 3691, 372, 2984, 8741, 394, 3901, 13, 51180], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 255, "seek": 75880, "start": 775.12, "end": 778.12, "text": " To jest drugi, niezwykle wa\u017cny wniosek.", "tokens": [51180, 1407, 3492, 4110, 72, 11, 33511, 9726, 14677, 27777, 1634, 261, 3722, 541, 74, 13, 51330], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 256, "seek": 75880, "start": 778.12, "end": 780.8399999999999, "text": " Udost\u0119pnienie publicznie modelu 20B,", "tokens": [51330, 624, 67, 555, 18085, 77, 27385, 1908, 89, 2766, 2316, 84, 945, 33, 11, 51466], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 257, "seek": 75880, "start": 780.8399999999999, "end": 782.92, "text": " kt\u00f3ry potrasznie robi\u0107 Chain of Thought,", "tokens": [51466, 9913, 1847, 3906, 89, 2766, 46900, 33252, 295, 23058, 11, 51570], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 258, "seek": 75880, "start": 782.92, "end": 786.8, "text": " to prawdziwa zmiana regu\u0142 gry dla ca\u0142ej spo\u0142eczno\u015bci bodawczej.", "tokens": [51570, 281, 41175, 3992, 4151, 17020, 8497, 1121, 84, 1221, 41974, 12285, 47631, 73, 36851, 89, 16438, 16737, 1607, 9680, 73, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13036296306512293, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0022095765452831984}, {"id": 259, "seek": 78680, "start": 786.8, "end": 790.28, "text": " Daje im to dost\u0119p do narz\u0119dzi, o kt\u00f3rych do tej pory mogli tylko czyta\u0107.", "tokens": [50364, 413, 11153, 566, 281, 48209, 360, 6714, 89, 6298, 3992, 11, 277, 30382, 360, 12573, 280, 827, 13172, 2081, 13219, 6430, 42931, 13, 50538], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 260, "seek": 78680, "start": 790.28, "end": 794.4799999999999, "text": " To fascynuj\u0105ce, \u017ce ta metoda dzia\u0142a na tak r\u00f3\u017cnych architekturach,", "tokens": [50538, 1407, 30632, 1344, 77, 13263, 384, 11, 3561, 1846, 1131, 13449, 37903, 1667, 991, 42602, 3912, 642, 2320, 374, 608, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 261, "seek": 78680, "start": 794.4799999999999, "end": 798.7199999999999, "text": " bo testowali j\u0105 i na modelach Encoder Decoder jak T5", "tokens": [50748, 748, 1500, 305, 5103, 35692, 741, 1667, 2316, 608, 29584, 19866, 12427, 19866, 4207, 314, 20, 50960], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 262, "seek": 78680, "start": 798.7199999999999, "end": 801.56, "text": " i Decoder Only jak GPT.", "tokens": [50960, 741, 12427, 19866, 5686, 4207, 26039, 51, 13, 51102], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 263, "seek": 78680, "start": 801.56, "end": 805.68, "text": " Czy to sugeruje, \u017ce mogli\u015bmy si\u0119 skupia\u0107 na niew\u0142a\u015bciwym aspekcie,", "tokens": [51102, 19832, 281, 459, 1321, 13008, 11, 3561, 13172, 38452, 3244, 1110, 1010, 654, 2162, 1667, 43622, 5024, 6199, 86, 4199, 382, 32659, 4260, 11, 51308], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 264, "seek": 78680, "start": 805.68, "end": 810.56, "text": " buduj\u0105c coraz nowsze silniki podczas gdy prze\u0142omd kwi\u0142\u0142 w paliwie?", "tokens": [51308, 3265, 44733, 25899, 586, 82, 1381, 3425, 77, 9850, 2497, 30989, 28405, 8325, 1221, 298, 67, 350, 6253, 1221, 1221, 261, 3984, 72, 8699, 30, 51552], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 265, "seek": 78680, "start": 810.56, "end": 814.1999999999999, "text": " My\u015bl\u0119, \u017ce to jest najwa\u017cniejszy wniosek naukowy z tej pracy.", "tokens": [51552, 1222, 28749, 11, 3561, 281, 3492, 11212, 27111, 10402, 7706, 261, 3722, 541, 74, 35616, 74, 10089, 710, 12573, 35591, 13, 51734], "temperature": 0.0, "avg_logprob": -0.10921612033596287, "compression_ratio": 1.4169381107491856, "no_speech_prob": 0.016692951321601868}, {"id": 266, "seek": 81420, "start": 814.2, "end": 819.0400000000001, "text": " Autorzy pokazuj\u0105, \u017ce cel treningowy, ta sprytna mixture of the noisers,", "tokens": [50364, 6049, 284, 1229, 13010, 921, 13263, 11, 3561, 9277, 2192, 773, 10089, 11, 1846, 637, 627, 83, 629, 9925, 295, 264, 572, 271, 433, 11, 50606], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 267, "seek": 81420, "start": 819.0400000000001, "end": 821.36, "text": " mo\u017ce by\u0107 wa\u017cniejsze ni\u017c sama architektura.", "tokens": [50606, 12034, 15069, 27777, 44258, 28502, 17768, 3912, 642, 2320, 2991, 13, 50722], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 268, "seek": 81420, "start": 821.36, "end": 822.5600000000001, "text": " Mhm.", "tokens": [50722, 26272, 13, 50782], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 269, "seek": 81420, "start": 822.5600000000001, "end": 824.12, "text": " To pot\u0119\u017cna wskaz\u00f3wka,", "tokens": [50782, 1407, 1847, 1274, 1427, 629, 261, 5161, 921, 3901, 2330, 11, 50860], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 270, "seek": 81420, "start": 824.12, "end": 827.5200000000001, "text": " kt\u00f3ra m\u00f3wi by\u0107 mo\u017ce najwi\u0119ksze zyski nie kryj\u0105 si\u0119 w projektowaniu", "tokens": [50860, 19456, 24592, 15069, 12034, 48636, 1694, 1381, 710, 749, 2984, 2838, 34847, 8555, 3244, 261, 26261, 305, 25849, 51030], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 271, "seek": 81420, "start": 827.5200000000001, "end": 832.32, "text": " coraz bardziej skomplikowanych sieci, ale w m\u0105drzejszym ich trenowaniu.", "tokens": [51030, 25899, 27209, 1110, 298, 564, 1035, 23341, 339, 2804, 537, 11, 6775, 261, 275, 18962, 13503, 73, 7706, 76, 1893, 23136, 305, 25849, 13, 51270], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 272, "seek": 81420, "start": 832.32, "end": 834.44, "text": " Wr\u00f3\u0107my wi\u0119c do naszej analogii.", "tokens": [51270, 10159, 812, 2162, 2226, 16677, 360, 42946, 16660, 5597, 13, 51376], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 273, "seek": 81420, "start": 834.44, "end": 838.2, "text": " Wygl\u0105da na to, \u017ce ten scyzorek jest nie tylko uniwersalny,", "tokens": [51376, 14458, 7191, 26398, 1667, 281, 11, 3561, 2064, 795, 37433, 418, 74, 3492, 2838, 13219, 36435, 5364, 304, 1634, 11, 51564], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 274, "seek": 81420, "start": 838.2, "end": 842.08, "text": " ale w wielu zadaniach ostrzejszy ni\u017c dedykowane narz\u0119dzia.", "tokens": [51564, 6775, 261, 40437, 42788, 3782, 608, 44024, 16920, 7706, 28502, 4172, 46127, 23066, 6714, 89, 6298, 40395, 13, 51758], "temperature": 0.0, "avg_logprob": -0.12666168452808693, "compression_ratio": 1.493421052631579, "no_speech_prob": 0.002805575728416443}, {"id": 275, "seek": 84208, "start": 842.08, "end": 846.72, "text": " Dzi\u0119ki tej innowatorskiej metodzie treningu, UL2 rzuca wyzwanie idei,", "tokens": [50364, 413, 34546, 12573, 294, 3785, 3391, 45145, 1131, 378, 3283, 2192, 773, 84, 11, 624, 43, 17, 367, 11728, 496, 4628, 14406, 7155, 1153, 72, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 276, "seek": 84208, "start": 846.72, "end": 850.0400000000001, "text": " \u017ce modele AI musz\u0105 by\u0107 w\u0105sko specjalizowane.", "tokens": [50596, 3561, 4391, 306, 7318, 1038, 8925, 15069, 261, 1611, 82, 4093, 46433, 590, 23066, 13, 50762], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 277, "seek": 84208, "start": 850.0400000000001, "end": 854.76, "text": " Pokazuje, \u017ce wszechstronno\u015b\u0107 jest nie tylko mo\u017cliwa, ale i niezwykle skuteczna.", "tokens": [50762, 14958, 43317, 11, 3561, 37647, 19439, 372, 2044, 23293, 3492, 2838, 13219, 30854, 4151, 11, 6775, 741, 33511, 9726, 14677, 1110, 1169, 3689, 629, 13, 50998], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 278, "seek": 84208, "start": 854.76, "end": 856.1600000000001, "text": " Tak.", "tokens": [50998, 9118, 13, 51068], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 279, "seek": 84208, "start": 856.1600000000001, "end": 858.6, "text": " Co wi\u0119cej, jest jeszcze jeden aspekt.", "tokens": [51068, 3066, 26004, 11, 3492, 14168, 12906, 382, 23533, 13, 51190], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 280, "seek": 84208, "start": 858.6, "end": 863.0, "text": " Autorzy sami przyznaj\u0105, \u017ce ich proces treningowy nie by\u0142 idealny.", "tokens": [51190, 6049, 284, 1229, 3247, 72, 6501, 35458, 8555, 11, 3561, 1893, 17565, 2192, 773, 10089, 2838, 16673, 7157, 1634, 13, 51410], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 281, "seek": 84208, "start": 863.0, "end": 867.44, "text": " W jego trakcie zdarza\u0142y si\u0119 problemy techniczne, pewne skoki w funkcji straty.", "tokens": [51410, 343, 26542, 944, 74, 4260, 16221, 289, 2394, 6825, 3244, 1154, 88, 1537, 17946, 716, 11, 25889, 716, 1110, 17056, 261, 26476, 19649, 1056, 21398, 13, 51632], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 282, "seek": 84208, "start": 867.44, "end": 868.2800000000001, "text": " Naprawd\u0119?", "tokens": [51632, 18287, 20098, 30, 51674], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 283, "seek": 84208, "start": 868.2800000000001, "end": 869.0400000000001, "text": " Tak.", "tokens": [51674, 9118, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1292844463039089, "compression_ratio": 1.3905723905723906, "no_speech_prob": 0.011446529999375343}, {"id": 284, "seek": 86904, "start": 869.12, "end": 871.8, "text": " Co wi\u0119cej, trenowali ten 20 miliardowy model", "tokens": [50368, 3066, 26004, 11, 23136, 305, 5103, 2064, 945, 1962, 72, 515, 10089, 2316, 50502], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 285, "seek": 86904, "start": 871.8, "end": 875.3199999999999, "text": " tylko na jednym og\u00f3lnodost\u0119pnym zbiorze danych C4,", "tokens": [50502, 13219, 1667, 5232, 12996, 5360, 15741, 77, 378, 555, 18085, 12996, 710, 33362, 1381, 274, 34644, 383, 19, 11, 50678], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 286, "seek": 86904, "start": 875.3199999999999, "end": 879.48, "text": " kt\u00f3ry, szczerze m\u00f3wi\u0105c, nie jest uwa\u017cany za najlepszy z mo\u017cliwych.", "tokens": [50678, 9913, 11, 22090, 260, 1381, 46591, 66, 11, 2838, 3492, 48089, 1325, 7949, 41903, 1878, 1229, 710, 30854, 9726, 339, 13, 50886], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 287, "seek": 86904, "start": 879.48, "end": 884.56, "text": " Chcesz powiedzie\u0107, \u017ce te wszystkie rewelacyjne, rekordowe wyniki, o kt\u00f3rych m\u00f3wi\u0142y\u015bmy,", "tokens": [50886, 761, 887, 89, 27886, 11, 3561, 535, 31723, 319, 45512, 31285, 716, 11, 33881, 765, 6880, 31936, 9850, 11, 277, 30382, 24592, 6825, 10513, 11, 51140], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 288, "seek": 86904, "start": 884.56, "end": 888.5999999999999, "text": " zosta\u0142y osi\u0105gni\u0119te w nie do ko\u0144ca optymalnych warunkach.", "tokens": [51140, 23154, 6825, 3003, 11404, 70, 35938, 975, 261, 2838, 360, 26470, 496, 2427, 4199, 304, 9399, 1516, 3197, 608, 13, 51342], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 289, "seek": 86904, "start": 888.5999999999999, "end": 889.92, "text": " Dok\u0142adnie.", "tokens": [51342, 29768, 10358, 2766, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 290, "seek": 86904, "start": 889.92, "end": 892.88, "text": " To wszystko sugeruje, \u017ce te imponuj\u0105ce rezultaty", "tokens": [51408, 1407, 22607, 459, 1321, 13008, 11, 3561, 535, 704, 266, 13263, 384, 48060, 723, 21398, 51556], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 291, "seek": 86904, "start": 892.88, "end": 897.48, "text": " mog\u0105 by\u0107 w rzeczywisto\u015bci niedoszacowaniem prawdziwego potencja\u0142u tej metody.", "tokens": [51556, 34123, 15069, 261, 26297, 86, 9334, 6199, 32488, 329, 89, 326, 37345, 4907, 41175, 3992, 826, 1571, 1847, 22660, 2938, 24066, 12573, 1131, 843, 13, 51786], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 292, "seek": 86904, "start": 897.48, "end": 898.7199999999999, "text": " Wow.", "tokens": [51786, 3153, 13, 51848], "temperature": 0.0, "avg_logprob": -0.1161408889584425, "compression_ratio": 1.4363636363636363, "no_speech_prob": 0.004518658388406038}, {"id": 293, "seek": 89872, "start": 898.76, "end": 903.08, "text": " A to prowadzi do prowokuj\u0105cego pytania, pytania do zastanowienia.", "tokens": [50366, 316, 281, 36590, 3992, 360, 45553, 453, 13263, 384, 1571, 25878, 5609, 11, 25878, 5609, 360, 36746, 282, 305, 18811, 13, 50582], "temperature": 0.0, "avg_logprob": -0.12324119896017095, "compression_ratio": 1.3018867924528301, "no_speech_prob": 0.0033780792728066444}, {"id": 294, "seek": 89872, "start": 903.08, "end": 907.5600000000001, "text": " Jakie mo\u017cliwo\u015bci otworzy\u0142by idealnie wytrenowany model UL2", "tokens": [50582, 15029, 414, 30854, 36476, 4337, 28321, 1229, 34635, 7157, 2766, 261, 4328, 1095, 23341, 2316, 624, 43, 17, 50806], "temperature": 0.0, "avg_logprob": -0.12324119896017095, "compression_ratio": 1.3018867924528301, "no_speech_prob": 0.0033780792728066444}, {"id": 295, "seek": 89872, "start": 907.5600000000001, "end": 912.32, "text": " uczony na jeszcze lepszych, bardziej zr\u00f3\u017cnicowanych i czystszych danych?", "tokens": [50806, 35403, 2526, 1667, 14168, 476, 1878, 28051, 11, 27209, 710, 11721, 1427, 7692, 23341, 339, 741, 6430, 372, 45021, 274, 34644, 30, 51044], "temperature": 0.0, "avg_logprob": -0.12324119896017095, "compression_ratio": 1.3018867924528301, "no_speech_prob": 0.0033780792728066444}, {"id": 296, "seek": 89872, "start": 912.32, "end": 915.96, "text": " By\u0107 mo\u017ce to, co zobaczyli\u015bmy, to dopiero wierzcho\u0142ek g\u00f3r\u0119 lodowej.", "tokens": [51044, 3146, 2162, 12034, 281, 11, 598, 37273, 38452, 11, 281, 21900, 12030, 261, 34602, 5738, 1221, 916, 290, 15614, 1274, 33311, 21091, 13, 51226], "temperature": 0.0, "avg_logprob": -0.12324119896017095, "compression_ratio": 1.3018867924528301, "no_speech_prob": 0.0033780792728066444}], "language": "pl"}