{"text": " Zaczynamy nasz\u0105 analiz\u0119 od takiego wielkiego pytania w \u015bwiecie AI. Jak nauczy\u0107 maszyn\u0119 prawdziwego rozumowania? Nie chodzi przecie\u017c tylko o znajdowanie fakt\u00f3w, ale o rozwi\u0105zywanie naprawd\u0119 z\u0142o\u017conych problem\u00f3w. Krok po kroku. I przez d\u0142ugi czas te modele z serii One od OpenAI by\u0142y takim niedo\u015bcigni\u0119tym wzorem. Totalnie. Wielu pr\u00f3bowa\u0142o, ale nikt tak naprawd\u0119 nie m\u00f3g\u0142 im dor\u00f3wna\u0107. Tak, bo dzisiaj przyjrzymy si\u0119 pracy naukowej, kt\u00f3ra rzuca wyzwanie temu status quo. Mam tu na my\u015bli DeepSeq R1 \u2013 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. O w\u0142a\u015bnie. Zesp\u00f3\u0142 DeepSeq AI postawi\u0142 sobie za cel nie tylko dogonienie czo\u0142\u00f3wki, oni chcieli to zrobi\u0107 w zupe\u0142nie nowy spos\u00f3b. Dok\u0142adnie. I celem naszego dzisiejszego spotkania jest zrozumienie tego ich no do\u015b\u0107 nietypowego podej\u015bcia. Zobaczymy, czy da si\u0119, jak oni to pisz\u0105, zach\u0119ci\u0107 model do my\u015blenia. U\u017cywaj\u0105c wy\u0142\u0105cznie metody pr\u00f3b i b\u0142\u0119d\u00f3w. Czyli tego s\u0142ynnego Reinforcement Learning. Roz\u0142o\u017cymy naczynniki pierwsze, ich eksperymenty, kluczowe odkrycia i no wiesz, zastanowimy si\u0119, co to wszystko oznacza. Zaczynajmy. Dobrze, to spr\u00f3bujmy to rozpakowa\u0107. Wi\u0119kszo\u015b\u0107 modeli, no wiesz, uczy si\u0119 na takich ogromnych, przygotowanych przez ludzi zestawach danych. To jest to, co nazywamy... Supervised Fine Tuning. Tak. Albo SFT. Dok\u0142adnie. SFT. Ale co by by\u0142o, gdyby model m\u00f3g\u0142 sam od zera nauczy\u0107 si\u0119 rozumowa\u0107? Do w\u0142a\u015bnie. I to jest idea, kt\u00f3ra stoi za tym ich pierwszym modelem DeepSeq R1-0. I to jest wiesz, fundamentalna zmiana perspektywy. Zamiast pokazywa\u0107 modelowi setki tysi\u0119cy przyk\u0142ad\u00f3w, jak rozwi\u0105za\u0107 zadanie, zastosowano Reinforcement Learning, czyli RL, bezpo\u015brednio na surowym, bazowym modelu. Czyli na takiej czystej karcie. Tak. To troch\u0119 jak uczenie dziecka gry w szachy. Nie pokazujesz mu zapis\u00f3w partii mistrz\u00f3w, tylko nagracasz za ka\u017cdy dobry ruch i powiedzmy, karzesz za z\u0142y. A co by\u0142o tak\u0105 nagrod\u0105 dla tego modelu? Wirtualna czekolada? Blisko. Stworzono system nagr\u00f3d oparty na bardzo prostych, twardych zasadach, a nie na jakiej\u015b skomplikowanej sieci neuronowej, kt\u00f3ra ocenia styl. By\u0142y w zasadzie dwa g\u0142\u00f3wne rodzaje nagr\u00f3d. Okej. Po pierwsze, Accuracy Rewards, czyli nagrody za dok\u0142adno\u015b\u0107. W zadaniach matematycznych sprawdzano po prostu, czy ostateczny wynik jest poprawny. Czyli 0,1 zgadza si\u0119 albo si\u0119 nie zgadza. Dok\u0142adnie. A w zadaniach programistycznych, czy kod si\u0119 k\u0105piluje i przechodzi przygotowane testy. A ten drugi rodzaj? Drugi to by\u0142y Format Rewards. Tu chodzi\u0142o o to, czy model trzyma\u0142 si\u0119 instrukcji. A, czyli na przyk\u0142ad? Na przyk\u0142ad, czy umie\u015bci\u0142 sw\u00f3j proces my\u015blowy, czyli ten Chain of Thought, w specjalnych znacznikach Think i Think. I co si\u0119 sta\u0142o? Bo tutaj robi si\u0119 naprawd\u0119 ciekawie. Wyniki by\u0142y, no, zdumiewaj\u0105ce. Skuteczno\u015b\u0107 modelu na testie matematycznym AMI 2024 wzros\u0142a z pocz\u0105tkowych 15,6% do 71%. Wow, to ogromny skok. Ogromne. Co wi\u0119cej, gdy zastosowano g\u0142osowanie wi\u0119kszo\u015bciowe na wielu pr\u00f3bach, wynik skoczy\u0142 do 86,7%. Czyli przewy\u017cszy\u0142 nawet model Open AI o 109,12%. Tak. Na wykresie w tej pracy wida\u0107 bardzo wyra\u017cnie, jak z ka\u017cdym tysi\u0105cem krok\u00f3w treningowych model stawa\u0142 si\u0119 po prostu coraz lepszy. Ale to chyba nie tylko suche wyniki. Podobno model zacz\u0105\u0142 zachowywa\u0107 si\u0119 w jaki\u015b, no, fascynuj\u0105cy spos\u00f3b. Zgadza si\u0119. Zaobserwowano proces, kt\u00f3ry autorzy nazwali Samoewolucj\u0105. Samoewolucj\u0105? Tak. Model sam z siebie zacz\u0105\u0142 generowa\u0107 coraz d\u0142u\u017csze odpowiedzi. Na jednym z wykres\u00f3w wida\u0107, jak \u015brednia d\u0142ugo\u015b\u0107 odpowiedzi ro\u015bnie. Czyli on jakby rozumia\u0142, \u017ce na trudniejsze problemy potrzebuje wi\u0119cej czasu do namys\u0142u. Dok\u0142adnie tak. Potrzebowa\u0142 wi\u0119cej miejsca, wi\u0119cej token\u00f3w na rozpisanie swojego Chain of Thought. To niesamowite. Ale to nie wszystko. Spontanicznie pojawi\u0142y si\u0119 te\u017c zaawansowane zachowania. Na przyk\u0142ad Reflection. Czyli? Wracanie do poprzednich krok\u00f3w i ponowna ich ocena. Sprawdzanie w\u0142asnej pracy. Aha. Model zacz\u0105\u0142 te\u017c eksplorowa\u0107 alternatywny \u015bcie\u017cki rozwi\u0105zania problemu, zamiast, wiesz, trzyma\u0107 si\u0119 kurczowo tej pierwszej my\u015bli. I wtedy nadszed\u0142 ten s\u0142ynny moment. Aha. Opowiedz o tym, bo to brzmi jak \u015bwietna historia. To jest jeden z najbardziej intryguj\u0105cych fragment\u00f3w tej pracy. W jednej z po\u015brednich wersji modelu, podczas rozwi\u0105zywania zadania, model dos\u0142ownie napisa\u0142 co\u015b w stylu. Czekaj, czekaj. Czekaj, to jest moment aha, kt\u00f3rym mog\u0119 tu zaznaczy\u0107. Oce\u0144my to jeszcze raz. Krok po kroku. Nieprawdopodobne. To nie by\u0142o w \u017caden spos\u00f3b zaprogramowane. Absolutnie nie. Model sam nauczy\u0142 si\u0119 kwestionowa\u0107 sw\u00f3j pocz\u0105tkowy tok my\u015blenia. To by\u0142 moment aha, nie tylko dla maszyny, ale te\u017c dla badaczy, kt\u00f3rzy zobaczyli, no, pot\u0119g\u0119 tej metody. No tak, ale jak to w nauce pewnie nie wszystko by\u0142o idealne, prawda? Dok\u0142adnie. DeepSeq R1-0. Mimo swojej mocy generowa\u0142 odpowiedzi trudne do czytania, cz\u0119sto miesza\u0142 j\u0119zyki. By\u0142 bardzo skuteczny, ale powiedzmy nieprzyjazny dla u\u017cytkownika. I to sta\u0142o si\u0119 punktem wyj\u015bcia do stworzenia kolejnej, ulepszonej wersji. Czyli DeepSeq R1-0 by\u0142 takim pot\u0119\u017cnym, ale troch\u0119 chaotycznym dowodem na s\u0142u\u017cno\u015b\u0107 koncepcji. W punkt. A jego nast\u0119pca, DeepSeq R1, mia\u0142 to wszystko uporz\u0105dkowa\u0107. Jak si\u0119 do tego zabrali? Zastosowali wieloetapowy proces. Zamiast zaczyna\u0107 od zera, postanowili da\u0107 modelowi pewien nazwimy to zapas wiedzy na start. Taki cold start. W\u0142a\u015bnie. I pierwszy etap to by\u0142 w\u0142a\u015bnie cold start. Wzi\u0119li model bazowy i najpierw go dostroili na niewielkim zbiorze kilkutysi\u0119cy, ale bardzo wysokiej jako\u015bci, d\u0142ugich przyk\u0142ad\u00f3w rozumowania. Czyli chain of thought. Tak. Te przyk\u0142ady by\u0142y starannie przygotowane, \u017ceby by\u0142y czytelne, uporz\u0105dkowane. To by\u0142o jak danie modelowi takich nasion dobiego z ty\u0142u my\u015blenia. Ok, czyli zacz\u0119li od pokazania mu wzorc\u00f3w, co by\u0142o drugim krokiem. Nagrod\u0119 za sp\u00f3jno\u015b\u0107 j\u0119zykow\u0105, co mia\u0142o go zniech\u0119ca\u0107 do mieszania j\u0119zyk\u00f3w. Rozumiem, a trzeci etap? Bo brzmi jakby zacz\u0119li uczy\u0107 model na jego w\u0142asnej pracy. Bo dok\u0142adnie o to chodzi\u0142o. A trzeci etap to rejection sampling i ponowne SFT. U\u017cyli wytrenowanego modelu, \u017ceby wygenerowa\u0142 ogromn\u0105 liczb\u0119 nowych danych treningowych. Oko\u0142o 600 tysi\u0119cy przyk\u0142ad\u00f3w rozumowania. I co z nimi zrobili? Zatrzymali tylko te poprawne. Do tego dorzucili 200 tysi\u0119cy przyk\u0142ad\u00f3w niezwi\u0105zanych z rozumowaniem. Na przyk\u0142ad pisanie, odpowiadanie na pytania, \u017ceby model nie straci\u0142 og\u00f3lnych zdolno\u015bci. Aha, \u017ceby nie sta\u0142 si\u0119 tylko maszynk\u0105 do matematyki. W\u0142a\u015bnie. I nast\u0119pnie na tym nowym, ogromnym 800 tys. zbiorze wytrenowali model od nowa. Czyli model sam stworzy\u0142 sobie podr\u0119cznik, z kt\u00f3rego potem si\u0119 uczy\u0142. Genialne. A ostatni czwarty krok? Na koniec przeprowadzili jeszcze jedn\u0105 rund\u0119 RL, tym razem by dostosowa\u0107 model do ludzkich preferencji. Chodzi\u0142o o pomocno\u015b\u0107 i nieszkodliwo\u015b\u0107. I co z tego wszystkiego wysz\u0142o? Jakie by\u0142y ostateczne wyniki? DeepSeq R1 osi\u0105gn\u0105\u0142 wydajno\u015b\u0107 porumywaln\u0105 stopowym modelem OpenIO 1.127. Naprawd\u0119? Tak. Na testie AIM-2024 uzyska\u0142 79,8% w metryce PassEd.1, minimalnie wyprzedzaj\u0105c wynik OpenIO. Niesamowite. Na testie Math 500 osi\u0105gn\u0105\u0142 97,3%, co jest wynikiem na r\u00f3wni z konkurencj\u0105. A programowanie? W zadaniach z programowania na platformie CodeForces osi\u0105gn\u0105\u0142 poziom ekspercki. To jest 96 centyl ludzkich uczestnik\u00f3w. Wow. I co wa\u017cne zachowa\u0142 te\u017c silne zdolno\u015bci w zadaniach og\u00f3lnych i konwersacyjnych. Stworzyli wi\u0119c pot\u0119\u017cny model. To jasne. Ale takie kolosy s\u0105 drogie, niedost\u0119pne dla wielu. Co z mniejszymi modelami? I tu dochodzimy do jednego z najciekawszych odkry\u0107 tej pracy. Do procesu, kt\u00f3ry nazywa si\u0119 dystylacja. Dystylacja. Tak. Wzi\u0119li te 800 tysi\u0119cy w wysokiej jako\u015bci przyk\u0142ad\u00f3w rozumowania, kt\u00f3re wygenerowa\u0142 DeepSync R1 i u\u017cyli ich do nauczenia mniejszych, popularnych modeli OpenSource. Takich jak kwen czy lama. I co? Mo\u017cna tak po prostu przela\u0107 zdolno\u015b\u0107 rozumowania z du\u017cego modelu do ma\u0142ego? Okazuje si\u0119, \u017ce tak. A efekty s\u0105 spektakularne. Ma\u0142y, siedmiu miliardowy model nazwany DeepSync R1 Dystyl Kwen 7B w zadaniach wymagaj\u0105cych rozumowania okaza\u0142 si\u0119 lepszy od znacznie wi\u0119kszych modeli, jak cho\u0107by GPT-4O. To naprawd\u0119 robi wra\u017cenie. Z kolei model 30-fu miliardowy znacz\u0105co przewy\u017cszy\u0142 O-Mine od OpenAI. To rodzi kluczo\u0142y pytali mi, kt\u00f3re zreszt\u0105 autorzy sami sobie zadali. Co jest lepsze? Uczy\u0107 ma\u0142y model od zera za pomoc\u0105 RL, tak jak zrobili z 1.0, czy destylowa\u0107 do niego wiedz\u0119 z wi\u0119kszego modelu? Zbadali to. Wytrenowali model QN32B metod\u0105 od zera i por\u00f3wnali go z wersj\u0105 destylowan\u0105. I jaki by\u0142 wniosek? Wersja destylowana by\u0142a znacznie, znacznie lepsza. Z tego p\u0142yn\u0105 chyba dwie wa\u017cne lekcje. Dok\u0142adnie. Po pierwsze, distillation jest niezwykle skuteczn\u0105 i, co wa\u017cne, ekonomiczn\u0105 metod\u0105. To \u015bwietna wiadomo\u015b\u0107 dla ca\u0142ej spo\u0142eczno\u015bci OpenSource. A po drugie? Po drugie, to pokazuje, \u017ce aby przesuwa\u0107 granice mo\u017cliwo\u015bci AI, wci\u0105\u017c potrzebne s\u0105 pot\u0119\u017cniejsze modele bazowe i trening na ogromn\u0105 skal\u0119. Czyli distillacja mo\u017ce tylko skopiowa\u0107 to, co ju\u017c wie nauczyciel? Nie stworzy nowej wiedzy. W\u0142a\u015bnie tak. Odna. Oczywi\u015bcie. I autorzy otwarcie pisz\u0105 o swoich nieudanych pr\u00f3bach. Na przyk\u0142ad pr\u00f3bowali zastosowa\u0107 tak zwany Process Reward Model. Czyli nagradzanie modelu za ka\u017cdy pojedynczy, poprawny krok w rozumowaniu, a nie tylko zako\u0144cowy wynik. W te\u0142owi brzmi to \u015bwietnie. Brzmi, ale w praktyce okaza\u0142o si\u0119 zbyt trudne do skalowania. Cieszko jest zdefiniowa\u0107, co to jest poprawny krok. Jeszcze ci\u0119\u017cej to automatycznie ocenia\u0107. A co z innymi pr\u00f3bami? S\u0142ysza\u0142am, \u017ce testowali te\u017c Monte Carlo Tree Search. Tak. Technik\u0119 znan\u0105 z AlphaGo. Niestety to te\u017c si\u0119 nie sprawdzi\u0142o. Dlaczego? Bo przestrze\u0144 mo\u017cliwych odpowiedzi w j\u0119zyku jest niesko\u0144czenie wi\u0119ksza ni\u017c na szachownicy. Podej\u015bcie, kt\u00f3re da\u0142o mistrzostwo w go tutaj po prostu nie zadzia\u0142a\u0142o. Dobrze. A jakie s\u0105 obecne wady samego DeepSync R1? Tego finalnego modelu. G\u0142\u00f3wne ograniczenia, kt\u00f3re sami wymieniaj\u0105, to po pierwsze, \u017ce nie jest jeszcze tak dobry w zadaniach og\u00f3lnych jak jego poprzednik. DeepSync V3. Czyli specjalizacja w rozumowaniu kosztowa\u0142a go troch\u0119 wszechstronno\u015bci. Mo\u017cna tak powiedzie\u0107. To klasyczny dylemat. Po drugie, wci\u0105\u017c ma problemy zmieszaniem j\u0119zyk\u00f3w. Je\u015bli zapytanie nie jest po angielsku lub chi\u0144sku. Czyli tego problemu z Rn0 nie uda\u0142 im si\u0119 do ko\u0144ca wyeliminowa\u0107. Po trzecie jest bardzo wra\u017cliwy na spos\u00f3b formu\u0142owania zapyta\u0144, czyli na prompting. I na koniec przyznaj\u0105, \u017ce wymaga dalszych prac nad zadaniami z in\u017cynierii oprogramowania. Ok. To podsumujmy ca\u0142\u0105 t\u0105 podr\u00f3\u017c. Ta praca pokazuje, \u017ce mo\u017cna nauczy\u0107 model rozumowania stosuj\u0105c czysty reinforcement learning. Co udowodni\u0142 eksperyment z Rn0? Tak. Pokazuje te\u017c, \u017ce podej\u015bcie hybrydowe, kt\u00f3re \u0142\u0105czy SFT i RL, daje bardziej dopracowane, przyjazne rezultaty. A na koniec udowodni\u0119, \u017ce distillation to pot\u0119\u017cne narz\u0119dzie, \u017ceby udost\u0119pni\u0107 te zaawansowane zdolno\u015bci szerszemu gronu. Ale wiesz co? Mnie w tym wszystkim najbardziej fascynuje co\u015b innego. Co takiego? To, \u017ce rozumowanie okazuje si\u0119 nie tylko kwesti\u0105 zapami\u0119tanych fakt\u00f3w, ale wykszta\u0142cenia pewnego procesu. Ten moment a haft modelu nie polega\u0142 na tym, \u017ce on sobie co\u015b przypomnia\u0142. On sobie u\u015bwiadomi\u0142, \u017ce jego w\u0142asny wewn\u0119trzny proces my\u015blowy by\u0142 wadliwy i wymaga\u0142 zmiany. I to jest fundamentalna r\u00f3\u017cnica. No w\u0142a\u015bnie. I to zostawia nas z tak\u0105, wiesz, prowokuj\u0105c\u0105 my\u015bl\u0105 na koniec. Dok\u0142adnie. Skoro uczymy modele tworzenia coraz bardziej z\u0142o\u017conych wewn\u0119trznych proces\u00f3w my\u015blowych, kt\u00f3re obejmuj\u0105 refleksje i zmiany strategii, to czy my tworzymy tylko lepsze narz\u0119dzia? Czy mo\u017ce robimy krok w kierunku systemu, kt\u00f3ry potrafi autentycznie analizowa\u0107 \u015bwiat? W daniach? To potencjalna zmiana regu\u0142 gry w dost\u0119pie do zaawansowanej AI.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.5200000000000005, "text": " Zaczynamy nasz\u0105 analiz\u0119 od takiego wielkiego pytania w \u015bwiecie AI.", "tokens": [50364, 1176, 14691, 5378, 88, 5382, 8925, 2624, 590, 1274, 3611, 32296, 20570, 42349, 25878, 5609, 261, 40078, 4260, 7318, 13, 50640], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 1, "seek": 0, "start": 5.5200000000000005, "end": 9.56, "text": " Jak nauczy\u0107 maszyn\u0119 prawdziwego rozumowania?", "tokens": [50640, 15029, 49103, 27150, 2300, 1229, 77, 1274, 41175, 3992, 826, 1571, 48797, 21308, 30, 50842], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 2, "seek": 0, "start": 9.56, "end": 16.68, "text": " Nie chodzi przecie\u017c tylko o znajdowanie fakt\u00f3w, ale o rozwi\u0105zywanie naprawd\u0119 z\u0142o\u017conych problem\u00f3w.", "tokens": [50842, 12016, 23998, 8325, 40082, 13219, 277, 27318, 67, 22028, 21310, 3901, 11, 6775, 277, 9544, 18234, 1229, 86, 7155, 20970, 710, 5249, 1427, 2526, 339, 1154, 3901, 13, 51198], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 3, "seek": 0, "start": 16.68, "end": 18.04, "text": " Krok po kroku.", "tokens": [51198, 591, 31621, 714, 45909, 5279, 13, 51266], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 4, "seek": 0, "start": 18.04, "end": 24.44, "text": " I przez d\u0142ugi czas te modele z serii One od OpenAI by\u0142y takim niedo\u015bcigni\u0119tym wzorem.", "tokens": [51266, 286, 14064, 44042, 24780, 13190, 535, 4391, 306, 710, 816, 5597, 1485, 3611, 7238, 48698, 26366, 31732, 32488, 78, 1788, 66, 788, 5034, 874, 76, 24809, 37956, 13, 51586], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 5, "seek": 0, "start": 24.44, "end": 28.72, "text": " Totalnie. Wielu pr\u00f3bowa\u0142o, ale nikt tak naprawd\u0119 nie m\u00f3g\u0142 im dor\u00f3wna\u0107.", "tokens": [51586, 23170, 2766, 13, 343, 1187, 84, 8565, 65, 5528, 5249, 11, 6775, 297, 9874, 991, 20970, 2838, 275, 14047, 1221, 566, 26313, 3901, 629, 2162, 13, 51800], "temperature": 0.0, "avg_logprob": -0.14672133501838236, "compression_ratio": 1.4125874125874125, "no_speech_prob": 0.01963408663868904}, {"id": 6, "seek": 2872, "start": 29.72, "end": 34.72, "text": " Tak, bo dzisiaj przyjrzymy si\u0119 pracy naukowej, kt\u00f3ra rzuca wyzwanie temu status quo.", "tokens": [50414, 9118, 11, 748, 25772, 6501, 73, 13047, 2226, 3244, 35591, 35616, 74, 21091, 11, 19456, 367, 11728, 496, 4628, 14406, 7155, 33346, 6558, 28425, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 7, "seek": 2872, "start": 34.72, "end": 42.72, "text": " Mam tu na my\u015bli DeepSeq R1 \u2013 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.", "tokens": [50664, 19899, 2604, 1667, 452, 15350, 14895, 10637, 80, 497, 16, 1662, 682, 2207, 592, 3319, 39693, 278, 8363, 2310, 294, 441, 43, 26386, 5766, 42116, 9382, 15205, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 8, "seek": 2872, "start": 42.72, "end": 43.72, "text": " O w\u0142a\u015bnie.", "tokens": [51064, 422, 14234, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 9, "seek": 2872, "start": 43.72, "end": 48.72, "text": " Zesp\u00f3\u0142 DeepSeq AI postawi\u0142 sobie za cel nie tylko dogonienie czo\u0142\u00f3wki,", "tokens": [51114, 1176, 13361, 16181, 14895, 10637, 80, 7318, 2183, 38402, 1221, 13652, 7949, 9277, 2838, 13219, 3000, 266, 27385, 269, 4765, 1221, 3901, 2984, 11, 51364], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 10, "seek": 2872, "start": 48.72, "end": 51.239999999999995, "text": " oni chcieli to zrobi\u0107 w zupe\u0142nie nowy spos\u00f3b.", "tokens": [51364, 36317, 417, 537, 10148, 281, 31785, 261, 49922, 586, 88, 22904, 13, 51490], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 11, "seek": 2872, "start": 51.239999999999995, "end": 58.64, "text": " Dok\u0142adnie. I celem naszego dzisiejszego spotkania jest zrozumienie tego ich no do\u015b\u0107 nietypowego podej\u015bcia.", "tokens": [51490, 29768, 10358, 2766, 13, 286, 1769, 10386, 44517, 9758, 50117, 15453, 6308, 4008, 5225, 654, 3492, 710, 27857, 449, 27385, 8627, 1893, 572, 49333, 297, 4014, 14701, 6308, 7468, 73, 1788, 2755, 13, 51860], "temperature": 0.0, "avg_logprob": -0.1651989092929758, "compression_ratio": 1.3730407523510972, "no_speech_prob": 0.01551741175353527}, {"id": 12, "seek": 5864, "start": 58.64, "end": 63.64, "text": " Zobaczymy, czy da si\u0119, jak oni to pisz\u0105, zach\u0119ci\u0107 model do my\u015blenia.", "tokens": [50364, 1176, 996, 14691, 2226, 11, 6430, 1120, 3244, 11, 4207, 36317, 281, 26584, 8925, 11, 29303, 1274, 39162, 2316, 360, 48633, 6698, 654, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 13, "seek": 5864, "start": 63.64, "end": 66.64, "text": " U\u017cywaj\u0105c wy\u0142\u0105cznie metody pr\u00f3b i b\u0142\u0119d\u00f3w.", "tokens": [50614, 624, 7735, 86, 38757, 4628, 15926, 19923, 1131, 843, 8565, 65, 741, 272, 1221, 6298, 3901, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 14, "seek": 5864, "start": 66.64, "end": 69.64, "text": " Czyli tego s\u0142ynnego Reinforcement Learning.", "tokens": [50764, 37099, 8627, 15116, 2534, 11858, 42116, 9382, 15205, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 15, "seek": 5864, "start": 69.64, "end": 78.16, "text": " Roz\u0142o\u017cymy naczynniki pierwsze, ich eksperymenty, kluczowe odkrycia i no wiesz, zastanowimy si\u0119, co to wszystko oznacza.", "tokens": [50914, 43313, 5249, 7735, 2226, 297, 14691, 26384, 9850, 45994, 11, 1893, 30724, 610, 88, 518, 88, 11, 9671, 1311, 89, 6880, 3611, 43298, 2755, 741, 572, 261, 15347, 11, 36746, 282, 305, 13189, 3244, 11, 598, 281, 22607, 277, 22672, 326, 2394, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 16, "seek": 5864, "start": 78.16, "end": 79.16, "text": " Zaczynajmy.", "tokens": [51340, 1176, 14691, 20981, 2226, 13, 51390], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 17, "seek": 5864, "start": 79.16, "end": 81.8, "text": " Dobrze, to spr\u00f3bujmy to rozpakowa\u0107.", "tokens": [51390, 29679, 13503, 11, 281, 6103, 14216, 4579, 2226, 281, 9544, 45944, 11445, 13, 51522], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 18, "seek": 5864, "start": 81.8, "end": 88.16, "text": " Wi\u0119kszo\u015b\u0107 modeli, no wiesz, uczy si\u0119 na takich ogromnych, przygotowanych przez ludzi zestawach danych.", "tokens": [51522, 30127, 1694, 4765, 7753, 2316, 72, 11, 572, 261, 15347, 11, 344, 6522, 3244, 1667, 29607, 34416, 298, 9399, 11, 35914, 23341, 339, 14064, 29586, 37889, 1607, 608, 274, 34644, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1203166261503968, "compression_ratio": 1.437299035369775, "no_speech_prob": 0.0003289160376880318}, {"id": 19, "seek": 8816, "start": 88.16, "end": 90.16, "text": " To jest to, co nazywamy...", "tokens": [50364, 1407, 3492, 281, 11, 598, 20151, 27112, 7804, 485, 50464], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 20, "seek": 8816, "start": 90.16, "end": 92.16, "text": " Supervised Fine Tuning. Tak.", "tokens": [50464, 4548, 24420, 12024, 21363, 278, 13, 9118, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 21, "seek": 8816, "start": 92.16, "end": 93.16, "text": " Albo SFT.", "tokens": [50564, 967, 1763, 318, 25469, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 22, "seek": 8816, "start": 93.16, "end": 95.16, "text": " Dok\u0142adnie. SFT.", "tokens": [50614, 29768, 10358, 2766, 13, 318, 25469, 13, 50714], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 23, "seek": 8816, "start": 95.16, "end": 101.16, "text": " Ale co by by\u0142o, gdyby model m\u00f3g\u0142 sam od zera nauczy\u0107 si\u0119 rozumowa\u0107?", "tokens": [50714, 9366, 598, 538, 14811, 11, 28405, 2322, 2316, 275, 14047, 1221, 3247, 3611, 710, 1663, 49103, 27150, 3244, 48797, 11445, 30, 51014], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 24, "seek": 8816, "start": 101.16, "end": 103.16, "text": " Do w\u0142a\u015bnie.", "tokens": [51014, 1144, 14234, 13, 51114], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 25, "seek": 8816, "start": 103.16, "end": 109.16, "text": " I to jest idea, kt\u00f3ra stoi za tym ich pierwszym modelem DeepSeq R1-0.", "tokens": [51114, 286, 281, 3492, 1558, 11, 19456, 342, 4869, 7949, 8107, 1893, 34016, 76, 4391, 10386, 14895, 10637, 80, 497, 16, 12, 15, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 26, "seek": 8816, "start": 109.16, "end": 113.16, "text": " I to jest wiesz, fundamentalna zmiana perspektywy.", "tokens": [51414, 286, 281, 3492, 261, 15347, 11, 8088, 629, 17020, 8497, 868, 32659, 874, 9726, 13, 51614], "temperature": 0.0, "avg_logprob": -0.20547677836286912, "compression_ratio": 1.2863436123348018, "no_speech_prob": 0.0028475425206124783}, {"id": 27, "seek": 11316, "start": 113.16, "end": 124.16, "text": " Zamiast pokazywa\u0107 modelowi setki tysi\u0119cy przyk\u0142ad\u00f3w, jak rozwi\u0105za\u0107 zadanie, zastosowano Reinforcement Learning, czyli RL, bezpo\u015brednio na surowym, bazowym modelu.", "tokens": [50364, 1176, 4526, 525, 13010, 33235, 25234, 2316, 24503, 992, 2984, 38156, 47303, 23144, 3901, 11, 4207, 9544, 18234, 35873, 42788, 7155, 11, 36746, 329, 305, 3730, 42116, 9382, 15205, 11, 16591, 497, 43, 11, 10782, 2259, 1788, 986, 41084, 1667, 1022, 31691, 11, 27147, 31691, 2316, 84, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08445228167942592, "compression_ratio": 1.4092409240924093, "no_speech_prob": 0.27802643179893494}, {"id": 28, "seek": 11316, "start": 124.16, "end": 126.16, "text": " Czyli na takiej czystej karcie.", "tokens": [50914, 37099, 1667, 38941, 6430, 2941, 73, 7917, 4260, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08445228167942592, "compression_ratio": 1.4092409240924093, "no_speech_prob": 0.27802643179893494}, {"id": 29, "seek": 11316, "start": 126.16, "end": 130.16, "text": " Tak. To troch\u0119 jak uczenie dziecka gry w szachy.", "tokens": [51014, 9118, 13, 1407, 24926, 4207, 344, 39043, 17953, 39342, 41974, 261, 7870, 608, 88, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08445228167942592, "compression_ratio": 1.4092409240924093, "no_speech_prob": 0.27802643179893494}, {"id": 30, "seek": 11316, "start": 130.16, "end": 137.16, "text": " Nie pokazujesz mu zapis\u00f3w partii mistrz\u00f3w, tylko nagracasz za ka\u017cdy dobry ruch i powiedzmy, karzesz za z\u0142y.", "tokens": [51214, 12016, 13010, 921, 4579, 10430, 2992, 14223, 271, 3901, 644, 5597, 3544, 19390, 3901, 11, 13219, 17096, 12080, 19601, 7949, 31615, 35884, 367, 625, 741, 27617, 2226, 11, 7917, 89, 10430, 7949, 710, 6825, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08445228167942592, "compression_ratio": 1.4092409240924093, "no_speech_prob": 0.27802643179893494}, {"id": 31, "seek": 11316, "start": 137.16, "end": 141.16, "text": " A co by\u0142o tak\u0105 nagrod\u0105 dla tego modelu? Wirtualna czekolada?", "tokens": [51564, 316, 598, 14811, 31069, 17096, 11452, 1611, 12285, 8627, 2316, 84, 30, 343, 2498, 901, 629, 6472, 916, 401, 1538, 30, 51764], "temperature": 0.0, "avg_logprob": -0.08445228167942592, "compression_ratio": 1.4092409240924093, "no_speech_prob": 0.27802643179893494}, {"id": 32, "seek": 14116, "start": 142.16, "end": 151.16, "text": " Blisko. Stworzono system nagr\u00f3d oparty na bardzo prostych, twardych zasadach, a nie na jakiej\u015b skomplikowanej sieci neuronowej, kt\u00f3ra ocenia styl.", "tokens": [50414, 2177, 43442, 13, 745, 28321, 89, 8957, 1185, 17096, 43678, 999, 446, 88, 1667, 9034, 10293, 16384, 11, 683, 515, 16384, 44585, 608, 11, 257, 2838, 1667, 4207, 7764, 1788, 1110, 298, 564, 1035, 23066, 73, 2804, 537, 34090, 21091, 11, 19456, 10409, 268, 654, 23736, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 33, "seek": 14116, "start": 151.16, "end": 154.16, "text": " By\u0142y w zasadzie dwa g\u0142\u00f3wne rodzaje nagr\u00f3d.", "tokens": [50864, 3146, 6825, 261, 44585, 3283, 35045, 18117, 3901, 716, 28607, 11153, 17096, 43678, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 34, "seek": 14116, "start": 154.16, "end": 155.16, "text": " Okej.", "tokens": [51014, 29094, 73, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 35, "seek": 14116, "start": 155.16, "end": 159.16, "text": " Po pierwsze, Accuracy Rewards, czyli nagrody za dok\u0142adno\u015b\u0107.", "tokens": [51064, 6165, 45994, 11, 5725, 374, 2551, 1300, 2015, 11, 16591, 17096, 340, 3173, 7949, 45864, 23293, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 36, "seek": 14116, "start": 159.16, "end": 163.16, "text": " W zadaniach matematycznych sprawdzano po prostu, czy ostateczny wynik jest poprawny.", "tokens": [51264, 343, 42788, 3782, 608, 3803, 8615, 17466, 9399, 46192, 89, 3730, 714, 19518, 11, 6430, 277, 15406, 3689, 1634, 31936, 1035, 3492, 1665, 29603, 88, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 37, "seek": 14116, "start": 163.16, "end": 167.16, "text": " Czyli 0,1 zgadza si\u0119 albo si\u0119 nie zgadza.", "tokens": [51464, 37099, 1958, 11, 16, 40948, 345, 2394, 3244, 22622, 3244, 2838, 40948, 345, 2394, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 38, "seek": 14116, "start": 167.16, "end": 168.16, "text": " Dok\u0142adnie.", "tokens": [51664, 29768, 10358, 2766, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08380113521092375, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.10558678209781647}, {"id": 39, "seek": 16816, "start": 168.16, "end": 173.16, "text": " A w zadaniach programistycznych, czy kod si\u0119 k\u0105piluje i przechodzi przygotowane testy.", "tokens": [50364, 316, 261, 42788, 3782, 608, 1461, 468, 17466, 9399, 11, 6430, 350, 378, 3244, 350, 1611, 79, 388, 13008, 741, 8325, 34616, 35914, 23066, 1500, 88, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 40, "seek": 16816, "start": 173.16, "end": 175.16, "text": " A ten drugi rodzaj?", "tokens": [50614, 316, 2064, 4110, 72, 28607, 1805, 30, 50714], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 41, "seek": 16816, "start": 175.16, "end": 177.16, "text": " Drugi to by\u0142y Format Rewards.", "tokens": [50714, 2491, 24780, 281, 26366, 10126, 267, 1300, 2015, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 42, "seek": 16816, "start": 177.16, "end": 180.16, "text": " Tu chodzi\u0142o o to, czy model trzyma\u0142 si\u0119 instrukcji.", "tokens": [50814, 7836, 23998, 5249, 277, 281, 11, 6430, 2316, 34573, 1696, 1221, 3244, 1058, 25126, 19649, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 43, "seek": 16816, "start": 180.16, "end": 182.16, "text": " A, czyli na przyk\u0142ad?", "tokens": [50964, 316, 11, 16591, 1667, 23144, 30, 51064], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 44, "seek": 16816, "start": 182.16, "end": 192.16, "text": " Na przyk\u0142ad, czy umie\u015bci\u0142 sw\u00f3j proces my\u015blowy, czyli ten Chain of Thought, w specjalnych znacznikach Think i Think.", "tokens": [51064, 6056, 23144, 11, 6430, 1105, 414, 6199, 1221, 1693, 18999, 17565, 452, 19212, 10089, 11, 16591, 2064, 33252, 295, 23058, 11, 261, 46433, 9399, 15397, 14875, 13123, 608, 6557, 741, 6557, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 45, "seek": 16816, "start": 192.16, "end": 195.16, "text": " I co si\u0119 sta\u0142o? Bo tutaj robi si\u0119 naprawd\u0119 ciekawie.", "tokens": [51564, 286, 598, 3244, 11135, 5249, 30, 3286, 12749, 47380, 3244, 20970, 46419, 1607, 414, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09588345885276794, "compression_ratio": 1.4468864468864469, "no_speech_prob": 0.038856469094753265}, {"id": 46, "seek": 19516, "start": 195.16, "end": 198.16, "text": " Wyniki by\u0142y, no, zdumiewaj\u0105ce.", "tokens": [50364, 343, 2534, 9850, 26366, 11, 572, 11, 16221, 449, 1093, 11133, 384, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 47, "seek": 19516, "start": 198.16, "end": 209.16, "text": " Skuteczno\u015b\u0107 modelu na testie matematycznym AMI 2024 wzros\u0142a z pocz\u0105tkowych 15,6% do 71%.", "tokens": [50514, 7324, 1169, 3689, 23293, 2316, 84, 1667, 1500, 414, 3803, 8615, 17466, 12996, 6475, 40, 45237, 24809, 2635, 5024, 710, 34397, 74, 19605, 2119, 11, 21, 4, 360, 30942, 6856, 51064], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 48, "seek": 19516, "start": 209.16, "end": 211.16, "text": " Wow, to ogromny skok.", "tokens": [51064, 3153, 11, 281, 34416, 298, 1634, 1110, 453, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 49, "seek": 19516, "start": 211.16, "end": 212.16, "text": " Ogromne.", "tokens": [51164, 422, 861, 298, 716, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 50, "seek": 19516, "start": 212.16, "end": 220.16, "text": " Co wi\u0119cej, gdy zastosowano g\u0142osowanie wi\u0119kszo\u015bciowe na wielu pr\u00f3bach, wynik skoczy\u0142 do 86,7%.", "tokens": [51214, 3066, 26004, 11, 28405, 36746, 329, 305, 3730, 43767, 22028, 29968, 4765, 6199, 6880, 1667, 40437, 8565, 32096, 11, 31936, 1035, 1110, 905, 1229, 1221, 360, 26687, 11, 22, 6856, 51614], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 51, "seek": 19516, "start": 220.16, "end": 224.16, "text": " Czyli przewy\u017cszy\u0142 nawet model Open AI o 109,12%.", "tokens": [51614, 37099, 39758, 88, 1427, 7706, 1221, 22696, 2316, 7238, 7318, 277, 1266, 24, 11, 4762, 6856, 51814], "temperature": 0.0, "avg_logprob": -0.12112347692505926, "compression_ratio": 1.2479674796747968, "no_speech_prob": 0.22744928300380707}, {"id": 52, "seek": 22416, "start": 224.16, "end": 233.16, "text": " Tak. Na wykresie w tej pracy wida\u0107 bardzo wyra\u017cnie, jak z ka\u017cdym tysi\u0105cem krok\u00f3w treningowych model stawa\u0142 si\u0119 po prostu coraz lepszy.", "tokens": [50364, 9118, 13, 6056, 39287, 495, 414, 261, 12573, 35591, 261, 46898, 9034, 4628, 424, 1427, 2766, 11, 4207, 710, 31615, 76, 38156, 11404, 26422, 45909, 23849, 2192, 773, 19605, 2316, 342, 10449, 1221, 3244, 714, 19518, 25899, 476, 1878, 1229, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 53, "seek": 22416, "start": 233.16, "end": 235.16, "text": " Ale to chyba nie tylko suche wyniki.", "tokens": [50814, 9366, 281, 31532, 2838, 13219, 1270, 68, 31936, 9850, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 54, "seek": 22416, "start": 235.16, "end": 240.16, "text": " Podobno model zacz\u0105\u0142 zachowywa\u0107 si\u0119 w jaki\u015b, no, fascynuj\u0105cy spos\u00f3b.", "tokens": [50914, 12646, 996, 1771, 2316, 34430, 8925, 1221, 29303, 10089, 25234, 3244, 261, 34721, 11, 572, 11, 30632, 1344, 77, 13263, 1344, 22904, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 55, "seek": 22416, "start": 240.16, "end": 241.16, "text": " Zgadza si\u0119.", "tokens": [51164, 1176, 70, 345, 2394, 3244, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 56, "seek": 22416, "start": 241.16, "end": 245.16, "text": " Zaobserwowano proces, kt\u00f3ry autorzy nazwali Samoewolucj\u0105.", "tokens": [51214, 31440, 16537, 260, 34354, 3730, 17565, 11, 9913, 19510, 1229, 20151, 40054, 4832, 78, 1023, 401, 1311, 8555, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 57, "seek": 22416, "start": 245.16, "end": 247.16, "text": " Samoewolucj\u0105?", "tokens": [51414, 4832, 78, 1023, 401, 1311, 8555, 30, 51514], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 58, "seek": 22416, "start": 247.16, "end": 252.16, "text": " Tak. Model sam z siebie zacz\u0105\u0142 generowa\u0107 coraz d\u0142u\u017csze odpowiedzi.", "tokens": [51514, 9118, 13, 17105, 3247, 710, 39137, 34430, 8925, 1221, 1337, 11445, 25899, 274, 24066, 1427, 82, 1381, 36574, 3992, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06534237928793464, "compression_ratio": 1.4325259515570934, "no_speech_prob": 0.019851304590702057}, {"id": 59, "seek": 25216, "start": 252.16, "end": 256.15999999999997, "text": " Na jednym z wykres\u00f3w wida\u0107, jak \u015brednia d\u0142ugo\u015b\u0107 odpowiedzi ro\u015bnie.", "tokens": [50364, 6056, 5232, 12996, 710, 39287, 495, 3901, 261, 46898, 11, 4207, 8299, 986, 12679, 44042, 20746, 7753, 36574, 3992, 744, 12221, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 60, "seek": 25216, "start": 256.15999999999997, "end": 263.15999999999997, "text": " Czyli on jakby rozumia\u0142, \u017ce na trudniejsze problemy potrzebuje wi\u0119cej czasu do namys\u0142u.", "tokens": [50564, 37099, 322, 28976, 48797, 8908, 11, 3561, 1667, 32007, 44258, 1154, 88, 28577, 6021, 2884, 26004, 40860, 360, 8835, 749, 24066, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 61, "seek": 25216, "start": 263.15999999999997, "end": 270.15999999999997, "text": " Dok\u0142adnie tak. Potrzebowa\u0142 wi\u0119cej miejsca, wi\u0119cej token\u00f3w na rozpisanie swojego Chain of Thought.", "tokens": [50914, 29768, 10358, 2766, 991, 13, 9145, 13503, 65, 30105, 26004, 18522, 44239, 11, 26004, 281, 2653, 3901, 1667, 9544, 40516, 7155, 13291, 39738, 33252, 295, 23058, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 62, "seek": 25216, "start": 270.15999999999997, "end": 271.15999999999997, "text": " To niesamowite.", "tokens": [51264, 1407, 48100, 335, 305, 642, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 63, "seek": 25216, "start": 271.15999999999997, "end": 272.15999999999997, "text": " Ale to nie wszystko.", "tokens": [51314, 9366, 281, 2838, 22607, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 64, "seek": 25216, "start": 272.15999999999997, "end": 276.15999999999997, "text": " Spontanicznie pojawi\u0142y si\u0119 te\u017c zaawansowane zachowania.", "tokens": [51364, 1738, 896, 282, 17946, 2766, 30655, 72, 6825, 3244, 9516, 7949, 1607, 599, 23066, 29303, 21308, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 65, "seek": 25216, "start": 276.15999999999997, "end": 278.15999999999997, "text": " Na przyk\u0142ad Reflection.", "tokens": [51564, 6056, 23144, 16957, 5450, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 66, "seek": 25216, "start": 278.15999999999997, "end": 279.15999999999997, "text": " Czyli?", "tokens": [51664, 37099, 30, 51714], "temperature": 0.0, "avg_logprob": -0.07207671288521059, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.0046867309138178825}, {"id": 67, "seek": 27916, "start": 279.16, "end": 283.16, "text": " Wracanie do poprzednich krok\u00f3w i ponowna ich ocena.", "tokens": [50364, 10159, 326, 7155, 360, 1665, 81, 11312, 77, 480, 45909, 23849, 741, 9224, 305, 629, 1893, 10409, 4118, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 68, "seek": 27916, "start": 283.16, "end": 284.16, "text": " Sprawdzanie w\u0142asnej pracy.", "tokens": [50564, 1738, 15889, 89, 7155, 43572, 11794, 35591, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 69, "seek": 27916, "start": 284.16, "end": 285.16, "text": " Aha.", "tokens": [50614, 27448, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 70, "seek": 27916, "start": 285.16, "end": 289.16, "text": " Model zacz\u0105\u0142 te\u017c eksplorowa\u0107 alternatywny \u015bcie\u017cki rozwi\u0105zania problemu,", "tokens": [50664, 17105, 34430, 8925, 1221, 9516, 30724, 564, 284, 11445, 5400, 21398, 43682, 8299, 40082, 2984, 9544, 22620, 5609, 1154, 84, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 71, "seek": 27916, "start": 289.16, "end": 292.16, "text": " zamiast, wiesz, trzyma\u0107 si\u0119 kurczowo tej pierwszej my\u015bli.", "tokens": [50864, 710, 4526, 525, 11, 261, 15347, 11, 34573, 1696, 2162, 3244, 10072, 3689, 19941, 12573, 27623, 16920, 452, 15350, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 72, "seek": 27916, "start": 292.16, "end": 295.16, "text": " I wtedy nadszed\u0142 ten s\u0142ynny moment. Aha.", "tokens": [51014, 286, 26959, 297, 5834, 11312, 1221, 2064, 15116, 2534, 1634, 1623, 13, 27448, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 73, "seek": 27916, "start": 295.16, "end": 298.16, "text": " Opowiedz o tym, bo to brzmi jak \u015bwietna historia.", "tokens": [51164, 12011, 305, 15338, 277, 8107, 11, 748, 281, 738, 89, 3057, 4207, 8299, 39083, 629, 18385, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 74, "seek": 27916, "start": 298.16, "end": 302.16, "text": " To jest jeden z najbardziej intryguj\u0105cych fragment\u00f3w tej pracy.", "tokens": [51314, 1407, 3492, 12906, 710, 41857, 560, 627, 2794, 8555, 31306, 26424, 3901, 12573, 35591, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 75, "seek": 27916, "start": 302.16, "end": 307.16, "text": " W jednej z po\u015brednich wersji modelu, podczas rozwi\u0105zywania zadania,", "tokens": [51514, 343, 5232, 11794, 710, 714, 1788, 986, 77, 480, 261, 433, 4013, 2316, 84, 11, 2497, 30989, 9544, 18234, 1229, 86, 5609, 42788, 5609, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08783028881001917, "compression_ratio": 1.4536741214057507, "no_speech_prob": 0.4019794166088104}, {"id": 76, "seek": 30716, "start": 307.16, "end": 310.16, "text": " model dos\u0142ownie napisa\u0142 co\u015b w stylu.", "tokens": [50364, 2316, 4491, 1221, 648, 414, 9296, 3837, 1221, 19241, 261, 7952, 2781, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 77, "seek": 30716, "start": 310.16, "end": 311.16, "text": " Czekaj, czekaj.", "tokens": [50514, 383, 19878, 1805, 11, 6472, 916, 1805, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 78, "seek": 30716, "start": 311.16, "end": 315.16, "text": " Czekaj, to jest moment aha, kt\u00f3rym mog\u0119 tu zaznaczy\u0107.", "tokens": [50564, 383, 19878, 1805, 11, 281, 3492, 1623, 47340, 11, 30120, 41737, 2604, 710, 921, 77, 14691, 2162, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 79, "seek": 30716, "start": 315.16, "end": 318.16, "text": " Oce\u0144my to jeszcze raz. Krok po kroku.", "tokens": [50764, 422, 384, 5248, 2226, 281, 14168, 9639, 13, 591, 31621, 714, 45909, 5279, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 80, "seek": 30716, "start": 318.16, "end": 319.16, "text": " Nieprawdopodobne.", "tokens": [50914, 12016, 79, 15889, 46684, 996, 716, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 81, "seek": 30716, "start": 319.16, "end": 322.16, "text": " To nie by\u0142o w \u017caden spos\u00f3b zaprogramowane.", "tokens": [50964, 1407, 2838, 14811, 261, 19625, 14771, 22904, 14223, 340, 1342, 23066, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 82, "seek": 30716, "start": 322.16, "end": 323.16, "text": " Absolutnie nie.", "tokens": [51114, 5813, 2308, 2766, 2838, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 83, "seek": 30716, "start": 323.16, "end": 328.16, "text": " Model sam nauczy\u0142 si\u0119 kwestionowa\u0107 sw\u00f3j pocz\u0105tkowy tok my\u015blenia.", "tokens": [51164, 17105, 3247, 49103, 1229, 1221, 3244, 42035, 313, 11445, 1693, 18999, 34397, 74, 10089, 19164, 48633, 6698, 654, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 84, "seek": 30716, "start": 328.16, "end": 332.16, "text": " To by\u0142 moment aha, nie tylko dla maszyny, ale te\u017c dla badaczy,", "tokens": [51414, 1407, 16673, 1623, 47340, 11, 2838, 13219, 12285, 2300, 1229, 1634, 11, 6775, 9516, 12285, 1578, 14691, 11, 51614], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 85, "seek": 30716, "start": 332.16, "end": 335.16, "text": " kt\u00f3rzy zobaczyli, no, pot\u0119g\u0119 tej metody.", "tokens": [51614, 25382, 37273, 2081, 11, 572, 11, 1847, 1274, 70, 1274, 12573, 1131, 843, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0673763910929362, "compression_ratio": 1.452296819787986, "no_speech_prob": 0.019133055582642555}, {"id": 86, "seek": 33516, "start": 335.16, "end": 339.16, "text": " No tak, ale jak to w nauce pewnie nie wszystko by\u0142o idealne, prawda?", "tokens": [50364, 883, 991, 11, 6775, 4207, 281, 261, 35616, 384, 520, 14215, 2838, 22607, 14811, 7157, 716, 11, 43607, 30, 50564], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 87, "seek": 33516, "start": 339.16, "end": 343.16, "text": " Dok\u0142adnie. DeepSeq R1-0.", "tokens": [50564, 29768, 10358, 2766, 13, 14895, 10637, 80, 497, 16, 12, 15, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 88, "seek": 33516, "start": 343.16, "end": 348.16, "text": " Mimo swojej mocy generowa\u0142 odpowiedzi trudne do czytania, cz\u0119sto miesza\u0142 j\u0119zyki.", "tokens": [50764, 376, 6934, 29489, 73, 705, 1344, 1337, 30105, 36574, 3992, 32007, 716, 360, 6430, 83, 5609, 11, 34369, 41543, 2394, 1221, 49055, 2984, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 89, "seek": 33516, "start": 348.16, "end": 353.16, "text": " By\u0142 bardzo skuteczny, ale powiedzmy nieprzyjazny dla u\u017cytkownika.", "tokens": [51014, 3146, 1221, 9034, 1110, 1169, 3689, 1634, 11, 6775, 27617, 2226, 2838, 1424, 1229, 34820, 1634, 12285, 344, 1427, 4328, 74, 648, 5439, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 90, "seek": 33516, "start": 353.16, "end": 357.16, "text": " I to sta\u0142o si\u0119 punktem wyj\u015bcia do stworzenia kolejnej, ulepszonej wersji.", "tokens": [51264, 286, 281, 11135, 5249, 3244, 39561, 443, 4628, 73, 1788, 2755, 360, 342, 28321, 14320, 23749, 11794, 11, 344, 306, 1878, 16896, 73, 261, 433, 4013, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 91, "seek": 33516, "start": 357.16, "end": 364.16, "text": " Czyli DeepSeq R1-0 by\u0142 takim pot\u0119\u017cnym, ale troch\u0119 chaotycznym dowodem na s\u0142u\u017cno\u015b\u0107 koncepcji.", "tokens": [51464, 37099, 14895, 10637, 80, 497, 16, 12, 15, 16673, 31732, 1847, 1274, 1427, 12996, 11, 6775, 24926, 6294, 6737, 3689, 12996, 9459, 378, 443, 1667, 48459, 1427, 23293, 5897, 27493, 19649, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07927493045204564, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.0026334032882004976}, {"id": 92, "seek": 36416, "start": 364.16, "end": 365.16, "text": " W punkt.", "tokens": [50364, 343, 39561, 13, 50414], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 93, "seek": 36416, "start": 365.16, "end": 370.16, "text": " A jego nast\u0119pca, DeepSeq R1, mia\u0142 to wszystko uporz\u0105dkowa\u0107.", "tokens": [50414, 316, 26542, 39662, 496, 11, 14895, 10637, 80, 497, 16, 11, 27989, 281, 22607, 493, 284, 23876, 74, 11445, 13, 50664], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 94, "seek": 36416, "start": 370.16, "end": 372.16, "text": " Jak si\u0119 do tego zabrali?", "tokens": [50664, 15029, 3244, 360, 8627, 24838, 2155, 72, 30, 50764], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 95, "seek": 36416, "start": 372.16, "end": 374.16, "text": " Zastosowali wieloetapowy proces.", "tokens": [50764, 1176, 525, 329, 305, 5103, 20570, 78, 302, 569, 10089, 17565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 96, "seek": 36416, "start": 374.16, "end": 380.16, "text": " Zamiast zaczyna\u0107 od zera, postanowili da\u0107 modelowi pewien nazwimy to zapas wiedzy na start.", "tokens": [50864, 1176, 4526, 525, 43811, 629, 2162, 3611, 710, 1663, 11, 2183, 282, 305, 2312, 1120, 2162, 2316, 24503, 25889, 1053, 20151, 86, 13189, 281, 14223, 296, 46894, 1229, 1667, 722, 13, 51164], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 97, "seek": 36416, "start": 380.16, "end": 381.16, "text": " Taki cold start.", "tokens": [51164, 314, 7421, 3554, 722, 13, 51214], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 98, "seek": 36416, "start": 381.16, "end": 385.16, "text": " W\u0142a\u015bnie. I pierwszy etap to by\u0142 w\u0142a\u015bnie cold start.", "tokens": [51214, 343, 5024, 12221, 13, 286, 34016, 47634, 281, 16673, 14234, 3554, 722, 13, 51414], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 99, "seek": 36416, "start": 385.16, "end": 389.16, "text": " Wzi\u0119li model bazowy i najpierw go dostroili na niewielkim zbiorze kilkutysi\u0119cy,", "tokens": [51414, 343, 16706, 2081, 2316, 27147, 10089, 741, 11212, 45119, 86, 352, 20568, 340, 2312, 1667, 43622, 1187, 25112, 710, 33362, 1381, 5128, 74, 325, 749, 47303, 11, 51614], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 100, "seek": 36416, "start": 389.16, "end": 393.16, "text": " ale bardzo wysokiej jako\u015bci, d\u0142ugich przyk\u0142ad\u00f3w rozumowania.", "tokens": [51614, 6775, 9034, 27062, 453, 7764, 17123, 6199, 11, 274, 34077, 480, 23144, 3901, 48797, 21308, 13, 51814], "temperature": 0.0, "avg_logprob": -0.060505436312767766, "compression_ratio": 1.457516339869281, "no_speech_prob": 0.01140834391117096}, {"id": 101, "seek": 39316, "start": 393.16, "end": 395.16, "text": " Czyli chain of thought.", "tokens": [50364, 37099, 5021, 295, 1194, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 102, "seek": 39316, "start": 395.16, "end": 399.16, "text": " Tak. Te przyk\u0142ady by\u0142y starannie przygotowane, \u017ceby by\u0142y czytelne, uporz\u0105dkowane.", "tokens": [50464, 9118, 13, 1989, 6501, 74, 1221, 880, 26366, 3543, 43433, 35914, 23066, 11, 11316, 26366, 6430, 83, 338, 716, 11, 493, 284, 23876, 74, 23066, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 103, "seek": 39316, "start": 399.16, "end": 403.16, "text": " To by\u0142o jak danie modelowi takich nasion dobiego z ty\u0142u my\u015blenia.", "tokens": [50664, 1407, 14811, 4207, 3277, 414, 2316, 24503, 29607, 5382, 313, 360, 7392, 1571, 710, 1104, 24066, 48633, 6698, 654, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 104, "seek": 39316, "start": 403.16, "end": 408.16, "text": " Ok, czyli zacz\u0119li od pokazania mu wzorc\u00f3w, co by\u0142o drugim krokiem.", "tokens": [50864, 3477, 11, 16591, 34430, 11052, 2081, 3611, 13010, 921, 5609, 2992, 24809, 284, 29268, 11, 598, 14811, 4110, 332, 45909, 26116, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 105, "seek": 39316, "start": 408.16, "end": 413.16, "text": " Nagrod\u0119 za sp\u00f3jno\u015b\u0107 j\u0119zykow\u0105, co mia\u0142o go zniech\u0119ca\u0107 do mieszania j\u0119zyk\u00f3w.", "tokens": [51114, 18913, 11452, 1274, 7949, 637, 18999, 23293, 49055, 74, 30297, 11, 598, 21290, 5249, 352, 710, 2766, 23006, 496, 2162, 360, 33039, 5609, 49055, 23849, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 106, "seek": 39316, "start": 413.16, "end": 419.16, "text": " Rozumiem, a trzeci etap? Bo brzmi jakby zacz\u0119li uczy\u0107 model na jego w\u0142asnej pracy.", "tokens": [51364, 43313, 449, 4907, 11, 257, 22266, 537, 47634, 30, 3286, 738, 89, 3057, 28976, 34430, 11052, 2081, 344, 33967, 2316, 1667, 26542, 43572, 11794, 35591, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 107, "seek": 39316, "start": 419.16, "end": 421.16, "text": " Bo dok\u0142adnie o to chodzi\u0142o.", "tokens": [51664, 3286, 45864, 2766, 277, 281, 23998, 5249, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09048201413762649, "compression_ratio": 1.478688524590164, "no_speech_prob": 0.02452271245419979}, {"id": 108, "seek": 42116, "start": 421.16, "end": 425.16, "text": " A trzeci etap to rejection sampling i ponowne SFT.", "tokens": [50364, 316, 22266, 537, 47634, 281, 26044, 21179, 741, 9224, 648, 68, 318, 25469, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 109, "seek": 42116, "start": 425.16, "end": 430.16, "text": " U\u017cyli wytrenowanego modelu, \u017ceby wygenerowa\u0142 ogromn\u0105 liczb\u0119 nowych danych treningowych.", "tokens": [50564, 624, 7735, 2081, 261, 4328, 1095, 37345, 6308, 2316, 84, 11, 11316, 4628, 21848, 30105, 34416, 298, 13113, 6169, 89, 65, 1274, 586, 16384, 274, 34644, 2192, 773, 19605, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 110, "seek": 42116, "start": 430.16, "end": 433.16, "text": " Oko\u0142o 600 tysi\u0119cy przyk\u0142ad\u00f3w rozumowania.", "tokens": [50814, 3477, 78, 5249, 11849, 38156, 47303, 23144, 3901, 48797, 21308, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 111, "seek": 42116, "start": 433.16, "end": 435.16, "text": " I co z nimi zrobili?", "tokens": [50964, 286, 598, 710, 297, 10121, 44399, 2312, 30, 51064], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 112, "seek": 42116, "start": 435.16, "end": 437.16, "text": " Zatrzymali tylko te poprawne.", "tokens": [51064, 1176, 267, 13047, 76, 5103, 13219, 535, 1665, 5131, 716, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 113, "seek": 42116, "start": 437.16, "end": 441.16, "text": " Do tego dorzucili 200 tysi\u0119cy przyk\u0142ad\u00f3w niezwi\u0105zanych z rozumowaniem.", "tokens": [51164, 1144, 8627, 26313, 89, 1311, 2312, 2331, 38156, 47303, 23144, 3901, 33511, 22620, 34644, 710, 48797, 37345, 4907, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 114, "seek": 42116, "start": 441.16, "end": 446.16, "text": " Na przyk\u0142ad pisanie, odpowiadanie na pytania, \u017ceby model nie straci\u0142 og\u00f3lnych zdolno\u015bci.", "tokens": [51364, 6056, 23144, 26584, 7155, 11, 24314, 38069, 7155, 1667, 25878, 5609, 11, 11316, 2316, 2838, 1056, 22086, 1221, 5360, 15741, 9399, 16221, 401, 16438, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 115, "seek": 42116, "start": 446.16, "end": 449.16, "text": " Aha, \u017ceby nie sta\u0142 si\u0119 tylko maszynk\u0105 do matematyki.", "tokens": [51614, 27448, 11, 11316, 2838, 11135, 1221, 3244, 13219, 2300, 1229, 77, 26304, 360, 3803, 8615, 88, 2984, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07112135825219093, "compression_ratio": 1.5430463576158941, "no_speech_prob": 0.0964573323726654}, {"id": 116, "seek": 44916, "start": 449.16, "end": 456.16, "text": " W\u0142a\u015bnie. I nast\u0119pnie na tym nowym, ogromnym 800 tys. zbiorze wytrenowali model od nowa.", "tokens": [50364, 343, 5024, 12221, 13, 286, 39662, 2766, 1667, 8107, 586, 4199, 11, 34416, 298, 12996, 13083, 38156, 13, 710, 33362, 1381, 261, 4328, 1095, 305, 5103, 2316, 3611, 586, 64, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 117, "seek": 44916, "start": 456.16, "end": 461.16, "text": " Czyli model sam stworzy\u0142 sobie podr\u0119cznik, z kt\u00f3rego potem si\u0119 uczy\u0142.", "tokens": [50714, 37099, 2316, 3247, 342, 28321, 1229, 1221, 13652, 15305, 1274, 3689, 13123, 11, 710, 46951, 36513, 3244, 344, 6522, 1221, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 118, "seek": 44916, "start": 461.16, "end": 465.16, "text": " Genialne. A ostatni czwarty krok?", "tokens": [50964, 3632, 831, 716, 13, 316, 32686, 3722, 6472, 29587, 88, 350, 31621, 30, 51164], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 119, "seek": 44916, "start": 465.16, "end": 471.16, "text": " Na koniec przeprowadzili jeszcze jedn\u0105 rund\u0119 RL, tym razem by dostosowa\u0107 model do ludzkich preferencji.", "tokens": [51164, 6056, 5897, 35733, 30829, 1892, 345, 89, 2312, 14168, 5232, 13113, 23096, 1274, 497, 43, 11, 8107, 40225, 538, 20568, 329, 11445, 2316, 360, 15946, 30154, 480, 4382, 268, 19649, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 120, "seek": 44916, "start": 471.16, "end": 474.16, "text": " Chodzi\u0142o o pomocno\u015b\u0107 i nieszkodliwo\u015b\u0107.", "tokens": [51464, 761, 14543, 5249, 277, 48962, 23293, 741, 297, 15347, 74, 378, 2081, 48847, 13, 51614], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 121, "seek": 44916, "start": 474.16, "end": 478.16, "text": " I co z tego wszystkiego wysz\u0142o? Jakie by\u0142y ostateczne wyniki?", "tokens": [51614, 286, 598, 710, 8627, 14615, 12200, 261, 20589, 5249, 30, 15029, 414, 26366, 277, 15406, 38491, 31936, 9850, 30, 51814], "temperature": 0.0, "avg_logprob": -0.05267382334995937, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.04401347041130066}, {"id": 122, "seek": 47816, "start": 478.16, "end": 485.16, "text": " DeepSeq R1 osi\u0105gn\u0105\u0142 wydajno\u015b\u0107 porumywaln\u0105 stopowym modelem OpenIO 1.127.", "tokens": [50364, 14895, 10637, 80, 497, 16, 3003, 11404, 4568, 1611, 1221, 25984, 1805, 23293, 1515, 449, 27112, 304, 13113, 1590, 31691, 4391, 10386, 7238, 15167, 502, 13, 4762, 22, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 123, "seek": 47816, "start": 485.16, "end": 486.16, "text": " Naprawd\u0119?", "tokens": [50714, 18287, 20098, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 124, "seek": 47816, "start": 486.16, "end": 498.16, "text": " Tak. Na testie AIM-2024 uzyska\u0142 79,8% w metryce PassEd.1, minimalnie wyprzedzaj\u0105c wynik OpenIO.", "tokens": [50764, 9118, 13, 6056, 1500, 414, 316, 6324, 12, 2009, 7911, 16851, 749, 2330, 1221, 32803, 11, 23, 4, 261, 1131, 627, 384, 10319, 27061, 13, 16, 11, 13206, 2766, 4628, 1424, 11312, 89, 38757, 31936, 1035, 7238, 15167, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 125, "seek": 47816, "start": 498.16, "end": 499.16, "text": " Niesamowite.", "tokens": [51364, 426, 530, 335, 305, 642, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 126, "seek": 47816, "start": 499.16, "end": 506.16, "text": " Na testie Math 500 osi\u0105gn\u0105\u0142 97,3%, co jest wynikiem na r\u00f3wni z konkurencj\u0105.", "tokens": [51414, 6056, 1500, 414, 15776, 5923, 3003, 11404, 4568, 1611, 1221, 23399, 11, 18, 8923, 598, 3492, 31936, 1035, 4907, 1667, 11416, 895, 72, 710, 21428, 9873, 66, 8555, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 127, "seek": 47816, "start": 506.16, "end": 507.16, "text": " A programowanie?", "tokens": [51764, 316, 1461, 22028, 30, 51814], "temperature": 0.0, "avg_logprob": -0.1526843040220199, "compression_ratio": 1.2521008403361344, "no_speech_prob": 0.03416163846850395}, {"id": 128, "seek": 50716, "start": 507.16, "end": 512.1600000000001, "text": " W zadaniach z programowania na platformie CodeForces osi\u0105gn\u0105\u0142 poziom ekspercki.", "tokens": [50364, 343, 42788, 3782, 608, 710, 1461, 21308, 1667, 3663, 414, 15549, 12587, 887, 3003, 11404, 4568, 1611, 1221, 38503, 298, 30724, 610, 547, 72, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 129, "seek": 50716, "start": 512.1600000000001, "end": 516.1600000000001, "text": " To jest 96 centyl ludzkich uczestnik\u00f3w.", "tokens": [50614, 1407, 3492, 24124, 1489, 5088, 15946, 30154, 480, 35403, 377, 47447, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 130, "seek": 50716, "start": 516.1600000000001, "end": 517.1600000000001, "text": " Wow.", "tokens": [50814, 3153, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 131, "seek": 50716, "start": 517.1600000000001, "end": 523.1600000000001, "text": " I co wa\u017cne zachowa\u0142 te\u017c silne zdolno\u015bci w zadaniach og\u00f3lnych i konwersacyjnych.", "tokens": [50864, 286, 598, 46110, 29303, 30105, 9516, 3425, 716, 16221, 401, 16438, 261, 42788, 3782, 608, 5360, 15741, 9399, 741, 5897, 5364, 31285, 9399, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 132, "seek": 50716, "start": 523.1600000000001, "end": 526.1600000000001, "text": " Stworzyli wi\u0119c pot\u0119\u017cny model. To jasne.", "tokens": [51164, 745, 28321, 1229, 2081, 16677, 1847, 1274, 1427, 1634, 2316, 13, 1407, 361, 296, 716, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 133, "seek": 50716, "start": 526.1600000000001, "end": 531.1600000000001, "text": " Ale takie kolosy s\u0105 drogie, niedost\u0119pne dla wielu. Co z mniejszymi modelami?", "tokens": [51314, 9366, 15963, 17818, 329, 88, 9015, 3789, 9997, 11, 32488, 555, 18085, 716, 12285, 40437, 13, 3066, 710, 39513, 7706, 3057, 2316, 4526, 30, 51564], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 134, "seek": 50716, "start": 531.1600000000001, "end": 535.1600000000001, "text": " I tu dochodzimy do jednego z najciekawszych odkry\u0107 tej pracy.", "tokens": [51564, 286, 2604, 9243, 378, 89, 13189, 360, 5232, 11858, 710, 11212, 4260, 74, 1607, 45021, 3611, 43298, 2162, 12573, 35591, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07684790066310337, "compression_ratio": 1.3916083916083917, "no_speech_prob": 0.012356548570096493}, {"id": 135, "seek": 53516, "start": 535.16, "end": 538.16, "text": " Do procesu, kt\u00f3ry nazywa si\u0119 dystylacja.", "tokens": [50364, 1144, 17565, 84, 11, 9913, 20151, 88, 4151, 3244, 14584, 372, 5088, 23395, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 136, "seek": 53516, "start": 538.16, "end": 539.16, "text": " Dystylacja.", "tokens": [50514, 31193, 372, 5088, 23395, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 137, "seek": 53516, "start": 539.16, "end": 545.16, "text": " Tak. Wzi\u0119li te 800 tysi\u0119cy w wysokiej jako\u015bci przyk\u0142ad\u00f3w rozumowania,", "tokens": [50564, 9118, 13, 343, 16706, 2081, 535, 13083, 38156, 47303, 261, 27062, 453, 7764, 17123, 6199, 23144, 3901, 48797, 21308, 11, 50864], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 138, "seek": 53516, "start": 545.16, "end": 552.16, "text": " kt\u00f3re wygenerowa\u0142 DeepSync R1 i u\u017cyli ich do nauczenia mniejszych, popularnych modeli OpenSource.", "tokens": [50864, 8864, 4628, 21848, 30105, 14895, 50, 34015, 497, 16, 741, 34097, 2081, 1893, 360, 49103, 14320, 39513, 45021, 11, 3743, 9399, 2316, 72, 7238, 50, 2948, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 139, "seek": 53516, "start": 552.16, "end": 555.16, "text": " Takich jak kwen czy lama.", "tokens": [51214, 9118, 480, 4207, 350, 15615, 6430, 45423, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 140, "seek": 53516, "start": 555.16, "end": 560.16, "text": " I co? Mo\u017cna tak po prostu przela\u0107 zdolno\u015b\u0107 rozumowania z du\u017cego modelu do ma\u0142ego?", "tokens": [51364, 286, 598, 30, 44736, 629, 991, 714, 19518, 6541, 4053, 2162, 16221, 401, 23293, 48797, 21308, 710, 21783, 6308, 2316, 84, 360, 463, 1221, 6308, 30, 51614], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 141, "seek": 53516, "start": 560.16, "end": 564.16, "text": " Okazuje si\u0119, \u017ce tak. A efekty s\u0105 spektakularne.", "tokens": [51614, 3477, 43317, 3244, 11, 3561, 991, 13, 316, 31482, 916, 874, 9015, 768, 2320, 514, 1040, 716, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12378422181997727, "compression_ratio": 1.405693950177936, "no_speech_prob": 0.01733226142823696}, {"id": 142, "seek": 56416, "start": 564.16, "end": 570.16, "text": " Ma\u0142y, siedmiu miliardowy model nazwany DeepSync R1 Dystyl Kwen 7B", "tokens": [50364, 4042, 6825, 11, 262, 1091, 3057, 84, 1962, 72, 515, 10089, 2316, 20151, 86, 1325, 14895, 50, 34015, 497, 16, 31193, 372, 5088, 591, 15615, 1614, 33, 50664], "temperature": 0.0, "avg_logprob": -0.11875595006727635, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.03390529379248619}, {"id": 143, "seek": 56416, "start": 570.16, "end": 578.16, "text": " w zadaniach wymagaj\u0105cych rozumowania okaza\u0142 si\u0119 lepszy od znacznie wi\u0119kszych modeli, jak cho\u0107by GPT-4O.", "tokens": [50664, 261, 42788, 3782, 608, 29764, 559, 11133, 31306, 48797, 21308, 3133, 12257, 1221, 3244, 476, 1878, 1229, 3611, 15397, 14875, 2766, 29968, 28051, 2316, 72, 11, 4207, 1586, 2162, 2322, 26039, 51, 12, 19, 46, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11875595006727635, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.03390529379248619}, {"id": 144, "seek": 56416, "start": 578.16, "end": 580.16, "text": " To naprawd\u0119 robi wra\u017cenie.", "tokens": [51064, 1407, 20970, 47380, 7843, 41118, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11875595006727635, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.03390529379248619}, {"id": 145, "seek": 56416, "start": 580.16, "end": 586.16, "text": " Z kolei model 30-fu miliardowy znacz\u0105co przewy\u017cszy\u0142 O-Mine od OpenAI.", "tokens": [51164, 1176, 18303, 72, 2316, 2217, 12, 14127, 1962, 72, 515, 10089, 15397, 326, 8925, 1291, 39758, 88, 1427, 7706, 1221, 422, 12, 44, 533, 3611, 7238, 48698, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11875595006727635, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.03390529379248619}, {"id": 146, "seek": 56416, "start": 586.16, "end": 590.16, "text": " To rodzi kluczo\u0142y pytali mi, kt\u00f3re zreszt\u0105 autorzy sami sobie zadali.", "tokens": [51464, 1407, 8685, 3992, 9671, 1311, 4765, 6825, 25878, 5103, 2752, 11, 8864, 710, 495, 2682, 1611, 19510, 1229, 3247, 72, 13652, 42788, 5103, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11875595006727635, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.03390529379248619}, {"id": 147, "seek": 59016, "start": 590.16, "end": 596.16, "text": " Co jest lepsze? Uczy\u0107 ma\u0142y model od zera za pomoc\u0105 RL, tak jak zrobili z 1.0,", "tokens": [50364, 3066, 3492, 476, 1878, 1381, 30, 624, 33967, 463, 6825, 2316, 3611, 710, 1663, 7949, 48962, 1611, 497, 43, 11, 991, 4207, 44399, 2312, 710, 502, 13, 15, 11, 50664], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 148, "seek": 59016, "start": 596.16, "end": 600.16, "text": " czy destylowa\u0107 do niego wiedz\u0119 z wi\u0119kszego modelu?", "tokens": [50664, 6430, 2677, 5088, 11445, 360, 49615, 46894, 11052, 710, 29968, 27725, 2316, 84, 30, 50864], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 149, "seek": 59016, "start": 600.16, "end": 608.16, "text": " Zbadali to. Wytrenowali model QN32B metod\u0105 od zera i por\u00f3wnali go z wersj\u0105 destylowan\u0105.", "tokens": [50864, 1176, 27580, 5103, 281, 13, 343, 4328, 1095, 305, 5103, 2316, 1249, 45, 11440, 33, 1131, 378, 1611, 3611, 710, 1663, 741, 1515, 812, 895, 5103, 352, 710, 261, 433, 8555, 2677, 5088, 37345, 1611, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 150, "seek": 59016, "start": 608.16, "end": 609.16, "text": " I jaki by\u0142 wniosek?", "tokens": [51264, 286, 24492, 16673, 261, 3722, 541, 74, 30, 51314], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 151, "seek": 59016, "start": 609.16, "end": 613.16, "text": " Wersja destylowana by\u0142a znacznie, znacznie lepsza.", "tokens": [51314, 343, 433, 2938, 2677, 5088, 40458, 23936, 15397, 14875, 2766, 11, 15397, 14875, 2766, 476, 1878, 2394, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 152, "seek": 59016, "start": 613.16, "end": 616.16, "text": " Z tego p\u0142yn\u0105 chyba dwie wa\u017cne lekcje.", "tokens": [51514, 1176, 8627, 28695, 2534, 1611, 31532, 274, 8699, 46110, 30863, 44261, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07671693263163093, "compression_ratio": 1.3821138211382114, "no_speech_prob": 0.2505999803543091}, {"id": 153, "seek": 61616, "start": 616.16, "end": 622.16, "text": " Dok\u0142adnie. Po pierwsze, distillation jest niezwykle skuteczn\u0105 i, co wa\u017cne, ekonomiczn\u0105 metod\u0105.", "tokens": [50364, 29768, 10358, 2766, 13, 6165, 45994, 11, 42923, 399, 3492, 33511, 9726, 14677, 1110, 1169, 3689, 13113, 741, 11, 598, 46110, 11, 13359, 12481, 17946, 13113, 1131, 378, 1611, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 154, "seek": 61616, "start": 622.16, "end": 625.16, "text": " To \u015bwietna wiadomo\u015b\u0107 dla ca\u0142ej spo\u0142eczno\u015bci OpenSource.", "tokens": [50664, 1407, 8299, 39083, 629, 26393, 40633, 7753, 12285, 47631, 73, 36851, 89, 16438, 7238, 50, 2948, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 155, "seek": 61616, "start": 625.16, "end": 626.16, "text": " A po drugie?", "tokens": [50814, 316, 714, 4110, 414, 30, 50864], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 156, "seek": 61616, "start": 626.16, "end": 630.16, "text": " Po drugie, to pokazuje, \u017ce aby przesuwa\u0107 granice mo\u017cliwo\u015bci AI,", "tokens": [50864, 6165, 4110, 414, 11, 281, 13010, 43317, 11, 3561, 24457, 6541, 279, 84, 25234, 9370, 573, 30854, 36476, 7318, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 157, "seek": 61616, "start": 630.16, "end": 635.16, "text": " wci\u0105\u017c potrzebne s\u0105 pot\u0119\u017cniejsze modele bazowe i trening na ogromn\u0105 skal\u0119.", "tokens": [51064, 261, 537, 27242, 37595, 716, 9015, 1847, 1274, 1427, 44258, 4391, 306, 27147, 6880, 741, 2192, 773, 1667, 34416, 298, 13113, 16890, 1274, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 158, "seek": 61616, "start": 635.16, "end": 639.16, "text": " Czyli distillacja mo\u017ce tylko skopiowa\u0107 to, co ju\u017c wie nauczyciel?", "tokens": [51314, 37099, 42923, 23395, 12034, 13219, 1110, 404, 72, 11445, 281, 11, 598, 10678, 3355, 49103, 1229, 537, 338, 30, 51514], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 159, "seek": 61616, "start": 639.16, "end": 641.16, "text": " Nie stworzy nowej wiedzy. W\u0142a\u015bnie tak.", "tokens": [51514, 12016, 342, 28321, 1229, 586, 40779, 46894, 1229, 13, 343, 5024, 12221, 991, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 160, "seek": 61616, "start": 641.16, "end": 642.16, "text": " Odna.", "tokens": [51614, 12210, 629, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08077516555786132, "compression_ratio": 1.4207119741100325, "no_speech_prob": 0.08422429114580154}, {"id": 161, "seek": 64216, "start": 642.16, "end": 646.16, "text": " Oczywi\u015bcie. I autorzy otwarcie pisz\u0105 o swoich nieudanych pr\u00f3bach.", "tokens": [50364, 42980, 13, 286, 19510, 1229, 4337, 6925, 4260, 26584, 8925, 277, 13291, 480, 2838, 532, 34644, 8565, 32096, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 162, "seek": 64216, "start": 646.16, "end": 651.16, "text": " Na przyk\u0142ad pr\u00f3bowali zastosowa\u0107 tak zwany Process Reward Model.", "tokens": [50564, 6056, 23144, 8565, 8202, 5103, 36746, 329, 11445, 991, 11873, 1325, 31093, 1300, 1007, 17105, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 163, "seek": 64216, "start": 651.16, "end": 657.16, "text": " Czyli nagradzanie modelu za ka\u017cdy pojedynczy, poprawny krok w rozumowaniu, a nie tylko zako\u0144cowy wynik.", "tokens": [50814, 37099, 17096, 6206, 89, 7155, 2316, 84, 7949, 31615, 714, 40543, 2534, 6522, 11, 1665, 29603, 88, 350, 31621, 261, 48797, 305, 25849, 11, 257, 2838, 13219, 710, 18501, 5248, 66, 10089, 31936, 1035, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 164, "seek": 64216, "start": 657.16, "end": 659.16, "text": " W te\u0142owi brzmi to \u015bwietnie.", "tokens": [51114, 343, 535, 1221, 24503, 738, 89, 3057, 281, 8299, 39083, 2766, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 165, "seek": 64216, "start": 659.16, "end": 663.16, "text": " Brzmi, ale w praktyce okaza\u0142o si\u0119 zbyt trudne do skalowania.", "tokens": [51214, 1603, 89, 3057, 11, 6775, 261, 3206, 74, 874, 384, 3133, 12257, 5249, 3244, 710, 2322, 83, 32007, 716, 360, 16890, 21308, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 166, "seek": 64216, "start": 663.16, "end": 666.16, "text": " Cieszko jest zdefiniowa\u0107, co to jest poprawny krok.", "tokens": [51414, 383, 15347, 4093, 3492, 710, 20595, 3812, 11445, 11, 598, 281, 3492, 1665, 29603, 88, 350, 31621, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 167, "seek": 64216, "start": 666.16, "end": 669.16, "text": " Jeszcze ci\u0119\u017cej to automatycznie ocenia\u0107.", "tokens": [51564, 2547, 89, 9680, 35484, 38493, 281, 28034, 17466, 2766, 10409, 268, 654, 2162, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09060089884240644, "compression_ratio": 1.44, "no_speech_prob": 0.18159444630146027}, {"id": 168, "seek": 66916, "start": 669.16, "end": 673.16, "text": " A co z innymi pr\u00f3bami? S\u0142ysza\u0142am, \u017ce testowali te\u017c Monte Carlo Tree Search.", "tokens": [50364, 316, 598, 710, 294, 31813, 8565, 65, 4526, 30, 318, 1221, 749, 2394, 20177, 11, 3561, 1500, 305, 5103, 9516, 38105, 45112, 22291, 17180, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 169, "seek": 66916, "start": 673.16, "end": 678.16, "text": " Tak. Technik\u0119 znan\u0105 z AlphaGo. Niestety to te\u017c si\u0119 nie sprawdzi\u0142o.", "tokens": [50564, 9118, 13, 8337, 1035, 1274, 710, 17622, 1611, 710, 20588, 12104, 13, 426, 6495, 2210, 281, 9516, 3244, 2838, 46192, 3992, 5249, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 170, "seek": 66916, "start": 678.16, "end": 679.16, "text": " Dlaczego?", "tokens": [50814, 413, 75, 39329, 30, 50864], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 171, "seek": 66916, "start": 679.16, "end": 684.16, "text": " Bo przestrze\u0144 mo\u017cliwych odpowiedzi w j\u0119zyku jest niesko\u0144czenie wi\u0119ksza ni\u017c na szachownicy.", "tokens": [50864, 3286, 44264, 13503, 5248, 30854, 9726, 339, 36574, 3992, 261, 49055, 5279, 3492, 48100, 4093, 5248, 39043, 29968, 2394, 28502, 1667, 7870, 608, 648, 2632, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 172, "seek": 66916, "start": 684.16, "end": 688.16, "text": " Podej\u015bcie, kt\u00f3re da\u0142o mistrzostwo w go tutaj po prostu nie zadzia\u0142a\u0142o.", "tokens": [51114, 39168, 73, 9815, 11, 8864, 1120, 5249, 3544, 19390, 555, 6120, 261, 352, 12749, 714, 19518, 2838, 42788, 89, 25605, 5249, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 173, "seek": 66916, "start": 688.16, "end": 694.16, "text": " Dobrze. A jakie s\u0105 obecne wady samego DeepSync R1? Tego finalnego modelu.", "tokens": [51314, 29679, 13503, 13, 316, 22124, 9015, 49141, 716, 261, 880, 912, 1571, 14895, 50, 34015, 497, 16, 30, 314, 6308, 2572, 11858, 2316, 84, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09507026260705304, "compression_ratio": 1.3666666666666667, "no_speech_prob": 0.17250755429267883}, {"id": 174, "seek": 69416, "start": 694.16, "end": 698.16, "text": " G\u0142\u00f3wne ograniczenia, kt\u00f3re sami wymieniaj\u0105, to po pierwsze,", "tokens": [50364, 460, 1221, 3901, 716, 34416, 30732, 14320, 11, 8864, 3247, 72, 29764, 18811, 8555, 11, 281, 714, 45994, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 175, "seek": 69416, "start": 698.16, "end": 702.16, "text": " \u017ce nie jest jeszcze tak dobry w zadaniach og\u00f3lnych jak jego poprzednik.", "tokens": [50564, 3561, 2838, 3492, 14168, 991, 35884, 261, 42788, 3782, 608, 5360, 15741, 9399, 4207, 26542, 1665, 81, 11312, 13123, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 176, "seek": 69416, "start": 702.16, "end": 704.16, "text": " DeepSync V3.", "tokens": [50764, 14895, 50, 34015, 691, 18, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 177, "seek": 69416, "start": 704.16, "end": 708.16, "text": " Czyli specjalizacja w rozumowaniu kosztowa\u0142a go troch\u0119 wszechstronno\u015bci.", "tokens": [50864, 37099, 46433, 590, 23395, 261, 48797, 305, 25849, 19532, 2682, 5528, 5024, 352, 24926, 37647, 19439, 372, 2044, 16438, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 178, "seek": 69416, "start": 708.16, "end": 711.16, "text": " Mo\u017cna tak powiedzie\u0107. To klasyczny dylemat.", "tokens": [51064, 44736, 629, 991, 27886, 13, 1407, 9671, 5871, 3689, 1634, 274, 2072, 15677, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 179, "seek": 69416, "start": 711.16, "end": 714.16, "text": " Po drugie, wci\u0105\u017c ma problemy zmieszaniem j\u0119zyk\u00f3w.", "tokens": [51214, 6165, 4110, 414, 11, 261, 537, 27242, 463, 1154, 88, 17020, 15347, 282, 4907, 49055, 23849, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 180, "seek": 69416, "start": 714.16, "end": 716.16, "text": " Je\u015bli zapytanie nie jest po angielsku lub chi\u0144sku.", "tokens": [51364, 37086, 14223, 4328, 7155, 2838, 3492, 714, 2562, 1187, 5161, 84, 15980, 13228, 27125, 84, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 181, "seek": 69416, "start": 716.16, "end": 720.16, "text": " Czyli tego problemu z Rn0 nie uda\u0142 im si\u0119 do ko\u0144ca wyeliminowa\u0107.", "tokens": [51464, 37099, 8627, 1154, 84, 710, 497, 77, 15, 2838, 44544, 1221, 566, 3244, 360, 26470, 496, 4628, 338, 4395, 11445, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08411859044965529, "compression_ratio": 1.395638629283489, "no_speech_prob": 0.07588327676057816}, {"id": 182, "seek": 72016, "start": 720.16, "end": 725.16, "text": " Po trzecie jest bardzo wra\u017cliwy na spos\u00f3b formu\u0142owania zapyta\u0144, czyli na prompting.", "tokens": [50364, 6165, 22266, 4260, 3492, 9034, 7843, 1427, 2081, 9726, 1667, 22904, 1254, 84, 1221, 21308, 14223, 88, 1328, 5248, 11, 16591, 1667, 12391, 278, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 183, "seek": 72016, "start": 725.16, "end": 730.16, "text": " I na koniec przyznaj\u0105, \u017ce wymaga dalszych prac nad zadaniami z in\u017cynierii oprogramowania.", "tokens": [50614, 286, 1667, 5897, 35733, 6501, 35458, 8555, 11, 3561, 29764, 9286, 274, 1124, 28051, 22404, 12617, 710, 11338, 15568, 710, 294, 1427, 2534, 811, 5597, 999, 340, 1342, 21308, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 184, "seek": 72016, "start": 730.16, "end": 733.16, "text": " Ok. To podsumujmy ca\u0142\u0105 t\u0105 podr\u00f3\u017c.", "tokens": [50864, 3477, 13, 1407, 31925, 449, 4579, 2226, 1335, 15926, 32294, 2497, 11721, 1427, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 185, "seek": 72016, "start": 733.16, "end": 739.16, "text": " Ta praca pokazuje, \u017ce mo\u017cna nauczy\u0107 model rozumowania stosuj\u0105c czysty reinforcement learning.", "tokens": [51014, 6551, 582, 6628, 13010, 43317, 11, 3561, 17790, 49103, 27150, 2316, 48797, 21308, 43581, 44733, 6430, 25134, 29280, 2539, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 186, "seek": 72016, "start": 739.16, "end": 742.16, "text": " Co udowodni\u0142 eksperyment z Rn0?", "tokens": [51314, 3066, 11727, 305, 378, 3722, 1221, 30724, 610, 88, 518, 710, 497, 77, 15, 30, 51464], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 187, "seek": 72016, "start": 742.16, "end": 747.16, "text": " Tak. Pokazuje te\u017c, \u017ce podej\u015bcie hybrydowe, kt\u00f3re \u0142\u0105czy SFT i RL,", "tokens": [51464, 9118, 13, 14958, 43317, 9516, 11, 3561, 7468, 73, 9815, 2477, 65, 627, 67, 6880, 11, 8864, 220, 15926, 6522, 31095, 51, 741, 497, 43, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08734242121378581, "compression_ratio": 1.398671096345515, "no_speech_prob": 0.3960755467414856}, {"id": 188, "seek": 74716, "start": 748.16, "end": 751.16, "text": " daje bardziej dopracowane, przyjazne rezultaty.", "tokens": [50414, 1120, 2884, 27209, 360, 1424, 326, 23066, 11, 6501, 34820, 716, 48060, 723, 21398, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 189, "seek": 74716, "start": 751.16, "end": 755.16, "text": " A na koniec udowodni\u0119, \u017ce distillation to pot\u0119\u017cne narz\u0119dzie,", "tokens": [50564, 316, 1667, 5897, 35733, 11727, 305, 378, 35938, 11, 3561, 42923, 399, 281, 1847, 1274, 1427, 716, 6714, 89, 42643, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 190, "seek": 74716, "start": 755.16, "end": 759.16, "text": " \u017ceby udost\u0119pni\u0107 te zaawansowane zdolno\u015bci szerszemu gronu.", "tokens": [50764, 11316, 11727, 555, 18085, 3722, 2162, 535, 7949, 1607, 599, 23066, 16221, 401, 16438, 7870, 433, 24313, 84, 677, 266, 84, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 191, "seek": 74716, "start": 759.16, "end": 763.16, "text": " Ale wiesz co? Mnie w tym wszystkim najbardziej fascynuje co\u015b innego.", "tokens": [50964, 9366, 261, 15347, 598, 30, 376, 2766, 261, 8107, 30481, 41857, 30632, 1344, 77, 13008, 19241, 294, 11858, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 192, "seek": 74716, "start": 763.16, "end": 764.16, "text": " Co takiego?", "tokens": [51164, 3066, 32296, 30, 51214], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 193, "seek": 74716, "start": 764.16, "end": 769.16, "text": " To, \u017ce rozumowanie okazuje si\u0119 nie tylko kwesti\u0105 zapami\u0119tanych fakt\u00f3w,", "tokens": [51214, 1407, 11, 3561, 48797, 22028, 3133, 43317, 3244, 2838, 13219, 42035, 11404, 14223, 23806, 83, 34644, 21310, 3901, 11, 51464], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 194, "seek": 74716, "start": 769.16, "end": 772.16, "text": " ale wykszta\u0142cenia pewnego procesu.", "tokens": [51464, 6775, 4628, 1694, 89, 46426, 13037, 654, 25889, 11858, 17565, 84, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06176458193561223, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.008191014640033245}, {"id": 195, "seek": 77216, "start": 772.16, "end": 777.16, "text": " Ten moment a haft modelu nie polega\u0142 na tym, \u017ce on sobie co\u015b przypomnia\u0142.", "tokens": [50364, 9380, 1623, 257, 324, 844, 2316, 84, 2838, 13208, 3680, 1221, 1667, 8107, 11, 3561, 322, 13652, 19241, 41780, 38131, 8908, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 196, "seek": 77216, "start": 777.16, "end": 783.16, "text": " On sobie u\u015bwiadomi\u0142, \u017ce jego w\u0142asny wewn\u0119trzny proces my\u015blowy by\u0142 wadliwy i wymaga\u0142 zmiany.", "tokens": [50614, 1282, 13652, 344, 37750, 9220, 1221, 11, 3561, 26542, 43572, 1634, 321, 895, 1274, 6903, 89, 1634, 17565, 452, 19212, 10089, 16673, 261, 345, 2081, 9726, 741, 29764, 9286, 1221, 43591, 88, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 197, "seek": 77216, "start": 783.16, "end": 785.16, "text": " I to jest fundamentalna r\u00f3\u017cnica.", "tokens": [50914, 286, 281, 3492, 8088, 629, 19637, 32687, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 198, "seek": 77216, "start": 785.16, "end": 790.16, "text": " No w\u0142a\u015bnie. I to zostawia nas z tak\u0105, wiesz, prowokuj\u0105c\u0105 my\u015bl\u0105 na koniec.", "tokens": [51014, 883, 14234, 13, 286, 281, 31873, 34953, 5382, 710, 31069, 11, 261, 15347, 11, 45553, 453, 13263, 32557, 452, 19212, 1611, 1667, 5897, 35733, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 199, "seek": 77216, "start": 790.16, "end": 796.16, "text": " Dok\u0142adnie. Skoro uczymy modele tworzenia coraz bardziej z\u0142o\u017conych wewn\u0119trznych proces\u00f3w my\u015blowych,", "tokens": [51264, 29768, 10358, 2766, 13, 7324, 10780, 344, 6522, 2226, 4391, 306, 46288, 14320, 25899, 27209, 710, 5249, 1427, 2526, 339, 321, 895, 1274, 6903, 89, 9399, 17565, 3901, 452, 19212, 19605, 11, 51564], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 200, "seek": 77216, "start": 796.16, "end": 801.16, "text": " kt\u00f3re obejmuj\u0105 refleksje i zmiany strategii, to czy my tworzymy tylko lepsze narz\u0119dzia?", "tokens": [51564, 8864, 36346, 35195, 13263, 36549, 1694, 2884, 741, 43591, 88, 5464, 5597, 11, 281, 6430, 452, 46288, 1229, 2226, 13219, 476, 1878, 1381, 6714, 89, 6298, 40395, 30, 51814], "temperature": 0.0, "avg_logprob": -0.06263692290694625, "compression_ratio": 1.5, "no_speech_prob": 0.06205186992883682}, {"id": 201, "seek": 80116, "start": 801.16, "end": 806.16, "text": " Czy mo\u017ce robimy krok w kierunku systemu, kt\u00f3ry potrafi autentycznie analizowa\u0107 \u015bwiat?", "tokens": [50364, 19832, 12034, 3870, 13189, 350, 31621, 261, 38767, 49910, 1185, 84, 11, 9913, 1847, 10437, 72, 1476, 4179, 19923, 2624, 590, 11445, 36425, 30, 50614], "temperature": 0.0, "avg_logprob": -0.07110549635806326, "compression_ratio": 1.1216216216216217, "no_speech_prob": 0.025707613676786423}, {"id": 202, "seek": 80116, "start": 806.16, "end": 807.16, "text": " W daniach?", "tokens": [50614, 343, 274, 3782, 608, 30, 50664], "temperature": 0.0, "avg_logprob": -0.07110549635806326, "compression_ratio": 1.1216216216216217, "no_speech_prob": 0.025707613676786423}, {"id": 203, "seek": 80116, "start": 807.16, "end": 811.16, "text": " To potencjalna zmiana regu\u0142 gry w dost\u0119pie do zaawansowanej AI.", "tokens": [50664, 1407, 1847, 22660, 22600, 629, 17020, 8497, 1121, 84, 1221, 41974, 261, 20568, 1274, 9144, 360, 7949, 1607, 599, 23066, 73, 7318, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07110549635806326, "compression_ratio": 1.1216216216216217, "no_speech_prob": 0.025707613676786423}], "language": "pl"}