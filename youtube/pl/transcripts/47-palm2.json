{"text": " Mam tutaj przed sob\u0105, wiesz, ten raport techniczny od Google o ich nowym modelu j\u0119zykowym, Palm 2. I powiem szczerze, co\u015b mi tu po prostu nie gra. W \u015bwiecie AI od lat panuje jedna zasada. Im wi\u0119kszy model, tym lepszy. Wszyscy si\u0119 \u015bcigaj\u0105, kto zbuduje cyfrowego giganta z wi\u0119ksz\u0105 liczb\u0105 parametr\u00f3w. A tutaj czytam, \u017ce Palm 2 jest znacz\u0105co mniejszy od swojego poprzednika. A jednocze\u015bnie znacznie od niego lepszy. To kompletnie wywraca stolik. Wygl\u0105da na to, \u017ce nie chodzi tu tylko o jak\u0105\u015b tam aktualizacj\u0119, ale o fundamentaln\u0105 zmian\u0119 filozofii. Spr\u00f3bujmy dzisiaj rozgry\u017a\u0107, co tak naprawd\u0119 stoi za tym prze\u0142omem. Bo to jest co\u015b wi\u0119cej ni\u017c tylko, wiesz, nowy produkt. To jest manifestacja nowego podej\u015bcia. Skupimy si\u0119 na trzech rzeczach. Po pierwsze, co jest tym tajemniczym sk\u0142adnikiem? Jak oni to zrobili, \u017ce mniejsze znaczy lepsze? Po drugie, zobaczymy dowody w praktyce, jak ten model radzi sobie z zadaniami, odpisania kodu po zdawanie egzamin\u00f3w, kt\u00f3re obla\u0142 jego pot\u0119\u017cniejszy przodek. I na koniec, co jest niezwykle wa\u017cne, przyjrzymy si\u0119, jak raport podchodzi do ogranicze\u0144 i odpowiedzialno\u015bci. Bo jak wiemy, z wielk\u0105 moc\u0105, no w\u0142a\u015bnie. To jest idealne podsumowanie. To jest, wiesz, dok\u0142adnie ten moment, kiedy ca\u0142a bran\u017ca przechodzi od takiego my\u015blenia w kategoriach wi\u0119cej, wi\u0119cej, wi\u0119cej, do m\u0105drzej. Dok\u0142adnie tak, do m\u0105drzej. Zamiast budowa\u0107 coraz wi\u0119ksze silniki, zacz\u0119li\u015bmy wreszcie zastanawia\u0107 si\u0119 nad jako\u015bci\u0105 paliwa i konstrukcj\u0105 samego mechanizmu. I ten raport opiera ca\u0142\u0105 t\u0119 rewolucj\u0119 w zasadzie na trzech filarach. Pierwszy to co\u015b, co nazywaj\u0105 compute optimal scaling. Czyli znalezienie idealnego balansu mi\u0119dzy rozmiarem modelu, ilo\u015bci\u0105 danych, a dost\u0119pn\u0105 moc\u0105 obliczeniow\u0105. Drugi filar to radykalnie inne paliwo, niewyobra\u017calnie zr\u00f3\u017cnicowany, wieloj\u0119zyczne zbi\u00f3r danych. A trzeci to po prostu sprytniejsze cele samego treningu. To nie jest jeden magiczny trik, tylko synergia tych trzech element\u00f3w. Czekaj, zatrzymajmy si\u0119 przy tym pierwszym filarze. Compute optimal scaling. To brzmi bardzo technicznie, ale idea za tym wydaje si\u0119, no, rewolucyjna. Czy to znaczy, \u017ce do tej pory wszyscy w bran\u017cy robili to \u017ale, budowali za du\u017ce modele i za ma\u0142o je karmili danymi? W pewnym sensie tak, to nie jest, wiesz, zupe\u0142nie nowa koncepcja wcze\u015bniejsze badania, na przyk\u0142ad te od Hofmana. Z 2022 roku ju\u017c to sugerowa\u0142y. Ale Google potwierdzi\u0142 to teraz na niewyobra\u017caln\u0105 skal\u0119. Okaza\u0142o si\u0119, \u017ce dotyczczasowy trend by\u0142, no, po prostu niew\u0142a\u015bciwy. Modele, czyli liczba ich parametr\u00f3w, ros\u0142y jakie\u015b trzy razy szybciej ni\u017c ilo\u015b\u0107 danych, na kt\u00f3rych je trenowano. Aha. To troch\u0119 tak, jakby\u015b budowa\u0142 m\u00f3zg wielko\u015bci planety, ale karmi\u0142 go tylko jedn\u0105 ksi\u0105\u017ck\u0105. Palm II to jest pr\u00f3ba naprawienia tej dysproporcji. Stwierdzono, \u017ce optymalny wzrost to mniej wi\u0119cej jeden do jednego. O ile powi\u0119kszasz model, o tyle samo musisz zwi\u0119kszy\u0107 ilo\u015b\u0107 danych. Czyli kluczem jest nie tylko to, \u017ceby model by\u0142 du\u017cy, \u017ceby mia\u0142 proporcjonalnie du\u017co do przeczytania. I jak rozumiem, to czytanie te\u017c si\u0119 zmieni\u0142o. Raport m\u00f3wi o ulepszonej mieszance danych. To nie by\u0142a po prostu wi\u0119ksza ilo\u015b\u0107 tego samego, co wcze\u015bniej. Absolutnie nie. I to jest ten drugi kluczowy filar. Stersze modele, w tym pierwszy palm, by\u0142y trenowane na danych, w kt\u00f3rych angielski stanowi\u0142 czasem nawet 78%. A\u017c tyle. Tak, to tworzy\u0142o bardzo anglocentryczny obraz \u015bwiata. Zbi\u00f3r danych dla Palm II jest radykalnie inny. Obejmuje setki j\u0119zyk\u00f3w, jest znacznie bardziej zr\u00f3\u017cnicowany tematycznie. Zawiera nie tylko strony internetowe, ale te\u017c ksi\u0105\u017cki, kod programistyczny z r\u00f3\u017cnych repozytor\u00f3w, artyku\u0142y naukowe z matematyki, a nawet dane konwersacyjne, czyli dialogi. A co z tymi parallel data? To brzmi jak co\u015b, co mog\u0142o da\u0107 mu super moce w t\u0142umaczeniu. Dok\u0142adnie tak. Parallel data to s\u0105 zbiory tekst\u00f3w, kt\u00f3re s\u0105 swoim dok\u0142adnym t\u0142umaczeniem. Na przyk\u0142ad ten sam artyku\u0142 po polsku i po angielsku. Karmi\u0105c model takimi parami, on nie uczy si\u0119 tylko statystyki s\u0142\u00f3w w danym j\u0119zyku, ale bezpo\u015brednio obserwuje, jak idee i struktury gramatyczne przenosz\u0105 si\u0119 z jednego j\u0119zyka na drugi. Czyli to jak dawanie studentowi klucza odpowiedzi do zada\u0144 z t\u0142umaczenia. W\u0142a\u015bnie. Chwila to jest niesamowite, czyli zamiast kaza\u0107 mu wk\u00f3\u0142ko robi\u0107 to samo, przewidywa\u0107 nast\u0119pne s\u0142owo w zdaniu, oni zrobili mu taki intensywny ob\u00f3z treningowy dla umys\u0142u. Mo\u017cna tak powiedzie\u0107. To jest ten trzeci filar inspirowany wcze\u015bniejszym modelem o nazwie UL2. Zamiast jednego monotonnego celu, Palm II dosta\u0142 dostrojon\u0105 mieszank\u0119 r\u00f3\u017cnych cel\u00f3w treningowych. Por\u00f3wnaj to do nauki. Mo\u017cesz uczy\u0107 si\u0119 na pami\u0119\u0107, co jest jednym celem, przewidywanie nast\u0119pnego s\u0142owa, ale mo\u017cesz te\u017c jednocze\u015bnie uczy\u0107 si\u0119 pisa\u0107 eseje, straszcza\u0107 teksty, rozwi\u0105zywa\u0107 \u0142omig\u0142\u00f3wki logiczne i prowadzi\u0107 debaty. Ka\u017cdy z tych zada\u0144 uczycie czego\u015b innego o j\u0119zyku i rozumowaniu. Taki zr\u00f3\u017cnicowany trening sprawia, \u017ce model nie jest tylko papug\u0105, ale zaczyna rozumie\u0107 j\u0119zyk z wielu r\u00f3\u017cnych perspektyw. I to w\u0142a\u015bnie przek\u0142ada si\u0119 na jego znacznie lepsze zdolno\u015bci rozumowania, o kt\u00f3rych zaraz powiemy. Wszystko to brzmi \u015bwietnie w teorii, lepszy balans, lepsze dane, m\u0105drzejszy trening. Ale pytanie, czy to naprawd\u0119 czu\u0107 w praktyce? Czy ten model faktycznie jest inteligentniejszy, czy po prostu inaczej wytresowany? Raport na szcz\u0119\u015bcie daje konkretne przyk\u0142ady, zaczynaj\u0105c od czego\u015b, co jest ostatecznym testem dla ka\u017cdego poligloty egzamin\u00f3w j\u0119zykowych. I to jest przyk\u0142ad, kt\u00f3ry najlepiej obrazuje t\u0105 zmian\u0119. Wyobra\u017a sobie, \u017ce zdajesz najtrudniejszy oficjalny egzamin z chi\u0144skiego, albo japo\u0144skiego, na poziomie C2. Poziom C2, czyli mistrzowski. Tak, to jest poziom, kt\u00f3ry pozwala ci oficjalnie uczy\u0107 tego j\u0119zyka. Palm II zda\u0142 te egzaminy. Chi\u0144ski HSK, japo\u0144ski J-test, w\u0142oski Plida, hiszpa\u0144ski Dele. A teraz najlepsze. Jego znacznie wi\u0119kszy pokrzednik, Palm, obla\u0142 wi\u0119kszo\u015b\u0107 z nich z kretesem. Niesamowite. To jest namacalny, bezpo\u015bredni dow\u00f3d na to, jak skuteczny by\u0142 ten wieloj\u0119zyczny trening. Dobra, j\u0119zyki to jedno, ale to cz\u0119sto mo\u017ce by\u0107 kwestia wykucia na blach\u0119 ogromnej ilo\u015bci danych. A co z czym\u015b, co wymaga prawdziwego my\u015blenia, jak matematyka, czy wieloetapowe zadania logiczne? To zawsze by\u0142a pi\u0119ta achilesowa tych modeli. Tu post\u0119p jest chyba jeszcze bardziej imponuj\u0105ce. Jest taki benchmark, sw\u00f3j stytor Przeszk\u00f3d dla AI, nazywa si\u0119 Big Bench Hard. W jednym z zada\u0144, Multistep Arithmetic, kt\u00f3re wymaga wykonania kilku operacji matematycznych w odpowiedniej kolejno\u015bci, poprawa wynik\u00f3w po r\u00f3wnaniu do starego modelu wynoszy ponad 286%. Zaraz 286%, ale raport wspomina, \u017ce to przy zastosowaniu Chain of Fault Prompting. Co to dok\u0142adnie znaczy? \u015awietne pytanie. Chain of Fault Prompting to jest technika, w kt\u00f3rej nie prosimy modelu po prostu o ko\u0144cow\u0105 odpowied\u017a. Zamiast tego, m\u00f3wimy o, poka\u017cmy, jak do tego doszed\u0142e\u015b, krok po kroku. To go zmusza do rozpisania swojego toku my\u015blenia. I okazuje si\u0119, \u017ce modele, tak jak ludzie, radz\u0105 sobie znacznie lepiej ze z\u0142o\u017conymi problemami, gdy mog\u0105 je rozbi\u0107 na mniejsze cz\u0119\u015bci. Ten gigantyczny skok wydajno\u015bci pokazuje, \u017ce Palm II nie tylko zna odpowied\u017a, ale potrafi te\u017c lepiej symu\u0142owa\u0107 proces logicznego rozumowania, \u017ceby do niej doj\u015b\u0107. To ma sens. A co ciekawe, ta umiej\u0119tno\u015b\u0107 rozumowania przenosi si\u0119 te\u017c na matematyk\u0119, na poziomie, kt\u00f3ry jest ju\u017c naprawd\u0119 wysoki. Tak, na standardowych testach matematycznych, takich jak GSMOid K, Palm II radzi sobie na poziomie, a czasem nawet lepiej ni\u017c w specjalizowane modele, jak Minerva. Minerva, czyli ten model trenowany specjalnie do matmy. Dok\u0142adnie. A Palm II osi\u0105ga to niejako przy okazji, dzi\u0119ki swojemu og\u00f3lnemu, ulepszonemu treningu rozumowania. Mniejszy model, ale nakarmiony lepszej jako\u015bci, bardziej zr\u00f3\u017cnicowanym kodem i trenowanym m\u0105drzejszymi metodami, okazuje si\u0119 po prostu lepszym programist\u0105. Ale to, co jest naprawd\u0119 fascynuj\u0105ce, to jego zdolno\u015bci w programowaniu wieloj\u0119zycznym. O tak. Wida\u0107 gigantyczn\u0105 popraw\u0119 w bardziej niszowych j\u0119zykach, jak Haskell czy Julia, gdzie wzrost wydajno\u015bci jest kilkukrotny, a najwi\u0119ksza niespodzianka. Jego wyniki w generowaniu kodu w j\u0119zykach Java, JavaScript i TypeScript s\u0105 lepsze ni\u017c w Paitonie, a przecie\u017c oryginalny benchmark zosta\u0142 stworzony w\u0142a\u015bnie dla Paitona. Niesamowite. To co to wszystko oznacza w praktyce dla przeci\u0119tnego u\u017cytkownika? Czy m\u00f3j Google Translate b\u0119dzie teraz dzia\u0142a\u0142 o niebo lepiej? W\u0142a\u015bnie tak. Raport pokazuje, \u017ce Palm II w t\u0142umaczeniach nie tylko przewy\u017csza swojego poprzednika, ale jest w pe\u0142ni konkurencyjny dla dedykowanych produkcyjnych system\u00f3w, jak dotychczasowy Google Translate. W bezpo\u015brednich testach por\u00f3wnawczych dla par chi\u0144ski, angielski i angielski niemiecki t\u0142umaczenia generowane przez Palm II by\u0142y oceniane przez ludzi jako znacznie lepsze. Co wi\u0119cej, dzi\u0119ki tym zr\u00f3\u017cnicowanym danym model znacznie lepiej radzi sobie z t\u0142umaczeniem niuans\u00f3w i dialekt\u00f3w regionalnych. OK, model jest m\u0105drzejszy, szybszy, lepszy. Brzmi idealnie, ale zwykle w takich historiach jest jaki\u015b haczyk. Raport nie zamiata problem\u00f3w pod dywan, prawda? Jak wygl\u0105da kwestia, powiedzmy, pami\u0119ci tego modelu i prywatno\u015bci danych? To bardzo wa\u017cny i z\u0142o\u017cony temat. Wniki s\u0105 tu, no, niejednoznaczne, co raport uczciwie przyznaje. Z jednej strony, Palm II \u015brednio rzadziej wypluwa z siebie unikalne, dos\u0142owne fragmenty danych treningowych. To du\u017cy plus dla prywatno\u015bci. Ale? Ale jest te\u017c druga strona medalu. Je\u015bli jaki\u015b fragment tekstu, np. popularny cytat, albo fragment regulaminu, by\u0142 w danych treningowych powtarzany tysi\u0105ce razy, to Palm II ma wi\u0119ksz\u0105 sk\u0142onno\u015b\u0107 do jego zapami\u0119tania i odtworzenia ni\u017c stare model. Z czego to mo\u017ce wynika\u0107? Prawdopodobnie to efekt uboczny procesu deduplikacji danych. Kiedy usuwasz wi\u0119kszo\u015b\u0107 powt\u00f3rze\u0144, te kt\u00f3re zostaj\u0105, staj\u0105 si\u0119 statystycznie bardziej widoczne dla modelu. Co paradoksalnie mo\u017ce zwi\u0119ksza\u0107 szanse na ich zapami\u0119tanie? Dokodnie. To pokazuje, jak skomplikowane s\u0105 te systemy i jak jedna poprawka mo\u017ce nieoczepiwanie wp\u0142yn\u0105\u0107 na inny aspekt ich dzia\u0142ania. A co zgenerowaniem, no wiesz, toksycznych, nieprzyjemnych tre\u015bci? Wiemy, \u017ce internet jest ich pe\u0142em, a to przecie\u017c g\u0142\u00f3wny \u017ar\u00f3d\u0142o danych. Da si\u0119 to jako\u015b kontrolowa\u0107? Pr\u00f3bowano. Podczas trening\u00f3w prowadzono specjalne tokeny kontrolne, kt\u00f3re oznacza\u0142y fragmenty tekstu jako ma\u0142o, \u015brednio lub bardzo toksyczne. Teoretycznie, podczas generowania odpowiedzi mo\u017cna by u\u017cy\u0107 tych token\u00f3w, \u017ceby nakaza\u0107 modelowi b\u0105d\u017a mi\u0142y. I co, dzia\u0142a? No w\u0142a\u015bnie, tutaj raport dochodzi do bardzo ciekawego wniosku. Okazuje si\u0119, \u017ce cz\u0119sto prosty prompt dialogowy, czyli instrukcja w stylu wciel si\u0119 w rol\u0119 pomocnego i uprzejmego asystenta, by\u0142 skuteczniejszy w redukcji toksyczno\u015bci. Skuteczniejszy ni\u017c te wszystkie skomplikowane tokeny kontrolne? Tak. To troch\u0119 podwa\u017ca sensowno\u015b\u0107 niekt\u00f3rych metod i pokazuje, \u017ce czasem najprostsze rozwi\u0105zania s\u0105 najlepsze. I to prowadzi do szerszego problemu, kt\u00f3ry wida\u0107 po analizie samych danych treningowych. Raport potwierdza to, czego wielu si\u0119 domy\u015bla\u0142o. Dane s\u0105 mocno przechylane strony o kultury zachodniej, a kobiety s\u0105 w nich niedostatecznie reprezentowane. Co wi\u0119cej, analiza wykaza\u0142a, \u017ce dokumenty, w kt\u00f3rych pojawiaj\u0105 si\u0119 okre\u015blenia pewnych grup to\u017csamo\u015bciowych, statystycznie cz\u0119\u015bciej zawieraj\u0105 tre\u015bci toksyczne. Czyli problem jest w danych \u017ar\u00f3d\u0142owych? Tak. To pokazuje, \u017ce nawet przyznacznie bardziej zr\u00f3\u017cnicowanych danych problem stronniczo\u015bci i uprzedze\u0144 wbudowanych w j\u0119zyk, kt\u00f3rego uczymy AI, pozostaje ogromnym, nierozwi\u0105zanym wyzwaniem. To nie jest co\u015b, co mo\u017cna naprawi\u0107 tylko lepszym algorytmem. To odbicie problem\u00f3w w naszym spo\u0142ecze\u0144stwie. Podsumowuj\u0105c, lekcja z tego raportu wydaje si\u0119 prosta, ale i pot\u0119\u017cna. W AI nadszed\u0142 czas na prac\u0119 m\u0105dr\u0105, a nie tylko ci\u0119\u017ck\u0105. Okazuje si\u0119, \u017ce liczy si\u0119 jako\u015b\u0107 danych, sprytny, wieloaspektowy trening i znalezienie w\u0142a\u015bciwej r\u00f3wnowagi, a nie tylko \u015blep\u0119 d\u0105\u017cenie do budowy jak najwi\u0119kszego modelu. Dok\u0142adnie. Szer\u017csza perspektywa jest taka, \u017ce wchodzimy w erefektywno\u015bci i inteligencji projektu, a nie tylko surowej skali. To mo\u017ce oznacza\u0107, \u017ce przysz\u0142o\u015b\u0107 AI niekoniecznie le\u017cy w budowaniu jeszcze wi\u0119kszych poch\u0142aniaj\u0105cych gigantyczne ilo\u015bci energii modeli. Mo\u017ce le\u017cy w lepszej kuracji danych i projektowaniu sprytniejszych architektur. Jak ten ma\u0142y model dokodowania. Idealny przyk\u0142ad. Ten ma\u0142y model Palm 2S, kt\u00f3ry b\u0119d\u0105c tylko u\u0142amkiem rozmiaru poprzednika, okaza\u0142 si\u0119 od niego znacznie lepszy. To dow\u00f3d na to, \u017ce inteligencja mo\u017ce pokona\u0107 si\u0142\u0119. I to zostawia nas z pytaniem, kt\u00f3re wydaje mi si\u0119 kluczowe na najbli\u017csze lata. Skoro stajemy si\u0119 coraz lepsi w dobieraniu danych i udoskonalaniu metod treningu, to jaki jest prawdziwy optymalny rozmiar dla modelu j\u0119zykowego? Czy mo\u017cliwe, \u017ce ju\u017c dawno przekroczyli\u015bmy punkt, w kt\u00f3rym dalsze powi\u0119kszanie modeli przynosi coraz mniejsze korzy\u015bci? Mo\u017ce prawdziwa rewolucja i najbardziej u\u017cyteczne narz\u0119dzia b\u0119d\u0105 pochodzi\u0107 nie z cyfrowych gigant\u00f3w, ale ze znacznie mniejszych, bardziej zwinnych i po prostu inteligentniej zaprojektowanych system\u00f3w?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.66, "text": " Mam tutaj przed sob\u0105, wiesz, ten raport techniczny od Google", "tokens": [50364, 19899, 12749, 18334, 18253, 1611, 11, 261, 15347, 11, 2064, 5099, 477, 1537, 17946, 1634, 3611, 3329, 50547], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 1, "seek": 0, "start": 3.66, "end": 7.08, "text": " o ich nowym modelu j\u0119zykowym, Palm 2.", "tokens": [50547, 277, 1893, 586, 4199, 2316, 84, 49055, 74, 31691, 11, 32668, 568, 13, 50718], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 2, "seek": 0, "start": 7.08, "end": 11.3, "text": " I powiem szczerze, co\u015b mi tu po prostu nie gra.", "tokens": [50718, 286, 3388, 4907, 22090, 260, 1381, 11, 19241, 2752, 2604, 714, 19518, 2838, 1295, 13, 50929], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 3, "seek": 0, "start": 11.3, "end": 14.6, "text": " W \u015bwiecie AI od lat panuje jedna zasada.", "tokens": [50929, 343, 40078, 4260, 7318, 3611, 4465, 2462, 13008, 5232, 629, 26530, 1538, 13, 51094], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 4, "seek": 0, "start": 14.6, "end": 16.9, "text": " Im wi\u0119kszy model, tym lepszy.", "tokens": [51094, 4331, 29968, 1229, 2316, 11, 8107, 476, 1878, 1229, 13, 51209], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 5, "seek": 0, "start": 16.9, "end": 19.6, "text": " Wszyscy si\u0119 \u015bcigaj\u0105, kto zbuduje cyfrowego giganta", "tokens": [51209, 343, 15453, 38966, 3244, 8299, 66, 328, 11133, 11, 23780, 710, 18281, 13008, 3185, 69, 1892, 6308, 8741, 5983, 51344], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 6, "seek": 0, "start": 19.6, "end": 21.5, "text": " z wi\u0119ksz\u0105 liczb\u0105 parametr\u00f3w.", "tokens": [51344, 710, 29968, 8925, 6169, 89, 65, 1611, 6220, 27965, 3901, 13, 51439], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 7, "seek": 0, "start": 21.5, "end": 27.1, "text": " A tutaj czytam, \u017ce Palm 2 jest znacz\u0105co mniejszy od swojego poprzednika.", "tokens": [51439, 316, 12749, 6430, 37323, 11, 3561, 32668, 568, 3492, 15397, 326, 8925, 1291, 39513, 7706, 3611, 13291, 39738, 1665, 81, 11312, 77, 5439, 13, 51719], "temperature": 0.0, "avg_logprob": -0.16008872985839845, "compression_ratio": 1.4275092936802973, "no_speech_prob": 0.0029062042012810707}, {"id": 8, "seek": 2710, "start": 27.200000000000003, "end": 30.3, "text": " A jednocze\u015bnie znacznie od niego lepszy.", "tokens": [50369, 316, 5232, 26694, 1381, 12221, 15397, 14875, 2766, 3611, 49615, 476, 1878, 1229, 13, 50524], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 9, "seek": 2710, "start": 30.3, "end": 32.4, "text": " To kompletnie wywraca stolik.", "tokens": [50524, 1407, 5207, 14657, 2766, 4628, 7449, 6628, 43553, 1035, 13, 50629], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 10, "seek": 2710, "start": 32.4, "end": 35.3, "text": " Wygl\u0105da na to, \u017ce nie chodzi tu tylko o jak\u0105\u015b tam aktualizacj\u0119,", "tokens": [50629, 14458, 7191, 26398, 1667, 281, 11, 3561, 2838, 23998, 2604, 13219, 277, 46719, 1788, 7677, 13680, 901, 590, 29924, 11, 50774], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 11, "seek": 2710, "start": 35.3, "end": 38.0, "text": " ale o fundamentaln\u0105 zmian\u0119 filozofii.", "tokens": [50774, 6775, 277, 8088, 13113, 43591, 1274, 1387, 15151, 2670, 5597, 13, 50909], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 12, "seek": 2710, "start": 38.0, "end": 41.800000000000004, "text": " Spr\u00f3bujmy dzisiaj rozgry\u017a\u0107, co tak naprawd\u0119 stoi za tym prze\u0142omem.", "tokens": [50909, 7702, 14216, 4579, 2226, 25772, 9544, 70, 627, 10659, 2162, 11, 598, 991, 20970, 342, 4869, 7949, 8107, 8325, 1221, 298, 443, 13, 51099], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 13, "seek": 2710, "start": 41.800000000000004, "end": 44.5, "text": " Bo to jest co\u015b wi\u0119cej ni\u017c tylko, wiesz, nowy produkt.", "tokens": [51099, 3286, 281, 3492, 19241, 26004, 28502, 13219, 11, 261, 15347, 11, 586, 88, 42816, 13, 51234], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 14, "seek": 2710, "start": 44.5, "end": 47.3, "text": " To jest manifestacja nowego podej\u015bcia.", "tokens": [51234, 1407, 3492, 10067, 23395, 586, 6308, 7468, 73, 1788, 2755, 13, 51374], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 15, "seek": 2710, "start": 47.3, "end": 49.0, "text": " Skupimy si\u0119 na trzech rzeczach.", "tokens": [51374, 7324, 1010, 13189, 3244, 1667, 504, 19439, 36833, 608, 13, 51459], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 16, "seek": 2710, "start": 49.0, "end": 52.900000000000006, "text": " Po pierwsze, co jest tym tajemniczym sk\u0142adnikiem?", "tokens": [51459, 6165, 45994, 11, 598, 3492, 8107, 256, 1805, 443, 7692, 26681, 1110, 10358, 13123, 4907, 30, 51654], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 17, "seek": 2710, "start": 52.900000000000006, "end": 56.0, "text": " Jak oni to zrobili, \u017ce mniejsze znaczy lepsze?", "tokens": [51654, 15029, 36317, 281, 44399, 2312, 11, 3561, 275, 44258, 36584, 476, 1878, 1381, 30, 51809], "temperature": 0.0, "avg_logprob": -0.09636573331901827, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09744533151388168}, {"id": 18, "seek": 5600, "start": 56.0, "end": 60.5, "text": " Po drugie, zobaczymy dowody w praktyce, jak ten model radzi sobie z zadaniami,", "tokens": [50364, 6165, 4110, 414, 11, 37273, 2226, 9459, 843, 261, 3206, 74, 874, 384, 11, 4207, 2064, 2316, 2843, 3992, 13652, 710, 710, 11338, 15568, 11, 50589], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 19, "seek": 5600, "start": 60.5, "end": 66.8, "text": " odpisania kodu po zdawanie egzamin\u00f3w, kt\u00f3re obla\u0142 jego pot\u0119\u017cniejszy przodek.", "tokens": [50589, 3611, 40516, 5609, 350, 34873, 714, 710, 2675, 86, 7155, 24263, 89, 7428, 3901, 11, 8864, 1111, 875, 1221, 26542, 1847, 1274, 1427, 10402, 7706, 6541, 378, 916, 13, 50904], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 20, "seek": 5600, "start": 66.8, "end": 69.1, "text": " I na koniec, co jest niezwykle wa\u017cne,", "tokens": [50904, 286, 1667, 5897, 35733, 11, 598, 3492, 33511, 9726, 14677, 46110, 11, 51019], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 21, "seek": 5600, "start": 69.1, "end": 73.9, "text": " przyjrzymy si\u0119, jak raport podchodzi do ogranicze\u0144 i odpowiedzialno\u015bci.", "tokens": [51019, 6501, 73, 13047, 2226, 3244, 11, 4207, 5099, 477, 2497, 34616, 360, 34416, 30732, 49689, 741, 24314, 15338, 831, 16438, 13, 51259], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 22, "seek": 5600, "start": 73.9, "end": 78.4, "text": " Bo jak wiemy, z wielk\u0105 moc\u0105, no w\u0142a\u015bnie.", "tokens": [51259, 3286, 4207, 3355, 2226, 11, 710, 20570, 26304, 705, 32557, 11, 572, 14234, 13, 51484], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 23, "seek": 5600, "start": 78.4, "end": 80.2, "text": " To jest idealne podsumowanie.", "tokens": [51484, 1407, 3492, 7157, 716, 31925, 449, 22028, 13, 51574], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 24, "seek": 5600, "start": 80.2, "end": 83.9, "text": " To jest, wiesz, dok\u0142adnie ten moment, kiedy ca\u0142a bran\u017ca przechodzi", "tokens": [51574, 1407, 3492, 11, 261, 15347, 11, 45864, 2766, 2064, 1623, 11, 18777, 1335, 5024, 12029, 35075, 8325, 34616, 51759], "temperature": 0.0, "avg_logprob": -0.12138730829412286, "compression_ratio": 1.4753521126760563, "no_speech_prob": 0.02694651484489441}, {"id": 25, "seek": 8390, "start": 83.9, "end": 88.80000000000001, "text": " od takiego my\u015blenia w kategoriach wi\u0119cej, wi\u0119cej, wi\u0119cej, do m\u0105drzej.", "tokens": [50364, 3611, 32296, 48633, 6698, 654, 261, 350, 2968, 7386, 608, 26004, 11, 26004, 11, 26004, 11, 360, 275, 18962, 13503, 73, 13, 50609], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 26, "seek": 8390, "start": 88.80000000000001, "end": 90.60000000000001, "text": " Dok\u0142adnie tak, do m\u0105drzej.", "tokens": [50609, 29768, 10358, 2766, 991, 11, 360, 275, 18962, 13503, 73, 13, 50699], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 27, "seek": 8390, "start": 90.60000000000001, "end": 95.7, "text": " Zamiast budowa\u0107 coraz wi\u0119ksze silniki, zacz\u0119li\u015bmy wreszcie zastanawia\u0107 si\u0119 nad jako\u015bci\u0105 paliwa", "tokens": [50699, 1176, 4526, 525, 3265, 11445, 25899, 29968, 1381, 3425, 77, 9850, 11, 34430, 11052, 38452, 261, 495, 89, 4260, 36746, 282, 34953, 2162, 3244, 12617, 17123, 50227, 3984, 72, 4151, 50954], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 28, "seek": 8390, "start": 95.7, "end": 98.7, "text": " i konstrukcj\u0105 samego mechanizmu.", "tokens": [50954, 741, 34208, 25126, 66, 8555, 912, 1571, 4236, 590, 20140, 13, 51104], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 29, "seek": 8390, "start": 98.7, "end": 103.0, "text": " I ten raport opiera ca\u0142\u0105 t\u0119 rewolucj\u0119 w zasadzie na trzech filarach.", "tokens": [51104, 286, 2064, 5099, 477, 999, 10609, 1335, 15926, 32489, 319, 48481, 1311, 11115, 261, 44585, 3283, 1667, 504, 19439, 1387, 289, 608, 13, 51319], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 30, "seek": 8390, "start": 103.0, "end": 107.0, "text": " Pierwszy to co\u015b, co nazywaj\u0105 compute optimal scaling.", "tokens": [51319, 16676, 30012, 281, 19241, 11, 598, 20151, 27112, 11133, 14722, 16252, 21589, 13, 51519], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 31, "seek": 8390, "start": 107.0, "end": 111.7, "text": " Czyli znalezienie idealnego balansu mi\u0119dzy rozmiarem modelu, ilo\u015bci\u0105 danych,", "tokens": [51519, 37099, 15397, 37646, 27385, 7157, 11858, 3119, 599, 84, 33964, 9544, 3057, 19183, 2316, 84, 11, 1930, 44468, 1611, 274, 34644, 11, 51754], "temperature": 0.0, "avg_logprob": -0.11386132884669949, "compression_ratio": 1.5117845117845117, "no_speech_prob": 0.014039162546396255}, {"id": 32, "seek": 11170, "start": 111.8, "end": 114.10000000000001, "text": " a dost\u0119pn\u0105 moc\u0105 obliczeniow\u0105.", "tokens": [50369, 257, 48209, 13113, 705, 32557, 1111, 1050, 42124, 30297, 13, 50484], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 33, "seek": 11170, "start": 114.10000000000001, "end": 118.7, "text": " Drugi filar to radykalnie inne paliwo, niewyobra\u017calnie zr\u00f3\u017cnicowany,", "tokens": [50484, 2491, 24780, 1387, 289, 281, 367, 880, 19990, 2766, 24170, 3984, 72, 6120, 11, 43622, 88, 24393, 1427, 304, 2766, 710, 11721, 1427, 7692, 23341, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 34, "seek": 11170, "start": 118.7, "end": 120.5, "text": " wieloj\u0119zyczne zbi\u00f3r danych.", "tokens": [50714, 20570, 78, 11115, 1229, 38491, 710, 5614, 15614, 274, 34644, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 35, "seek": 11170, "start": 120.5, "end": 124.10000000000001, "text": " A trzeci to po prostu sprytniejsze cele samego treningu.", "tokens": [50804, 316, 22266, 537, 281, 714, 19518, 637, 627, 83, 44258, 43165, 912, 1571, 2192, 773, 84, 13, 50984], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 36, "seek": 11170, "start": 124.10000000000001, "end": 127.9, "text": " To nie jest jeden magiczny trik, tylko synergia tych trzech element\u00f3w.", "tokens": [50984, 1407, 2838, 3492, 12906, 5585, 89, 1634, 1376, 74, 11, 13219, 33781, 40550, 15180, 504, 19439, 4478, 3901, 13, 51174], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 37, "seek": 11170, "start": 127.9, "end": 130.8, "text": " Czekaj, zatrzymajmy si\u0119 przy tym pierwszym filarze.", "tokens": [51174, 383, 19878, 1805, 11, 35802, 13047, 1696, 73, 2226, 3244, 6501, 8107, 34016, 76, 1387, 289, 1381, 13, 51319], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 38, "seek": 11170, "start": 130.8, "end": 132.9, "text": " Compute optimal scaling.", "tokens": [51319, 6620, 1169, 16252, 21589, 13, 51424], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 39, "seek": 11170, "start": 132.9, "end": 138.9, "text": " To brzmi bardzo technicznie, ale idea za tym wydaje si\u0119, no, rewolucyjna.", "tokens": [51424, 1407, 738, 89, 3057, 9034, 1537, 17946, 2766, 11, 6775, 1558, 7949, 8107, 49165, 3244, 11, 572, 11, 319, 48481, 1311, 88, 73, 629, 13, 51724], "temperature": 0.0, "avg_logprob": -0.10376684457663722, "compression_ratio": 1.4379310344827587, "no_speech_prob": 0.029428280889987946}, {"id": 40, "seek": 13890, "start": 138.9, "end": 142.20000000000002, "text": " Czy to znaczy, \u017ce do tej pory wszyscy w bran\u017cy robili to \u017ale,", "tokens": [50364, 19832, 281, 36584, 11, 3561, 360, 12573, 280, 827, 44232, 261, 12029, 7735, 3870, 2312, 281, 50212, 306, 11, 50529], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 41, "seek": 13890, "start": 142.20000000000002, "end": 145.70000000000002, "text": " budowali za du\u017ce modele i za ma\u0142o je karmili danymi?", "tokens": [50529, 3265, 305, 5103, 7949, 1581, 2875, 4391, 306, 741, 7949, 463, 5249, 1506, 350, 4452, 2312, 274, 1325, 3057, 30, 50704], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 42, "seek": 13890, "start": 145.70000000000002, "end": 149.4, "text": " W pewnym sensie tak, to nie jest, wiesz, zupe\u0142nie nowa koncepcja", "tokens": [50704, 343, 47160, 4199, 2923, 414, 991, 11, 281, 2838, 3492, 11, 261, 15347, 11, 49922, 586, 64, 5897, 27493, 34056, 50889], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 43, "seek": 13890, "start": 149.4, "end": 152.1, "text": " wcze\u015bniejsze badania, na przyk\u0142ad te od Hofmana.", "tokens": [50889, 40785, 82, 1381, 1578, 5609, 11, 1667, 23144, 535, 3611, 37379, 14524, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 44, "seek": 13890, "start": 152.1, "end": 155.6, "text": " Z 2022 roku ju\u017c to sugerowa\u0142y.", "tokens": [51024, 1176, 20229, 19451, 10678, 281, 459, 1321, 5528, 6825, 13, 51199], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 45, "seek": 13890, "start": 155.6, "end": 159.5, "text": " Ale Google potwierdzi\u0142 to teraz na niewyobra\u017caln\u0105 skal\u0119.", "tokens": [51199, 9366, 3329, 1847, 40717, 67, 3992, 1221, 281, 16854, 1667, 43622, 88, 24393, 1427, 304, 13113, 16890, 1274, 13, 51394], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 46, "seek": 13890, "start": 159.5, "end": 163.8, "text": " Okaza\u0142o si\u0119, \u017ce dotyczczasowy trend by\u0142, no, po prostu niew\u0142a\u015bciwy.", "tokens": [51394, 3477, 12257, 5249, 3244, 11, 3561, 5893, 17466, 30989, 10089, 6028, 16673, 11, 572, 11, 714, 19518, 43622, 5024, 6199, 9726, 13, 51609], "temperature": 0.0, "avg_logprob": -0.13067790244123062, "compression_ratio": 1.4027777777777777, "no_speech_prob": 0.00761833880096674}, {"id": 47, "seek": 16380, "start": 163.9, "end": 166.4, "text": " Modele, czyli liczba ich parametr\u00f3w,", "tokens": [50369, 20500, 306, 11, 16591, 6169, 89, 4231, 1893, 6220, 27965, 3901, 11, 50494], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 48, "seek": 16380, "start": 166.4, "end": 170.70000000000002, "text": " ros\u0142y jakie\u015b trzy razy szybciej ni\u017c ilo\u015b\u0107 danych, na kt\u00f3rych je trenowano.", "tokens": [50494, 18953, 6825, 31163, 34573, 9639, 88, 36456, 4260, 73, 28502, 1930, 78, 7753, 274, 34644, 11, 1667, 30382, 1506, 23136, 305, 3730, 13, 50709], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 49, "seek": 16380, "start": 170.70000000000002, "end": 171.5, "text": " Aha.", "tokens": [50709, 27448, 13, 50749], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 50, "seek": 16380, "start": 171.5, "end": 174.9, "text": " To troch\u0119 tak, jakby\u015b budowa\u0142 m\u00f3zg wielko\u015bci planety,", "tokens": [50749, 1407, 24926, 991, 11, 28976, 1788, 3265, 30105, 32515, 89, 70, 20570, 4093, 6199, 1393, 2210, 11, 50919], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 51, "seek": 16380, "start": 174.9, "end": 177.20000000000002, "text": " ale karmi\u0142 go tylko jedn\u0105 ksi\u0105\u017ck\u0105.", "tokens": [50919, 6775, 350, 4452, 40622, 352, 13219, 5232, 13113, 39311, 26304, 13, 51034], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 52, "seek": 16380, "start": 177.20000000000002, "end": 180.5, "text": " Palm II to jest pr\u00f3ba naprawienia tej dysproporcji.", "tokens": [51034, 32668, 6351, 281, 3492, 8565, 4231, 9296, 5131, 18811, 12573, 15243, 79, 1513, 284, 19649, 13, 51199], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 53, "seek": 16380, "start": 180.5, "end": 184.70000000000002, "text": " Stwierdzono, \u017ce optymalny wzrost to mniej wi\u0119cej jeden do jednego.", "tokens": [51199, 745, 40717, 28168, 8957, 11, 3561, 2427, 4199, 304, 1634, 24809, 27494, 281, 39513, 26004, 12906, 360, 5232, 11858, 13, 51409], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 54, "seek": 16380, "start": 184.70000000000002, "end": 189.10000000000002, "text": " O ile powi\u0119kszasz model, o tyle samo musisz zwi\u0119kszy\u0107 ilo\u015b\u0107 danych.", "tokens": [51409, 422, 15465, 3388, 5034, 1694, 89, 19601, 2316, 11, 277, 39293, 36422, 1038, 23848, 11873, 5034, 1694, 27150, 1930, 78, 7753, 274, 34644, 13, 51629], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 55, "seek": 16380, "start": 189.10000000000002, "end": 192.8, "text": " Czyli kluczem jest nie tylko to, \u017ceby model by\u0142 du\u017cy,", "tokens": [51629, 37099, 9671, 1311, 24313, 3492, 2838, 13219, 281, 11, 11316, 2316, 16673, 1581, 7735, 11, 51814], "temperature": 0.0, "avg_logprob": -0.11342264413833618, "compression_ratio": 1.4584615384615385, "no_speech_prob": 0.39651843905448914}, {"id": 56, "seek": 19280, "start": 192.8, "end": 196.8, "text": " \u017ceby mia\u0142 proporcjonalnie du\u017co do przeczytania.", "tokens": [50364, 11316, 27989, 2365, 36003, 15735, 304, 2766, 26673, 360, 8325, 6522, 83, 5609, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 57, "seek": 19280, "start": 196.8, "end": 199.70000000000002, "text": " I jak rozumiem, to czytanie te\u017c si\u0119 zmieni\u0142o.", "tokens": [50564, 286, 4207, 48797, 4907, 11, 281, 6430, 83, 7155, 9516, 3244, 17020, 35462, 5249, 13, 50709], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 58, "seek": 19280, "start": 199.70000000000002, "end": 203.4, "text": " Raport m\u00f3wi o ulepszonej mieszance danych.", "tokens": [50709, 16184, 477, 24592, 277, 344, 306, 1878, 16896, 73, 33039, 719, 274, 34644, 13, 50894], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 59, "seek": 19280, "start": 203.4, "end": 206.4, "text": " To nie by\u0142a po prostu wi\u0119ksza ilo\u015b\u0107 tego samego, co wcze\u015bniej.", "tokens": [50894, 1407, 2838, 23936, 714, 19518, 29968, 2394, 1930, 78, 7753, 8627, 912, 1571, 11, 598, 40785, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 60, "seek": 19280, "start": 206.4, "end": 210.0, "text": " Absolutnie nie. I to jest ten drugi kluczowy filar.", "tokens": [51044, 5813, 2308, 2766, 2838, 13, 286, 281, 3492, 2064, 4110, 72, 9671, 1311, 89, 10089, 1387, 289, 13, 51224], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 61, "seek": 19280, "start": 210.0, "end": 212.5, "text": " Stersze modele, w tym pierwszy palm,", "tokens": [51224, 745, 433, 1381, 4391, 306, 11, 261, 8107, 34016, 17018, 11, 51349], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 62, "seek": 19280, "start": 212.5, "end": 217.70000000000002, "text": " by\u0142y trenowane na danych, w kt\u00f3rych angielski stanowi\u0142 czasem nawet 78%.", "tokens": [51349, 26366, 23136, 23066, 1667, 274, 34644, 11, 261, 30382, 2562, 1187, 18020, 27984, 24503, 1221, 13190, 443, 22696, 26369, 6856, 51609], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 63, "seek": 19280, "start": 217.70000000000002, "end": 218.60000000000002, "text": " A\u017c tyle.", "tokens": [51609, 316, 1427, 39293, 13, 51654], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 64, "seek": 19280, "start": 218.60000000000002, "end": 222.70000000000002, "text": " Tak, to tworzy\u0142o bardzo anglocentryczny obraz \u015bwiata.", "tokens": [51654, 9118, 11, 281, 46288, 1229, 5249, 9034, 2562, 752, 2207, 627, 3689, 1634, 22798, 89, 21485, 3274, 13, 51859], "temperature": 0.0, "avg_logprob": -0.11026743705698985, "compression_ratio": 1.4304207119741101, "no_speech_prob": 0.007063217926770449}, {"id": 65, "seek": 22270, "start": 222.79999999999998, "end": 226.6, "text": " Zbi\u00f3r danych dla Palm II jest radykalnie inny.", "tokens": [50369, 1176, 5614, 15614, 274, 34644, 12285, 32668, 6351, 3492, 367, 880, 19990, 2766, 294, 1634, 13, 50559], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 66, "seek": 22270, "start": 226.6, "end": 231.39999999999998, "text": " Obejmuje setki j\u0119zyk\u00f3w, jest znacznie bardziej zr\u00f3\u017cnicowany tematycznie.", "tokens": [50559, 422, 650, 35195, 13008, 992, 2984, 49055, 23849, 11, 3492, 15397, 14875, 2766, 27209, 710, 11721, 1427, 7692, 23341, 32954, 17466, 2766, 13, 50799], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 67, "seek": 22270, "start": 231.39999999999998, "end": 235.1, "text": " Zawiera nie tylko strony internetowe, ale te\u017c ksi\u0105\u017cki,", "tokens": [50799, 1176, 1607, 10609, 2838, 13219, 32406, 4705, 6880, 11, 6775, 9516, 39311, 2984, 11, 50984], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 68, "seek": 22270, "start": 235.1, "end": 240.1, "text": " kod programistyczny z r\u00f3\u017cnych repozytor\u00f3w, artyku\u0142y naukowe z matematyki,", "tokens": [50984, 350, 378, 1461, 468, 17466, 1634, 710, 42602, 1085, 78, 1229, 21151, 3901, 11, 594, 874, 5279, 6825, 35616, 74, 6880, 710, 3803, 8615, 88, 2984, 11, 51234], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 69, "seek": 22270, "start": 240.1, "end": 242.89999999999998, "text": " a nawet dane konwersacyjne, czyli dialogi.", "tokens": [51234, 257, 22696, 49206, 5897, 5364, 31285, 716, 11, 16591, 19308, 72, 13, 51374], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 70, "seek": 22270, "start": 242.89999999999998, "end": 244.5, "text": " A co z tymi parallel data?", "tokens": [51374, 316, 598, 710, 1104, 3057, 8952, 1412, 30, 51454], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 71, "seek": 22270, "start": 244.5, "end": 247.6, "text": " To brzmi jak co\u015b, co mog\u0142o da\u0107 mu super moce w t\u0142umaczeniu.", "tokens": [51454, 1407, 738, 89, 3057, 4207, 19241, 11, 598, 13172, 5249, 1120, 2162, 2992, 1687, 705, 384, 261, 256, 49166, 326, 39651, 13, 51609], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 72, "seek": 22270, "start": 247.6, "end": 251.29999999999998, "text": " Dok\u0142adnie tak. Parallel data to s\u0105 zbiory tekst\u00f3w,", "tokens": [51609, 29768, 10358, 2766, 991, 13, 3457, 336, 338, 1412, 281, 9015, 710, 5614, 827, 16624, 372, 3901, 11, 51794], "temperature": 0.0, "avg_logprob": -0.1119930291477638, "compression_ratio": 1.4313099041533546, "no_speech_prob": 0.0043412488885223866}, {"id": 73, "seek": 25130, "start": 251.3, "end": 254.70000000000002, "text": " kt\u00f3re s\u0105 swoim dok\u0142adnym t\u0142umaczeniem.", "tokens": [50364, 8864, 9015, 13291, 332, 45864, 12996, 256, 49166, 326, 2904, 4907, 13, 50534], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 74, "seek": 25130, "start": 254.70000000000002, "end": 257.7, "text": " Na przyk\u0142ad ten sam artyku\u0142 po polsku i po angielsku.", "tokens": [50534, 6056, 23144, 2064, 3247, 594, 874, 5279, 1221, 714, 28757, 84, 741, 714, 2562, 1187, 5161, 84, 13, 50684], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 75, "seek": 25130, "start": 257.7, "end": 260.0, "text": " Karmi\u0105c model takimi parami,", "tokens": [50684, 591, 4452, 11404, 66, 2316, 991, 10121, 971, 4526, 11, 50799], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 76, "seek": 25130, "start": 260.0, "end": 263.8, "text": " on nie uczy si\u0119 tylko statystyki s\u0142\u00f3w w danym j\u0119zyku,", "tokens": [50799, 322, 2838, 344, 6522, 3244, 13219, 2219, 88, 25134, 2984, 15116, 3901, 261, 274, 1325, 76, 49055, 5279, 11, 50989], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 77, "seek": 25130, "start": 263.8, "end": 267.7, "text": " ale bezpo\u015brednio obserwuje, jak idee i struktury gramatyczne", "tokens": [50989, 6775, 10782, 2259, 1788, 986, 41084, 12887, 86, 13008, 11, 4207, 49742, 741, 342, 19977, 2598, 21353, 267, 17466, 716, 51184], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 78, "seek": 25130, "start": 267.7, "end": 269.6, "text": " przenosz\u0105 si\u0119 z jednego j\u0119zyka na drugi.", "tokens": [51184, 582, 2904, 329, 8925, 3244, 710, 5232, 11858, 42309, 40940, 1667, 4110, 72, 13, 51279], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 79, "seek": 25130, "start": 269.6, "end": 273.5, "text": " Czyli to jak dawanie studentowi klucza odpowiedzi do zada\u0144 z t\u0142umaczenia.", "tokens": [51279, 37099, 281, 4207, 43438, 7155, 3107, 24503, 9671, 1311, 2394, 36574, 3992, 360, 710, 1538, 5248, 710, 256, 49166, 326, 14320, 13, 51474], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 80, "seek": 25130, "start": 273.5, "end": 274.90000000000003, "text": " W\u0142a\u015bnie.", "tokens": [51474, 343, 5024, 12221, 13, 51544], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 81, "seek": 25130, "start": 274.90000000000003, "end": 278.90000000000003, "text": " Chwila to jest niesamowite, czyli zamiast kaza\u0107 mu wk\u00f3\u0142ko robi\u0107 to samo,", "tokens": [51544, 761, 86, 7371, 281, 3492, 48100, 335, 305, 642, 11, 16591, 710, 4526, 525, 350, 12257, 2162, 2992, 261, 74, 16181, 4093, 46900, 281, 36422, 11, 51744], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 82, "seek": 25130, "start": 278.90000000000003, "end": 281.1, "text": " przewidywa\u0107 nast\u0119pne s\u0142owo w zdaniu,", "tokens": [51744, 39758, 38836, 25234, 39662, 716, 15116, 19941, 261, 16221, 25849, 11, 51854], "temperature": 0.0, "avg_logprob": -0.0943878259551659, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.03265196084976196}, {"id": 83, "seek": 28110, "start": 281.20000000000005, "end": 285.6, "text": " oni zrobili mu taki intensywny ob\u00f3z treningowy dla umys\u0142u.", "tokens": [50369, 36317, 44399, 2312, 2992, 20065, 14056, 88, 43682, 1111, 812, 89, 2192, 773, 10089, 12285, 1105, 749, 24066, 13, 50589], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 84, "seek": 28110, "start": 285.6, "end": 286.8, "text": " Mo\u017cna tak powiedzie\u0107.", "tokens": [50589, 44736, 629, 991, 27886, 13, 50649], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 85, "seek": 28110, "start": 286.8, "end": 292.20000000000005, "text": " To jest ten trzeci filar inspirowany wcze\u015bniejszym modelem o nazwie UL2.", "tokens": [50649, 1407, 3492, 2064, 22266, 537, 1387, 289, 17432, 23341, 40785, 7706, 76, 4391, 10386, 277, 20151, 8699, 624, 43, 17, 13, 50919], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 86, "seek": 28110, "start": 292.20000000000005, "end": 295.1, "text": " Zamiast jednego monotonnego celu,", "tokens": [50919, 1176, 4526, 525, 5232, 11858, 1108, 27794, 11858, 9277, 84, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 87, "seek": 28110, "start": 295.1, "end": 300.5, "text": " Palm II dosta\u0142 dostrojon\u0105 mieszank\u0119 r\u00f3\u017cnych cel\u00f3w treningowych.", "tokens": [51064, 32668, 6351, 274, 8638, 1221, 20568, 340, 15735, 1611, 33039, 657, 1274, 42602, 9277, 3901, 2192, 773, 19605, 13, 51334], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 88, "seek": 28110, "start": 300.5, "end": 301.8, "text": " Por\u00f3wnaj to do nauki.", "tokens": [51334, 5269, 3901, 20981, 281, 360, 35616, 2984, 13, 51399], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 89, "seek": 28110, "start": 301.8, "end": 304.70000000000005, "text": " Mo\u017cesz uczy\u0107 si\u0119 na pami\u0119\u0107, co jest jednym celem,", "tokens": [51399, 44736, 10430, 344, 33967, 3244, 1667, 31088, 2162, 11, 598, 3492, 5232, 12996, 1769, 10386, 11, 51544], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 90, "seek": 28110, "start": 304.70000000000005, "end": 306.8, "text": " przewidywanie nast\u0119pnego s\u0142owa,", "tokens": [51544, 39758, 38836, 86, 7155, 39662, 11858, 15116, 5528, 11, 51649], "temperature": 0.0, "avg_logprob": -0.13665499005998885, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0012264378601685166}, {"id": 91, "seek": 30680, "start": 306.90000000000003, "end": 311.2, "text": " ale mo\u017cesz te\u017c jednocze\u015bnie uczy\u0107 si\u0119 pisa\u0107 eseje, straszcza\u0107 teksty,", "tokens": [50369, 6775, 10697, 10430, 9516, 5232, 26694, 1381, 12221, 344, 33967, 3244, 280, 3837, 2162, 10167, 2884, 11, 1056, 19601, 66, 35873, 16624, 25134, 11, 50584], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 92, "seek": 30680, "start": 311.2, "end": 315.1, "text": " rozwi\u0105zywa\u0107 \u0142omig\u0142\u00f3wki logiczne i prowadzi\u0107 debaty.", "tokens": [50584, 9544, 18234, 1229, 25234, 25387, 298, 328, 1221, 3901, 2984, 9952, 43077, 741, 36590, 28496, 3001, 21398, 13, 50779], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 93, "seek": 30680, "start": 315.1, "end": 319.5, "text": " Ka\u017cdy z tych zada\u0144 uczycie czego\u015b innego o j\u0119zyku i rozumowaniu.", "tokens": [50779, 10988, 1427, 3173, 710, 15180, 710, 1538, 5248, 344, 6522, 4260, 36559, 1788, 294, 11858, 277, 49055, 5279, 741, 48797, 305, 25849, 13, 50999], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 94, "seek": 30680, "start": 319.5, "end": 323.8, "text": " Taki zr\u00f3\u017cnicowany trening sprawia, \u017ce model nie jest tylko papug\u0105,", "tokens": [50999, 314, 7421, 710, 11721, 1427, 7692, 23341, 2192, 773, 22734, 654, 11, 3561, 2316, 2838, 3492, 13219, 5806, 697, 1611, 11, 51214], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 95, "seek": 30680, "start": 323.8, "end": 327.2, "text": " ale zaczyna rozumie\u0107 j\u0119zyk z wielu r\u00f3\u017cnych perspektyw.", "tokens": [51214, 6775, 43811, 629, 48797, 414, 2162, 49055, 74, 710, 40437, 42602, 868, 32659, 874, 86, 13, 51384], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 96, "seek": 30680, "start": 327.2, "end": 331.2, "text": " I to w\u0142a\u015bnie przek\u0142ada si\u0119 na jego znacznie lepsze zdolno\u015bci rozumowania,", "tokens": [51384, 286, 281, 14234, 29785, 46217, 3244, 1667, 26542, 15397, 14875, 2766, 476, 1878, 1381, 16221, 401, 16438, 48797, 21308, 11, 51584], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 97, "seek": 30680, "start": 331.2, "end": 332.6, "text": " o kt\u00f3rych zaraz powiemy.", "tokens": [51584, 277, 30382, 22675, 921, 3388, 414, 2226, 13, 51654], "temperature": 0.0, "avg_logprob": -0.10115016649847161, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.009222359396517277}, {"id": 98, "seek": 33260, "start": 332.6, "end": 338.20000000000005, "text": " Wszystko to brzmi \u015bwietnie w teorii, lepszy balans, lepsze dane, m\u0105drzejszy trening.", "tokens": [50364, 343, 10424, 4093, 281, 738, 89, 3057, 8299, 39083, 2766, 261, 40238, 5597, 11, 476, 1878, 1229, 3119, 599, 11, 476, 1878, 1381, 49206, 11, 275, 18962, 13503, 73, 7706, 2192, 773, 13, 50644], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 99, "seek": 33260, "start": 338.20000000000005, "end": 341.20000000000005, "text": " Ale pytanie, czy to naprawd\u0119 czu\u0107 w praktyce?", "tokens": [50644, 9366, 36610, 11, 6430, 281, 20970, 6472, 84, 2162, 261, 3206, 74, 874, 384, 30, 50794], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 100, "seek": 33260, "start": 341.20000000000005, "end": 346.40000000000003, "text": " Czy ten model faktycznie jest inteligentniejszy, czy po prostu inaczej wytresowany?", "tokens": [50794, 19832, 2064, 2316, 33647, 45586, 3492, 24777, 25002, 10402, 7706, 11, 6430, 714, 19518, 33230, 16920, 261, 4328, 495, 23341, 30, 51054], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 101, "seek": 33260, "start": 346.40000000000003, "end": 349.0, "text": " Raport na szcz\u0119\u015bcie daje konkretne przyk\u0142ady,", "tokens": [51054, 16184, 477, 1667, 22090, 1274, 9815, 1120, 2884, 36500, 716, 6501, 74, 1221, 880, 11, 51184], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 102, "seek": 33260, "start": 349.0, "end": 355.3, "text": " zaczynaj\u0105c od czego\u015b, co jest ostatecznym testem dla ka\u017cdego poligloty egzamin\u00f3w j\u0119zykowych.", "tokens": [51184, 43811, 629, 8555, 66, 3611, 36559, 1788, 11, 598, 3492, 277, 15406, 3689, 12996, 1500, 443, 12285, 21912, 67, 6308, 1180, 328, 75, 6737, 24263, 89, 7428, 3901, 49055, 74, 19605, 13, 51499], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 103, "seek": 33260, "start": 355.3, "end": 358.40000000000003, "text": " I to jest przyk\u0142ad, kt\u00f3ry najlepiej obrazuje t\u0105 zmian\u0119.", "tokens": [51499, 286, 281, 3492, 23144, 11, 9913, 41903, 39699, 22798, 11728, 2884, 32294, 43591, 1274, 13, 51654], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 104, "seek": 33260, "start": 358.40000000000003, "end": 362.5, "text": " Wyobra\u017a sobie, \u017ce zdajesz najtrudniejszy oficjalny egzamin z chi\u0144skiego,", "tokens": [51654, 14458, 24393, 10659, 13652, 11, 3561, 16221, 1805, 10430, 11212, 6903, 532, 10402, 7706, 295, 299, 22600, 1634, 24263, 89, 7428, 710, 13228, 27125, 12200, 11, 51859], "temperature": 0.0, "avg_logprob": -0.06747748534803445, "compression_ratio": 1.486646884272997, "no_speech_prob": 0.00862650666385889}, {"id": 105, "seek": 36250, "start": 362.5, "end": 365.3, "text": " albo japo\u0144skiego, na poziomie C2.", "tokens": [50364, 22622, 361, 37615, 27125, 12200, 11, 1667, 38503, 40120, 383, 17, 13, 50504], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 106, "seek": 36250, "start": 365.3, "end": 367.8, "text": " Poziom C2, czyli mistrzowski.", "tokens": [50504, 6165, 3992, 298, 383, 17, 11, 16591, 3544, 19390, 21866, 13, 50629], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 107, "seek": 36250, "start": 367.8, "end": 372.3, "text": " Tak, to jest poziom, kt\u00f3ry pozwala ci oficjalnie uczy\u0107 tego j\u0119zyka.", "tokens": [50629, 9118, 11, 281, 3492, 38503, 298, 11, 9913, 40557, 5159, 6983, 295, 299, 22600, 2766, 344, 33967, 8627, 42309, 40940, 13, 50854], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 108, "seek": 36250, "start": 372.3, "end": 374.3, "text": " Palm II zda\u0142 te egzaminy.", "tokens": [50854, 32668, 6351, 710, 2675, 1221, 535, 24263, 28915, 3519, 13, 50954], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 109, "seek": 36250, "start": 374.3, "end": 379.6, "text": " Chi\u0144ski HSK, japo\u0144ski J-test, w\u0142oski Plida, hiszpa\u0144ski Dele.", "tokens": [50954, 17730, 5248, 18020, 34194, 42, 11, 361, 37615, 5248, 18020, 508, 12, 31636, 11, 34696, 329, 2984, 2149, 2887, 11, 702, 89, 4306, 5248, 18020, 1346, 306, 13, 51219], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 110, "seek": 36250, "start": 379.6, "end": 381.0, "text": " A teraz najlepsze.", "tokens": [51219, 316, 16854, 41903, 1878, 1381, 13, 51289], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 111, "seek": 36250, "start": 381.0, "end": 385.8, "text": " Jego znacznie wi\u0119kszy pokrzednik, Palm, obla\u0142 wi\u0119kszo\u015b\u0107 z nich z kretesem.", "tokens": [51289, 508, 6308, 15397, 14875, 2766, 29968, 1229, 13010, 81, 11312, 13123, 11, 32668, 11, 1111, 875, 1221, 29968, 4765, 7753, 710, 25570, 710, 350, 1505, 279, 443, 13, 51529], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 112, "seek": 36250, "start": 385.8, "end": 386.8, "text": " Niesamowite.", "tokens": [51529, 426, 530, 335, 305, 642, 13, 51579], "temperature": 0.0, "avg_logprob": -0.15093842915126254, "compression_ratio": 1.356, "no_speech_prob": 0.013317680917680264}, {"id": 113, "seek": 38680, "start": 386.8, "end": 393.2, "text": " To jest namacalny, bezpo\u015bredni dow\u00f3d na to, jak skuteczny by\u0142 ten wieloj\u0119zyczny trening.", "tokens": [50364, 1407, 3492, 8835, 326, 304, 1634, 11, 10782, 2259, 1788, 986, 3722, 9459, 17081, 1667, 281, 11, 4207, 1110, 1169, 3689, 1634, 16673, 2064, 20570, 78, 11115, 1229, 3689, 1634, 2192, 773, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 114, "seek": 38680, "start": 393.2, "end": 399.5, "text": " Dobra, j\u0119zyki to jedno, ale to cz\u0119sto mo\u017ce by\u0107 kwestia wykucia na blach\u0119 ogromnej ilo\u015bci danych.", "tokens": [50684, 413, 24393, 11, 49055, 2984, 281, 5232, 1771, 11, 6775, 281, 34369, 12034, 15069, 42035, 654, 4628, 5279, 2755, 1667, 888, 608, 1274, 34416, 298, 11794, 1930, 44468, 274, 34644, 13, 50999], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 115, "seek": 38680, "start": 399.5, "end": 405.40000000000003, "text": " A co z czym\u015b, co wymaga prawdziwego my\u015blenia, jak matematyka, czy wieloetapowe zadania logiczne?", "tokens": [50999, 316, 598, 710, 31466, 1788, 11, 598, 29764, 9286, 41175, 3992, 826, 1571, 48633, 6698, 654, 11, 4207, 3803, 8615, 88, 2330, 11, 6430, 20570, 78, 302, 569, 6880, 42788, 5609, 9952, 43077, 30, 51294], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 116, "seek": 38680, "start": 405.40000000000003, "end": 408.1, "text": " To zawsze by\u0142a pi\u0119ta achilesowa tych modeli.", "tokens": [51294, 1407, 30964, 23936, 32677, 1328, 2800, 4680, 5528, 15180, 2316, 72, 13, 51429], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 117, "seek": 38680, "start": 408.1, "end": 410.90000000000003, "text": " Tu post\u0119p jest chyba jeszcze bardziej imponuj\u0105ce.", "tokens": [51429, 7836, 2183, 18085, 3492, 31532, 14168, 27209, 704, 266, 13263, 384, 13, 51569], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 118, "seek": 38680, "start": 410.90000000000003, "end": 416.2, "text": " Jest taki benchmark, sw\u00f3j stytor Przeszk\u00f3d dla AI, nazywa si\u0119 Big Bench Hard.", "tokens": [51569, 24918, 20065, 18927, 11, 1693, 18999, 342, 4328, 284, 2114, 89, 10430, 74, 17081, 12285, 7318, 11, 20151, 88, 4151, 3244, 5429, 3964, 339, 11817, 13, 51834], "temperature": 0.0, "avg_logprob": -0.11686694769211757, "compression_ratio": 1.4407294832826747, "no_speech_prob": 0.13677962124347687}, {"id": 119, "seek": 41620, "start": 416.2, "end": 422.8, "text": " W jednym z zada\u0144, Multistep Arithmetic, kt\u00f3re wymaga wykonania kilku operacji matematycznych w odpowiedniej kolejno\u015bci,", "tokens": [50364, 343, 5232, 12996, 710, 710, 1538, 5248, 11, 14665, 468, 595, 1587, 41179, 11, 8864, 29764, 9286, 46702, 5609, 5128, 5279, 2208, 13152, 3803, 8615, 17466, 9399, 261, 36574, 10402, 23749, 16438, 11, 50694], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 120, "seek": 41620, "start": 422.8, "end": 427.9, "text": " poprawa wynik\u00f3w po r\u00f3wnaniu do starego modelu wynoszy ponad 286%.", "tokens": [50694, 1665, 424, 4151, 31936, 1035, 3901, 714, 11416, 895, 25849, 360, 22432, 1571, 2316, 84, 31936, 329, 1229, 9224, 345, 7562, 21, 6856, 50949], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 121, "seek": 41620, "start": 427.9, "end": 434.8, "text": " Zaraz 286%, ale raport wspomina, \u017ce to przy zastosowaniu Chain of Fault Prompting.", "tokens": [50949, 41580, 921, 7562, 21, 8923, 6775, 5099, 477, 17757, 49217, 11, 3561, 281, 6501, 36746, 329, 305, 25849, 33252, 295, 479, 5107, 15833, 662, 278, 13, 51294], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 122, "seek": 41620, "start": 434.8, "end": 435.9, "text": " Co to dok\u0142adnie znaczy?", "tokens": [51294, 3066, 281, 45864, 2766, 36584, 30, 51349], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 123, "seek": 41620, "start": 435.9, "end": 436.7, "text": " \u015awietne pytanie.", "tokens": [51349, 27933, 39083, 716, 36610, 13, 51389], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 124, "seek": 41620, "start": 436.7, "end": 442.2, "text": " Chain of Fault Prompting to jest technika, w kt\u00f3rej nie prosimy modelu po prostu o ko\u0144cow\u0105 odpowied\u017a.", "tokens": [51389, 33252, 295, 479, 5107, 15833, 662, 278, 281, 3492, 1537, 5439, 11, 261, 36023, 2838, 6267, 13189, 2316, 84, 714, 19518, 277, 26470, 66, 30297, 36574, 10659, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12951849478262442, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.002867245813831687}, {"id": 125, "seek": 44220, "start": 442.2, "end": 446.8, "text": " Zamiast tego, m\u00f3wimy o, poka\u017cmy, jak do tego doszed\u0142e\u015b, krok po kroku.", "tokens": [50364, 1176, 4526, 525, 8627, 11, 13489, 13189, 277, 11, 13010, 18264, 2226, 11, 4207, 360, 8627, 4491, 11312, 19827, 1788, 11, 350, 31621, 714, 45909, 5279, 13, 50594], "temperature": 0.0, "avg_logprob": -0.09016154059048356, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.33742961287498474}, {"id": 126, "seek": 44220, "start": 446.8, "end": 450.0, "text": " To go zmusza do rozpisania swojego toku my\u015blenia.", "tokens": [50594, 1407, 352, 17020, 301, 2394, 360, 9544, 40516, 5609, 13291, 39738, 281, 5279, 48633, 6698, 654, 13, 50754], "temperature": 0.0, "avg_logprob": -0.09016154059048356, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.33742961287498474}, {"id": 127, "seek": 44220, "start": 450.0, "end": 460.09999999999997, "text": " I okazuje si\u0119, \u017ce modele, tak jak ludzie, radz\u0105 sobie znacznie lepiej ze z\u0142o\u017conymi problemami, gdy mog\u0105 je rozbi\u0107 na mniejsze cz\u0119\u015bci.", "tokens": [50754, 286, 3133, 43317, 3244, 11, 3561, 4391, 306, 11, 991, 4207, 37025, 11, 2843, 8925, 13652, 15397, 14875, 2766, 476, 39699, 5277, 710, 5249, 1427, 2526, 3057, 1154, 4526, 11, 28405, 34123, 1506, 9544, 5614, 2162, 1667, 275, 44258, 41314, 13, 51259], "temperature": 0.0, "avg_logprob": -0.09016154059048356, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.33742961287498474}, {"id": 128, "seek": 44220, "start": 460.09999999999997, "end": 465.9, "text": " Ten gigantyczny skok wydajno\u015bci pokazuje, \u017ce Palm II nie tylko zna odpowied\u017a,", "tokens": [51259, 9380, 8741, 394, 17466, 1634, 1110, 453, 25984, 1805, 16438, 13010, 43317, 11, 3561, 32668, 6351, 2838, 13219, 710, 629, 36574, 10659, 11, 51549], "temperature": 0.0, "avg_logprob": -0.09016154059048356, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.33742961287498474}, {"id": 129, "seek": 44220, "start": 465.9, "end": 470.59999999999997, "text": " ale potrafi te\u017c lepiej symu\u0142owa\u0107 proces logicznego rozumowania, \u017ceby do niej doj\u015b\u0107.", "tokens": [51549, 6775, 1847, 10437, 72, 9516, 476, 39699, 6697, 84, 1221, 11445, 17565, 9952, 89, 11858, 48797, 21308, 11, 11316, 360, 2838, 73, 360, 44536, 13, 51784], "temperature": 0.0, "avg_logprob": -0.09016154059048356, "compression_ratio": 1.4536423841059603, "no_speech_prob": 0.33742961287498474}, {"id": 130, "seek": 47060, "start": 470.6, "end": 471.6, "text": " To ma sens.", "tokens": [50364, 1407, 463, 2923, 13, 50414], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 131, "seek": 47060, "start": 471.6, "end": 478.5, "text": " A co ciekawe, ta umiej\u0119tno\u015b\u0107 rozumowania przenosi si\u0119 te\u017c na matematyk\u0119, na poziomie, kt\u00f3ry jest ju\u017c naprawd\u0119 wysoki.", "tokens": [50414, 316, 598, 30596, 2330, 826, 11, 1846, 1105, 7764, 46788, 23293, 48797, 21308, 582, 2904, 21521, 3244, 9516, 1667, 3803, 8615, 88, 15724, 11, 1667, 38503, 40120, 11, 9913, 3492, 10678, 20970, 27062, 17056, 13, 50759], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 132, "seek": 47060, "start": 478.5, "end": 484.90000000000003, "text": " Tak, na standardowych testach matematycznych, takich jak GSMOid K, Palm II radzi sobie na poziomie,", "tokens": [50759, 9118, 11, 1667, 3832, 19605, 1500, 608, 3803, 8615, 17466, 9399, 11, 29607, 4207, 460, 26693, 46, 327, 591, 11, 32668, 6351, 2843, 3992, 13652, 1667, 38503, 40120, 11, 51079], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 133, "seek": 47060, "start": 484.90000000000003, "end": 488.3, "text": " a czasem nawet lepiej ni\u017c w specjalizowane modele, jak Minerva.", "tokens": [51079, 257, 13190, 443, 22696, 476, 39699, 28502, 261, 46433, 590, 23066, 4391, 306, 11, 4207, 2829, 1978, 64, 13, 51249], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 134, "seek": 47060, "start": 488.3, "end": 492.1, "text": " Minerva, czyli ten model trenowany specjalnie do matmy.", "tokens": [51249, 2829, 1978, 64, 11, 16591, 2064, 2316, 23136, 23341, 46433, 2766, 360, 3803, 2226, 13, 51439], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 135, "seek": 47060, "start": 492.1, "end": 493.3, "text": " Dok\u0142adnie.", "tokens": [51439, 29768, 10358, 2766, 13, 51499], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 136, "seek": 47060, "start": 493.3, "end": 500.0, "text": " A Palm II osi\u0105ga to niejako przy okazji, dzi\u0119ki swojemu og\u00f3lnemu, ulepszonemu treningu rozumowania.", "tokens": [51499, 316, 32668, 6351, 3003, 11404, 3680, 281, 2838, 73, 18501, 6501, 3133, 921, 4013, 11, 45003, 13291, 30833, 84, 5360, 15741, 25989, 84, 11, 344, 306, 1878, 35296, 37552, 2192, 773, 84, 48797, 21308, 13, 51834], "temperature": 0.0, "avg_logprob": -0.13326846566169884, "compression_ratio": 1.5095541401273886, "no_speech_prob": 0.06122254952788353}, {"id": 137, "seek": 50000, "start": 500.1, "end": 508.1, "text": " Mniejszy model, ale nakarmiony lepszej jako\u015bci, bardziej zr\u00f3\u017cnicowanym kodem i trenowanym m\u0105drzejszymi metodami,", "tokens": [50369, 376, 10402, 7706, 2316, 11, 6775, 20332, 4452, 46184, 476, 1878, 16920, 17123, 6199, 11, 27209, 710, 11721, 1427, 7692, 23341, 76, 350, 378, 443, 741, 23136, 23341, 76, 275, 18962, 13503, 73, 7706, 3057, 1131, 378, 4526, 11, 50769], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 138, "seek": 50000, "start": 508.1, "end": 510.9, "text": " okazuje si\u0119 po prostu lepszym programist\u0105.", "tokens": [50769, 3133, 43317, 3244, 714, 19518, 476, 1878, 26681, 1461, 468, 1611, 13, 50909], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 139, "seek": 50000, "start": 510.9, "end": 516.4, "text": " Ale to, co jest naprawd\u0119 fascynuj\u0105ce, to jego zdolno\u015bci w programowaniu wieloj\u0119zycznym.", "tokens": [50909, 9366, 281, 11, 598, 3492, 20970, 30632, 1344, 77, 13263, 384, 11, 281, 26542, 16221, 401, 16438, 261, 1461, 305, 25849, 20570, 78, 11115, 1229, 3689, 12996, 13, 51184], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 140, "seek": 50000, "start": 516.4, "end": 517.1, "text": " O tak.", "tokens": [51184, 422, 991, 13, 51219], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 141, "seek": 50000, "start": 517.1, "end": 522.4, "text": " Wida\u0107 gigantyczn\u0105 popraw\u0119 w bardziej niszowych j\u0119zykach, jak Haskell czy Julia,", "tokens": [51219, 343, 46898, 8741, 394, 17466, 13113, 1665, 5131, 1274, 261, 27209, 297, 23848, 19605, 49055, 41326, 11, 4207, 8646, 43723, 6430, 18551, 11, 51484], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 142, "seek": 50000, "start": 522.4, "end": 526.9, "text": " gdzie wzrost wydajno\u015bci jest kilkukrotny, a najwi\u0119ksza niespodzianka.", "tokens": [51484, 18922, 24809, 27494, 25984, 1805, 16438, 3492, 5128, 74, 2034, 10536, 1634, 11, 257, 48636, 1694, 2394, 48100, 79, 14543, 21729, 13, 51709], "temperature": 0.0, "avg_logprob": -0.08180049463366786, "compression_ratio": 1.4596491228070176, "no_speech_prob": 0.004299558699131012}, {"id": 143, "seek": 52690, "start": 526.9, "end": 533.6, "text": " Jego wyniki w generowaniu kodu w j\u0119zykach Java, JavaScript i TypeScript s\u0105 lepsze ni\u017c w Paitonie,", "tokens": [50364, 508, 6308, 31936, 9850, 261, 1337, 305, 25849, 350, 34873, 261, 49055, 41326, 10745, 11, 15778, 741, 15576, 14237, 9015, 476, 1878, 1381, 28502, 261, 430, 1001, 32242, 11, 50699], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 144, "seek": 52690, "start": 533.6, "end": 537.4, "text": " a przecie\u017c oryginalny benchmark zosta\u0142 stworzony w\u0142a\u015bnie dla Paitona.", "tokens": [50699, 257, 8325, 40082, 420, 88, 1494, 304, 1634, 18927, 23154, 1221, 342, 28321, 44479, 14234, 12285, 430, 1001, 4037, 13, 50889], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 145, "seek": 52690, "start": 537.4, "end": 538.9, "text": " Niesamowite.", "tokens": [50889, 426, 530, 335, 305, 642, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 146, "seek": 52690, "start": 538.9, "end": 542.8, "text": " To co to wszystko oznacza w praktyce dla przeci\u0119tnego u\u017cytkownika?", "tokens": [50964, 1407, 598, 281, 22607, 277, 22672, 326, 2394, 261, 3206, 74, 874, 384, 12285, 39622, 46788, 11858, 344, 1427, 4328, 74, 648, 5439, 30, 51159], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 147, "seek": 52690, "start": 542.8, "end": 546.4, "text": " Czy m\u00f3j Google Translate b\u0119dzie teraz dzia\u0142a\u0142 o niebo lepiej?", "tokens": [51159, 19832, 275, 18999, 3329, 6531, 17593, 10562, 16854, 37903, 1221, 277, 2838, 1763, 476, 39699, 30, 51339], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 148, "seek": 52690, "start": 546.4, "end": 547.6999999999999, "text": " W\u0142a\u015bnie tak.", "tokens": [51339, 343, 5024, 12221, 991, 13, 51404], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 149, "seek": 52690, "start": 547.6999999999999, "end": 553.6, "text": " Raport pokazuje, \u017ce Palm II w t\u0142umaczeniach nie tylko przewy\u017csza swojego poprzednika,", "tokens": [51404, 16184, 477, 13010, 43317, 11, 3561, 32668, 6351, 261, 256, 49166, 326, 42124, 608, 2838, 13219, 39758, 88, 1427, 82, 2394, 13291, 39738, 1665, 81, 11312, 77, 5439, 11, 51699], "temperature": 0.0, "avg_logprob": -0.06986058333824421, "compression_ratio": 1.415282392026578, "no_speech_prob": 0.024458233267068863}, {"id": 150, "seek": 55360, "start": 553.6, "end": 560.2, "text": " ale jest w pe\u0142ni konkurencyjny dla dedykowanych produkcyjnych system\u00f3w, jak dotychczasowy Google Translate.", "tokens": [50364, 6775, 3492, 261, 43205, 3722, 21428, 9873, 42949, 1634, 12285, 4172, 46127, 23341, 339, 33699, 42949, 9399, 1185, 3901, 11, 4207, 5893, 16384, 30989, 10089, 3329, 6531, 17593, 13, 50694], "temperature": 0.0, "avg_logprob": -0.08221820575087818, "compression_ratio": 1.5071942446043165, "no_speech_prob": 0.08461842685937881}, {"id": 151, "seek": 55360, "start": 560.2, "end": 565.7, "text": " W bezpo\u015brednich testach por\u00f3wnawczych dla par chi\u0144ski, angielski i angielski niemiecki", "tokens": [50694, 343, 10782, 2259, 1788, 986, 77, 480, 1500, 608, 1515, 3901, 629, 86, 6522, 339, 12285, 971, 13228, 5248, 18020, 11, 2562, 1187, 18020, 741, 2562, 1187, 18020, 2838, 25210, 547, 72, 50969], "temperature": 0.0, "avg_logprob": -0.08221820575087818, "compression_ratio": 1.5071942446043165, "no_speech_prob": 0.08461842685937881}, {"id": 152, "seek": 55360, "start": 565.7, "end": 572.1, "text": " t\u0142umaczenia generowane przez Palm II by\u0142y oceniane przez ludzi jako znacznie lepsze.", "tokens": [50969, 256, 49166, 326, 14320, 1337, 23066, 14064, 32668, 6351, 26366, 10409, 268, 21133, 14064, 29586, 17123, 15397, 14875, 2766, 476, 1878, 1381, 13, 51289], "temperature": 0.0, "avg_logprob": -0.08221820575087818, "compression_ratio": 1.5071942446043165, "no_speech_prob": 0.08461842685937881}, {"id": 153, "seek": 55360, "start": 572.1, "end": 580.6, "text": " Co wi\u0119cej, dzi\u0119ki tym zr\u00f3\u017cnicowanym danym model znacznie lepiej radzi sobie z t\u0142umaczeniem niuans\u00f3w i dialekt\u00f3w regionalnych.", "tokens": [51289, 3066, 26004, 11, 45003, 8107, 710, 11721, 1427, 7692, 23341, 76, 274, 1325, 76, 2316, 15397, 14875, 2766, 476, 39699, 2843, 3992, 13652, 710, 256, 49166, 326, 2904, 4907, 3867, 84, 599, 3901, 741, 5502, 8192, 3901, 10964, 9399, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08221820575087818, "compression_ratio": 1.5071942446043165, "no_speech_prob": 0.08461842685937881}, {"id": 154, "seek": 58060, "start": 580.6, "end": 588.6, "text": " OK, model jest m\u0105drzejszy, szybszy, lepszy. Brzmi idealnie, ale zwykle w takich historiach jest jaki\u015b haczyk.", "tokens": [50364, 2264, 11, 2316, 3492, 275, 18962, 13503, 73, 7706, 11, 30526, 929, 1229, 11, 476, 1878, 1229, 13, 1603, 89, 3057, 7157, 2766, 11, 6775, 43436, 14677, 261, 29607, 4058, 72, 608, 3492, 34721, 324, 6522, 74, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10263539936916888, "compression_ratio": 1.352, "no_speech_prob": 0.0024161774199455976}, {"id": 155, "seek": 58060, "start": 588.6, "end": 591.6, "text": " Raport nie zamiata problem\u00f3w pod dywan, prawda?", "tokens": [50764, 16184, 477, 2838, 710, 4526, 3274, 1154, 3901, 2497, 14584, 7916, 11, 43607, 30, 50914], "temperature": 0.0, "avg_logprob": -0.10263539936916888, "compression_ratio": 1.352, "no_speech_prob": 0.0024161774199455976}, {"id": 156, "seek": 58060, "start": 591.6, "end": 596.1, "text": " Jak wygl\u0105da kwestia, powiedzmy, pami\u0119ci tego modelu i prywatno\u015bci danych?", "tokens": [50914, 15029, 32015, 42035, 654, 11, 27617, 2226, 11, 31088, 537, 8627, 2316, 84, 741, 582, 27112, 267, 16438, 274, 34644, 30, 51139], "temperature": 0.0, "avg_logprob": -0.10263539936916888, "compression_ratio": 1.352, "no_speech_prob": 0.0024161774199455976}, {"id": 157, "seek": 58060, "start": 596.1, "end": 599.1, "text": " To bardzo wa\u017cny i z\u0142o\u017cony temat.", "tokens": [51139, 1407, 9034, 27777, 1634, 741, 710, 5249, 1427, 2526, 32954, 13, 51289], "temperature": 0.0, "avg_logprob": -0.10263539936916888, "compression_ratio": 1.352, "no_speech_prob": 0.0024161774199455976}, {"id": 158, "seek": 58060, "start": 599.1, "end": 604.6, "text": " Wniki s\u0105 tu, no, niejednoznaczne, co raport uczciwie przyznaje.", "tokens": [51289, 343, 77, 9850, 9015, 2604, 11, 572, 11, 2838, 40543, 1771, 22672, 14875, 716, 11, 598, 5099, 477, 35403, 537, 8699, 6501, 35458, 2884, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10263539936916888, "compression_ratio": 1.352, "no_speech_prob": 0.0024161774199455976}, {"id": 159, "seek": 60460, "start": 604.6, "end": 612.6, "text": " Z jednej strony, Palm II \u015brednio rzadziej wypluwa z siebie unikalne, dos\u0142owne fragmenty danych treningowych.", "tokens": [50364, 1176, 5232, 11794, 32406, 11, 32668, 6351, 8299, 986, 41084, 367, 89, 345, 19554, 4628, 564, 84, 4151, 710, 39137, 517, 41216, 716, 11, 4491, 1221, 648, 68, 26424, 88, 274, 34644, 2192, 773, 19605, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 160, "seek": 60460, "start": 612.6, "end": 614.6, "text": " To du\u017cy plus dla prywatno\u015bci.", "tokens": [50764, 1407, 1581, 7735, 1804, 12285, 582, 27112, 267, 16438, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 161, "seek": 60460, "start": 614.6, "end": 615.6, "text": " Ale?", "tokens": [50864, 9366, 30, 50914], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 162, "seek": 60460, "start": 615.6, "end": 617.6, "text": " Ale jest te\u017c druga strona medalu.", "tokens": [50914, 9366, 3492, 9516, 4110, 64, 1056, 4037, 1205, 4929, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 163, "seek": 60460, "start": 617.6, "end": 626.1, "text": " Je\u015bli jaki\u015b fragment tekstu, np. popularny cytat, albo fragment regulaminu, by\u0142 w danych treningowych powtarzany tysi\u0105ce razy,", "tokens": [51014, 37086, 34721, 26424, 16624, 372, 84, 11, 33808, 13, 3743, 1634, 3185, 27321, 11, 22622, 26424, 9837, 7428, 84, 11, 16673, 261, 274, 34644, 2192, 773, 19605, 3388, 23480, 89, 1325, 38156, 11404, 384, 9639, 88, 11, 51439], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 164, "seek": 60460, "start": 626.1, "end": 632.1, "text": " to Palm II ma wi\u0119ksz\u0105 sk\u0142onno\u015b\u0107 do jego zapami\u0119tania i odtworzenia ni\u017c stare model.", "tokens": [51439, 281, 32668, 6351, 463, 29968, 8925, 1110, 1221, 266, 23293, 360, 26542, 14223, 23806, 83, 5609, 741, 3611, 20270, 284, 14320, 28502, 22432, 2316, 13, 51739], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 165, "seek": 60460, "start": 632.1, "end": 634.1, "text": " Z czego to mo\u017ce wynika\u0107?", "tokens": [51739, 1176, 36559, 281, 12034, 31936, 5439, 2162, 30, 51839], "temperature": 0.0, "avg_logprob": -0.08168605301115248, "compression_ratio": 1.465986394557823, "no_speech_prob": 0.019004054367542267}, {"id": 166, "seek": 63410, "start": 634.1, "end": 638.1, "text": " Prawdopodobnie to efekt uboczny procesu deduplikacji danych.", "tokens": [50364, 430, 15889, 46684, 996, 2766, 281, 31482, 8192, 26709, 905, 89, 1634, 17565, 84, 4172, 44810, 1035, 13152, 274, 34644, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 167, "seek": 63410, "start": 638.1, "end": 644.6, "text": " Kiedy usuwasz wi\u0119kszo\u015b\u0107 powt\u00f3rze\u0144, te kt\u00f3re zostaj\u0105, staj\u0105 si\u0119 statystycznie bardziej widoczne dla modelu.", "tokens": [50564, 591, 16446, 32247, 6569, 89, 29968, 4765, 7753, 3388, 4547, 13503, 5248, 11, 535, 8864, 31873, 11133, 11, 342, 11133, 3244, 2219, 38593, 17466, 2766, 27209, 5274, 905, 43077, 12285, 2316, 84, 13, 50889], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 168, "seek": 63410, "start": 644.6, "end": 648.1, "text": " Co paradoksalnie mo\u017ce zwi\u0119ksza\u0107 szanse na ich zapami\u0119tanie?", "tokens": [50889, 3066, 13480, 453, 15142, 2766, 12034, 11873, 5034, 1694, 35873, 7870, 47661, 1667, 1893, 14223, 23806, 83, 7155, 30, 51064], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 169, "seek": 63410, "start": 648.1, "end": 649.1, "text": " Dokodnie.", "tokens": [51064, 29768, 378, 2766, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 170, "seek": 63410, "start": 649.1, "end": 657.1, "text": " To pokazuje, jak skomplikowane s\u0105 te systemy i jak jedna poprawka mo\u017ce nieoczepiwanie wp\u0142yn\u0105\u0107 na inny aspekt ich dzia\u0142ania.", "tokens": [51114, 1407, 13010, 43317, 11, 4207, 1110, 298, 564, 1035, 23066, 9015, 535, 1185, 88, 741, 4207, 5232, 629, 1665, 5131, 2330, 12034, 2838, 905, 46342, 72, 86, 7155, 32444, 1221, 2534, 36374, 1667, 294, 1634, 382, 23533, 1893, 27121, 5609, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 171, "seek": 63410, "start": 657.1, "end": 661.6, "text": " A co zgenerowaniem, no wiesz, toksycznych, nieprzyjemnych tre\u015bci?", "tokens": [51514, 316, 598, 710, 21848, 37345, 4907, 11, 572, 261, 15347, 11, 281, 1694, 17466, 9399, 11, 2838, 1424, 1229, 30833, 9399, 2192, 6199, 30, 51739], "temperature": 0.0, "avg_logprob": -0.06444296470055214, "compression_ratio": 1.4466019417475728, "no_speech_prob": 0.0008452906040474772}, {"id": 172, "seek": 66160, "start": 661.6, "end": 667.1, "text": " Wiemy, \u017ce internet jest ich pe\u0142em, a to przecie\u017c g\u0142\u00f3wny \u017ar\u00f3d\u0142o danych.", "tokens": [50364, 9233, 2226, 11, 3561, 4705, 3492, 1893, 43205, 443, 11, 257, 281, 8325, 40082, 18117, 812, 43682, 50212, 43678, 5249, 274, 34644, 13, 50639], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 173, "seek": 66160, "start": 667.1, "end": 669.1, "text": " Da si\u0119 to jako\u015b kontrolowa\u0107?", "tokens": [50639, 3933, 3244, 281, 17123, 1788, 14373, 6623, 11445, 30, 50739], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 174, "seek": 66160, "start": 669.1, "end": 670.6, "text": " Pr\u00f3bowano.", "tokens": [50739, 2114, 812, 8202, 3730, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 175, "seek": 66160, "start": 670.6, "end": 681.1, "text": " Podczas trening\u00f3w prowadzono specjalne tokeny kontrolne, kt\u00f3re oznacza\u0142y fragmenty tekstu jako ma\u0142o, \u015brednio lub bardzo toksyczne.", "tokens": [50814, 12646, 30989, 2192, 773, 3901, 36590, 89, 8957, 46433, 716, 14862, 88, 14373, 6623, 716, 11, 8864, 277, 22672, 326, 2394, 6825, 26424, 88, 16624, 372, 84, 17123, 463, 5249, 11, 8299, 986, 41084, 15980, 9034, 281, 1694, 17466, 716, 13, 51339], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 176, "seek": 66160, "start": 681.1, "end": 688.1, "text": " Teoretycznie, podczas generowania odpowiedzi mo\u017cna by u\u017cy\u0107 tych token\u00f3w, \u017ceby nakaza\u0107 modelowi b\u0105d\u017a mi\u0142y.", "tokens": [51339, 1989, 418, 45586, 11, 2497, 30989, 1337, 21308, 36574, 3992, 17790, 538, 34097, 2162, 15180, 14862, 3901, 11, 11316, 20332, 12257, 2162, 2316, 24503, 272, 18962, 10659, 2752, 6825, 13, 51689], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 177, "seek": 66160, "start": 688.1, "end": 689.1, "text": " I co, dzia\u0142a?", "tokens": [51689, 286, 598, 11, 37903, 30, 51739], "temperature": 0.0, "avg_logprob": -0.07699093856210784, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.0029298856388777494}, {"id": 178, "seek": 68910, "start": 689.1, "end": 693.6, "text": " No w\u0142a\u015bnie, tutaj raport dochodzi do bardzo ciekawego wniosku.", "tokens": [50364, 883, 14234, 11, 12749, 5099, 477, 9243, 14543, 360, 9034, 30596, 2330, 826, 1571, 45368, 2717, 5279, 13, 50589], "temperature": 0.0, "avg_logprob": -0.06388581914009808, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0029766089282929897}, {"id": 179, "seek": 68910, "start": 693.6, "end": 704.6, "text": " Okazuje si\u0119, \u017ce cz\u0119sto prosty prompt dialogowy, czyli instrukcja w stylu wciel si\u0119 w rol\u0119 pomocnego i uprzejmego asystenta, by\u0142 skuteczniejszy w redukcji toksyczno\u015bci.", "tokens": [50589, 3477, 43317, 3244, 11, 3561, 34369, 10293, 88, 12391, 19308, 10089, 11, 16591, 1058, 25126, 34056, 261, 7952, 2781, 261, 537, 338, 3244, 261, 34109, 1274, 48962, 11858, 741, 493, 13503, 73, 76, 6308, 382, 38593, 8938, 11, 16673, 1110, 1169, 3689, 10402, 7706, 261, 2783, 74, 19649, 281, 1694, 17466, 16438, 13, 51139], "temperature": 0.0, "avg_logprob": -0.06388581914009808, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0029766089282929897}, {"id": 180, "seek": 68910, "start": 704.6, "end": 708.1, "text": " Skuteczniejszy ni\u017c te wszystkie skomplikowane tokeny kontrolne?", "tokens": [51139, 7324, 1169, 3689, 10402, 7706, 28502, 535, 31723, 1110, 298, 564, 1035, 23066, 14862, 88, 14373, 6623, 716, 30, 51314], "temperature": 0.0, "avg_logprob": -0.06388581914009808, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0029766089282929897}, {"id": 181, "seek": 68910, "start": 708.1, "end": 709.1, "text": " Tak.", "tokens": [51314, 9118, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06388581914009808, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0029766089282929897}, {"id": 182, "seek": 68910, "start": 709.1, "end": 717.1, "text": " To troch\u0119 podwa\u017ca sensowno\u015b\u0107 niekt\u00f3rych metod i pokazuje, \u017ce czasem najprostsze rozwi\u0105zania s\u0105 najlepsze.", "tokens": [51364, 1407, 24926, 2497, 27111, 64, 2923, 648, 78, 7753, 2838, 43073, 627, 339, 1131, 378, 741, 13010, 43317, 11, 3561, 13190, 443, 11212, 1424, 555, 82, 1381, 9544, 22620, 5609, 9015, 41903, 1878, 1381, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06388581914009808, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.0029766089282929897}, {"id": 183, "seek": 71710, "start": 717.1, "end": 722.1, "text": " I to prowadzi do szerszego problemu, kt\u00f3ry wida\u0107 po analizie samych danych treningowych.", "tokens": [50364, 286, 281, 36590, 3992, 360, 7870, 433, 27725, 1154, 84, 11, 9913, 261, 46898, 714, 2624, 590, 414, 3247, 16384, 274, 34644, 2192, 773, 19605, 13, 50614], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 184, "seek": 71710, "start": 722.1, "end": 725.6, "text": " Raport potwierdza to, czego wielu si\u0119 domy\u015bla\u0142o.", "tokens": [50614, 16184, 477, 1847, 40717, 67, 2394, 281, 11, 36559, 40437, 3244, 3285, 88, 1788, 875, 5249, 13, 50789], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 185, "seek": 71710, "start": 725.6, "end": 732.6, "text": " Dane s\u0105 mocno przechylane strony o kultury zachodniej, a kobiety s\u0105 w nich niedostatecznie reprezentowane.", "tokens": [50789, 413, 1929, 9015, 34962, 1771, 8325, 28629, 46121, 32406, 277, 350, 723, 2598, 29303, 378, 10402, 11, 257, 43057, 4014, 9015, 261, 25570, 32488, 555, 473, 19923, 1085, 265, 14185, 23066, 13, 51139], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 186, "seek": 71710, "start": 732.6, "end": 742.6, "text": " Co wi\u0119cej, analiza wykaza\u0142a, \u017ce dokumenty, w kt\u00f3rych pojawiaj\u0105 si\u0119 okre\u015blenia pewnych grup to\u017csamo\u015bciowych, statystycznie cz\u0119\u015bciej zawieraj\u0105 tre\u015bci toksyczne.", "tokens": [51139, 3066, 26004, 11, 2624, 13427, 39287, 12257, 5024, 11, 3561, 40858, 88, 11, 261, 30382, 30655, 48125, 3244, 3133, 265, 1788, 6698, 654, 47160, 16384, 12740, 281, 1427, 82, 10502, 6199, 19605, 11, 2219, 38593, 17466, 2766, 18544, 9815, 73, 28165, 811, 11133, 2192, 6199, 281, 1694, 17466, 716, 13, 51639], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 187, "seek": 71710, "start": 742.6, "end": 744.6, "text": " Czyli problem jest w danych \u017ar\u00f3d\u0142owych?", "tokens": [51639, 37099, 1154, 3492, 261, 274, 34644, 50212, 43678, 1221, 19605, 30, 51739], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 188, "seek": 71710, "start": 744.6, "end": 745.6, "text": " Tak.", "tokens": [51739, 9118, 13, 51789], "temperature": 0.0, "avg_logprob": -0.058251732274105676, "compression_ratio": 1.4858044164037856, "no_speech_prob": 0.01591678149998188}, {"id": 189, "seek": 74560, "start": 745.6, "end": 757.6, "text": " To pokazuje, \u017ce nawet przyznacznie bardziej zr\u00f3\u017cnicowanych danych problem stronniczo\u015bci i uprzedze\u0144 wbudowanych w j\u0119zyk, kt\u00f3rego uczymy AI, pozostaje ogromnym, nierozwi\u0105zanym wyzwaniem.", "tokens": [50364, 1407, 13010, 43317, 11, 3561, 22696, 6501, 22672, 14875, 2766, 27209, 710, 11721, 1427, 7692, 23341, 339, 274, 34644, 1154, 1056, 266, 7692, 4765, 6199, 741, 493, 81, 11312, 49689, 261, 18281, 23341, 339, 261, 49055, 74, 11, 46951, 344, 6522, 2226, 7318, 11, 21281, 555, 11153, 34416, 298, 12996, 11, 297, 12030, 89, 22620, 1325, 76, 4628, 89, 7916, 4907, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07372169118178518, "compression_ratio": 1.4397394136807817, "no_speech_prob": 0.026883486658334732}, {"id": 190, "seek": 74560, "start": 757.6, "end": 761.6, "text": " To nie jest co\u015b, co mo\u017cna naprawi\u0107 tylko lepszym algorytmem.", "tokens": [50964, 1407, 2838, 3492, 19241, 11, 598, 17790, 9296, 5131, 12757, 13219, 476, 1878, 26681, 3501, 827, 83, 17886, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07372169118178518, "compression_ratio": 1.4397394136807817, "no_speech_prob": 0.026883486658334732}, {"id": 191, "seek": 74560, "start": 761.6, "end": 764.6, "text": " To odbicie problem\u00f3w w naszym spo\u0142ecze\u0144stwie.", "tokens": [51164, 1407, 3611, 65, 28434, 1154, 3901, 261, 48094, 36851, 1381, 12229, 8699, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07372169118178518, "compression_ratio": 1.4397394136807817, "no_speech_prob": 0.026883486658334732}, {"id": 192, "seek": 74560, "start": 764.6, "end": 769.1, "text": " Podsumowuj\u0105c, lekcja z tego raportu wydaje si\u0119 prosta, ale i pot\u0119\u017cna.", "tokens": [51314, 12646, 82, 449, 305, 44733, 11, 30863, 34056, 710, 8627, 5099, 477, 84, 49165, 3244, 582, 8638, 11, 6775, 741, 1847, 1274, 1427, 629, 13, 51539], "temperature": 0.0, "avg_logprob": -0.07372169118178518, "compression_ratio": 1.4397394136807817, "no_speech_prob": 0.026883486658334732}, {"id": 193, "seek": 74560, "start": 769.1, "end": 773.1, "text": " W AI nadszed\u0142 czas na prac\u0119 m\u0105dr\u0105, a nie tylko ci\u0119\u017ck\u0105.", "tokens": [51539, 343, 7318, 297, 5834, 11312, 1221, 13190, 1667, 22404, 1274, 275, 18962, 32881, 11, 257, 2838, 13219, 35484, 1427, 26304, 13, 51739], "temperature": 0.0, "avg_logprob": -0.07372169118178518, "compression_ratio": 1.4397394136807817, "no_speech_prob": 0.026883486658334732}, {"id": 194, "seek": 77310, "start": 773.1, "end": 785.6, "text": " Okazuje si\u0119, \u017ce liczy si\u0119 jako\u015b\u0107 danych, sprytny, wieloaspektowy trening i znalezienie w\u0142a\u015bciwej r\u00f3wnowagi, a nie tylko \u015blep\u0119 d\u0105\u017cenie do budowy jak najwi\u0119kszego modelu.", "tokens": [50364, 3477, 43317, 3244, 11, 3561, 6169, 1229, 3244, 17123, 7753, 274, 34644, 11, 637, 627, 83, 1634, 11, 20570, 78, 296, 23533, 10089, 2192, 773, 741, 15397, 37646, 27385, 40112, 826, 73, 11416, 895, 305, 20291, 11, 257, 2838, 13219, 8299, 306, 79, 1274, 274, 1611, 41118, 360, 3265, 10089, 4207, 48636, 1694, 27725, 2316, 84, 13, 50989], "temperature": 0.0, "avg_logprob": -0.09841716731036151, "compression_ratio": 1.3777777777777778, "no_speech_prob": 0.023803267627954483}, {"id": 195, "seek": 77310, "start": 785.6, "end": 786.6, "text": " Dok\u0142adnie.", "tokens": [50989, 29768, 10358, 2766, 13, 51039], "temperature": 0.0, "avg_logprob": -0.09841716731036151, "compression_ratio": 1.3777777777777778, "no_speech_prob": 0.023803267627954483}, {"id": 196, "seek": 77310, "start": 786.6, "end": 794.6, "text": " Szer\u017csza perspektywa jest taka, \u017ce wchodzimy w erefektywno\u015bci i inteligencji projektu, a nie tylko surowej skali.", "tokens": [51039, 318, 4527, 1427, 82, 2394, 868, 32659, 874, 4151, 3492, 28017, 11, 3561, 261, 29914, 89, 13189, 261, 25022, 69, 916, 874, 20944, 6199, 741, 24777, 3213, 19649, 26261, 84, 11, 257, 2838, 13219, 1022, 21091, 1110, 5103, 13, 51439], "temperature": 0.0, "avg_logprob": -0.09841716731036151, "compression_ratio": 1.3777777777777778, "no_speech_prob": 0.023803267627954483}, {"id": 197, "seek": 79460, "start": 795.1, "end": 803.1, "text": " To mo\u017ce oznacza\u0107, \u017ce przysz\u0142o\u015b\u0107 AI niekoniecznie le\u017cy w budowaniu jeszcze wi\u0119kszych poch\u0142aniaj\u0105cych gigantyczne ilo\u015bci energii modeli.", "tokens": [50389, 1407, 12034, 277, 22672, 326, 35873, 11, 3561, 44018, 44742, 7318, 2838, 18295, 414, 19923, 476, 7735, 261, 3265, 305, 25849, 14168, 29968, 28051, 714, 339, 1221, 5609, 8555, 31306, 8741, 394, 17466, 716, 1930, 44468, 10575, 5597, 2316, 72, 13, 50789], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 198, "seek": 79460, "start": 803.1, "end": 808.1, "text": " Mo\u017ce le\u017cy w lepszej kuracji danych i projektowaniu sprytniejszych architektur.", "tokens": [50789, 43774, 476, 7735, 261, 476, 1878, 16920, 10072, 13152, 274, 34644, 741, 26261, 305, 25849, 637, 627, 83, 10402, 45021, 3912, 642, 2320, 374, 13, 51039], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 199, "seek": 79460, "start": 808.1, "end": 810.6, "text": " Jak ten ma\u0142y model dokodowania.", "tokens": [51039, 15029, 2064, 463, 6825, 2316, 25037, 378, 21308, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 200, "seek": 79460, "start": 810.6, "end": 812.1, "text": " Idealny przyk\u0142ad.", "tokens": [51164, 13090, 304, 1634, 23144, 13, 51239], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 201, "seek": 79460, "start": 812.1, "end": 820.1, "text": " Ten ma\u0142y model Palm 2S, kt\u00f3ry b\u0119d\u0105c tylko u\u0142amkiem rozmiaru poprzednika, okaza\u0142 si\u0119 od niego znacznie lepszy.", "tokens": [51239, 9380, 463, 6825, 2316, 32668, 568, 50, 11, 9913, 26239, 66, 13219, 344, 20177, 26116, 9544, 3057, 16870, 1665, 81, 11312, 77, 5439, 11, 3133, 12257, 1221, 3244, 3611, 49615, 15397, 14875, 2766, 476, 1878, 1229, 13, 51639], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 202, "seek": 79460, "start": 820.1, "end": 824.1, "text": " To dow\u00f3d na to, \u017ce inteligencja mo\u017ce pokona\u0107 si\u0142\u0119.", "tokens": [51639, 1407, 9459, 17081, 1667, 281, 11, 3561, 24777, 3213, 34056, 12034, 13010, 4037, 2162, 1511, 46564, 13, 51839], "temperature": 0.0, "avg_logprob": -0.05426065986220901, "compression_ratio": 1.4627831715210355, "no_speech_prob": 0.14614751935005188}, {"id": 203, "seek": 82410, "start": 824.1, "end": 829.1, "text": " I to zostawia nas z pytaniem, kt\u00f3re wydaje mi si\u0119 kluczowe na najbli\u017csze lata.", "tokens": [50364, 286, 281, 31873, 34953, 5382, 710, 25878, 282, 4907, 11, 8864, 49165, 2752, 3244, 9671, 1311, 89, 6880, 1667, 11212, 32117, 1427, 82, 1381, 46722, 13, 50614], "temperature": 0.0, "avg_logprob": -0.045527890577154645, "compression_ratio": 1.4087301587301588, "no_speech_prob": 0.00048242221237160265}, {"id": 204, "seek": 82410, "start": 829.1, "end": 839.1, "text": " Skoro stajemy si\u0119 coraz lepsi w dobieraniu danych i udoskonalaniu metod treningu, to jaki jest prawdziwy optymalny rozmiar dla modelu j\u0119zykowego?", "tokens": [50614, 7324, 10780, 342, 1805, 3633, 3244, 25899, 476, 1878, 72, 261, 27082, 811, 25849, 274, 34644, 741, 11727, 329, 18295, 304, 25849, 1131, 378, 2192, 773, 84, 11, 281, 24492, 3492, 41175, 3992, 9726, 2427, 4199, 304, 1634, 9544, 3057, 289, 12285, 2316, 84, 49055, 74, 26576, 30, 51114], "temperature": 0.0, "avg_logprob": -0.045527890577154645, "compression_ratio": 1.4087301587301588, "no_speech_prob": 0.00048242221237160265}, {"id": 205, "seek": 82410, "start": 839.1, "end": 846.6, "text": " Czy mo\u017cliwe, \u017ce ju\u017c dawno przekroczyli\u015bmy punkt, w kt\u00f3rym dalsze powi\u0119kszanie modeli przynosi coraz mniejsze korzy\u015bci?", "tokens": [51114, 19832, 30854, 826, 11, 3561, 10678, 18192, 78, 29785, 340, 6522, 38452, 39561, 11, 261, 30120, 274, 1124, 1381, 3388, 5034, 1694, 89, 7155, 2316, 72, 6501, 16751, 72, 25899, 275, 44258, 14784, 1229, 6199, 30, 51489], "temperature": 0.0, "avg_logprob": -0.045527890577154645, "compression_ratio": 1.4087301587301588, "no_speech_prob": 0.00048242221237160265}, {"id": 206, "seek": 84660, "start": 846.6, "end": 859.1, "text": " Mo\u017ce prawdziwa rewolucja i najbardziej u\u017cyteczne narz\u0119dzia b\u0119d\u0105 pochodzi\u0107 nie z cyfrowych gigant\u00f3w, ale ze znacznie mniejszych, bardziej zwinnych i po prostu inteligentniej zaprojektowanych system\u00f3w?", "tokens": [50364, 43774, 41175, 3992, 4151, 319, 48481, 1311, 2938, 741, 41857, 34097, 975, 38491, 6714, 89, 6298, 40395, 26239, 714, 34616, 2162, 2838, 710, 3185, 69, 1892, 16384, 8741, 394, 3901, 11, 6775, 5277, 15397, 14875, 2766, 39513, 45021, 11, 27209, 710, 9136, 9399, 741, 714, 19518, 24777, 25002, 10402, 14223, 340, 14930, 23341, 339, 1185, 3901, 30, 50989], "temperature": 0.0, "avg_logprob": -0.06372497081756592, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.15029224753379822}], "language": "pl"}