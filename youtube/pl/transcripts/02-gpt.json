{"text": " Witam w naszej kolejnej analizie. Dzi\u015b cofniemy si\u0119 w czasie do momentu, kt\u00f3ry no c\u00f3\u017c, zdefiniowa\u0142 wsp\u00f3\u0142czesn\u0105 sztuczn\u0105 inteligencj\u0119. Mamy przed sob\u0105 artyku\u0142 z 2018 roku od zespo\u0142u OpenAI. Improving Language Understanding by Generative Pre-Training. Tytu\u0142 brzmi do\u015b\u0107 skromnie. Bardzo skromnie. Ale to jest dokument za\u0142o\u017cycielski ca\u0142ej RGPT. Taki, mo\u017cna powiedzie\u0107, pacjent zero. Dok\u0142adnie. I \u017ceby zrozumie\u0107, jak wielki to by\u0142 prze\u0142om, trzeba sobie przypomnie\u0107, jak wygl\u0105da\u0142 wtedy \u015bwiat NLP, czyli przetwarzania j\u0119zyka naturalnego. By\u0142 bardzo poszatkowany. Niezwykle fragmentaryczny. Jak chcia\u0142o si\u0119 zbudowa\u0107 model do analizy sentimentu, no to tworzy\u0142o si\u0119 go od zera. Do odpowiadania na pytania, zupe\u0142nie inny model, inna architektura, inny proces. Ka\u017cde zadanie to by\u0142a osobna, taka rzemie\u015bnicza praca. I ka\u017cde z tych zada\u0144 wymaga\u0142o gigantycznych, r\u0119cznie tworzonych zbior\u00f3w danych. Trzeba by\u0142o p\u0142aci\u0107 tysi\u0105com ludzi za etykietowanie setek tysi\u0119cy przyk\u0142ad\u00f3w. To by\u0142a prawdziwa blokada dla post\u0119pu. Brakowa\u0142o nie mocy obliczeniowej, ale w\u0142a\u015bnie dobrych oznaczonych danych. W\u0142a\u015bnie. A autorzy tego artyku\u0142u zadali pytanie, kt\u00f3re no, wywr\u00f3ci\u0142o stolik. A co je\u015bli? Przestaniemy tak my\u015ble\u0107. A co je\u015bli podejdziemy do tego inaczej? Tak. Co je\u015bli we\u017amiemy ca\u0142y tekst, jaki mamy? Ksi\u0105\u017cki, artyku\u0142y, internet i wykorzystamy go do stworzenia jednego, pot\u0119\u017cnego, uniwersalnego modelu bazowego. Takiego studenta, kt\u00f3ry najpierw idzie na studia og\u00f3lne? O to chodzi. Modelu, kt\u00f3ry potem m\u00f3g\u0142by si\u0119 wiesz, szybko wyspecjalizowa\u0107 w dowolnej dziedzinie przy minimalnym dodatkowym wysi\u0142ku. Nasz\u0105 misj\u0105 jest wi\u0119c roz\u0142o\u017cenie tej rewolucyjnej koncepcji na czynniki pierwsze. Zobaczymy, jak dzia\u0142a ten dwuetapowy proces, czyli pretraining i fine tuning. I dlaczego wyb\u00f3r architektury transformera by\u0142 takim strza\u0142em w dziesi\u0105tk\u0119? I jakie absolutnie szokuj\u0105ce, jak na tamte czasy, przynios\u0142o to rezultat. Zanurzmy si\u0119 w tym. No dobrze, to rozpakujmy ten fundamentalny pomys\u0142. M\u00f3wimy o dw\u00f3ch etapach. Na czym one dok\u0142adnie polegaj\u0105? Wiesz, koncepcja jest w gruncie rzeczy zwodniczo prosta. Etap pierwszy to generatywny pretraining, bez nadzoru, czyli surowy tekst. Tak, bierzemy du\u017cy model sieci neuronowej i dajemy mu jedno, pro\u015bciutkie zadanie. Czytaj i przewiduj nast\u0119pne s\u0142owo. W tym przypadku dali mu do przeczytania zbi\u00f3r B\u00f3g Skorpus. To by\u0142o ponad 7000 ksi\u0105\u017cek. Tak, niepublikowanych ksi\u0105\u017cek z r\u00f3\u017cnych gatunk\u00f3w. I ten prosty cel jest kluczowy, prawda? To brzmi trywialnie, zgadnij nast\u0119pne s\u0142owo, ale. Ale \u017ceby robi\u0107 to dobrze, tak na masow\u0105 skal\u0119, w milionach zda\u0144 model jest zmuszony nauczy\u0107 si\u0119 wszystkiego po drodza. Ukrycie. W\u0142a\u015bnie, musi zrozumie\u0107 gramatyk\u0119, sk\u0142adnie, kontekst, jakie\u015b relacje przyczynowo-skutkowe, nawet zdoby\u0107 w szt\u0105tkow\u0105 wiedz\u0119 o \u015bwiecie. Czyli nikt mu nie m\u00f3wi, ucz si\u0119 gramatyki? Nie, absolutnie. On sam dochodzi do wniosku, \u017ce znajomo\u015b\u0107 gramatyki jest po prostu niezwykle u\u017cyteczna w zadaniu przewidywania i w ten spos\u00f3b po przeczytaniu tych wszystkich ksi\u0105\u017cek model buduje w sobie co\u015b, co autorzy nazywaj\u0105 uniwersaln\u0105 reprezentacj\u0105 j\u0119zyka. To jest fundament. I dopiero na tym fundamencie budujemy dalej, przechodzimy do etapu drugiego. Czyli do fine tuningu. Tak zwanego dyskryminacyjnego fine tuningu z nadzorem. Dok\u0142adnie. Bierzemy nasz wst\u0119pnie wytremowany taki oczytany model i teraz pokazujemy mu ju\u017c specyficzne zadanie. Na przyk\u0142ad klasyfikacje recenzji filmowych. Idealnie. Pozytywna czy negatywna. U\u017cywamy ju\u017c ma\u0142ego, specjalistycznego zbiaru danych z etykietami. Ale kluczowe jest to, \u017ce model nie startuje od zera. On ju\u017c wie, czym jest j\u0119zyk. Czyli to jest dok\u0142adnie ta analogia, o kt\u00f3rej wspomnia\u0142e\u015bmy. Zamiast uczy\u0107 ka\u017cdego specjalist\u0119 od zera, wysy\u0142amy go na solidne og\u00f3lne studia. A dopiero potem na kr\u00f3tk\u0105, intensywn\u0105 praktyk\u0119. A wcze\u015bniej ka\u017cdy by\u0142 uczony tylko swojego w\u0105skiego fachu od samych podstaw. To jest idealna analogia i to jest fundamentalna zmiana w podej\u015bciu. Wcze\u015bniej transfer wiedzy, je\u015bli w og\u00f3le by\u0142, to odbywa\u0142 si\u0119 g\u0142\u00f3wnie na poziomie s\u0142\u00f3w. Przez tak zwane word embeddings. Co by\u0142o jak daniu studentowi tylko s\u0142ownika. W\u0142a\u015bnie. A tutaj dajemy mu ca\u0142\u0105 bibliotek\u0119 i czas, \u017ceby j\u0105 przestudiowa\u0142. To jest zupe\u0142nie inna skala rozumienia. Dobrze, mamy wi\u0119c t\u0119 eleganck\u0105 dwuetapow\u0105 filozofi\u0119. Ale diabe\u0142 tkwi w \u015btygu\u0142ach, a w tym szoppadku w architekturze. M\u00f3zgiem ca\u0142ej operacji by\u0142 model transformer. Tak. Dlaczego w\u0142a\u015bnie on, a nie popularne wtedy sieci rekurencyjne jak LSTM? To by\u0142a krytyczna decyzja. Modele takie jak LSTM mia\u0142y jeden fundamentalny problem. Kr\u00f3tk\u0105 pami\u0119\u0107. Radzi\u0142y sobie z kontekstem w obr\u0119bie powiedzmy jednego zdania, ale mia\u0142y ogromne trudno\u015bci z\u0142\u0105czeniem fakt\u00f3w, kt\u00f3re by\u0142y od siebie oddalone o kilka akapit\u00f3w. Czyli w przypadku analizy ksi\u0105\u017cki taki model m\u00f3g\u0142by zapami\u0119\u0107, co wydarzy\u0142o si\u0119 w pierwszym rozdziel\u0119, zanim dotar\u0142by do dziesi\u0105tego. I wtedy ca\u0142e zrozumienie fabu\u0142y bierze w \u0142eb. Jasne. Dok\u0142adnie. A transformer, dzi\u0119ki mechanizmowi zwanemu self-attention, potrafi wa\u017cy\u0107 znaczenie wszystkich s\u0142\u00f3w w kontek\u015bcie, niezale\u017cnie od tego, jak daleko si\u0119 znajduj\u0105. Czyli odleg\u0142o\u015b\u0107 nie ma takiego znaczenia. R\u00f3wnie wa\u017cne, co s\u0142owo z poprzedniego zdania. A skoro zadaniem by\u0142o czytanie ca\u0142ych ksi\u0105\u017cek, ta zdolno\u015b\u0107 by\u0142a absolutnie niezb\u0119dna. W artykule u\u017cyli konkretnej wersji dwunastowarstwowego modelu transformer typu decoder only. Co to w praktyce oznacza\u0142o? Decoder only oznacza, \u017ce jest to architektura zoptymalizowana do generowania sekwencji s\u0142owo po s\u0142owie. U\u017cywa czego\u015b takiego jak masked self-attention. Masked, czyli zamaskowane. Tak, co po prostu znaczy, \u017ce podczas przewidywania s\u0142owa numer n model mo\u017ce patrze\u0107 tylko na s\u0142owa od pierwszego do n minus jeden. Nie mo\u017ce podgl\u0105da\u0107 przysz\u0142o\u015bci. Co jest naturalne, skoro ma przewidzie\u0107 nast\u0119pne s\u0142owo? Oczywi\u015bcie. OK, czyli mamy pot\u0119\u017cn\u0105 architektur\u0119 i sprytn\u0105 metod\u0119 treningu. Ale tu pojawia si\u0119 kolejny problem. Jak zaadaptowa\u0107 jeden uniwersalny model do tak r\u00f3\u017cnych zada\u0144? Bo czym innym jest ocenaczy dwa zdania s\u0105 do siebie podobne, a czym innym odpowiadanie na pytanie, prawda? Ka\u017cde z tych zada\u0144 ma inn\u0105 struktur\u0119. I to jest chyba najbardziej elekanski trik w ca\u0142ym tym artykule. Naprawd\u0119? Tak, zamiast zmienia\u0107 architektur\u0119 modelu dla ka\u017cdego zadania, autorzy zmieniali format danych wej\u015bciowych. A, czyli dopasowywali problem do modelu, a nie model do problemu? Dok\u0142adnie, tak \u017ceby pasowa\u0142y do tego, co model ju\u017c umie robi\u0107, czyli przetwarza\u0107 pojedyncz\u0105 ci\u0105g\u0142\u0105 sekwencj\u0119 token\u00f3w. Czyli t\u0142umaczyli zadanie na j\u0119zyk zrozumia\u0142e dla modelu? W\u0142a\u015bnie, we\u017amy przyk\u0142ady z artyku\u0142u. W zadaniu entailment, czyli wynikania logicznego, gdzie mamy przes\u0142ank\u0119 i hipotez\u0119. Pok prostu \u0142\u0105czyli te dwa zdania w jeden ci\u0105g, tak? Tak, wstawiaj\u0105c mi\u0119dzy niespecjalny token rozdzielaj\u0105cy. Model patrzy\u0142 na ca\u0142o\u015b\u0107 i mia\u0142 wyda\u0107 werdykt. Wynika sprzeczne czy neutralne. A co w sytuacji, gdy kolejno\u015b\u0107 nie ma znaczenia, jak przy poruzmywaniu podobie\u0144stwa dw\u00f3ch zda\u0144? Kot siedzi na macie, jest tak samo podobne do kocur drzemie nadywanie, jak na odwrot. \u015awietne pytanie. W zadaniu similarity robili dok\u0142adnie to. Przepuszczali przez model obie kombinacje. A, czyli zdanie A, separator zdanie B, a potem zdanie B, separator zdanie A. Tak, nast\u0119pnie sumowali uzyskane reprezentacje i dopiero na tej podstawie podejmowali decyzj\u0119. To prosty spos\u00f3b, \u017ceby poinformowa\u0107 model o symetrii problemu, bez dotykania jego architektury. To jest genialne. A co z jeszcze bardziej skomplikowanymi zadaniami? Jak pytania wielokrotnego wyboru, gdzie mamy kontekst, pytanie i kilka mo\u017cliwych odpowiedzi? Tutaj, zastosowano podobn\u0105 logik\u0119. Dla ka\u017cdej mo\u017cliwej odpowiedzi tworzono osobn\u0105 pe\u0142n\u0105 sekwencj\u0119. Czyli jakby osobne wsady dla modelu. Dok\u0142adnie. Wygl\u0105da\u0142o to tak. Kontekst, separator, pytanie, separator, odpowied\u017a A. Potem druga sekwencja. Kontekst, separator, pytanie, separator, odpowied\u017a B i tak dalej. I model ocenia\u0142, kt\u00f3ra z tych ca\u0142o\u015bci jest najbardziej prawdopodobna? Tak. Wybierano t\u0119 odpowied\u017a, dla kt\u00f3rej ca\u0142a sekwencja by\u0142a najbardziej naturalna i prawdopodobna w jego ocenie. Niesamowite. Czyli model pozostaje nietkni\u0119ty, a ca\u0142a adaptacja odbywa si\u0119 na zewn\u0105trz, na poziomie przygotowania danych. Co jest ogromnym uproszczeniem? Unikamy budowania skomplikowanych, dedykowanych g\u0142owic dla ka\u017cdego zadania. I to otworzy\u0142o drog\u0119 do generalizacji. Jeden model, kt\u00f3ry potrafi nauczy\u0107 si\u0119 niemal wszystkiego i je\u015bli tylko odpowiednio sformu\u0142ujemy mu pytanie. OK, teoria jest pi\u0119kna, architektura sprytna, a sztuczki z danymi eleganckie. Ale w uczeniu maszynowym pi\u0119kne teorie umieraj\u0105 ka\u017cdego dnia, gdy zderzaj\u0105 si\u0119 z twardymi danymi. Niestety tak. Wi\u0119c pytanie za milion dolar\u00f3w brzmi. Czy to zadzia\u0142a\u0142o? Czy ten uniwersalny student mia\u0142 jakiekolwiek szanse w starciu z wysoko wyspecjalizowanymi rzemie\u015blnikami, kt\u00f3rzy dominowali wtedy w tej dziedzinie? Nie tylko mia\u0142 szanse. On ich zdeklasowa\u0142. A\u017c tak? Model pobi\u0142 dotychczasowe najlepsze wyniki, tak zwane State of the Art, na 9 z 12 analizowanych zestaw\u00f3w danych. I to cz\u0119sto zmierznancom przewag\u0105. 9 z 12 przeciwko modelom, kt\u00f3re by\u0142y latami szyte na miar\u0119 pod te konkretne zadania, to brzmi niewiarygodnie. We\u017amy kilka przyk\u0142ad\u00f3w, \u017ceby poczu\u0107 skal\u0119 tego sukcesu. Na przyk\u0142ad story close test. To jest to zadanie, kt\u00f3re wymaga rozumowania zdroworos\u0105dkowego. Tak. Dok\u0142adnie. Model dostaje kr\u00f3tki fragment historyjki i musi wybra\u0107 jedno z dw\u00f3ch mo\u017cliwych, logicznych zako\u0144czeni. Poprzedni najlepszy wynik to by\u0142o 75%. Ten model osi\u0105gn\u0105\u0142 83,9%. 83,9% to jest prawie 9 punkt\u00f3w procentowych r\u00f3\u017cnicy. Prawie 9%. W badaniach NLP to nie jest krok naprz\u00f3d. To jest skok w nadprzestrze\u0144. To faktycznie knockout, a w innych, bardziej standardowych zadaniach. Jaki\u015b bli\u017cszych, realnym zastosowaniom. No to sp\u00f3jrzmy na rejs. To zbi\u00f3r danych oparty na egzaminach zczytania ze zrozumieniem dla nastolatk\u00f3w w Chinach. Czyli d\u0142ugie teksty, skomplikowane pytania. Tak. Tutaj poprawa wynios\u0142a 5,7%. To pokaza\u0142o, \u017ce model potrafi\u0142 nie tylko dopasowywa\u0107 s\u0142owa kluczowe, ale faktycznie rozumie\u0107 z\u0142o\u017cone zale\u017cno\u015bci w d\u0142u\u017cszych tekstach. Ale chyba najbardziej imponuj\u0105cy jest wynik na zbiorze ko\u0142a, gdzie ocenia si\u0119 poprawno\u015b\u0107 gramatyczn\u0105 zda\u0144. Tak, to jest jeden z najciekapszych rezultat\u00f3w. Wynik skoczy\u0142 z 35 do 45-4. Wow. To dowodzi, \u017ce w trakcie nienadzorowanego pri treningu na ksi\u0105\u017ckach model nauczy\u0142 si\u0119 g\u0142\u0119bokiej wewn\u0119trznej intuicji j\u0119zykowej. Czego\u015b, co wykracza daleko poza proste statystyki. On naprawd\u0119 poczu\u0142 struktur\u0119 j\u0119zyka. Nawet na zadaniu tak no brudnym i specyficznym jak QQP, czyli wykrywanie duplikat\u00f3w pyta\u0144 na platformie Quora. Spodziewa\u0142am im si\u0119, \u017ce tam specjalistyczny model, nauczony na \u017cargonie u\u017cytkownik\u00f3w, b\u0119dzie mia\u0142 przewag\u0119. A jednak. I tam odnotowano popraw\u0105 o 4,2%. To dowiod\u0142o, \u017ce ob\u00f3lna wiedza, kt\u00f3r\u0105 model posiad\u0142, jest autentycznie elastyczna. I daje przewag\u0119 nawet w niszowych domenach? Tak. Te liczby to nie by\u0142y jakie\u015b drobne usprawnienia. To by\u0142 sygna\u0142, \u017ce w ca\u0142ej dziedzinie nast\u0119puje tektoniczna zmiana. Dobrze, czyli mieli te fenomenalne wyniki. Ale czy autorzy sami do ko\u0144ca rozumieli, dlaczego to zadzia\u0142a\u0142o a\u017c tak dobrze? Czy przeprowadzili jak\u0105\u015b, nie wiem, sekcj\u0119 zw\u0142ok tego modelu, \u017ceby zobaczy\u0107, sk\u0105d bierze si\u0119 ta magia? Oczywi\u015bcie. I ta cz\u0119\u015b\u0107 analityczna artyku\u0142u jest r\u00f3wnie fascynuj\u0105ca co same wyniki. To taka praca detektywistyczna. OK. Pierwszy trop. Zbadali, jak na wynik ko\u0144cowy wp\u0142ywa liczba warstw transferowanych z modelu bazowego do zadania docelowego. Czyli sprawdzali, czy ca\u0142a wiedza jest np. w pierwszych warstwach, blisko embedding\u00f3w, a reszta to tylko dostrojenie? Dok\u0142adnie takie by\u0142o jedno z wcze\u015bniejszych przekona\u0144. Ale okaza\u0142o si\u0119, \u017ce jest zupe\u0142nie inaczej. A jak? Wyniki na testach takich jak Multien Li czy Race systematycznie ros\u0142y z ka\u017cd\u0105 kolejn\u0105 dodan\u0105 warstw\u0105. Z ka\u017cd\u0105 jedn\u0105? Tak. To dowiod\u0142o, \u017ce wiedza jest rozproszona pod ca\u0142ej g\u0142\u0119bi sieci. Niszcze warstwy ucz\u0105 si\u0119 podstawowych cech sk\u0142adniowych, a wy\u017csze warstwy buduj\u0105 na tym bardziej abstrakcyjne, semantyczne koncepty. Ka\u017cda warstwa wnosi\u0142a co\u015b cennego. To podwa\u017ca\u0142o ide\u0119, \u017ce wystarczy przenie\u015b\u0107 same embeddingi. Ale cz\u0119\u015b\u0107, kt\u00f3ra dla mnie jest najbardziej zdumiewaj\u0105ca, to te zdolno\u015bci zero shot. To brzmi jak co\u015b science fiction. To by\u0142 moment, w kt\u00f3rym wielu badaczom musia\u0142y otworzy\u0107 si\u0119 oczy ze zdumienia. Sprawdzono, jak model radzi sobie z zadaniami jeszcze przed jakimkolwiek fine tuningiem. U\u017cywaj\u0105c bardzo prostych heurystyk. Jakich? We\u017amy analiz\u0119 sentymentu. Do zdania, kt\u00f3re mieli oceni\u0107 np. ten film by\u0142 wspania\u0142y, dodawali na ko\u0144cu s\u0142owo bardzo. OK. A nast\u0119pnie sprawdzali z jakim prawdopodobie\u0144stwem model doko\u0144czy te sekwencje s\u0142owem pozytywny w por\u00f3wnaniu do s\u0142owa negatywny. I co si\u0119 okaza\u0142o? Okaza\u0142o si\u0119, \u017ce im d\u0142u\u017cej trwa\u0142 nienadzorowany pre-training, tym model by\u0142 w tym lepszy. Czyli sam proces nauki bycia dobrym modelem j\u0119zykowym. Doprowadzi\u0142 do wykszta\u0142cenia si\u0119 umiej\u0119tno\u015bci klasyfikacji sentymentu jako produktu ubocznego. To jest niesamowite. To jest w\u0142asno\u015b\u0107 emergentna. Nikt nie uczy\u0142 go analizy sentymentu. To po prostu si\u0119 sta\u0142o. Dok\u0142adnie. To musia\u0142 by\u0107 ekscytuj\u0105cy i mo\u017ce troch\u0119 niepokoj\u0105cy moment w laboratorium. Zdecydowanie. Pokaza\u0142o to, \u017ce d\u0105\u017cenie do doskona\u0142o\u015bci w jednym bardzo og\u00f3lnym zadaniu j\u0119zykowym niejako przy okazji uczy model rozwi\u0105zywania wielu innych problem\u00f3w. Ale \u017ceby ostatecznie udowodni\u0107, co by\u0142o kluczem do sukcesu, przeprowadzili tak zwane ablation studies. Czyli badania ablacyjne. Mieli swoich g\u0142\u00f3wnych podejrzanych o sukces pre-trainingi, architektur\u0119 transformer i przeprowadzili eksperymenty, \u017ceby to potwierdzi\u0107. Dok\u0142adnie tak. To jak usuwanie poszczeg\u00f3lnych element\u00f3w z dzia\u0142aj\u0105cej maszyny, \u017ceby zobaczy\u0107, co si\u0119 zepsuje. I co si\u0119 zepsu\u0142o? Najpierw wy\u0142\u0105czyli ca\u0142y etap pre-trainingu. Trenowali model transformer od zera bezpo\u015brednio na zadaniach docelowych. Efekt. \u015aredni spadek skuteczno\u015bci o 14,8%. 14,8% to przepa\u015b\u0107. To przepa\u015b\u0107, kt\u00f3ra pokazuje, jak absolutnie kluczowy by\u0142 ten pierwszy, nienadzorowany etap nauki. A co z wyborem architektury? Mo\u017ce pre-training zadzia\u0142a\u0142by z ka\u017cdym modelem? To te\u017c sprawdzili. Zast\u0105pili transformera klasycznym modelem LSTM, ale zachowali ca\u0142y schemat pre-train i fine-tune. I? Tym razem spadek \u015bredniej skuteczno\u015bci wyni\u00f3s\u0142 5-6%. Czyli te\u017c znacz\u0105cy? Znacz\u0105cy. Model LSTM po prostu gorzej radzi\u0142 sobie z wykorzystaniem wiedzy zdobytej podczas pre-trainingu, co potwierdzi\u0142o, \u017ce zdolno\u015b\u0107 transformera do pracy z d\u0142ugim kontekstem by\u0142a drugim filarem tego sukcesu. Te dwa eksperymenty by\u0142y jak postawienie kropki nad i. Zdecydowanie. Podsumowuj\u0105c, ten artyku\u0142 nie by\u0142 tylko prezentacj\u0105 kolejnego troch\u0119 lepszego modelu. On ustanowi\u0142 kompletnie nowy paradigma w przetwarzaniu j\u0119zyka naturalnego. Pre-train fine-tune. W\u0142a\u015bnie, zmieni\u0142 fundamentalne my\u015blenie w ca\u0142ej dziedzinie. Tak, pokaza\u0142, \u017ce problem niedoboru danych etykietowanych mo\u017cna obej\u015b\u0107, je\u015bli tylko mamy wystarchaj\u0105c\u0105 du\u017co nieoznakowanego tekstu. I odpowiedni\u0105 moc obliczeniow\u0105. Oczywi\u015bcie. To by\u0142 moment, w kt\u00f3rym gra przesta\u0142a polega\u0107 na sprytnym zbieraniu danych, a zacz\u0119\u0142a polega\u0107 na efektywnym skalowaniu modeli i oblicze\u0144. I to otworzy\u0142o drzwi do wszystkiego, co widzimy dzisiaj. Bez tej pracy i tej filozofii nie by\u0142oby GPT-2, GPT-3, hatacza GPT i ca\u0142ej tej rewolucji generatywnej AI. Autorzy dostarczyli przepis. Przepis, kt\u00f3ry ca\u0142a reszta \u015bwiata zacz\u0119\u0142a kopiowa\u0107, ulepsza\u0107 i skalowa\u0107 przez nast\u0119pne lata. To by\u0142 prawdziwy punkt zwrotny. Moment, w kt\u00f3rym dziedzina NLP obra\u0142a mowy kurs, z kt\u00f3rego nie zawr\u00f3ci\u0142a do dzi\u015b. I to prowadzi nas do ostatniej my\u015bli, tego\u015b do przemy\u015blenia. Autorzy wykazali, \u017ce model, ucz\u0105c si\u0119 jedynie przewidywa\u0107 kolejne s\u0142owo w tek\u015bcie, nabywa zdumiewaj\u0105co szerok\u0105 wiedz\u0119 o \u015bwiecie. I zdolno\u015b\u0107 do rozumowania. I to rodzi fundamentalne pytanie. Jakie s\u0105 ostateczne granice tego podej\u015bcia? To jest pytanie, z kt\u00f3rym mierzymy si\u0119 do dzi\u015b. Gdyby\u015bmy mieli model, kt\u00f3ry by\u0142by w stanie idealnie przewidzie\u0107 nast\u0119pny token w dowolnej mo\u017cliwej sekwencji tekstowej. Czy to by\u0142oby to\u017csame z prawdziwym, ludzkim rozumieniem i \u015bwiadomo\u015bci\u0105? Czy te\u017c jest tam jaka\u015b fundamentalna r\u00f3\u017cnica, jaka\u015b, nie wiem, iskra, kt\u00f3rej samo statystyczne przewidywanie, nawet doprowadzone do perfekcji, nigdy nie b\u0119dzie w stanie przeskoczy\u0107. A to chyba zmusza nas te\u017c do zrewidowania naszej w\u0142asnej definicji i rozumienia, je\u015bli system, kt\u00f3ry tylko przewiduje, daje odpowiedzi nieodr\u00f3\u017cnialne od systemu, kt\u00f3ry rozumie, to w kt\u00f3rym momencie ta r\u00f3\u017cnica przestaje mie\u0107 praktyczne znaczenie. To pytanie zostawiamy otwarte.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Witam w naszej kolejnej analizie.", "tokens": [50364, 42299, 335, 261, 42946, 23749, 11794, 2624, 590, 414, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 1, "seek": 0, "start": 2.2, "end": 5.48, "text": " Dzi\u015b cofniemy si\u0119 w czasie do momentu, kt\u00f3ry", "tokens": [50474, 413, 3992, 1788, 598, 69, 2766, 2226, 3244, 261, 42667, 360, 1623, 84, 11, 9913, 50638], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 2, "seek": 0, "start": 5.68, "end": 9.200000000000001, "text": " no c\u00f3\u017c, zdefiniowa\u0142 wsp\u00f3\u0142czesn\u0105 sztuczn\u0105 inteligencj\u0119.", "tokens": [50648, 572, 6333, 1427, 11, 710, 20595, 3812, 30105, 39069, 3689, 279, 13113, 262, 2682, 1311, 89, 13113, 24777, 3213, 41960, 13, 50824], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 3, "seek": 0, "start": 9.4, "end": 14.36, "text": " Mamy przed sob\u0105 artyku\u0142 z 2018 roku od zespo\u0142u OpenAI.", "tokens": [50834, 376, 7804, 18334, 18253, 1611, 594, 874, 5279, 1221, 710, 6096, 19451, 3611, 710, 279, 2259, 24066, 7238, 48698, 13, 51082], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 4, "seek": 0, "start": 14.56, "end": 18.240000000000002, "text": " Improving Language Understanding by Generative Pre-Training.", "tokens": [51092, 8270, 340, 798, 24445, 36858, 538, 15409, 1166, 6001, 12, 38971, 1760, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 5, "seek": 0, "start": 18.44, "end": 20.76, "text": " Tytu\u0142 brzmi do\u015b\u0107 skromnie.", "tokens": [51286, 314, 4328, 84, 1221, 738, 89, 3057, 49333, 1110, 4397, 2766, 13, 51402], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 6, "seek": 0, "start": 20.96, "end": 22.32, "text": " Bardzo skromnie.", "tokens": [51412, 38559, 1110, 4397, 2766, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 7, "seek": 0, "start": 22.52, "end": 25.68, "text": " Ale to jest dokument za\u0142o\u017cycielski ca\u0142ej RGPT.", "tokens": [51490, 9366, 281, 3492, 40858, 7949, 5249, 7735, 537, 1625, 2984, 47631, 73, 497, 38, 47, 51, 13, 51648], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 8, "seek": 0, "start": 25.88, "end": 28.080000000000002, "text": " Taki, mo\u017cna powiedzie\u0107, pacjent zero.", "tokens": [51658, 314, 7421, 11, 17790, 27886, 11, 15165, 73, 317, 4018, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 9, "seek": 0, "start": 28.28, "end": 29.36, "text": " Dok\u0142adnie.", "tokens": [51778, 29768, 10358, 2766, 13, 51832], "temperature": 0.0, "avg_logprob": -0.1792684555053711, "compression_ratio": 1.3205128205128205, "no_speech_prob": 0.01479636412113905}, {"id": 10, "seek": 2936, "start": 29.56, "end": 31.8, "text": " I \u017ceby zrozumie\u0107, jak wielki to by\u0142 prze\u0142om,", "tokens": [50374, 286, 11316, 710, 27857, 449, 414, 2162, 11, 4207, 20570, 2984, 281, 16673, 8325, 1221, 298, 11, 50486], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 11, "seek": 2936, "start": 32.0, "end": 35.64, "text": " trzeba sobie przypomnie\u0107, jak wygl\u0105da\u0142 wtedy \u015bwiat NLP, czyli", "tokens": [50496, 25860, 13652, 41780, 298, 2766, 2162, 11, 4207, 32015, 1221, 26959, 36425, 426, 45196, 11, 16591, 50678], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 12, "seek": 2936, "start": 35.84, "end": 37.76, "text": " przetwarzania j\u0119zyka naturalnego.", "tokens": [50688, 6541, 302, 31991, 5609, 42309, 40940, 3303, 11858, 13, 50784], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 13, "seek": 2936, "start": 37.96, "end": 41.32, "text": " By\u0142 bardzo poszatkowany.", "tokens": [50794, 3146, 1221, 9034, 1366, 89, 33525, 23341, 13, 50962], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 14, "seek": 2936, "start": 41.519999999999996, "end": 43.4, "text": " Niezwykle fragmentaryczny.", "tokens": [50972, 12016, 89, 9726, 14677, 26424, 822, 3689, 1634, 13, 51066], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 15, "seek": 2936, "start": 43.6, "end": 45.84, "text": " Jak chcia\u0142o si\u0119 zbudowa\u0107 model do analizy", "tokens": [51076, 15029, 26497, 5249, 3244, 710, 18281, 11445, 2316, 360, 2624, 590, 88, 51188], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 16, "seek": 2936, "start": 46.04, "end": 48.36, "text": " sentimentu, no to tworzy\u0142o si\u0119 go od zera.", "tokens": [51198, 16149, 84, 11, 572, 281, 46288, 1229, 5249, 3244, 352, 3611, 710, 1663, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 17, "seek": 2936, "start": 48.56, "end": 51.44, "text": " Do odpowiadania na pytania, zupe\u0142nie inny model,", "tokens": [51324, 1144, 24314, 38069, 5609, 1667, 25878, 5609, 11, 49922, 294, 1634, 2316, 11, 51468], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 18, "seek": 2936, "start": 51.64, "end": 54.16, "text": " inna architektura, inny proces.", "tokens": [51478, 294, 629, 3912, 642, 2320, 2991, 11, 294, 1634, 17565, 13, 51604], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 19, "seek": 2936, "start": 54.36, "end": 57.6, "text": " Ka\u017cde zadanie to by\u0142a osobna, taka rzemie\u015bnicza praca.", "tokens": [51614, 10988, 1427, 1479, 42788, 7155, 281, 23936, 41518, 629, 11, 28017, 367, 24313, 414, 1788, 7692, 2394, 582, 6628, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13320588118193166, "compression_ratio": 1.469387755102041, "no_speech_prob": 0.013468111865222454}, {"id": 20, "seek": 5760, "start": 57.800000000000004, "end": 60.4, "text": " I ka\u017cde z tych zada\u0144 wymaga\u0142o gigantycznych,", "tokens": [50374, 286, 21912, 1479, 710, 15180, 710, 1538, 5248, 29764, 9286, 5249, 8741, 394, 17466, 9399, 11, 50504], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 21, "seek": 5760, "start": 60.6, "end": 62.88, "text": " r\u0119cznie tworzonych zbior\u00f3w danych.", "tokens": [50514, 41197, 19923, 46288, 44479, 339, 710, 33362, 3901, 274, 34644, 13, 50628], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 22, "seek": 5760, "start": 63.08, "end": 68.4, "text": " Trzeba by\u0142o p\u0142aci\u0107 tysi\u0105com ludzi za etykietowanie setek tysi\u0119cy przyk\u0142ad\u00f3w.", "tokens": [50638, 1765, 1381, 4231, 14811, 28695, 326, 12757, 38156, 11404, 1112, 29586, 7949, 1030, 46127, 1684, 22028, 992, 916, 38156, 47303, 23144, 3901, 13, 50904], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 23, "seek": 5760, "start": 68.6, "end": 71.2, "text": " To by\u0142a prawdziwa blokada dla post\u0119pu.", "tokens": [50914, 1407, 23936, 41175, 3992, 4151, 888, 453, 1538, 12285, 2183, 18085, 84, 13, 51044], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 24, "seek": 5760, "start": 71.4, "end": 74.36, "text": " Brakowa\u0142o nie mocy obliczeniowej, ale w\u0142a\u015bnie", "tokens": [51054, 4991, 74, 5528, 5249, 2838, 705, 1344, 1111, 1050, 42124, 21091, 11, 6775, 14234, 51202], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 25, "seek": 5760, "start": 74.56, "end": 76.92, "text": " dobrych oznaczonych danych. W\u0142a\u015bnie.", "tokens": [51212, 35884, 339, 277, 22672, 14875, 2526, 339, 274, 34644, 13, 343, 5024, 12221, 13, 51330], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 26, "seek": 5760, "start": 77.12, "end": 79.84, "text": " A autorzy tego artyku\u0142u zadali pytanie, kt\u00f3re", "tokens": [51340, 316, 19510, 1229, 8627, 594, 874, 5279, 24066, 42788, 5103, 36610, 11, 8864, 51476], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 27, "seek": 5760, "start": 80.04, "end": 82.0, "text": " no, wywr\u00f3ci\u0142o stolik.", "tokens": [51486, 572, 11, 4628, 7449, 812, 537, 5249, 43553, 1035, 13, 51584], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 28, "seek": 5760, "start": 82.2, "end": 84.92, "text": " A co je\u015bli? Przestaniemy tak my\u015ble\u0107.", "tokens": [51594, 316, 598, 25630, 30, 2114, 89, 377, 7155, 2226, 991, 48633, 306, 2162, 13, 51730], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 29, "seek": 5760, "start": 85.12, "end": 87.04, "text": " A co je\u015bli podejdziemy do tego inaczej?", "tokens": [51740, 316, 598, 25630, 7468, 73, 13096, 2226, 360, 8627, 33230, 16920, 30, 51836], "temperature": 0.0, "avg_logprob": -0.16049953743263526, "compression_ratio": 1.5, "no_speech_prob": 0.004047716502100229}, {"id": 30, "seek": 8704, "start": 87.16000000000001, "end": 90.32000000000001, "text": " Tak. Co je\u015bli we\u017amiemy ca\u0142y tekst, jaki mamy?", "tokens": [50370, 9118, 13, 3066, 25630, 321, 10659, 25210, 2226, 35226, 16624, 372, 11, 24492, 17335, 30, 50528], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 31, "seek": 8704, "start": 90.52000000000001, "end": 94.64, "text": " Ksi\u0105\u017cki, artyku\u0142y, internet i wykorzystamy go do stworzenia jednego,", "tokens": [50538, 591, 7691, 27242, 2984, 11, 594, 874, 5279, 6825, 11, 4705, 741, 43606, 36049, 7804, 352, 360, 342, 28321, 14320, 5232, 11858, 11, 50744], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 32, "seek": 8704, "start": 94.84, "end": 97.76, "text": " pot\u0119\u017cnego, uniwersalnego modelu bazowego.", "tokens": [50754, 1847, 1274, 1427, 11858, 11, 36435, 5364, 304, 11858, 2316, 84, 27147, 26576, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 33, "seek": 8704, "start": 97.96000000000001, "end": 100.72, "text": " Takiego studenta, kt\u00f3ry najpierw idzie na studia og\u00f3lne?", "tokens": [50910, 9118, 12200, 3107, 64, 11, 9913, 11212, 45119, 86, 4496, 3283, 1667, 972, 654, 5360, 15741, 716, 30, 51048], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 34, "seek": 8704, "start": 100.92, "end": 103.44, "text": " O to chodzi. Modelu, kt\u00f3ry potem m\u00f3g\u0142by si\u0119 wiesz,", "tokens": [51058, 422, 281, 23998, 13, 17105, 84, 11, 9913, 36513, 275, 14047, 34635, 3244, 261, 15347, 11, 51184], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 35, "seek": 8704, "start": 103.64000000000001, "end": 107.92, "text": " szybko wyspecjalizowa\u0107 w dowolnej dziedzinie przy minimalnym dodatkowym wysi\u0142ku.", "tokens": [51194, 36456, 4093, 27062, 494, 66, 22600, 590, 11445, 261, 9459, 401, 11794, 9758, 15338, 259, 414, 6501, 13206, 12996, 13886, 33525, 31691, 27062, 40622, 5279, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 36, "seek": 8704, "start": 108.12, "end": 113.68, "text": " Nasz\u0105 misj\u0105 jest wi\u0119c roz\u0142o\u017cenie tej rewolucyjnej koncepcji na czynniki pierwsze.", "tokens": [51418, 16151, 8925, 3346, 8555, 3492, 16677, 9544, 5249, 41118, 12573, 319, 48481, 1311, 88, 73, 11794, 5897, 27493, 19649, 1667, 6430, 26384, 9850, 45994, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 37, "seek": 8704, "start": 113.88000000000001, "end": 116.64000000000001, "text": " Zobaczymy, jak dzia\u0142a ten dwuetapowy proces,", "tokens": [51706, 1176, 996, 14691, 2226, 11, 4207, 37903, 2064, 27379, 15382, 569, 10089, 17565, 11, 51844], "temperature": 0.0, "avg_logprob": -0.1403381076790172, "compression_ratio": 1.4402332361516035, "no_speech_prob": 0.0007337781134992838}, {"id": 38, "seek": 11664, "start": 116.76, "end": 118.92, "text": " czyli pretraining i fine tuning.", "tokens": [50370, 16591, 1162, 424, 1760, 741, 2489, 15164, 13, 50478], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 39, "seek": 11664, "start": 119.12, "end": 122.72, "text": " I dlaczego wyb\u00f3r architektury transformera by\u0142 takim strza\u0142em w dziesi\u0105tk\u0119?", "tokens": [50488, 286, 37873, 39329, 45780, 15614, 3912, 642, 2320, 2598, 4088, 1663, 16673, 31732, 1056, 2394, 11126, 261, 9758, 530, 11404, 83, 15724, 30, 50668], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 40, "seek": 11664, "start": 122.92, "end": 127.96000000000001, "text": " I jakie absolutnie szokuj\u0105ce, jak na tamte czasy, przynios\u0142o to rezultat.", "tokens": [50678, 286, 22124, 18757, 2766, 7870, 453, 13263, 384, 11, 4207, 1667, 7677, 975, 6472, 5871, 11, 6501, 77, 2717, 5249, 281, 48060, 723, 267, 13, 50930], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 41, "seek": 11664, "start": 128.16, "end": 129.16, "text": " Zanurzmy si\u0119 w tym.", "tokens": [50940, 1176, 282, 374, 89, 2226, 3244, 261, 8107, 13, 50990], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 42, "seek": 11664, "start": 129.36, "end": 132.2, "text": " No dobrze, to rozpakujmy ten fundamentalny pomys\u0142.", "tokens": [51000, 883, 28335, 11, 281, 9544, 45944, 4579, 2226, 2064, 8088, 1634, 12991, 39508, 13, 51142], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 43, "seek": 11664, "start": 132.4, "end": 135.88, "text": " M\u00f3wimy o dw\u00f3ch etapach. Na czym one dok\u0142adnie polegaj\u0105?", "tokens": [51152, 376, 3901, 13189, 277, 27379, 812, 339, 47634, 608, 13, 6056, 31466, 472, 45864, 2766, 714, 6363, 11133, 30, 51326], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 44, "seek": 11664, "start": 136.08, "end": 138.76, "text": " Wiesz, koncepcja jest w gruncie rzeczy zwodniczo prosta.", "tokens": [51336, 343, 15347, 11, 5897, 27493, 34056, 3492, 261, 677, 409, 4260, 26297, 11873, 378, 7692, 4765, 582, 8638, 13, 51470], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 45, "seek": 11664, "start": 138.96, "end": 141.88, "text": " Etap pierwszy to generatywny pretraining,", "tokens": [51480, 3790, 569, 34016, 281, 1337, 21398, 43682, 1162, 424, 1760, 11, 51626], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 46, "seek": 11664, "start": 142.08, "end": 144.08, "text": " bez nadzoru, czyli surowy tekst.", "tokens": [51636, 10782, 12617, 89, 32963, 11, 16591, 1022, 10089, 16624, 372, 13, 51736], "temperature": 0.0, "avg_logprob": -0.15482687800185485, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.004469509702175856}, {"id": 47, "seek": 14408, "start": 144.20000000000002, "end": 149.56, "text": " Tak, bierzemy du\u017cy model sieci neuronowej i dajemy mu jedno, pro\u015bciutkie zadanie.", "tokens": [50370, 9118, 11, 272, 34602, 3633, 1581, 7735, 2316, 2804, 537, 34090, 21091, 741, 1120, 73, 3633, 2992, 5232, 1771, 11, 447, 6199, 325, 22872, 42788, 7155, 13, 50638], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 48, "seek": 14408, "start": 149.76000000000002, "end": 151.76000000000002, "text": " Czytaj i przewiduj nast\u0119pne s\u0142owo.", "tokens": [50648, 19832, 1328, 73, 741, 39758, 327, 4579, 39662, 716, 15116, 19941, 13, 50748], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 49, "seek": 14408, "start": 151.96, "end": 154.88000000000002, "text": " W tym przypadku dali mu do przeczytania zbi\u00f3r B\u00f3g Skorpus.", "tokens": [50758, 343, 8107, 41955, 274, 5103, 2992, 360, 8325, 6522, 83, 5609, 710, 5614, 15614, 363, 14047, 7324, 18703, 301, 13, 50904], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 50, "seek": 14408, "start": 155.08, "end": 157.0, "text": " To by\u0142o ponad 7000 ksi\u0105\u017cek.", "tokens": [50914, 1407, 14811, 9224, 345, 1614, 1360, 39311, 916, 13, 51010], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 51, "seek": 14408, "start": 157.20000000000002, "end": 159.72000000000003, "text": " Tak, niepublikowanych ksi\u0105\u017cek z r\u00f3\u017cnych gatunk\u00f3w.", "tokens": [51020, 9118, 11, 2838, 79, 48620, 23341, 339, 39311, 916, 710, 42602, 44092, 3197, 3901, 13, 51146], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 52, "seek": 14408, "start": 159.92000000000002, "end": 161.92000000000002, "text": " I ten prosty cel jest kluczowy, prawda?", "tokens": [51156, 286, 2064, 10293, 88, 9277, 3492, 9671, 1311, 89, 10089, 11, 43607, 30, 51256], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 53, "seek": 14408, "start": 162.12, "end": 164.56, "text": " To brzmi trywialnie, zgadnij nast\u0119pne s\u0142owo, ale.", "tokens": [51266, 1407, 738, 89, 3057, 853, 86, 831, 2766, 11, 40948, 345, 77, 1718, 39662, 716, 15116, 19941, 11, 6775, 13, 51388], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 54, "seek": 14408, "start": 164.76000000000002, "end": 167.12, "text": " Ale \u017ceby robi\u0107 to dobrze, tak na masow\u0105 skal\u0119,", "tokens": [51398, 9366, 11316, 46900, 281, 28335, 11, 991, 1667, 2300, 30297, 16890, 1274, 11, 51516], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 55, "seek": 14408, "start": 167.32000000000002, "end": 171.72000000000003, "text": " w milionach zda\u0144 model jest zmuszony nauczy\u0107 si\u0119 wszystkiego po drodza.", "tokens": [51526, 261, 1962, 313, 608, 710, 2675, 5248, 2316, 3492, 17020, 22378, 2526, 49103, 27150, 3244, 14615, 12200, 714, 3789, 67, 2394, 13, 51746], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 56, "seek": 14408, "start": 171.92000000000002, "end": 172.56, "text": " Ukrycie.", "tokens": [51756, 9816, 627, 4260, 13, 51788], "temperature": 0.0, "avg_logprob": -0.16460657927949549, "compression_ratio": 1.4486803519061584, "no_speech_prob": 0.19212108850479126}, {"id": 57, "seek": 17256, "start": 172.68, "end": 176.52, "text": " W\u0142a\u015bnie, musi zrozumie\u0107 gramatyk\u0119, sk\u0142adnie, kontekst,", "tokens": [50370, 343, 5024, 12221, 11, 37587, 710, 27857, 449, 414, 2162, 21353, 21398, 15724, 11, 1110, 10358, 2766, 11, 14373, 916, 372, 11, 50562], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 58, "seek": 17256, "start": 176.72, "end": 181.6, "text": " jakie\u015b relacje przyczynowo-skutkowe, nawet zdoby\u0107 w szt\u0105tkow\u0105 wiedz\u0119 o \u015bwiecie.", "tokens": [50572, 31163, 1039, 29293, 6501, 6522, 3785, 78, 12, 5161, 325, 74, 6880, 11, 22696, 16221, 13944, 2162, 261, 262, 2682, 23430, 74, 30297, 46894, 11052, 277, 40078, 4260, 13, 50816], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 59, "seek": 17256, "start": 181.8, "end": 184.36, "text": " Czyli nikt mu nie m\u00f3wi, ucz si\u0119 gramatyki?", "tokens": [50826, 37099, 297, 9874, 2992, 2838, 24592, 11, 35403, 3244, 21353, 21398, 2984, 30, 50954], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 60, "seek": 17256, "start": 184.56, "end": 185.68, "text": " Nie, absolutnie.", "tokens": [50964, 12016, 11, 18757, 2766, 13, 51020], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 61, "seek": 17256, "start": 185.88, "end": 190.64000000000001, "text": " On sam dochodzi do wniosku, \u017ce znajomo\u015b\u0107 gramatyki jest po prostu niezwykle u\u017cyteczna", "tokens": [51030, 1282, 3247, 9243, 14543, 360, 45368, 2717, 5279, 11, 3561, 27318, 13395, 7753, 21353, 21398, 2984, 3492, 714, 19518, 33511, 9726, 14677, 34097, 975, 3689, 629, 51268], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 62, "seek": 17256, "start": 190.84, "end": 195.4, "text": " w zadaniu przewidywania i w ten spos\u00f3b po przeczytaniu tych wszystkich ksi\u0105\u017cek", "tokens": [51278, 261, 42788, 25849, 39758, 327, 27112, 5609, 741, 261, 2064, 22904, 714, 8325, 6522, 83, 25849, 15180, 34234, 39311, 916, 51506], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 63, "seek": 17256, "start": 195.6, "end": 201.04, "text": " model buduje w sobie co\u015b, co autorzy nazywaj\u0105 uniwersaln\u0105 reprezentacj\u0105 j\u0119zyka.", "tokens": [51516, 2316, 3265, 13008, 261, 13652, 19241, 11, 598, 19510, 1229, 20151, 27112, 11133, 36435, 5364, 304, 13113, 1085, 265, 14185, 326, 8555, 42309, 40940, 13, 51788], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 64, "seek": 17256, "start": 201.24, "end": 202.2, "text": " To jest fundament.", "tokens": [51798, 1407, 3492, 6073, 13, 51846], "temperature": 0.0, "avg_logprob": -0.13605871318299093, "compression_ratio": 1.459214501510574, "no_speech_prob": 0.009401833638548851}, {"id": 65, "seek": 20220, "start": 202.39999999999998, "end": 206.88, "text": " I dopiero na tym fundamencie budujemy dalej, przechodzimy do etapu drugiego.", "tokens": [50374, 286, 21900, 12030, 1667, 8107, 2374, 22403, 4260, 3265, 21767, 34257, 11, 8325, 29914, 89, 13189, 360, 47634, 84, 4110, 12200, 13, 50598], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 66, "seek": 20220, "start": 207.07999999999998, "end": 208.44, "text": " Czyli do fine tuningu.", "tokens": [50608, 37099, 360, 2489, 15164, 84, 13, 50676], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 67, "seek": 20220, "start": 208.64, "end": 212.23999999999998, "text": " Tak zwanego dyskryminacyjnego fine tuningu z nadzorem.", "tokens": [50686, 9118, 710, 7916, 6308, 15243, 43298, 2367, 31285, 11858, 2489, 15164, 84, 710, 12617, 89, 37956, 13, 50866], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 68, "seek": 20220, "start": 212.44, "end": 213.04, "text": " Dok\u0142adnie.", "tokens": [50876, 29768, 10358, 2766, 13, 50906], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 69, "seek": 20220, "start": 213.23999999999998, "end": 218.23999999999998, "text": " Bierzemy nasz wst\u0119pnie wytremowany taki oczytany model i teraz pokazujemy mu ju\u017c", "tokens": [50916, 363, 34602, 3633, 5382, 89, 261, 372, 18085, 2766, 261, 4328, 2579, 23341, 20065, 277, 6522, 83, 1325, 2316, 741, 16854, 13010, 921, 21767, 2992, 10678, 51166], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 70, "seek": 20220, "start": 218.44, "end": 219.56, "text": " specyficzne zadanie.", "tokens": [51176, 768, 1344, 1786, 43077, 42788, 7155, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 71, "seek": 20220, "start": 219.76, "end": 222.51999999999998, "text": " Na przyk\u0142ad klasyfikacje recenzji filmowych.", "tokens": [51242, 6056, 23144, 9671, 5871, 31230, 29293, 850, 11368, 4013, 2007, 19605, 13, 51380], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 72, "seek": 20220, "start": 222.72, "end": 223.76, "text": " Idealnie.", "tokens": [51390, 13090, 304, 2766, 13, 51442], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 73, "seek": 20220, "start": 223.95999999999998, "end": 225.76, "text": " Pozytywna czy negatywna.", "tokens": [51452, 6165, 1229, 874, 86, 629, 6430, 2485, 21398, 86, 629, 13, 51542], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 74, "seek": 20220, "start": 225.95999999999998, "end": 230.2, "text": " U\u017cywamy ju\u017c ma\u0142ego, specjalistycznego zbiaru danych z etykietami.", "tokens": [51552, 624, 7735, 86, 7804, 10678, 463, 1221, 6308, 11, 46433, 468, 17466, 11858, 710, 5614, 16870, 274, 34644, 710, 1030, 46127, 1684, 4526, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15907789661038307, "compression_ratio": 1.4788732394366197, "no_speech_prob": 0.0022832308895885944}, {"id": 75, "seek": 23020, "start": 230.48, "end": 233.6, "text": " Ale kluczowe jest to, \u017ce model nie startuje od zera.", "tokens": [50378, 9366, 9671, 1311, 89, 6880, 3492, 281, 11, 3561, 2316, 2838, 722, 13008, 3611, 710, 1663, 13, 50534], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 76, "seek": 23020, "start": 233.79999999999998, "end": 235.79999999999998, "text": " On ju\u017c wie, czym jest j\u0119zyk.", "tokens": [50544, 1282, 10678, 3355, 11, 31466, 3492, 49055, 74, 13, 50644], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 77, "seek": 23020, "start": 236.0, "end": 238.51999999999998, "text": " Czyli to jest dok\u0142adnie ta analogia, o kt\u00f3rej wspomnia\u0142e\u015bmy.", "tokens": [50654, 37099, 281, 3492, 45864, 2766, 1846, 16660, 654, 11, 277, 36023, 17757, 38131, 8908, 68, 10513, 13, 50780], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 78, "seek": 23020, "start": 238.72, "end": 243.64, "text": " Zamiast uczy\u0107 ka\u017cdego specjalist\u0119 od zera, wysy\u0142amy go na solidne og\u00f3lne studia.", "tokens": [50790, 1176, 4526, 525, 344, 33967, 21912, 67, 6308, 46433, 468, 1274, 3611, 710, 1663, 11, 27062, 88, 1221, 7804, 352, 1667, 5100, 716, 5360, 15741, 716, 972, 654, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 79, "seek": 23020, "start": 243.83999999999997, "end": 246.28, "text": " A dopiero potem na kr\u00f3tk\u0105, intensywn\u0105 praktyk\u0119.", "tokens": [51046, 316, 21900, 12030, 36513, 1667, 42366, 83, 26304, 11, 14056, 88, 895, 1611, 3206, 74, 874, 15724, 13, 51168], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 80, "seek": 23020, "start": 246.48, "end": 250.76, "text": " A wcze\u015bniej ka\u017cdy by\u0142 uczony tylko swojego w\u0105skiego fachu od samych podstaw.", "tokens": [51178, 316, 40785, 31615, 16673, 35403, 2526, 13219, 13291, 39738, 261, 1611, 5161, 12200, 283, 29220, 3611, 3247, 16384, 43443, 13, 51392], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 81, "seek": 23020, "start": 250.95999999999998, "end": 255.07999999999998, "text": " To jest idealna analogia i to jest fundamentalna zmiana w podej\u015bciu.", "tokens": [51402, 1407, 3492, 7157, 629, 16660, 654, 741, 281, 3492, 8088, 629, 17020, 8497, 261, 7468, 73, 6199, 84, 13, 51608], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 82, "seek": 23020, "start": 255.28, "end": 259.56, "text": " Wcze\u015bniej transfer wiedzy, je\u015bli w og\u00f3le by\u0142, to odbywa\u0142 si\u0119 g\u0142\u00f3wnie na poziomie s\u0142\u00f3w.", "tokens": [51618, 343, 9680, 37511, 5003, 46894, 1229, 11, 25630, 261, 29229, 16673, 11, 281, 3611, 2322, 44603, 3244, 18117, 812, 14215, 1667, 38503, 40120, 15116, 3901, 13, 51832], "temperature": 0.0, "avg_logprob": -0.10489105489212654, "compression_ratio": 1.5155807365439093, "no_speech_prob": 0.003222340950742364}, {"id": 83, "seek": 25956, "start": 259.72, "end": 261.76, "text": " Przez tak zwane word embeddings.", "tokens": [50372, 2114, 1381, 89, 991, 11873, 1929, 1349, 12240, 29432, 13, 50474], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 84, "seek": 25956, "start": 261.96, "end": 264.8, "text": " Co by\u0142o jak daniu studentowi tylko s\u0142ownika.", "tokens": [50484, 3066, 14811, 4207, 3277, 5951, 3107, 24503, 13219, 15116, 648, 5439, 13, 50626], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 85, "seek": 25956, "start": 265.0, "end": 270.04, "text": " W\u0142a\u015bnie. A tutaj dajemy mu ca\u0142\u0105 bibliotek\u0119 i czas, \u017ceby j\u0105 przestudiowa\u0142.", "tokens": [50636, 343, 5024, 12221, 13, 316, 12749, 1120, 73, 3633, 2992, 1335, 15926, 34344, 310, 916, 1274, 741, 13190, 11, 11316, 35692, 44264, 26000, 30105, 13, 50888], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 86, "seek": 25956, "start": 270.24, "end": 272.76, "text": " To jest zupe\u0142nie inna skala rozumienia.", "tokens": [50898, 1407, 3492, 49922, 294, 629, 1110, 5159, 48797, 18811, 13, 51024], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 87, "seek": 25956, "start": 272.96, "end": 277.68, "text": " Dobrze, mamy wi\u0119c t\u0119 eleganck\u0105 dwuetapow\u0105 filozofi\u0119.", "tokens": [51034, 29679, 13503, 11, 17335, 16677, 32489, 1118, 1275, 547, 1611, 27379, 15382, 569, 30297, 1387, 15151, 2670, 5034, 13, 51270], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 88, "seek": 25956, "start": 277.88, "end": 279.8, "text": " Ale diabe\u0142 tkwi w \u015btygu\u0142ach, a w tym", "tokens": [51280, 9366, 1026, 4488, 1221, 256, 74, 6253, 261, 8299, 874, 2794, 1221, 608, 11, 257, 261, 8107, 51376], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 89, "seek": 25956, "start": 280.0, "end": 281.84000000000003, "text": " szoppadku w architekturze.", "tokens": [51386, 7870, 404, 13647, 5279, 261, 3912, 642, 2320, 374, 1381, 13, 51478], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 90, "seek": 25956, "start": 282.04, "end": 284.92, "text": " M\u00f3zgiem ca\u0142ej operacji by\u0142 model transformer.", "tokens": [51488, 376, 812, 89, 70, 4907, 47631, 73, 2208, 13152, 16673, 2316, 31782, 13, 51632], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 91, "seek": 25956, "start": 285.12, "end": 289.28, "text": " Tak. Dlaczego w\u0142a\u015bnie on, a nie popularne wtedy sieci", "tokens": [51642, 9118, 13, 413, 75, 39329, 14234, 322, 11, 257, 2838, 3743, 716, 26959, 2804, 537, 51850], "temperature": 0.0, "avg_logprob": -0.18427173714888723, "compression_ratio": 1.4025974025974026, "no_speech_prob": 0.0082252137362957}, {"id": 92, "seek": 28928, "start": 289.67999999999995, "end": 291.84, "text": " rekurencyjne jak LSTM?", "tokens": [50384, 33881, 9873, 42949, 716, 4207, 441, 6840, 44, 30, 50492], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 93, "seek": 28928, "start": 292.03999999999996, "end": 294.15999999999997, "text": " To by\u0142a krytyczna decyzja.", "tokens": [50502, 1407, 23936, 34847, 874, 3689, 629, 979, 37433, 2938, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 94, "seek": 28928, "start": 294.35999999999996, "end": 298.4, "text": " Modele takie jak LSTM mia\u0142y jeden fundamentalny problem.", "tokens": [50618, 20500, 306, 15963, 4207, 441, 6840, 44, 21290, 6825, 12906, 8088, 1634, 1154, 13, 50820], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 95, "seek": 28928, "start": 298.59999999999997, "end": 300.44, "text": " Kr\u00f3tk\u0105 pami\u0119\u0107.", "tokens": [50830, 6332, 34712, 26304, 31088, 2162, 13, 50922], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 96, "seek": 28928, "start": 300.64, "end": 304.11999999999995, "text": " Radzi\u0142y sobie z kontekstem w obr\u0119bie powiedzmy jednego zdania,", "tokens": [50932, 9654, 3992, 6825, 13652, 710, 14373, 916, 1099, 261, 1111, 81, 1274, 7392, 27617, 2226, 5232, 11858, 16221, 5609, 11, 51106], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 97, "seek": 28928, "start": 304.32, "end": 309.91999999999996, "text": " ale mia\u0142y ogromne trudno\u015bci z\u0142\u0105czeniem fakt\u00f3w, kt\u00f3re by\u0142y od siebie oddalone o kilka akapit\u00f3w.", "tokens": [51116, 6775, 21290, 6825, 34416, 298, 716, 32007, 16438, 710, 15926, 66, 2904, 4907, 21310, 3901, 11, 8864, 26366, 3611, 39137, 7401, 24806, 277, 36466, 9308, 569, 270, 3901, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 98, "seek": 28928, "start": 310.11999999999995, "end": 314.88, "text": " Czyli w przypadku analizy ksi\u0105\u017cki taki model m\u00f3g\u0142by zapami\u0119\u0107, co wydarzy\u0142o si\u0119 w pierwszym", "tokens": [51406, 37099, 261, 41955, 2624, 590, 88, 39311, 2984, 20065, 2316, 275, 14047, 34635, 14223, 23806, 2162, 11, 598, 4628, 20327, 1229, 5249, 3244, 261, 34016, 76, 51644], "temperature": 0.0, "avg_logprob": -0.1585718741783729, "compression_ratio": 1.392226148409894, "no_speech_prob": 0.013317263685166836}, {"id": 99, "seek": 31488, "start": 314.88, "end": 317.92, "text": " rozdziel\u0119, zanim dotar\u0142by do dziesi\u0105tego.", "tokens": [50364, 9544, 28168, 1187, 1274, 11, 710, 17869, 5893, 289, 34635, 360, 9758, 530, 11404, 975, 1571, 13, 50516], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 100, "seek": 31488, "start": 318.12, "end": 321.64, "text": " I wtedy ca\u0142e zrozumienie fabu\u0142y bierze w \u0142eb.", "tokens": [50526, 286, 26959, 47631, 710, 27857, 449, 27385, 5355, 84, 6825, 272, 811, 1381, 261, 220, 19827, 65, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 101, "seek": 31488, "start": 321.84, "end": 323.36, "text": " Jasne. Dok\u0142adnie.", "tokens": [50712, 34023, 716, 13, 29768, 10358, 2766, 13, 50788], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 102, "seek": 31488, "start": 323.56, "end": 328.04, "text": " A transformer, dzi\u0119ki mechanizmowi zwanemu self-attention, potrafi", "tokens": [50798, 316, 31782, 11, 45003, 4236, 590, 76, 24503, 710, 7916, 37552, 2698, 12, 1591, 1251, 11, 1847, 10437, 72, 51022], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 103, "seek": 31488, "start": 328.24, "end": 333.52, "text": " wa\u017cy\u0107 znaczenie wszystkich s\u0142\u00f3w w kontek\u015bcie, niezale\u017cnie od tego, jak daleko si\u0119 znajduj\u0105.", "tokens": [51032, 5406, 39687, 15397, 326, 16778, 34234, 15116, 3901, 261, 14373, 916, 9815, 11, 33511, 45494, 2766, 3611, 8627, 11, 4207, 11702, 34241, 3244, 47570, 8555, 13, 51296], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 104, "seek": 31488, "start": 333.71999999999997, "end": 336.08, "text": " Czyli odleg\u0142o\u015b\u0107 nie ma takiego znaczenia.", "tokens": [51306, 37099, 277, 2285, 70, 44742, 2838, 463, 32296, 15397, 326, 14320, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 105, "seek": 31488, "start": 336.28, "end": 339.2, "text": " R\u00f3wnie wa\u017cne, co s\u0142owo z poprzedniego zdania.", "tokens": [51434, 497, 812, 14215, 46110, 11, 598, 15116, 19941, 710, 1665, 81, 11312, 2766, 1571, 16221, 5609, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 106, "seek": 31488, "start": 339.4, "end": 344.8, "text": " A skoro zadaniem by\u0142o czytanie ca\u0142ych ksi\u0105\u017cek, ta zdolno\u015b\u0107 by\u0142a absolutnie niezb\u0119dna.", "tokens": [51590, 316, 1110, 10780, 710, 11338, 4907, 14811, 6430, 83, 7155, 35226, 339, 39311, 916, 11, 1846, 16221, 401, 23293, 23936, 18757, 2766, 33511, 65, 6298, 629, 13, 51860], "temperature": 0.0, "avg_logprob": -0.1519846200942993, "compression_ratio": 1.4625, "no_speech_prob": 0.12909163534641266}, {"id": 107, "seek": 34488, "start": 345.12, "end": 351.44, "text": " W artykule u\u017cyli konkretnej wersji dwunastowarstwowego modelu transformer typu decoder only.", "tokens": [50376, 343, 594, 874, 74, 2271, 34097, 2081, 36500, 11794, 261, 433, 4013, 27379, 409, 525, 305, 289, 372, 86, 26576, 2316, 84, 31782, 2125, 84, 979, 19866, 787, 13, 50692], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 108, "seek": 34488, "start": 351.64, "end": 353.2, "text": " Co to w praktyce oznacza\u0142o?", "tokens": [50702, 3066, 281, 261, 3206, 74, 874, 384, 277, 22672, 326, 2394, 5249, 30, 50780], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 109, "seek": 34488, "start": 353.4, "end": 360.56, "text": " Decoder only oznacza, \u017ce jest to architektura zoptymalizowana do generowania sekwencji s\u0142owo po s\u0142owie.", "tokens": [50790, 12427, 19866, 787, 277, 22672, 326, 2394, 11, 3561, 3492, 281, 3912, 642, 2320, 2991, 710, 404, 874, 5579, 590, 40458, 360, 1337, 21308, 17215, 15615, 19649, 15116, 19941, 714, 15116, 13998, 13, 51148], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 110, "seek": 34488, "start": 360.76, "end": 363.84, "text": " U\u017cywa czego\u015b takiego jak masked self-attention.", "tokens": [51158, 624, 7735, 4151, 36559, 1788, 32296, 4207, 45249, 2698, 12, 1591, 1251, 13, 51312], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 111, "seek": 34488, "start": 364.04, "end": 366.15999999999997, "text": " Masked, czyli zamaskowane.", "tokens": [51322, 25414, 292, 11, 16591, 19876, 3863, 23066, 13, 51428], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 112, "seek": 34488, "start": 366.36, "end": 372.71999999999997, "text": " Tak, co po prostu znaczy, \u017ce podczas przewidywania s\u0142owa numer n model mo\u017ce patrze\u0107 tylko", "tokens": [51438, 9118, 11, 598, 714, 19518, 36584, 11, 3561, 2497, 30989, 39758, 38836, 86, 5609, 15116, 5528, 7866, 297, 2316, 12034, 1947, 13503, 2162, 13219, 51756], "temperature": 0.0, "avg_logprob": -0.16392349129292502, "compression_ratio": 1.5037593984962405, "no_speech_prob": 0.0006212872103787959}, {"id": 113, "seek": 37272, "start": 372.72, "end": 375.40000000000003, "text": " na s\u0142owa od pierwszego do n minus jeden.", "tokens": [50364, 1667, 15116, 5528, 3611, 27623, 27725, 360, 297, 3175, 12906, 13, 50498], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 114, "seek": 37272, "start": 375.6, "end": 377.20000000000005, "text": " Nie mo\u017ce podgl\u0105da\u0107 przysz\u0142o\u015bci.", "tokens": [50508, 12016, 12034, 2497, 7191, 26398, 2162, 44018, 35059, 13, 50588], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 115, "seek": 37272, "start": 377.40000000000003, "end": 380.36, "text": " Co jest naturalne, skoro ma przewidzie\u0107 nast\u0119pne s\u0142owo?", "tokens": [50598, 3066, 3492, 3303, 716, 11, 1110, 10780, 463, 39758, 327, 21214, 39662, 716, 15116, 19941, 30, 50746], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 116, "seek": 37272, "start": 380.56, "end": 381.20000000000005, "text": " Oczywi\u015bcie.", "tokens": [50756, 42980, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 117, "seek": 37272, "start": 381.40000000000003, "end": 386.04, "text": " OK, czyli mamy pot\u0119\u017cn\u0105 architektur\u0119 i sprytn\u0105 metod\u0119 treningu.", "tokens": [50798, 2264, 11, 16591, 17335, 1847, 1274, 1427, 13113, 3912, 642, 2320, 374, 1274, 741, 637, 627, 83, 13113, 1131, 378, 1274, 2192, 773, 84, 13, 51030], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 118, "seek": 37272, "start": 386.24, "end": 388.0, "text": " Ale tu pojawia si\u0119 kolejny problem.", "tokens": [51040, 9366, 2604, 30655, 654, 3244, 23749, 1634, 1154, 13, 51128], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 119, "seek": 37272, "start": 388.20000000000005, "end": 393.04, "text": " Jak zaadaptowa\u0107 jeden uniwersalny model do tak r\u00f3\u017cnych zada\u0144?", "tokens": [51138, 15029, 7949, 345, 2796, 11445, 12906, 36435, 5364, 304, 1634, 2316, 360, 991, 42602, 710, 1538, 5248, 30, 51380], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 120, "seek": 37272, "start": 393.24, "end": 395.44000000000005, "text": " Bo czym innym jest ocenaczy dwa zdania", "tokens": [51390, 3286, 31466, 294, 12996, 3492, 10409, 268, 14691, 35045, 16221, 5609, 51500], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 121, "seek": 37272, "start": 395.64000000000004, "end": 399.04, "text": " s\u0105 do siebie podobne, a czym innym odpowiadanie na pytanie, prawda?", "tokens": [51510, 9015, 360, 39137, 43024, 716, 11, 257, 31466, 294, 12996, 24314, 38069, 7155, 1667, 36610, 11, 43607, 30, 51680], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 122, "seek": 37272, "start": 399.24, "end": 401.32000000000005, "text": " Ka\u017cde z tych zada\u0144 ma inn\u0105 struktur\u0119.", "tokens": [51690, 10988, 1427, 1479, 710, 15180, 710, 1538, 5248, 463, 7714, 1611, 342, 31543, 1274, 13, 51794], "temperature": 0.0, "avg_logprob": -0.13757722805707884, "compression_ratio": 1.4842767295597483, "no_speech_prob": 0.06568365544080734}, {"id": 123, "seek": 40132, "start": 401.44, "end": 405.2, "text": " I to jest chyba najbardziej elekanski trik w ca\u0142ym tym artykule.", "tokens": [50370, 286, 281, 3492, 31532, 41857, 1118, 74, 599, 2984, 1376, 74, 261, 35224, 4199, 8107, 594, 874, 74, 2271, 13, 50558], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 124, "seek": 40132, "start": 405.4, "end": 405.92, "text": " Naprawd\u0119?", "tokens": [50568, 18287, 20098, 30, 50594], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 125, "seek": 40132, "start": 406.12, "end": 409.92, "text": " Tak, zamiast zmienia\u0107 architektur\u0119 modelu dla ka\u017cdego zadania,", "tokens": [50604, 9118, 11, 710, 4526, 525, 17020, 18811, 2162, 3912, 642, 2320, 374, 1274, 2316, 84, 12285, 21912, 67, 6308, 42788, 5609, 11, 50794], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 126, "seek": 40132, "start": 410.12, "end": 412.64, "text": " autorzy zmieniali format danych wej\u015bciowych.", "tokens": [50804, 19510, 1229, 17020, 1053, 831, 72, 7877, 274, 34644, 321, 73, 6199, 19605, 13, 50930], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 127, "seek": 40132, "start": 412.84, "end": 416.6, "text": " A, czyli dopasowywali problem do modelu, a nie model do problemu?", "tokens": [50940, 316, 11, 16591, 360, 20990, 10089, 40054, 1154, 360, 2316, 84, 11, 257, 2838, 2316, 360, 1154, 84, 30, 51128], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 128, "seek": 40132, "start": 416.8, "end": 421.32, "text": " Dok\u0142adnie, tak \u017ceby pasowa\u0142y do tego, co model ju\u017c umie robi\u0107, czyli przetwarza\u0107", "tokens": [51138, 29768, 10358, 2766, 11, 991, 11316, 1736, 5528, 6825, 360, 8627, 11, 598, 2316, 10678, 1105, 414, 46900, 11, 16591, 6541, 302, 6925, 35873, 51364], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 129, "seek": 40132, "start": 421.52, "end": 423.6, "text": " pojedyncz\u0105 ci\u0105g\u0142\u0105 sekwencj\u0119 token\u00f3w.", "tokens": [51374, 714, 40543, 2534, 3689, 1611, 42398, 70, 15926, 17215, 15615, 41960, 14862, 3901, 13, 51478], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 130, "seek": 40132, "start": 423.8, "end": 427.32, "text": " Czyli t\u0142umaczyli zadanie na j\u0119zyk zrozumia\u0142e dla modelu?", "tokens": [51488, 37099, 256, 49166, 14691, 2081, 42788, 7155, 1667, 49055, 74, 710, 27857, 449, 8908, 68, 12285, 2316, 84, 30, 51664], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 131, "seek": 40132, "start": 427.52, "end": 429.92, "text": " W\u0142a\u015bnie, we\u017amy przyk\u0142ady z artyku\u0142u.", "tokens": [51674, 343, 5024, 12221, 11, 321, 10659, 2226, 6501, 74, 1221, 880, 710, 594, 874, 5279, 24066, 13, 51794], "temperature": 0.0, "avg_logprob": -0.13670173911161201, "compression_ratio": 1.4953846153846153, "no_speech_prob": 0.0016582724638283253}, {"id": 132, "seek": 42992, "start": 430.12, "end": 435.76, "text": " W zadaniu entailment, czyli wynikania logicznego, gdzie mamy przes\u0142ank\u0119 i hipotez\u0119.", "tokens": [50374, 343, 42788, 25849, 948, 864, 518, 11, 16591, 31936, 1035, 5609, 9952, 89, 11858, 11, 18922, 17335, 6541, 279, 1221, 657, 1274, 741, 8103, 1370, 11052, 13, 50656], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 133, "seek": 42992, "start": 435.96000000000004, "end": 439.04, "text": " Pok prostu \u0142\u0105czyli te dwa zdania w jeden ci\u0105g, tak?", "tokens": [50666, 14958, 19518, 220, 15926, 6522, 2081, 535, 35045, 16221, 5609, 261, 12906, 42398, 70, 11, 991, 30, 50820], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 134, "seek": 42992, "start": 439.24, "end": 443.44, "text": " Tak, wstawiaj\u0105c mi\u0119dzy niespecjalny token rozdzielaj\u0105cy.", "tokens": [50830, 9118, 11, 261, 22580, 48125, 66, 33964, 48100, 494, 66, 22600, 1634, 14862, 9544, 28168, 1187, 11133, 1344, 13, 51040], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 135, "seek": 42992, "start": 443.64000000000004, "end": 446.28000000000003, "text": " Model patrzy\u0142 na ca\u0142o\u015b\u0107 i mia\u0142 wyda\u0107 werdykt.", "tokens": [51050, 17105, 1947, 13047, 1221, 1667, 1335, 44742, 741, 27989, 4628, 2675, 2162, 2612, 3173, 2320, 13, 51182], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 136, "seek": 42992, "start": 446.48, "end": 449.04, "text": " Wynika sprzeczne czy neutralne.", "tokens": [51192, 343, 2534, 5439, 6103, 1381, 38491, 6430, 10598, 716, 13, 51320], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 137, "seek": 42992, "start": 449.24, "end": 454.20000000000005, "text": " A co w sytuacji, gdy kolejno\u015b\u0107 nie ma znaczenia, jak przy poruzmywaniu podobie\u0144stwa dw\u00f3ch zda\u0144?", "tokens": [51330, 316, 598, 261, 28275, 13152, 11, 28405, 23749, 23293, 2838, 463, 15397, 326, 14320, 11, 4207, 6501, 1515, 3334, 2226, 86, 25849, 43024, 414, 12229, 4151, 27379, 812, 339, 710, 2675, 5248, 30, 51578], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 138, "seek": 42992, "start": 454.40000000000003, "end": 459.48, "text": " Kot siedzi na macie, jest tak samo podobne do kocur drzemie nadywanie, jak na odwrot.", "tokens": [51588, 30123, 262, 1091, 3992, 1667, 7912, 414, 11, 3492, 991, 36422, 43024, 716, 360, 350, 905, 374, 1224, 24313, 414, 297, 880, 86, 7155, 11, 4207, 1667, 3611, 7449, 310, 13, 51842], "temperature": 0.0, "avg_logprob": -0.14984490885537052, "compression_ratio": 1.4613003095975232, "no_speech_prob": 0.005442935042083263}, {"id": 139, "seek": 45948, "start": 459.68, "end": 460.88, "text": " \u015awietne pytanie.", "tokens": [50374, 27933, 39083, 716, 36610, 13, 50434], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 140, "seek": 45948, "start": 461.08000000000004, "end": 463.96000000000004, "text": " W zadaniu similarity robili dok\u0142adnie to.", "tokens": [50444, 343, 42788, 25849, 32194, 3870, 2312, 45864, 2766, 281, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 141, "seek": 45948, "start": 464.16, "end": 466.44, "text": " Przepuszczali przez model obie kombinacje.", "tokens": [50598, 2114, 46342, 22378, 3689, 5103, 14064, 2316, 1111, 414, 42925, 259, 29293, 13, 50712], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 142, "seek": 45948, "start": 466.64000000000004, "end": 473.16, "text": " A, czyli zdanie A, separator zdanie B, a potem zdanie B, separator zdanie A.", "tokens": [50722, 316, 11, 16591, 16221, 7155, 316, 11, 3128, 1639, 16221, 7155, 363, 11, 257, 36513, 16221, 7155, 363, 11, 3128, 1639, 16221, 7155, 316, 13, 51048], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 143, "seek": 45948, "start": 473.36, "end": 479.40000000000003, "text": " Tak, nast\u0119pnie sumowali uzyskane reprezentacje i dopiero na tej podstawie podejmowali decyzj\u0119.", "tokens": [51058, 9118, 11, 39662, 2766, 2408, 305, 5103, 16851, 749, 74, 1929, 1085, 265, 14185, 29293, 741, 21900, 12030, 1667, 12573, 43443, 414, 7468, 35195, 305, 5103, 979, 37433, 11115, 13, 51360], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 144, "seek": 45948, "start": 479.6, "end": 484.68, "text": " To prosty spos\u00f3b, \u017ceby poinformowa\u0107 model o symetrii problemu, bez dotykania jego architektury.", "tokens": [51370, 1407, 10293, 88, 22904, 11, 11316, 714, 37811, 11445, 2316, 277, 943, 5537, 470, 72, 1154, 84, 11, 10782, 5893, 88, 5225, 654, 26542, 3912, 642, 2320, 2598, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 145, "seek": 45948, "start": 484.88, "end": 486.52000000000004, "text": " To jest genialne.", "tokens": [51634, 1407, 3492, 48228, 716, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1416699689133723, "compression_ratio": 1.4980988593155893, "no_speech_prob": 0.0017482686089351773}, {"id": 146, "seek": 48652, "start": 486.76, "end": 489.35999999999996, "text": " A co z jeszcze bardziej skomplikowanymi zadaniami?", "tokens": [50376, 316, 598, 710, 14168, 27209, 1110, 298, 564, 1035, 23341, 3057, 710, 11338, 15568, 30, 50506], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 147, "seek": 48652, "start": 489.56, "end": 494.52, "text": " Jak pytania wielokrotnego wyboru, gdzie mamy kontekst, pytanie i kilka mo\u017cliwych odpowiedzi?", "tokens": [50516, 15029, 25878, 5609, 20570, 453, 10536, 11858, 4628, 3918, 84, 11, 18922, 17335, 14373, 916, 372, 11, 36610, 741, 36466, 30854, 9726, 339, 36574, 3992, 30, 50764], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 148, "seek": 48652, "start": 494.71999999999997, "end": 498.03999999999996, "text": " Tutaj, zastosowano podobn\u0105 logik\u0119.", "tokens": [50774, 41819, 11, 710, 525, 329, 305, 3730, 43024, 13113, 3565, 1035, 1274, 13, 50940], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 149, "seek": 48652, "start": 498.24, "end": 502.91999999999996, "text": " Dla ka\u017cdej mo\u017cliwej odpowiedzi tworzono osobn\u0105 pe\u0142n\u0105 sekwencj\u0119.", "tokens": [50950, 413, 875, 21912, 1479, 73, 30854, 826, 73, 36574, 3992, 46288, 89, 8957, 41518, 13113, 43205, 13113, 17215, 15615, 41960, 13, 51184], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 150, "seek": 48652, "start": 503.12, "end": 505.44, "text": " Czyli jakby osobne wsady dla modelu.", "tokens": [51194, 37099, 28976, 41518, 716, 37647, 880, 12285, 2316, 84, 13, 51310], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 151, "seek": 48652, "start": 505.64, "end": 506.56, "text": " Dok\u0142adnie.", "tokens": [51320, 29768, 10358, 2766, 13, 51366], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 152, "seek": 48652, "start": 506.76, "end": 508.15999999999997, "text": " Wygl\u0105da\u0142o to tak.", "tokens": [51376, 14458, 7191, 26398, 5249, 281, 991, 13, 51446], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 153, "seek": 48652, "start": 508.35999999999996, "end": 513.72, "text": " Kontekst, separator, pytanie, separator, odpowied\u017a A.", "tokens": [51456, 20629, 916, 372, 11, 3128, 1639, 11, 36610, 11, 3128, 1639, 11, 36574, 10659, 316, 13, 51724], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 154, "seek": 48652, "start": 513.92, "end": 515.4399999999999, "text": " Potem druga sekwencja.", "tokens": [51734, 9145, 443, 4110, 64, 17215, 15615, 34056, 13, 51810], "temperature": 0.0, "avg_logprob": -0.13695665087018694, "compression_ratio": 1.5075757575757576, "no_speech_prob": 0.001989291748031974}, {"id": 155, "seek": 51544, "start": 515.5600000000001, "end": 520.1600000000001, "text": " Kontekst, separator, pytanie, separator, odpowied\u017a B i tak dalej.", "tokens": [50370, 20629, 916, 372, 11, 3128, 1639, 11, 36610, 11, 3128, 1639, 11, 36574, 10659, 363, 741, 991, 34257, 13, 50600], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 156, "seek": 51544, "start": 520.36, "end": 524.0, "text": " I model ocenia\u0142, kt\u00f3ra z tych ca\u0142o\u015bci jest najbardziej prawdopodobna?", "tokens": [50610, 286, 2316, 10409, 268, 8908, 11, 19456, 710, 15180, 1335, 35059, 3492, 41857, 41175, 46684, 996, 629, 30, 50792], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 157, "seek": 51544, "start": 524.2, "end": 531.32, "text": " Tak. Wybierano t\u0119 odpowied\u017a, dla kt\u00f3rej ca\u0142a sekwencja by\u0142a najbardziej naturalna i prawdopodobna w jego ocenie.", "tokens": [50802, 9118, 13, 14458, 65, 811, 3730, 32489, 36574, 10659, 11, 12285, 36023, 1335, 5024, 17215, 15615, 34056, 23936, 41857, 3303, 629, 741, 41175, 46684, 996, 629, 261, 26542, 10409, 268, 414, 13, 51158], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 158, "seek": 51544, "start": 531.5200000000001, "end": 532.7600000000001, "text": " Niesamowite.", "tokens": [51168, 426, 530, 335, 305, 642, 13, 51230], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 159, "seek": 51544, "start": 532.96, "end": 539.7600000000001, "text": " Czyli model pozostaje nietkni\u0119ty, a ca\u0142a adaptacja odbywa si\u0119 na zewn\u0105trz, na poziomie przygotowania danych.", "tokens": [51240, 37099, 2316, 21281, 555, 11153, 6899, 74, 35938, 874, 11, 257, 1335, 5024, 6231, 23395, 3611, 2322, 4151, 3244, 1667, 5277, 895, 1611, 6903, 89, 11, 1667, 38503, 40120, 35914, 21308, 274, 34644, 13, 51580], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 160, "seek": 51544, "start": 539.96, "end": 541.7600000000001, "text": " Co jest ogromnym uproszczeniem?", "tokens": [51590, 3066, 3492, 34416, 298, 12996, 493, 2635, 89, 66, 2904, 4907, 30, 51680], "temperature": 0.0, "avg_logprob": -0.11216307039614078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.004206723999232054}, {"id": 161, "seek": 54176, "start": 541.92, "end": 546.12, "text": " Unikamy budowania skomplikowanych, dedykowanych g\u0142owic dla ka\u017cdego zadania.", "tokens": [50372, 1156, 1035, 7804, 3265, 21308, 1110, 298, 564, 1035, 23341, 339, 11, 4172, 46127, 23341, 339, 18117, 305, 299, 12285, 21912, 67, 6308, 42788, 5609, 13, 50582], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 162, "seek": 54176, "start": 546.3199999999999, "end": 548.64, "text": " I to otworzy\u0142o drog\u0119 do generalizacji.", "tokens": [50592, 286, 281, 4337, 28321, 1229, 5249, 3789, 70, 1274, 360, 2674, 590, 13152, 13, 50708], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 163, "seek": 54176, "start": 548.84, "end": 554.8, "text": " Jeden model, kt\u00f3ry potrafi nauczy\u0107 si\u0119 niemal wszystkiego i je\u015bli tylko odpowiednio sformu\u0142ujemy mu pytanie.", "tokens": [50718, 508, 6876, 2316, 11, 9913, 1847, 10437, 72, 49103, 27150, 3244, 2838, 5579, 14615, 12200, 741, 25630, 13219, 36574, 41084, 262, 837, 84, 1221, 21767, 2992, 36610, 13, 51016], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 164, "seek": 54176, "start": 555.0, "end": 561.72, "text": " OK, teoria jest pi\u0119kna, architektura sprytna, a sztuczki z danymi eleganckie.", "tokens": [51026, 2264, 11, 535, 8172, 3492, 48085, 629, 11, 3912, 642, 2320, 2991, 637, 627, 83, 629, 11, 257, 262, 2682, 1311, 89, 2984, 710, 274, 1325, 3057, 1118, 1275, 547, 414, 13, 51362], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 165, "seek": 54176, "start": 561.92, "end": 568.2, "text": " Ale w uczeniu maszynowym pi\u0119kne teorie umieraj\u0105 ka\u017cdego dnia, gdy zderzaj\u0105 si\u0119 z twardymi danymi.", "tokens": [51372, 9366, 261, 344, 66, 39651, 2300, 1229, 3785, 4199, 48085, 716, 535, 17473, 1105, 811, 11133, 21912, 67, 6308, 274, 12679, 11, 28405, 710, 1068, 89, 11133, 3244, 710, 683, 515, 88, 3057, 274, 1325, 3057, 13, 51686], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 166, "seek": 54176, "start": 568.4, "end": 569.28, "text": " Niestety tak.", "tokens": [51696, 426, 6495, 2210, 991, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10438086436345027, "compression_ratio": 1.4607508532423208, "no_speech_prob": 0.021284904330968857}, {"id": 167, "seek": 56928, "start": 569.48, "end": 571.9599999999999, "text": " Wi\u0119c pytanie za milion dolar\u00f3w brzmi.", "tokens": [50374, 32508, 36610, 7949, 1962, 313, 360, 2200, 3901, 738, 89, 3057, 13, 50498], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 168, "seek": 56928, "start": 572.16, "end": 573.8399999999999, "text": " Czy to zadzia\u0142a\u0142o?", "tokens": [50508, 19832, 281, 42788, 89, 25605, 5249, 30, 50592], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 169, "seek": 56928, "start": 574.04, "end": 582.8399999999999, "text": " Czy ten uniwersalny student mia\u0142 jakiekolwiek szanse w starciu z wysoko wyspecjalizowanymi rzemie\u015blnikami, kt\u00f3rzy dominowali wtedy w tej dziedzinie?", "tokens": [50602, 19832, 2064, 36435, 5364, 304, 1634, 3107, 27989, 4207, 19487, 401, 44674, 7870, 47661, 261, 3543, 30795, 710, 27062, 13704, 27062, 494, 66, 22600, 590, 23341, 3057, 367, 24313, 414, 19212, 13123, 4526, 11, 25382, 8859, 305, 5103, 26959, 261, 12573, 9758, 15338, 259, 414, 30, 51042], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 170, "seek": 56928, "start": 583.04, "end": 584.72, "text": " Nie tylko mia\u0142 szanse.", "tokens": [51052, 12016, 13219, 27989, 7870, 47661, 13, 51136], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 171, "seek": 56928, "start": 584.92, "end": 586.24, "text": " On ich zdeklasowa\u0142.", "tokens": [51146, 1282, 1893, 710, 67, 916, 7743, 30105, 13, 51212], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 172, "seek": 56928, "start": 586.4399999999999, "end": 587.12, "text": " A\u017c tak?", "tokens": [51222, 316, 1427, 991, 30, 51256], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 173, "seek": 56928, "start": 587.3199999999999, "end": 594.88, "text": " Model pobi\u0142 dotychczasowe najlepsze wyniki, tak zwane State of the Art, na 9 z 12 analizowanych zestaw\u00f3w danych.", "tokens": [51266, 17105, 714, 5614, 1221, 5893, 16384, 30989, 6880, 41903, 1878, 1381, 31936, 9850, 11, 991, 11873, 1929, 4533, 295, 264, 5735, 11, 1667, 1722, 710, 2272, 2624, 590, 23341, 339, 37889, 1607, 3901, 274, 34644, 13, 51644], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 174, "seek": 56928, "start": 595.0799999999999, "end": 597.16, "text": " I to cz\u0119sto zmierznancom przewag\u0105.", "tokens": [51654, 286, 281, 34369, 17020, 34602, 17622, 1112, 39758, 559, 1611, 13, 51758], "temperature": 0.0, "avg_logprob": -0.17813450581318624, "compression_ratio": 1.4026845637583893, "no_speech_prob": 0.08103655278682709}, {"id": 175, "seek": 59716, "start": 597.4, "end": 605.64, "text": " 9 z 12 przeciwko modelom, kt\u00f3re by\u0142y latami szyte na miar\u0119 pod te konkretne zadania, to brzmi niewiarygodnie.", "tokens": [50376, 1722, 710, 2272, 39622, 86, 4093, 2316, 298, 11, 8864, 26366, 4465, 4526, 30526, 975, 1667, 2752, 289, 1274, 2497, 535, 36500, 716, 42788, 5609, 11, 281, 738, 89, 3057, 43622, 29104, 21787, 2766, 13, 50788], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 176, "seek": 59716, "start": 605.8399999999999, "end": 609.28, "text": " We\u017amy kilka przyk\u0142ad\u00f3w, \u017ceby poczu\u0107 skal\u0119 tego sukcesu.", "tokens": [50798, 492, 10659, 2226, 36466, 23144, 3901, 11, 11316, 26423, 84, 2162, 16890, 1274, 8627, 46432, 887, 84, 13, 50970], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 177, "seek": 59716, "start": 609.48, "end": 611.1999999999999, "text": " Na przyk\u0142ad story close test.", "tokens": [50980, 6056, 23144, 1657, 1998, 1500, 13, 51066], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 178, "seek": 59716, "start": 611.4, "end": 614.68, "text": " To jest to zadanie, kt\u00f3re wymaga rozumowania zdroworos\u0105dkowego.", "tokens": [51076, 1407, 3492, 281, 42788, 7155, 11, 8864, 29764, 9286, 48797, 21308, 49745, 284, 329, 18962, 74, 26576, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 179, "seek": 59716, "start": 614.88, "end": 615.24, "text": " Tak.", "tokens": [51250, 9118, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 180, "seek": 59716, "start": 615.4399999999999, "end": 616.36, "text": " Dok\u0142adnie.", "tokens": [51278, 29768, 10358, 2766, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 181, "seek": 59716, "start": 616.56, "end": 623.56, "text": " Model dostaje kr\u00f3tki fragment historyjki i musi wybra\u0107 jedno z dw\u00f3ch mo\u017cliwych, logicznych zako\u0144czeni.", "tokens": [51334, 17105, 20568, 11153, 42366, 83, 2984, 26424, 2503, 73, 2984, 741, 37587, 4628, 6198, 2162, 5232, 1771, 710, 27379, 812, 339, 30854, 9726, 339, 11, 9952, 89, 9399, 710, 18501, 5248, 66, 42124, 13, 51684], "temperature": 0.0, "avg_logprob": -0.1545260723372151, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.004093940369784832}, {"id": 182, "seek": 62356, "start": 623.76, "end": 627.04, "text": " Poprzedni najlepszy wynik to by\u0142o 75%.", "tokens": [50374, 10215, 81, 11312, 3722, 41903, 1878, 1229, 31936, 1035, 281, 14811, 9562, 6856, 50538], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 183, "seek": 62356, "start": 627.2399999999999, "end": 630.76, "text": " Ten model osi\u0105gn\u0105\u0142 83,9%.", "tokens": [50548, 9380, 2316, 3003, 11404, 4568, 1611, 1221, 30997, 11, 24, 6856, 50724], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 184, "seek": 62356, "start": 630.9599999999999, "end": 635.3599999999999, "text": " 83,9% to jest prawie 9 punkt\u00f3w procentowych r\u00f3\u017cnicy.", "tokens": [50734, 30997, 11, 24, 4, 281, 3492, 3206, 8699, 1722, 39561, 3901, 38826, 19605, 19637, 77, 2632, 13, 50954], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 185, "seek": 62356, "start": 635.56, "end": 636.56, "text": " Prawie 9%.", "tokens": [50964, 430, 5131, 414, 1722, 6856, 51014], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 186, "seek": 62356, "start": 636.76, "end": 639.4, "text": " W badaniach NLP to nie jest krok naprz\u00f3d.", "tokens": [51024, 343, 1578, 3782, 608, 426, 45196, 281, 2838, 3492, 350, 31621, 9296, 19390, 17081, 13, 51156], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 187, "seek": 62356, "start": 639.5999999999999, "end": 641.4, "text": " To jest skok w nadprzestrze\u0144.", "tokens": [51166, 1407, 3492, 1110, 453, 261, 12617, 1424, 89, 377, 13503, 5248, 13, 51256], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 188, "seek": 62356, "start": 641.5999999999999, "end": 645.3599999999999, "text": " To faktycznie knockout, a w innych, bardziej standardowych zadaniach.", "tokens": [51266, 1407, 33647, 45586, 6728, 346, 11, 257, 261, 36286, 11, 27209, 3832, 19605, 42788, 3782, 608, 13, 51454], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 189, "seek": 62356, "start": 645.56, "end": 647.88, "text": " Jaki\u015b bli\u017cszych, realnym zastosowaniom.", "tokens": [51464, 508, 7421, 1788, 27182, 1427, 45021, 11, 957, 12996, 36746, 329, 305, 3782, 298, 13, 51580], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 190, "seek": 62356, "start": 648.0799999999999, "end": 649.7199999999999, "text": " No to sp\u00f3jrzmy na rejs.", "tokens": [51590, 883, 281, 637, 18999, 19390, 2226, 1667, 319, 25530, 13, 51672], "temperature": 0.0, "avg_logprob": -0.19574734723126447, "compression_ratio": 1.3568627450980393, "no_speech_prob": 0.01704416610300541}, {"id": 191, "seek": 64972, "start": 649.9200000000001, "end": 652.0400000000001, "text": " To zbi\u00f3r danych oparty na egzaminach", "tokens": [50374, 1407, 710, 5614, 15614, 274, 34644, 999, 446, 88, 1667, 24263, 89, 7428, 608, 50480], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 192, "seek": 64972, "start": 652.24, "end": 655.08, "text": " zczytania ze zrozumieniem dla nastolatk\u00f3w w Chinach.", "tokens": [50490, 710, 6522, 83, 5609, 5277, 710, 27857, 449, 1053, 4907, 12285, 26088, 401, 267, 23849, 261, 4430, 608, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 193, "seek": 64972, "start": 655.28, "end": 657.88, "text": " Czyli d\u0142ugie teksty, skomplikowane pytania.", "tokens": [50642, 37099, 274, 34077, 414, 16624, 25134, 11, 1110, 298, 564, 1035, 23066, 25878, 5609, 13, 50772], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 194, "seek": 64972, "start": 658.08, "end": 661.36, "text": " Tak. Tutaj poprawa wynios\u0142a 5,7%.", "tokens": [50782, 9118, 13, 41819, 1665, 424, 4151, 31936, 2717, 5024, 1025, 11, 22, 6856, 50946], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 195, "seek": 64972, "start": 661.5600000000001, "end": 666.48, "text": " To pokaza\u0142o, \u017ce model potrafi\u0142 nie tylko dopasowywa\u0107 s\u0142owa kluczowe, ale faktycznie", "tokens": [50956, 1407, 13010, 12257, 5249, 11, 3561, 2316, 1847, 10437, 40622, 2838, 13219, 360, 20990, 10089, 25234, 15116, 5528, 9671, 1311, 89, 6880, 11, 6775, 33647, 45586, 51202], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 196, "seek": 64972, "start": 666.6800000000001, "end": 669.5600000000001, "text": " rozumie\u0107 z\u0142o\u017cone zale\u017cno\u015bci w d\u0142u\u017cszych tekstach.", "tokens": [51212, 48797, 414, 2162, 710, 5249, 1427, 546, 710, 45494, 16438, 261, 274, 24066, 1427, 45021, 16624, 372, 608, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 197, "seek": 64972, "start": 669.76, "end": 675.48, "text": " Ale chyba najbardziej imponuj\u0105cy jest wynik na zbiorze ko\u0142a, gdzie ocenia si\u0119 poprawno\u015b\u0107 gramatyczn\u0105 zda\u0144.", "tokens": [51366, 9366, 31532, 41857, 704, 266, 13263, 1344, 3492, 31936, 1035, 1667, 710, 33362, 1381, 8384, 5024, 11, 18922, 10409, 268, 654, 3244, 1665, 424, 20944, 7753, 21353, 267, 17466, 13113, 710, 2675, 5248, 13, 51652], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 198, "seek": 64972, "start": 675.6800000000001, "end": 678.6800000000001, "text": " Tak, to jest jeden z najciekapszych rezultat\u00f3w.", "tokens": [51662, 9118, 11, 281, 3492, 12906, 710, 11212, 4260, 74, 2382, 28051, 48060, 723, 267, 3901, 13, 51812], "temperature": 0.0, "avg_logprob": -0.11974659185299928, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01604953594505787}, {"id": 199, "seek": 67868, "start": 678.8399999999999, "end": 682.0, "text": " Wynik skoczy\u0142 z 35 do 45-4.", "tokens": [50372, 343, 2534, 1035, 1110, 905, 1229, 1221, 710, 6976, 360, 6905, 12, 19, 13, 50530], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 200, "seek": 67868, "start": 682.1999999999999, "end": 685.1999999999999, "text": " Wow. To dowodzi, \u017ce w trakcie nienadzorowanego", "tokens": [50540, 3153, 13, 1407, 9459, 14543, 11, 3561, 261, 944, 74, 4260, 297, 1053, 345, 89, 284, 37345, 6308, 50690], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 201, "seek": 67868, "start": 685.4, "end": 690.92, "text": " pri treningu na ksi\u0105\u017ckach model nauczy\u0142 si\u0119 g\u0142\u0119bokiej wewn\u0119trznej intuicji j\u0119zykowej.", "tokens": [50700, 1790, 2192, 773, 84, 1667, 39311, 41326, 2316, 49103, 1229, 1221, 3244, 18117, 1274, 21666, 7764, 321, 895, 1274, 6903, 89, 11794, 560, 84, 299, 4013, 49055, 74, 21091, 13, 50976], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 202, "seek": 67868, "start": 691.12, "end": 694.0, "text": " Czego\u015b, co wykracza daleko poza proste statystyki.", "tokens": [50986, 383, 27725, 1788, 11, 598, 39287, 12080, 2394, 11702, 34241, 714, 2394, 10293, 68, 2219, 88, 25134, 2984, 13, 51130], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 203, "seek": 67868, "start": 694.1999999999999, "end": 696.8399999999999, "text": " On naprawd\u0119 poczu\u0142 struktur\u0119 j\u0119zyka.", "tokens": [51140, 1282, 20970, 26423, 84, 1221, 342, 31543, 1274, 42309, 40940, 13, 51272], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 204, "seek": 67868, "start": 697.04, "end": 702.0, "text": " Nawet na zadaniu tak no brudnym i specyficznym jak QQP, czyli wykrywanie", "tokens": [51282, 40315, 302, 1667, 42788, 25849, 991, 572, 738, 532, 12996, 741, 768, 1344, 1786, 89, 12996, 4207, 1249, 48, 47, 11, 16591, 39287, 47705, 7155, 51530], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 205, "seek": 67868, "start": 702.1999999999999, "end": 704.0799999999999, "text": " duplikat\u00f3w pyta\u0144 na platformie Quora.", "tokens": [51540, 1581, 564, 36300, 3901, 10664, 1328, 5248, 1667, 3663, 414, 2326, 3252, 13, 51634], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 206, "seek": 67868, "start": 704.28, "end": 706.76, "text": " Spodziewa\u0142am im si\u0119, \u017ce tam specjalistyczny model,", "tokens": [51644, 1738, 378, 89, 1093, 64, 20177, 566, 3244, 11, 3561, 7677, 46433, 468, 17466, 1634, 2316, 11, 51768], "temperature": 0.0, "avg_logprob": -0.16950350674715908, "compression_ratio": 1.4006514657980456, "no_speech_prob": 0.00395677424967289}, {"id": 207, "seek": 70676, "start": 706.8, "end": 710.04, "text": " nauczony na \u017cargonie u\u017cytkownik\u00f3w, b\u0119dzie mia\u0142 przewag\u0119.", "tokens": [50366, 49103, 44479, 1667, 19625, 289, 10660, 414, 344, 1427, 4328, 74, 44895, 3901, 11, 10562, 27989, 39758, 40748, 13, 50528], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 208, "seek": 70676, "start": 710.24, "end": 715.04, "text": " A jednak. I tam odnotowano popraw\u0105 o 4,2%.", "tokens": [50538, 316, 25897, 13, 286, 7677, 3611, 2247, 305, 3730, 1665, 5131, 1611, 277, 1017, 11, 17, 6856, 50778], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 209, "seek": 70676, "start": 715.24, "end": 720.4, "text": " To dowiod\u0142o, \u017ce ob\u00f3lna wiedza, kt\u00f3r\u0105 model posiad\u0142, jest autentycznie elastyczna.", "tokens": [50788, 1407, 9459, 2695, 5249, 11, 3561, 1111, 15741, 629, 46894, 2394, 11, 37415, 2316, 1366, 38069, 1221, 11, 3492, 1476, 4179, 19923, 806, 9820, 3689, 629, 13, 51046], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 210, "seek": 70676, "start": 720.6, "end": 723.08, "text": " I daje przewag\u0119 nawet w niszowych domenach?", "tokens": [51056, 286, 1120, 2884, 39758, 40748, 22696, 261, 297, 23848, 19605, 3285, 268, 608, 30, 51180], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 211, "seek": 70676, "start": 723.28, "end": 726.56, "text": " Tak. Te liczby to nie by\u0142y jakie\u015b drobne usprawnienia.", "tokens": [51190, 9118, 13, 1989, 6169, 89, 2322, 281, 2838, 26366, 31163, 3789, 65, 716, 505, 79, 29603, 18811, 13, 51354], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 212, "seek": 70676, "start": 726.76, "end": 730.12, "text": " To by\u0142 sygna\u0142, \u017ce w ca\u0142ej dziedzinie nast\u0119puje tektoniczna zmiana.", "tokens": [51364, 1407, 16673, 943, 70, 629, 1221, 11, 3561, 261, 47631, 73, 9758, 15338, 259, 414, 39662, 13008, 16624, 1756, 17946, 629, 17020, 8497, 13, 51532], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 213, "seek": 70676, "start": 730.3199999999999, "end": 733.04, "text": " Dobrze, czyli mieli te fenomenalne wyniki.", "tokens": [51542, 29679, 13503, 11, 16591, 41214, 535, 26830, 4726, 304, 716, 31936, 9850, 13, 51678], "temperature": 0.0, "avg_logprob": -0.12196475106316644, "compression_ratio": 1.4123711340206186, "no_speech_prob": 0.10327757894992828}, {"id": 214, "seek": 73304, "start": 733.28, "end": 738.0, "text": " Ale czy autorzy sami do ko\u0144ca rozumieli, dlaczego to zadzia\u0142a\u0142o a\u017c tak dobrze?", "tokens": [50376, 9366, 6430, 19510, 1229, 3247, 72, 360, 26470, 496, 48797, 23099, 11, 37873, 39329, 281, 42788, 89, 25605, 5249, 48134, 991, 28335, 30, 50612], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 215, "seek": 73304, "start": 738.1999999999999, "end": 741.7199999999999, "text": " Czy przeprowadzili jak\u0105\u015b, nie wiem, sekcj\u0119 zw\u0142ok tego modelu,", "tokens": [50622, 19832, 30829, 1892, 345, 89, 2312, 46719, 1788, 11, 2838, 26522, 11, 17215, 41960, 11873, 1221, 453, 8627, 2316, 84, 11, 50798], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 216, "seek": 73304, "start": 741.92, "end": 744.1999999999999, "text": " \u017ceby zobaczy\u0107, sk\u0105d bierze si\u0119 ta magia?", "tokens": [50808, 11316, 37273, 2162, 11, 1110, 18962, 272, 811, 1381, 3244, 1846, 2258, 654, 30, 50922], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 217, "seek": 73304, "start": 744.4, "end": 747.12, "text": " Oczywi\u015bcie. I ta cz\u0119\u015b\u0107 analityczna artyku\u0142u jest", "tokens": [50932, 42980, 13, 286, 1846, 47149, 364, 1860, 3689, 629, 594, 874, 5279, 24066, 3492, 51068], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 218, "seek": 73304, "start": 747.3199999999999, "end": 751.4399999999999, "text": " r\u00f3wnie fascynuj\u0105ca co same wyniki. To taka praca detektywistyczna.", "tokens": [51078, 11416, 14215, 30632, 1344, 77, 13263, 496, 598, 912, 31936, 9850, 13, 1407, 28017, 582, 6628, 1141, 916, 874, 86, 468, 17466, 629, 13, 51284], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 219, "seek": 73304, "start": 751.64, "end": 752.48, "text": " OK.", "tokens": [51294, 2264, 13, 51336], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 220, "seek": 73304, "start": 752.68, "end": 757.16, "text": " Pierwszy trop. Zbadali, jak na wynik ko\u0144cowy wp\u0142ywa liczba warstw", "tokens": [51346, 16676, 30012, 9006, 13, 1176, 27580, 5103, 11, 4207, 1667, 31936, 1035, 26470, 66, 10089, 32444, 6825, 4151, 6169, 89, 4231, 1516, 372, 86, 51570], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 221, "seek": 73304, "start": 757.36, "end": 760.48, "text": " transferowanych z modelu bazowego do zadania docelowego.", "tokens": [51580, 5003, 23341, 339, 710, 2316, 84, 27147, 26576, 360, 42788, 5609, 3211, 338, 26576, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13941512569304434, "compression_ratio": 1.4171974522292994, "no_speech_prob": 0.014957789331674576}, {"id": 222, "seek": 76048, "start": 760.52, "end": 765.16, "text": " Czyli sprawdzali, czy ca\u0142a wiedza jest np. w pierwszych warstwach, blisko", "tokens": [50366, 37099, 46192, 89, 5103, 11, 6430, 1335, 5024, 46894, 2394, 3492, 33808, 13, 261, 34016, 339, 1516, 372, 50038, 11, 888, 43442, 50598], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 223, "seek": 76048, "start": 765.36, "end": 768.2, "text": " embedding\u00f3w, a reszta to tylko dostrojenie?", "tokens": [50608, 12240, 3584, 3901, 11, 257, 725, 89, 1328, 281, 13219, 20568, 340, 15378, 414, 30, 50750], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 224, "seek": 76048, "start": 768.4, "end": 770.6800000000001, "text": " Dok\u0142adnie takie by\u0142o jedno z wcze\u015bniejszych przekona\u0144.", "tokens": [50760, 29768, 10358, 2766, 15963, 14811, 5232, 1771, 710, 40785, 45021, 29785, 4037, 5248, 13, 50874], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 225, "seek": 76048, "start": 770.88, "end": 772.88, "text": " Ale okaza\u0142o si\u0119, \u017ce jest zupe\u0142nie inaczej.", "tokens": [50884, 9366, 3133, 12257, 5249, 3244, 11, 3561, 3492, 49922, 33230, 16920, 13, 50984], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 226, "seek": 76048, "start": 773.08, "end": 775.4, "text": " A jak? Wyniki na testach takich jak", "tokens": [50994, 316, 4207, 30, 343, 2534, 9850, 1667, 1500, 608, 29607, 4207, 51110], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 227, "seek": 76048, "start": 775.6, "end": 781.28, "text": " Multien Li czy Race systematycznie ros\u0142y z ka\u017cd\u0105 kolejn\u0105 dodan\u0105 warstw\u0105.", "tokens": [51120, 14665, 1053, 8349, 6430, 25908, 1185, 267, 17466, 2766, 18953, 6825, 710, 21912, 67, 1611, 23749, 13113, 13886, 282, 1611, 1516, 372, 86, 1611, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 228, "seek": 76048, "start": 781.48, "end": 783.36, "text": " Z ka\u017cd\u0105 jedn\u0105? Tak.", "tokens": [51414, 1176, 21912, 67, 1611, 5232, 13113, 30, 9118, 13, 51508], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 229, "seek": 76048, "start": 783.5600000000001, "end": 787.6, "text": " To dowiod\u0142o, \u017ce wiedza jest rozproszona pod ca\u0142ej g\u0142\u0119bi sieci.", "tokens": [51518, 1407, 9459, 2695, 5249, 11, 3561, 46894, 2394, 3492, 9544, 1424, 329, 13383, 2497, 47631, 73, 18117, 1274, 5614, 2804, 537, 13, 51720], "temperature": 0.0, "avg_logprob": -0.15198301624607397, "compression_ratio": 1.4366666666666668, "no_speech_prob": 0.006868250202387571}, {"id": 230, "seek": 78760, "start": 787.8000000000001, "end": 793.0, "text": " Niszcze warstwy ucz\u0105 si\u0119 podstawowych cech sk\u0142adniowych, a wy\u017csze warstwy buduj\u0105 na tym", "tokens": [50374, 426, 23848, 9680, 1516, 372, 9726, 35403, 1611, 3244, 43443, 19605, 1769, 339, 1110, 10358, 3722, 19605, 11, 257, 4628, 1427, 82, 1381, 1516, 372, 9726, 3265, 13263, 1667, 8107, 50634], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 231, "seek": 78760, "start": 793.2, "end": 796.16, "text": " bardziej abstrakcyjne, semantyczne koncepty.", "tokens": [50644, 27209, 10823, 11272, 42949, 716, 11, 4361, 394, 17466, 716, 5897, 27493, 874, 13, 50792], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 232, "seek": 78760, "start": 796.36, "end": 798.6800000000001, "text": " Ka\u017cda warstwa wnosi\u0142a co\u015b cennego.", "tokens": [50802, 10988, 1427, 2675, 1516, 372, 4151, 261, 16751, 72, 5024, 19241, 27900, 11858, 13, 50918], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 233, "seek": 78760, "start": 798.88, "end": 803.0400000000001, "text": " To podwa\u017ca\u0142o ide\u0119, \u017ce wystarczy przenie\u015b\u0107 same embeddingi.", "tokens": [50928, 1407, 2497, 27111, 64, 5249, 1153, 1274, 11, 3561, 4628, 9710, 6522, 582, 16778, 7753, 912, 12240, 3584, 72, 13, 51136], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 234, "seek": 78760, "start": 803.24, "end": 808.8000000000001, "text": " Ale cz\u0119\u015b\u0107, kt\u00f3ra dla mnie jest najbardziej zdumiewaj\u0105ca, to te zdolno\u015bci zero shot.", "tokens": [51146, 9366, 47149, 11, 19456, 12285, 17661, 3492, 41857, 16221, 449, 1093, 11133, 496, 11, 281, 535, 16221, 401, 16438, 4018, 3347, 13, 51424], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 235, "seek": 78760, "start": 809.0, "end": 810.8000000000001, "text": " To brzmi jak co\u015b science fiction.", "tokens": [51434, 1407, 738, 89, 3057, 4207, 19241, 3497, 13266, 13, 51524], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 236, "seek": 78760, "start": 811.0, "end": 815.48, "text": " To by\u0142 moment, w kt\u00f3rym wielu badaczom musia\u0142y otworzy\u0107 si\u0119 oczy ze zdumienia.", "tokens": [51534, 1407, 16673, 1623, 11, 261, 30120, 40437, 1578, 14875, 298, 1038, 654, 6825, 4337, 28321, 27150, 3244, 277, 6522, 5277, 16221, 449, 18811, 13, 51758], "temperature": 0.0, "avg_logprob": -0.11996945118744101, "compression_ratio": 1.4721311475409835, "no_speech_prob": 0.003893568878993392}, {"id": 237, "seek": 81548, "start": 815.6800000000001, "end": 820.6800000000001, "text": " Sprawdzono, jak model radzi sobie z zadaniami jeszcze przed jakimkolwiek fine tuningiem.", "tokens": [50374, 1738, 15889, 89, 8957, 11, 4207, 2316, 2843, 3992, 13652, 710, 710, 11338, 15568, 14168, 18334, 49410, 36620, 44674, 2489, 15164, 4907, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 238, "seek": 81548, "start": 820.88, "end": 822.9200000000001, "text": " U\u017cywaj\u0105c bardzo prostych heurystyk.", "tokens": [50634, 624, 7735, 86, 38757, 9034, 10293, 16384, 415, 2598, 25134, 74, 13, 50736], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 239, "seek": 81548, "start": 823.12, "end": 826.2, "text": " Jakich? We\u017amy analiz\u0119 sentymentu.", "tokens": [50746, 15029, 480, 30, 492, 10659, 2226, 2624, 590, 1274, 2279, 88, 518, 84, 13, 50900], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 240, "seek": 81548, "start": 826.4, "end": 828.52, "text": " Do zdania, kt\u00f3re mieli oceni\u0107 np.", "tokens": [50910, 1144, 16221, 5609, 11, 8864, 41214, 10409, 268, 12757, 33808, 13, 51016], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 241, "seek": 81548, "start": 828.72, "end": 832.12, "text": " ten film by\u0142 wspania\u0142y, dodawali na ko\u0144cu s\u0142owo bardzo.", "tokens": [51026, 2064, 2007, 16673, 17757, 5609, 6825, 11, 13886, 1607, 5103, 1667, 26470, 12032, 15116, 19941, 9034, 13, 51196], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 242, "seek": 81548, "start": 832.32, "end": 834.6800000000001, "text": " OK. A nast\u0119pnie sprawdzali z jakim", "tokens": [51206, 2264, 13, 316, 39662, 2766, 46192, 89, 5103, 710, 49410, 51324], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 243, "seek": 81548, "start": 834.88, "end": 840.44, "text": " prawdopodobie\u0144stwem model doko\u0144czy te sekwencje s\u0142owem pozytywny w por\u00f3wnaniu do s\u0142owa negatywny.", "tokens": [51334, 41175, 46684, 996, 414, 12229, 86, 443, 2316, 360, 4093, 5248, 6522, 535, 17215, 15615, 44261, 15116, 305, 443, 49358, 874, 43682, 261, 1515, 812, 895, 25849, 360, 15116, 5528, 2485, 21398, 43682, 13, 51612], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 244, "seek": 81548, "start": 840.64, "end": 843.9200000000001, "text": " I co si\u0119 okaza\u0142o? Okaza\u0142o si\u0119, \u017ce im d\u0142u\u017cej trwa\u0142", "tokens": [51622, 286, 598, 3244, 3133, 12257, 5249, 30, 3477, 12257, 5249, 3244, 11, 3561, 566, 274, 24066, 38493, 504, 44603, 51786], "temperature": 0.0, "avg_logprob": -0.13272293911704533, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.09658476710319519}, {"id": 245, "seek": 84392, "start": 844.16, "end": 848.1999999999999, "text": " nienadzorowany pre-training, tym model by\u0142 w tym lepszy.", "tokens": [50376, 297, 1053, 345, 89, 284, 23341, 659, 12, 17227, 1760, 11, 8107, 2316, 16673, 261, 8107, 476, 1878, 1229, 13, 50578], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 246, "seek": 84392, "start": 848.4, "end": 852.4, "text": " Czyli sam proces nauki bycia dobrym modelem j\u0119zykowym.", "tokens": [50588, 37099, 3247, 17565, 35616, 2984, 538, 2755, 35884, 76, 4391, 10386, 49055, 74, 31691, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 247, "seek": 84392, "start": 852.5999999999999, "end": 859.16, "text": " Doprowadzi\u0142 do wykszta\u0142cenia si\u0119 umiej\u0119tno\u015bci klasyfikacji sentymentu jako produktu ubocznego.", "tokens": [50798, 42657, 1892, 345, 3992, 1221, 360, 4628, 1694, 89, 46426, 13037, 654, 3244, 1105, 7764, 46788, 16438, 9671, 5871, 31230, 13152, 2279, 88, 518, 84, 17123, 42816, 84, 26709, 905, 89, 11858, 13, 51126], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 248, "seek": 84392, "start": 859.36, "end": 861.5999999999999, "text": " To jest niesamowite. To jest w\u0142asno\u015b\u0107 emergentna.", "tokens": [51136, 1407, 3492, 48100, 335, 305, 642, 13, 1407, 3492, 43572, 23293, 4345, 6930, 629, 13, 51248], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 249, "seek": 84392, "start": 861.8, "end": 864.3199999999999, "text": " Nikt nie uczy\u0142 go analizy sentymentu.", "tokens": [51258, 426, 9874, 2838, 344, 6522, 1221, 352, 2624, 590, 88, 2279, 88, 518, 84, 13, 51384], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 250, "seek": 84392, "start": 864.52, "end": 866.92, "text": " To po prostu si\u0119 sta\u0142o.", "tokens": [51394, 1407, 714, 19518, 3244, 11135, 5249, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 251, "seek": 84392, "start": 867.12, "end": 869.56, "text": " Dok\u0142adnie. To musia\u0142 by\u0107 ekscytuj\u0105cy i mo\u017ce troch\u0119", "tokens": [51524, 29768, 10358, 2766, 13, 1407, 1038, 8908, 15069, 30724, 1344, 83, 13263, 1344, 741, 12034, 24926, 51646], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 252, "seek": 84392, "start": 869.76, "end": 871.48, "text": " niepokoj\u0105cy moment w laboratorium.", "tokens": [51656, 2838, 79, 13704, 8555, 1344, 1623, 261, 5938, 41679, 13, 51742], "temperature": 0.0, "avg_logprob": -0.13620585243173894, "compression_ratio": 1.508896797153025, "no_speech_prob": 0.003318359376862645}, {"id": 253, "seek": 87148, "start": 871.6, "end": 872.76, "text": " Zdecydowanie.", "tokens": [50370, 1176, 1479, 1344, 67, 22028, 13, 50428], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 254, "seek": 87148, "start": 872.96, "end": 878.52, "text": " Pokaza\u0142o to, \u017ce d\u0105\u017cenie do doskona\u0142o\u015bci w jednym bardzo og\u00f3lnym zadaniu j\u0119zykowym", "tokens": [50438, 14958, 12257, 5249, 281, 11, 3561, 274, 1611, 41118, 360, 4491, 74, 4037, 35059, 261, 5232, 12996, 9034, 5360, 15741, 12996, 42788, 25849, 49055, 74, 31691, 50716], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 255, "seek": 87148, "start": 878.72, "end": 884.2, "text": " niejako przy okazji uczy model rozwi\u0105zywania wielu innych problem\u00f3w.", "tokens": [50726, 2838, 73, 18501, 6501, 3133, 921, 4013, 344, 6522, 2316, 9544, 18234, 1229, 86, 5609, 40437, 36286, 1154, 3901, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 256, "seek": 87148, "start": 884.4, "end": 890.52, "text": " Ale \u017ceby ostatecznie udowodni\u0107, co by\u0142o kluczem do sukcesu, przeprowadzili tak zwane ablation studies.", "tokens": [51010, 9366, 11316, 277, 15406, 19923, 11727, 305, 378, 3722, 2162, 11, 598, 14811, 9671, 1311, 24313, 360, 46432, 887, 84, 11, 30829, 1892, 345, 89, 2312, 991, 11873, 1929, 410, 24278, 5313, 13, 51316], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 257, "seek": 87148, "start": 890.72, "end": 892.4, "text": " Czyli badania ablacyjne.", "tokens": [51326, 37099, 1578, 5609, 410, 75, 31285, 716, 13, 51410], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 258, "seek": 87148, "start": 892.6, "end": 897.9200000000001, "text": " Mieli swoich g\u0142\u00f3wnych podejrzanych o sukces pre-trainingi, architektur\u0119 transformer", "tokens": [51420, 376, 23099, 13291, 480, 18117, 812, 895, 16384, 7468, 73, 19390, 34644, 277, 46432, 887, 659, 12, 17227, 1760, 72, 11, 3912, 642, 2320, 374, 1274, 31782, 51686], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 259, "seek": 87148, "start": 898.12, "end": 900.72, "text": " i przeprowadzili eksperymenty, \u017ceby to potwierdzi\u0107.", "tokens": [51696, 741, 30829, 1892, 345, 89, 2312, 30724, 610, 88, 518, 88, 11, 11316, 281, 1847, 40717, 67, 28496, 13, 51826], "temperature": 0.0, "avg_logprob": -0.11982467405257687, "compression_ratio": 1.471947194719472, "no_speech_prob": 0.009930342435836792}, {"id": 260, "seek": 90072, "start": 900.9200000000001, "end": 902.1600000000001, "text": " Dok\u0142adnie tak.", "tokens": [50374, 29768, 10358, 2766, 991, 13, 50436], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 261, "seek": 90072, "start": 902.36, "end": 908.12, "text": " To jak usuwanie poszczeg\u00f3lnych element\u00f3w z dzia\u0142aj\u0105cej maszyny, \u017ceby zobaczy\u0107, co si\u0119 zepsuje.", "tokens": [50446, 1407, 4207, 32247, 86, 7155, 1366, 43771, 38079, 9399, 4478, 3901, 710, 27121, 11133, 20811, 2300, 1229, 1634, 11, 11316, 37273, 2162, 11, 598, 3244, 710, 10653, 13008, 13, 50734], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 262, "seek": 90072, "start": 908.32, "end": 909.48, "text": " I co si\u0119 zepsu\u0142o?", "tokens": [50744, 286, 598, 3244, 710, 10653, 84, 5249, 30, 50802], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 263, "seek": 90072, "start": 909.6800000000001, "end": 913.12, "text": " Najpierw wy\u0142\u0105czyli ca\u0142y etap pre-trainingu.", "tokens": [50812, 31576, 45119, 86, 4628, 15926, 6522, 2081, 35226, 47634, 659, 12, 17227, 1760, 84, 13, 50984], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 264, "seek": 90072, "start": 913.32, "end": 917.96, "text": " Trenowali model transformer od zera bezpo\u015brednio na zadaniach docelowych.", "tokens": [50994, 314, 1095, 305, 5103, 2316, 31782, 3611, 710, 1663, 10782, 2259, 1788, 986, 41084, 1667, 42788, 3782, 608, 3211, 338, 19605, 13, 51226], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 265, "seek": 90072, "start": 918.1600000000001, "end": 918.96, "text": " Efekt.", "tokens": [51236, 31840, 8192, 13, 51276], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 266, "seek": 90072, "start": 919.1600000000001, "end": 923.2, "text": " \u015aredni spadek skuteczno\u015bci o 14,8%.", "tokens": [51286, 27933, 986, 3722, 637, 762, 74, 1110, 1169, 3689, 16438, 277, 3499, 11, 23, 6856, 51488], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 267, "seek": 90072, "start": 923.4, "end": 925.76, "text": " 14,8% to przepa\u015b\u0107.", "tokens": [51498, 3499, 11, 23, 4, 281, 30829, 64, 7753, 13, 51616], "temperature": 0.0, "avg_logprob": -0.14851027150307933, "compression_ratio": 1.3052208835341366, "no_speech_prob": 0.0018821971025317907}, {"id": 268, "seek": 92576, "start": 925.84, "end": 932.2, "text": " To przepa\u015b\u0107, kt\u00f3ra pokazuje, jak absolutnie kluczowy by\u0142 ten pierwszy, nienadzorowany etap nauki.", "tokens": [50368, 1407, 30829, 64, 7753, 11, 19456, 13010, 43317, 11, 4207, 18757, 2766, 9671, 1311, 89, 10089, 16673, 2064, 34016, 11, 297, 1053, 345, 89, 284, 23341, 47634, 35616, 2984, 13, 50686], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 269, "seek": 92576, "start": 932.4, "end": 933.92, "text": " A co z wyborem architektury?", "tokens": [50696, 316, 598, 710, 45780, 37956, 3912, 642, 2320, 2598, 30, 50772], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 270, "seek": 92576, "start": 934.12, "end": 936.68, "text": " Mo\u017ce pre-training zadzia\u0142a\u0142by z ka\u017cdym modelem?", "tokens": [50782, 43774, 659, 12, 17227, 1760, 42788, 89, 25605, 34635, 710, 31615, 76, 4391, 10386, 30, 50910], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 271, "seek": 92576, "start": 936.88, "end": 938.3199999999999, "text": " To te\u017c sprawdzili.", "tokens": [50920, 1407, 9516, 46192, 89, 2312, 13, 50992], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 272, "seek": 92576, "start": 938.52, "end": 946.0, "text": " Zast\u0105pili transformera klasycznym modelem LSTM, ale zachowali ca\u0142y schemat pre-train i fine-tune.", "tokens": [51002, 1176, 525, 1611, 79, 2312, 31782, 64, 9671, 5871, 3689, 12996, 4391, 10386, 441, 6840, 44, 11, 6775, 29303, 305, 5103, 35226, 956, 8615, 659, 12, 83, 7146, 741, 2489, 12, 83, 2613, 13, 51376], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 273, "seek": 92576, "start": 946.2, "end": 946.88, "text": " I?", "tokens": [51386, 286, 30, 51420], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 274, "seek": 92576, "start": 947.08, "end": 950.92, "text": " Tym razem spadek \u015bredniej skuteczno\u015bci wyni\u00f3s\u0142 5-6%.", "tokens": [51430, 314, 4199, 40225, 637, 762, 74, 8299, 986, 10402, 1110, 1169, 3689, 16438, 31936, 7138, 82, 1221, 1025, 12, 21, 6856, 51622], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 275, "seek": 92576, "start": 951.12, "end": 952.04, "text": " Czyli te\u017c znacz\u0105cy?", "tokens": [51632, 37099, 9516, 15397, 326, 8925, 1344, 30, 51678], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 276, "seek": 92576, "start": 952.24, "end": 953.24, "text": " Znacz\u0105cy.", "tokens": [51688, 1176, 77, 326, 8925, 1344, 13, 51738], "temperature": 0.0, "avg_logprob": -0.13825881402224105, "compression_ratio": 1.3620689655172413, "no_speech_prob": 0.0017954614013433456}, {"id": 277, "seek": 95324, "start": 953.4, "end": 959.84, "text": " Model LSTM po prostu gorzej radzi\u0142 sobie z wykorzystaniem wiedzy zdobytej podczas pre-trainingu, co", "tokens": [50372, 17105, 441, 6840, 44, 714, 19518, 24012, 16920, 2843, 3992, 1221, 13652, 710, 43606, 1229, 18758, 4907, 46894, 1229, 16221, 13944, 975, 73, 2497, 30989, 659, 12, 17227, 1760, 84, 11, 598, 50694], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 278, "seek": 95324, "start": 960.04, "end": 966.16, "text": " potwierdzi\u0142o, \u017ce zdolno\u015b\u0107 transformera do pracy z d\u0142ugim kontekstem by\u0142a drugim filarem tego sukcesu.", "tokens": [50704, 1847, 40717, 67, 3992, 5249, 11, 3561, 16221, 401, 23293, 31782, 64, 360, 35591, 710, 274, 34077, 332, 14373, 916, 1099, 23936, 4110, 332, 1387, 19183, 8627, 46432, 887, 84, 13, 51010], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 279, "seek": 95324, "start": 966.36, "end": 970.04, "text": " Te dwa eksperymenty by\u0142y jak postawienie kropki nad i.", "tokens": [51020, 1989, 35045, 30724, 610, 88, 518, 88, 26366, 4207, 2183, 1607, 27385, 350, 1513, 2984, 12617, 741, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 280, "seek": 95324, "start": 970.24, "end": 971.36, "text": " Zdecydowanie.", "tokens": [51214, 1176, 1479, 1344, 67, 22028, 13, 51270], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 281, "seek": 95324, "start": 971.5600000000001, "end": 977.88, "text": " Podsumowuj\u0105c, ten artyku\u0142 nie by\u0142 tylko prezentacj\u0105 kolejnego troch\u0119 lepszego modelu.", "tokens": [51280, 12646, 82, 449, 305, 44733, 11, 2064, 594, 874, 5279, 1221, 2838, 16673, 13219, 659, 14185, 326, 8555, 23749, 11858, 24926, 476, 1878, 27725, 2316, 84, 13, 51596], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 282, "seek": 95324, "start": 978.08, "end": 983.12, "text": " On ustanowi\u0142 kompletnie nowy paradigma w przetwarzaniu j\u0119zyka naturalnego.", "tokens": [51606, 1282, 26189, 282, 24503, 1221, 5207, 14657, 2766, 586, 88, 13480, 16150, 261, 6541, 302, 31991, 25849, 42309, 40940, 3303, 11858, 13, 51858], "temperature": 0.0, "avg_logprob": -0.11915131383294227, "compression_ratio": 1.4527687296416938, "no_speech_prob": 0.003333283355459571}, {"id": 283, "seek": 98324, "start": 983.28, "end": 984.76, "text": " Pre-train fine-tune.", "tokens": [50366, 6001, 12, 83, 7146, 2489, 12, 83, 2613, 13, 50440], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 284, "seek": 98324, "start": 984.96, "end": 989.0, "text": " W\u0142a\u015bnie, zmieni\u0142 fundamentalne my\u015blenie w ca\u0142ej dziedzinie.", "tokens": [50450, 343, 5024, 12221, 11, 17020, 35462, 1221, 8088, 716, 48633, 6698, 414, 261, 47631, 73, 9758, 15338, 259, 414, 13, 50652], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 285, "seek": 98324, "start": 989.2, "end": 995.32, "text": " Tak, pokaza\u0142, \u017ce problem niedoboru danych etykietowanych mo\u017cna obej\u015b\u0107,", "tokens": [50662, 9118, 11, 13010, 12257, 1221, 11, 3561, 1154, 32488, 996, 32963, 274, 34644, 1030, 46127, 1684, 23341, 339, 17790, 36346, 44536, 11, 50968], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 286, "seek": 98324, "start": 995.52, "end": 999.72, "text": " je\u015bli tylko mamy wystarchaj\u0105c\u0105 du\u017co nieoznakowanego tekstu.", "tokens": [50978, 25630, 13219, 17335, 4628, 9710, 339, 11133, 32557, 26673, 2838, 78, 89, 16852, 37345, 6308, 16624, 372, 84, 13, 51188], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 287, "seek": 98324, "start": 999.92, "end": 1002.16, "text": " I odpowiedni\u0105 moc obliczeniow\u0105.", "tokens": [51198, 286, 36574, 3722, 1611, 34962, 1111, 1050, 42124, 30297, 13, 51310], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 288, "seek": 98324, "start": 1002.36, "end": 1004.24, "text": " Oczywi\u015bcie.", "tokens": [51320, 42980, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 289, "seek": 98324, "start": 1004.44, "end": 1008.92, "text": " To by\u0142 moment, w kt\u00f3rym gra przesta\u0142a polega\u0107 na sprytnym zbieraniu danych,", "tokens": [51424, 1407, 16673, 1623, 11, 261, 30120, 1295, 6541, 7841, 5024, 13208, 3680, 2162, 1667, 637, 627, 83, 12996, 710, 65, 811, 25849, 274, 34644, 11, 51648], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 290, "seek": 98324, "start": 1009.12, "end": 1013.08, "text": " a zacz\u0119\u0142a polega\u0107 na efektywnym skalowaniu modeli i oblicze\u0144.", "tokens": [51658, 257, 34430, 11052, 5024, 13208, 3680, 2162, 1667, 31482, 916, 874, 895, 4199, 16890, 305, 25849, 2316, 72, 741, 1111, 1050, 49689, 13, 51856], "temperature": 0.0, "avg_logprob": -0.12714767456054688, "compression_ratio": 1.4266211604095562, "no_speech_prob": 0.00607986468821764}, {"id": 291, "seek": 101324, "start": 1013.24, "end": 1015.44, "text": " I to otworzy\u0142o drzwi do wszystkiego, co widzimy dzisiaj.", "tokens": [50364, 286, 281, 4337, 28321, 1229, 5249, 1224, 89, 6253, 360, 14615, 12200, 11, 598, 27486, 13189, 25772, 13, 50474], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 292, "seek": 101324, "start": 1015.64, "end": 1022.04, "text": " Bez tej pracy i tej filozofii nie by\u0142oby GPT-2, GPT-3, hatacza GPT i ca\u0142ej tej rewolucji", "tokens": [50484, 879, 89, 12573, 35591, 741, 12573, 1387, 15151, 2670, 5597, 2838, 16673, 13944, 26039, 51, 12, 17, 11, 26039, 51, 12, 18, 11, 2385, 326, 2394, 26039, 51, 741, 47631, 73, 12573, 319, 48481, 1311, 4013, 50804], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 293, "seek": 101324, "start": 1022.24, "end": 1025.52, "text": " generatywnej AI. Autorzy dostarczyli przepis.", "tokens": [50814, 1337, 21398, 86, 11794, 7318, 13, 6049, 284, 1229, 20568, 289, 6522, 2081, 30829, 271, 13, 50978], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 294, "seek": 101324, "start": 1025.72, "end": 1030.32, "text": " Przepis, kt\u00f3ry ca\u0142a reszta \u015bwiata zacz\u0119\u0142a kopiowa\u0107, ulepsza\u0107 i skalowa\u0107 przez", "tokens": [50988, 2114, 46342, 271, 11, 9913, 1335, 5024, 725, 89, 1328, 21485, 3274, 34430, 11052, 5024, 28920, 72, 11445, 11, 344, 306, 1878, 35873, 741, 16890, 11445, 14064, 51218], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 295, "seek": 101324, "start": 1030.52, "end": 1033.1200000000001, "text": " nast\u0119pne lata. To by\u0142 prawdziwy punkt zwrotny.", "tokens": [51228, 39662, 716, 46722, 13, 1407, 16673, 41175, 3992, 9726, 39561, 49111, 310, 1634, 13, 51358], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 296, "seek": 101324, "start": 1033.32, "end": 1038.88, "text": " Moment, w kt\u00f3rym dziedzina NLP obra\u0142a mowy kurs, z kt\u00f3rego nie zawr\u00f3ci\u0142a do dzi\u015b.", "tokens": [51368, 19093, 11, 261, 30120, 9758, 15338, 1426, 426, 45196, 22798, 5024, 275, 10089, 350, 2156, 11, 710, 46951, 2838, 28165, 11721, 537, 5024, 360, 31981, 1788, 13, 51646], "temperature": 0.0, "avg_logprob": -0.13182998958386874, "compression_ratio": 1.428082191780822, "no_speech_prob": 0.0038154753856360912}, {"id": 297, "seek": 103888, "start": 1038.88, "end": 1043.44, "text": " I to prowadzi nas do ostatniej my\u015bli, tego\u015b do przemy\u015blenia.", "tokens": [50364, 286, 281, 36590, 3992, 5382, 360, 32686, 10402, 452, 15350, 11, 8627, 1788, 360, 6541, 3633, 1788, 6698, 654, 13, 50592], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 298, "seek": 103888, "start": 1043.64, "end": 1049.2800000000002, "text": " Autorzy wykazali, \u017ce model, ucz\u0105c si\u0119 jedynie przewidywa\u0107 kolejne s\u0142owo w tek\u015bcie,", "tokens": [50602, 6049, 284, 1229, 39287, 921, 5103, 11, 3561, 2316, 11, 35403, 1611, 66, 3244, 5232, 2534, 414, 39758, 38836, 25234, 23749, 716, 15116, 19941, 261, 16624, 9815, 11, 50884], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 299, "seek": 103888, "start": 1049.48, "end": 1052.5600000000002, "text": " nabywa zdumiewaj\u0105co szerok\u0105 wiedz\u0119 o \u015bwiecie.", "tokens": [50894, 297, 2509, 4151, 16221, 449, 1093, 11133, 1291, 36160, 453, 1611, 46894, 11052, 277, 40078, 4260, 13, 51048], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 300, "seek": 103888, "start": 1052.7600000000002, "end": 1054.16, "text": " I zdolno\u015b\u0107 do rozumowania.", "tokens": [51058, 286, 16221, 401, 23293, 360, 48797, 21308, 13, 51128], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 301, "seek": 103888, "start": 1054.3600000000001, "end": 1056.5200000000002, "text": " I to rodzi fundamentalne pytanie.", "tokens": [51138, 286, 281, 8685, 3992, 8088, 716, 36610, 13, 51246], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 302, "seek": 103888, "start": 1056.72, "end": 1059.44, "text": " Jakie s\u0105 ostateczne granice tego podej\u015bcia?", "tokens": [51256, 15029, 414, 9015, 277, 15406, 38491, 9370, 573, 8627, 7468, 73, 1788, 2755, 30, 51392], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 303, "seek": 103888, "start": 1059.64, "end": 1062.0, "text": " To jest pytanie, z kt\u00f3rym mierzymy si\u0119 do dzi\u015b.", "tokens": [51402, 1407, 3492, 36610, 11, 710, 30120, 47448, 1229, 2226, 3244, 360, 31981, 1788, 13, 51520], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 304, "seek": 103888, "start": 1062.2, "end": 1067.5600000000002, "text": " Gdyby\u015bmy mieli model, kt\u00f3ry by\u0142by w stanie idealnie przewidzie\u0107 nast\u0119pny token", "tokens": [51530, 460, 3173, 2322, 10513, 41214, 2316, 11, 9913, 16673, 2322, 261, 40013, 7157, 2766, 39758, 327, 21214, 39662, 1634, 14862, 51798], "temperature": 0.0, "avg_logprob": -0.12473452821069834, "compression_ratio": 1.4966442953020134, "no_speech_prob": 0.009768457151949406}, {"id": 305, "seek": 106756, "start": 1067.56, "end": 1070.32, "text": " w dowolnej mo\u017cliwej sekwencji tekstowej.", "tokens": [50364, 261, 9459, 401, 11794, 30854, 826, 73, 17215, 15615, 19649, 16624, 372, 21091, 13, 50502], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 306, "seek": 106756, "start": 1070.52, "end": 1074.9199999999998, "text": " Czy to by\u0142oby to\u017csame z prawdziwym, ludzkim rozumieniem i \u015bwiadomo\u015bci\u0105?", "tokens": [50512, 19832, 281, 16673, 13944, 281, 1427, 82, 529, 710, 41175, 3992, 86, 4199, 11, 15946, 89, 25112, 48797, 1053, 4907, 741, 21485, 40633, 50227, 30, 50732], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 307, "seek": 106756, "start": 1075.12, "end": 1080.0, "text": " Czy te\u017c jest tam jaka\u015b fundamentalna r\u00f3\u017cnica, jaka\u015b, nie wiem, iskra,", "tokens": [50742, 19832, 9516, 3492, 7677, 4207, 64, 1788, 8088, 629, 19637, 32687, 11, 4207, 64, 1788, 11, 2838, 26522, 11, 307, 42913, 11, 50986], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 308, "seek": 106756, "start": 1080.2, "end": 1084.8, "text": " kt\u00f3rej samo statystyczne przewidywanie, nawet doprowadzone do perfekcji,", "tokens": [50996, 36023, 36422, 2219, 38593, 17466, 716, 39758, 327, 27112, 7155, 11, 22696, 360, 35019, 16896, 360, 13826, 916, 19649, 11, 51226], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 309, "seek": 106756, "start": 1085.0, "end": 1087.24, "text": " nigdy nie b\u0119dzie w stanie przeskoczy\u0107.", "tokens": [51236, 26996, 3173, 2838, 10562, 261, 40013, 6541, 279, 74, 905, 27150, 13, 51348], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 310, "seek": 106756, "start": 1087.44, "end": 1092.48, "text": " A to chyba zmusza nas te\u017c do zrewidowania naszej w\u0142asnej definicji i rozumienia,", "tokens": [51358, 316, 281, 31532, 17020, 301, 2394, 5382, 9516, 360, 710, 2236, 327, 21308, 42946, 43572, 11794, 1561, 299, 4013, 741, 48797, 18811, 11, 51610], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 311, "seek": 106756, "start": 1092.6799999999998, "end": 1097.3999999999999, "text": " je\u015bli system, kt\u00f3ry tylko przewiduje, daje odpowiedzi nieodr\u00f3\u017cnialne od systemu,", "tokens": [51620, 25630, 1185, 11, 9913, 13219, 39758, 327, 13008, 11, 1120, 2884, 36574, 3992, 2838, 378, 11721, 1427, 77, 831, 716, 3611, 1185, 84, 11, 51856], "temperature": 0.0, "avg_logprob": -0.13749477017310358, "compression_ratio": 1.5354838709677419, "no_speech_prob": 0.009396796114742756}, {"id": 312, "seek": 109756, "start": 1097.6, "end": 1103.28, "text": " kt\u00f3ry rozumie, to w kt\u00f3rym momencie ta r\u00f3\u017cnica przestaje mie\u0107 praktyczne znaczenie.", "tokens": [50366, 9913, 48797, 414, 11, 281, 261, 30120, 40883, 1846, 19637, 32687, 44264, 11153, 35612, 3206, 74, 874, 38491, 15397, 326, 16778, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1870743648425953, "compression_ratio": 1.1121495327102804, "no_speech_prob": 0.007688627112656832}, {"id": 313, "seek": 109756, "start": 1103.48, "end": 1106.48, "text": " To pytanie zostawiamy otwarte.", "tokens": [50660, 1407, 36610, 31873, 1607, 2918, 88, 4337, 86, 11026, 13, 50810], "temperature": 0.0, "avg_logprob": -0.1870743648425953, "compression_ratio": 1.1121495327102804, "no_speech_prob": 0.007688627112656832}], "language": "pl"}