{"text": " W \u015bwiecie sztucznej inteligencji mamy do czynienia z tak\u0105 przedziwn\u0105 sytuacj\u0105. Z jednej strony s\u0105 te gigantyczne modele j\u0119zykowe jak GPT-3, kt\u00f3re kompletnie zmieni\u0142y zasady gry. Prawdziwe rewolucja. Dok\u0142adnie. Potrafi\u0105 pisa\u0107, programowa\u0107, ale z drugiej strony dla naukowc\u00f3w, kt\u00f3rzy chcieliby zrozumie\u0107, jak one dzia\u0142aj\u0105, s\u0105 jak fortece. Zamkni\u0119te niedost\u0119pne czarne skrzynki. A koszt ich stworzenia jest astronomiczny. I w\u0142a\u015bnie w ten kraj obraz wchodzi praca naukowa od Meta AI, kt\u00f3ra mam wra\u017cenie postanowi\u0142a wywa\u017cy\u0107 drzwi do tej fortecy. Tak. I to jest w\u0142a\u015bnie klucz. Tytu\u0142 to OPT, Open Pretrained Transformer Language Models. I im nie chodzi\u0142o tylko o to, \u017ceby pokaza\u0107, hej, my te\u017c potrafimy zbudowa\u0107 wielki model. Chodzi\u0142o o co\u015b znacznie, znacznie g\u0142\u0119bszego. O co? Orzucenie wyzwania ca\u0142ej filozofii tych zamkni\u0119tych bada\u0144 i postawienie pytania. Czy nauka naprawd\u0119 mo\u017ce rozwija\u0107 si\u0119 w tajemnice? OK, czyli naszym celem jest zajrzenie do \u015brodka. Zobaczymy, czym jest ten model OPT. Dlaczego jego otwarcie by\u0142o tak wa\u017cne i jak faktycznie wypada w por\u00f3wnaniu z GPT-3? Ale nie b\u0119dziemy patrze\u0107 tylko na suche wyniki. Przyjrzymy si\u0119 zapiskom z niezwyk\u0142e trudnego treningu. Tym wszystkim zaskakuj\u0105cym zdolno\u015bciom i co wa\u017cne, brutalnie szczerym przyznaniu si\u0119 tw\u00f3rc\u00f3w do jego VAT. Dok\u0142adnie. Chcemy zrozumie\u0107, co ta praca naprawd\u0119 zmieni\u0142a. Bo to nie jest tylko historia o technologii, ale te\u017c o kulturze bada\u0144 w AI. No dobrze, to zacznijmy od podstaw. Kiedy m\u00f3wimy, \u017ce meta AI chcia\u0142a rzuci\u0107 wyzwanie temu statusowi, co to konkretnie znaczy? Po prostu zbudowali klona GPT-3 i udost\u0119pnili go za darmo. No w\u0142a\u015bnie nie do ko\u0144ca, bo wegl\u0105da to tak jakby wydali miliony dolar\u00f3w tylko po to, \u017ceby co\u015b komu\u015b udowodni\u0107. Wiesz, to znacznie wi\u0119cej ni\u017c tylko udowadnianie. To pr\u00f3ba zmiany ca\u0142ego paradygmatu badawczego. Ca\u0142ego paradygmatu? Tak, stworzyli ca\u0142\u0105 rodzin\u0119 modeli od takich malutkich 125 milionowych a\u017c po giganta maj\u0105cego 175 miliard\u00f3w parametr\u00f3w. Czyli dok\u0142adnie tyle, co GPT-3? Dok\u0142adnie tak. Architektura jest celowo bardzo podobna, ale misj\u0105 nie by\u0142o samo zbudowanie modelu. Misj\u0105 by\u0142o jego uwolnienie. Uwolnienie, czyli co ka\u017cdy m\u00f3g\u0142 sobie go po prostu pobra\u0107? Dok\u0142adnie tak. Udost\u0119pnili nie tylko sam model, ale przede wszystkim pe\u0142ny dost\u0119p do jego wn\u0119trzno\u015bci, czyli wag. Wcze\u015bniej, je\u015bli naukowiec chcia\u0142 bada\u0107 GPT-3, m\u00f3g\u0142 jedynie korzysta\u0107 z komercyjnego API. To troch\u0119 tak, jakby mechanik samochodowy m\u00f3g\u0142 diagnozowa\u0107 silnik. S\u0142uchaj\u0105c go tylko przez zamkni\u0119t\u0105 mask\u0119. Tak, analizuj\u0105c spaliny. M\u00f3g\u0142 zadawa\u0107 pytania, dostawa\u0142 odpowiedzi, ale nie mia\u0142 poj\u0119cia, co dzieje si\u0119 w \u015brodku. A OPT to tak jakby dali ka\u017cdemu klucze do warsztatu i pozwolili rozkr\u0119ci\u0107 ten silnik na cz\u0119\u015bci pierwsze. To jest idealna analogia. Nagle badacze mogli zobaczy\u0107, jak informacja przep\u0142ywa przez sie\u0107, kt\u00f3re neurony si\u0119 aktywuj\u0105, gdzie kryj\u0105 si\u0119 uprzedzenia. I dlaczego model pope\u0142nia b\u0142\u0119dy? W\u0142a\u015bnie. To zmieni\u0142o wszystko. Zamiast by\u0107 tylko u\u017cytkownikami, stali si\u0119 badaczami. To by\u0142a prawdziwa demokratyzacja bada\u0144 na DI, na wielk\u0105 skal\u0119. To, co mnie uderzy\u0142o w tej pracy, to co\u015b, czego prawie nigdy nie widzi si\u0119 w publikacjach naukowych. Taka, wiesz, niezwyk\u0142a, niemal bolesna szczero\u015b\u0107. Szczero\u015b\u0107 na temat tego, co posz\u0142o nie tak. Tak, zazwyczaj czytamy histori\u0119 sukcesu, a tutaj dostali\u015bmy szczeg\u00f3\u0142owy dziennik z pola bitwy. A to jest prawdopodobnie jedna z najcenniejszych cz\u0119\u015bci tej publikacji. Nazwali to logbook, czyli dziennik pok\u0142adowy. A co w nim jest? To bezcenny zapis dla ka\u017cdego, kto pr\u00f3buje trenowa\u0107 modele na tak\u0105 skal\u0119. Dowiadujemy si\u0119 z niego o brutalnej rzeczywisto\u015bci, np. o awariach sprz\u0119tu. A\u017c tak? W ci\u0105gu zaledwie dw\u00f3ch miesi\u0119cy treningu tego najwi\u0119kszego modelu OPTI 75B musieli ponad 35 razy r\u0119cznie restartowa\u0107 ca\u0142y proces. 35 razy? Tak. I wymienili ponad 100 serwer\u00f3w, kt\u00f3re po prostu si\u0119 zepsu\u0142y pod obci\u0105\u017ceniem. Fila, czyli to nie wygl\u0105da\u0142o tak, \u017ce wcisn\u0119li guzik start, poszli na kaw\u0119 i wr\u00f3cili po dw\u00f3ch miesi\u0105cach po gotowy model? Absolutno nie. To by\u0142a ci\u0105g\u0142a walka z maszyn\u0105, ci\u0105g\u0142e gaszenie po\u017car\u00f3w. Niesamowite. A to prowadzi do jeszcze ciekawszego problemu, kt\u00f3re opisali. Tak zwane loss divergences. Co to takiego? Wyobra\u017amy sobie, \u017ce trening modelu to takie powolne schodzenie w d\u00f3\u0142 do liny, gdzie na dnie jest optymalne rozwi\u0105zanie. Loss Divergence to sytuacja, w kt\u00f3rej model nagle, bez ostrze\u017cenia, zamiast schodzi\u0107. Zaczyna si\u0119 wspina\u0107. Gorzej. Teleportuje si\u0119 na szczyt pobliskiej g\u00f3ry i zaczyna generowa\u0107 kompletne bzdury. Wanto\u015b\u0107 funkcji strate, kt\u00f3ra powinna male\u0107, po prostu eksplodowa\u0142a. I co wtedy? Ca\u0142a praca namarny? Musia\u0142y dzia\u0142a\u0107 r\u0119cznie, zatrzyma\u0107 wszystko, wr\u00f3ci\u0107 do ostatniego zapisanego punktu kontrolnego, czasem sprzed wielu godzin i spr\u00f3bowa\u0107 ponownie, ale z innymi ustawieniami. Jakimi ustawieniami? Najcz\u0119\u015bciej zmniejszali tak zwane Learning Rate. OK, a czym jest ten Learning Rate? To paramet, kt\u00f3ry kontroluje, jak du\u017ce kroki stawia model podczas nauki. Zbyt du\u017cy Learning Rate jest jak pr\u00f3ba zej\u015bcia z g\u00f3ry wielkimi skokami. \u0141atwo straci\u0107 r\u00f3wnowag\u0119. I spa\u015b\u0107. Musieli wi\u0119c zmniejszy\u0107 d\u0142ugo\u015b\u0107 kroku i kaza\u0107 mu i\u015b\u0107 ostro\u017cniej. Ten logbook pokazuje, \u017ce trening wielkiego modelu to nie jest czysta in\u017cynieria. To bardziej sztuka i ci\u0105g\u0142a improwizacja. Czyli to mniej przypomina\u0142o opieczenie ciasta wed\u0142ug idealnego przepisu, a bardziej pr\u00f3b\u0119 utrzymania na ziemi eksperymentalnej rakiety, kt\u00f3ra w ka\u017cdej chwili grozi wybuchem. Doskonale powiedziane. Ka\u017cdy restart, ka\u017cda korekta, to by\u0142 realny problem, stracony czas i pieni\u0105dze. Zdecydowanie. I jest jeszcze jeden aspekt tej transparentno\u015bci, o kt\u00f3rym trzeba wspomnie\u0107. \u015alad w\u0119glowy to gor\u0105cy temat w AI. No tak. Tw\u00f3rcy OPT oszacowali, \u017ce wytrenowanie ich najwi\u0119kszego modelu poch\u0142on\u0119\u0142o oko\u0142o 75 ton ekwiwalentu CO2. 75 ton, a dla por\u00f3wnania GPT-3. W tej samej pracy przytaczaj\u0105 szacunki dla GPT-3, kt\u00f3re m\u00f3wi\u0142y o ponad 500 tonach. 500? To jest niemal siedmiokrotna r\u00f3\u017cnica. Ogromna. Ale chwila. Czy te liczwy s\u0105 w og\u00f3le por\u00f3wnywalne? Czy my wiemy, jak OpenAI liczy\u0142o sw\u00f3j \u015blad w\u0119glowy, a jak zrobi\u0142a to meta? I to jest \u015bwietne pytanie, kt\u00f3re pokazuje, dlaczego otwarto\u015b\u0107 jest tak wa\u017cna. Szacunki dla GPT-3 s\u0105 w\u0142a\u015bnie tym szacunkami zewn\u0119trznych badaczy. Bo OpenAI nigdy nie opublikowa\u0142o oficjalnych danych. Dok\u0142adnie. Meta Natoniast poda\u0142a swoj\u0105 metodologi\u0119. U\u017cyli bardziej energooszcz\u0119dnych procesor\u00f3w graficznych, zoptymalizowali proces. Nawet je\u015bli jest tu pewien margines b\u0142\u0119du. To pokazali, \u017ce da si\u0119 to zrobi\u0107 znacznie wydajniej. I podzielili si\u0119 wiedz\u0105, jak to osi\u0105gn\u0119li. Zn\u00f3w. Chodzi o transparentno\u015b\u0107. OK, mamy wi\u0119c model, kt\u00f3ry powsta\u0142 w bardziej otwarty, transparentny i oszcz\u0119dny spos\u00f3b. Ale przejd\u017amy do sedna. Czy jest r\u00f3wnie dobry? Jak OPT wypada w bezpo\u015brednim starciu z legendarnym GPT-3? No i tu dochodzimy do najbardziej fascynuj\u0105cej cz\u0119\u015bci. Przetestowali go na szesnastu standardowych benchmark\u00f3w NLP. Jakie to by\u0142y testy? Sprawdzali go w dw\u00f3ch trybach. Pierwszy to zero shot. Dajesz modelowi zadanie, kt\u00f3rego nigdy wcze\u015bniej nie widzia\u0142 i oczekujesz poprawnej odpowiedzi bez \u017cadnych przyk\u0142ad\u00f3w. Czyli taki sprawdzian z zaskoczenia. A drugi tryb? Drugi to Fuse Shot, gdzie dajesz mu dos\u0142ownie kilka przyk\u0142ad\u00f3w, \u017ceby go naprowadzi\u0107 na to, o co ci chodzi. Rozumiem i jak wysz\u0142o. W obu tych scenariuszach wyniki by\u0142y uderzaj\u0105co podobne. Wykresy w pracy pokazuj\u0105, \u017ce krzywe wydajno\u015bci dla OPT i GPT-3 id\u0105 niemal web w web wraz ze wzrostem skali. Czyli wniosek jest prosty. Tak. W og\u00f3lnym rozrachunku OPT zbudowano za \u0142amek kosztu w\u0119glowego dor\u00f3wnuje wydajno\u015bci\u0105 GPT-3. A czy by\u0142y jakie\u015b obszary, w kt\u00f3rych OPT szczeg\u00f3lnie zaskoczy\u0142, gdzie pokaza\u0142 co\u015b nieoczekiwanego? By\u0142y dwa takie obszary i to bardzo wymowne. Pierwszy to dialog. OPT 175B, kt\u00f3ry by\u0142 trenowany w spos\u00f3b unsupervised. Fila, co to znaczy unsupervised? To znaczy, \u017ce nikt go nie nadzorowa\u0142, nie uczy\u0142 konkretnych zada\u0144. Po prostu karmiono go gigantyczn\u0105 ilo\u015bci\u0105 surowego tekstu z internetu i pozwolono mu samodzielnie odkrywa\u0107 wzorce w j\u0119zyku. OK. I ten model, nietrenowany do bycia chatbotem, w niekt\u00f3rych testach radzi\u0142 sobie r\u00f3wnie dobrze, a czasem nawet lepiej, czasem nawet lepiej ni\u017c modele takie jak Blenderbot, kt\u00f3re przesz\u0142y specjalistyczny trening, tak zwany fine tuning, \u017ceby dobrze prowadzi\u0107 konwersacje. Czyli zdolno\u015b\u0107 do prowadzenia dialogu po prostu si\u0119 w nim pojawi\u0142a. Dok\u0142adnie. To jest w\u0142a\u015bnie to, co naukowcy nazywaj\u0105 emergent abilities. Wy\u0142aniaj\u0105ce si\u0119 zdolno\u015bci zdolno\u015bci, kt\u00f3rych nikt nie programowa\u0142, a kt\u00f3re pojawiaj\u0105 si\u0119 spontanicznie, gdy model osi\u0105ga odpowiednio du\u017c\u0105 skal\u0119 i z\u0142o\u017cono\u015b\u0107. To pokazuje, jak pot\u0119\u017cne s\u0105 te architektury. Niesamowite. A ten drugi zaskakuj\u0105cy obszar wspomnia\u0142a\u015b o dw\u00f3ch. Drugi jest jeszcze bardziej fascynuj\u0105cy i dotyczy toksyczno\u015bci, a czyli mroczna strona AI. I tu mamy do czynienia z prawdziwym paradoksem. Zbi\u00f3r danych, na kt\u00f3rym trenowano OPTI, by\u0142 mniej filtrowany ni\u017c ten u\u017cyty dla GP3. Zawiera\u0142 wi\u0119cej surowych, nieoczyszczonych tre\u015bci z internetu. Na przyk\u0142ad serwisu Reddit. OK, czyli wi\u0119cej tego, co w internecie najgorszy. Mo\u017cna tak powiedzie\u0107. I co si\u0119 okaza\u0142o? W testach polegaj\u0105cych na wykrywaniu mowy nienawi\u015bci OPTI by\u0142 od GPT3 lepszy. Jak to? Mo\u017cliwe. Bo po prostu widzia\u0142 wi\u0119cej tego typu tre\u015bci. Nauczy\u0142 si\u0119 rozpoznawa\u0107 toksyczny j\u0119zyk, bo mia\u0142 z nim wi\u0119cej do czynienia podczas treningu. To troch\u0119 jak z lekarzem, kt\u00f3ry lepiej diagnozuje rzadk\u0105 chorob\u0119, bo widzia\u0142 w swojej karierze wi\u0119cej jej przypadk\u00f3w. Dok\u0142adnie tak. To brzmi jak dobra wiadomo\u015b\u0107, ale czuj\u0119, \u017ce jest tu jakie\u015b ale. A to pot\u0119\u017cne. Jest te\u017c druga strona medalu. Z tego samego powodu przez te same brudne dane treningowe OPTI jest r\u00f3wnie\u017c bardziej sk\u0142onny do generowania toksycznych tre\u015bci. A, czyli nie tylko je rozpoznaje, ale i tworzy. I po wiele stereotypy. To jest fundamentalny dylemat. Niefiltrowane dane daj\u0105 modelowi g\u0142\u0119bsze, bardziej realistyczne zrozumienie j\u0119zyka, ale jednocze\u015bnie ucz\u0105 go t\u0119 mroczne wzorce na\u015bladowa\u0107. Mamy wi\u0119c pot\u0119\u017cny, otwarty, ale i potencjalnie niebezpieczny model. Czy autorzy pr\u00f3buj\u0105 to jako\u015b, no wiesz, zamie\u015b\u0107 pod dywan? Wr\u0119cz przeciwnie i to jest kolejny dow\u00f3d na ich odpowiedzialne podej\u015bcie. Ca\u0142y rozdzia\u0142 pracy po\u015bwi\u0119cili na um\u00f3wienie znanych im ogranicze\u0144. I co tam wymieniaj\u0105? Wymieniaj\u0105 je z rozbrajaj\u0105c\u0105 szczero\u015bci\u0105. Po pierwsze model ma problem z wykonywaniem prostych polece\u0144. Co to znaczy? Prosisz go o co\u015b, a on odmawia? Gorzej. Zawezd wykona\u0107 instrukcj\u0119, cz\u0119sto zaczyna symurowa\u0107 rozmow\u0119 o tej instrukcji. Dziwne. Prosisz go o podsumowanie tekstu, a on generuje dialog, w kt\u00f3rym jedna posta\u0107 prosi drug\u0105 o podsumowanie tego tekstu. Niesamowite. Jakie\u015b inne problemy. Tak, ma tendencj\u0119 do powtarzania si\u0119, wpadania w p\u0119tl\u0119. Generuje te same frazy w k\u00f3\u0142ko. Oczywi\u015bcie potrafi te\u017c generowa\u0107 kompletnie fa\u0142szywe informacje, co znamy jako halucynacj\u0119. Ale najwa\u017cniejsze jest zdanie, kt\u00f3re wie\u0144czy czytno zdzia\u0142. Jakie? Warto je zacytowa\u0107 niemal dos\u0142ownie. Autorzy stwierdzaj\u0105, \u017ce w ich ocenie technologia ta jest przedwczesna do wdro\u017ce\u0144 w produktach komercyjnych z powodu ryzyka zwi\u0105zanego z bezpiecze\u0144stwem. To jest bardzo mocne o\u015bwiadczenie. W bran\u017cy, kt\u00f3ra p\u0119dzi, by jak najszybciej monetyzowa\u0107 ka\u017cdy nowy model, oni m\u00f3wi\u0105 wprost. Nasze dzie\u0142o nie jest jeszcze na to gotowe. To jest akt niezwyk\u0142ej odpowiedzialno\u015bci. Zamiast ukrywa\u0107 wady, wystawili je na widok publiczny, daj\u0105c innym badaczom narz\u0119dzie i jednocze\u015bnie ostrzegaj\u0105c ich przed potencjalnymi zagro\u017ceniami. Podsumujmy wi\u0119c. Mamy otwarty, pot\u0119\u017cny, wydajny, ale jednocze\u015bnie niedoskona\u0142y i momentami toksyczny model. Jaki jest wi\u0119c ostateczny wniosek z tej pracy? Co ona tak naprawd\u0119 zmieni\u0142a? Zmieni\u0142a rozmow\u0119. Publikacja OLPT to co\u015b znacznie wi\u0119cej ni\u017c prezentacja kolejnego modelu. To by\u0142 manifest. Manifest na temat czego? Na temat tego, jak powinny wygl\u0105da\u0107 badania nad AI. Meta pokaza\u0142a, \u017ce priorytetem nie musi by\u0107 budowanie najwi\u0119kszych, najbardziej zamkni\u0119tych system\u00f3w. Zamiast tego? Zamiast tego mo\u017cna skupi\u0107 si\u0119 na tworzeniu narz\u0119dzi, kt\u00f3re pozwol\u0105 ca\u0142ej spo\u0142eczno\u015bci naukowej wsp\u00f3lnie zrozumie\u0107, jak te pot\u0119\u017cne technologie dzia\u0142aj\u0105, jakie nios\u0105 ze sob\u0105 ryzyka i jak mo\u017cna je w przysz\u0142o\u015bci ulepszy\u0107. Czyli OLPT nie jest celem samym w sobie, a raczej pot\u0119\u017cnym mikroskopem, kt\u00f3ry zosta\u0142 podarowany ca\u0142ej spo\u0142eczno\u015bci naukowej. Dok\u0142adnie. Mikroskopem do badania fenomenu wielkich modeli j\u0119zykowych. To narz\u0119dzie do wsp\u00f3lnego badania odpowiedzialnej sztucznej inteligencji. Tak, to \u015bwietne podsumowanie. Przesun\u0119\u0142o akcent z wy\u015bcigu na wsp\u00f3\u0142prac\u0119. Na koniec chcia\u0142bym podrzuci\u0107 my\u015bl, kt\u00f3ra zosta\u0142a ze mn\u0105 po lekturze tej pracy. Jasno z niej wynika, \u017ce niefiltrowane, brudne dane z internetu da\u0142y modelowi jednocze\u015bnie co\u015b dobrego, zdolno\u015b\u0107 do rozpoznawania toksyczno\u015bci i co\u015b z\u0142ego, sk\u0142onno\u015b\u0107 do jej generowania. To jest sedno problemu. I to prowadzi do fundamentalnego pytania, kt\u00f3re ta praca przed nami stawia. Czy w og\u00f3le da si\u0119 stworzy\u0107 model AI, kt\u00f3ry b\u0119dzie w pe\u0142ni rozumia\u0142 ludzki j\u0119zyk z ca\u0142ym jego bogactwem i mrocznymi zakamarkami, ale jednocze\u015bnie nie o dziedziczy naszych najgorszych cech? Dobre pytanie. A mo\u017ce jedyna droga do bezpiecznej AI prowadzi przez stworzenie sterylnych modeli, trenowanych tylko na wyselekcjonowanych czy z tych danych? Ale wtedy? By\u0142yby mo\u017ce bezpieczniejsze, ale jednocze\u015bnie odci\u0119te od rzeczywisto\u015bci. Mniej \u015bwiadome \u015bwiata, w kt\u00f3rym maj\u0105 funkcjonowa\u0107, \u017cy\u0142yby w sztucznej, wyidealizowanej ba\u0144ce. I pytanie brzmi, co wtedy tracimy?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.24, "text": " W \u015bwiecie sztucznej inteligencji mamy do czynienia z tak\u0105 przedziwn\u0105 sytuacj\u0105.", "tokens": [50364, 343, 40078, 4260, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 17335, 360, 6430, 77, 18811, 710, 31069, 18334, 3992, 895, 1611, 28275, 326, 8555, 13, 50676], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 1, "seek": 0, "start": 7.44, "end": 12.76, "text": " Z jednej strony s\u0105 te gigantyczne modele j\u0119zykowe jak GPT-3, kt\u00f3re", "tokens": [50736, 1176, 5232, 11794, 32406, 9015, 535, 8741, 394, 17466, 716, 4391, 306, 49055, 74, 6880, 4207, 26039, 51, 12, 18, 11, 8864, 51002], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 2, "seek": 0, "start": 12.96, "end": 14.96, "text": " kompletnie zmieni\u0142y zasady gry.", "tokens": [51012, 5207, 14657, 2766, 17020, 35462, 6825, 26530, 880, 41974, 13, 51112], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 3, "seek": 0, "start": 15.16, "end": 16.32, "text": " Prawdziwe rewolucja.", "tokens": [51122, 430, 15889, 3992, 826, 319, 48481, 1311, 2938, 13, 51180], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 4, "seek": 0, "start": 16.52, "end": 22.84, "text": " Dok\u0142adnie. Potrafi\u0105 pisa\u0107, programowa\u0107, ale z drugiej strony dla naukowc\u00f3w,", "tokens": [51190, 29768, 10358, 2766, 13, 9145, 10437, 11404, 280, 3837, 2162, 11, 1461, 11445, 11, 6775, 710, 47373, 32406, 12285, 35616, 74, 305, 29268, 11, 51506], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 5, "seek": 0, "start": 23.04, "end": 27.48, "text": " kt\u00f3rzy chcieliby zrozumie\u0107, jak one dzia\u0142aj\u0105, s\u0105 jak fortece.", "tokens": [51516, 25382, 417, 537, 338, 897, 88, 710, 27857, 449, 414, 2162, 11, 4207, 472, 27121, 11133, 11, 9015, 4207, 23235, 384, 13, 51738], "temperature": 0.0, "avg_logprob": -0.16037392804003137, "compression_ratio": 1.3667953667953667, "no_speech_prob": 0.020086616277694702}, {"id": 6, "seek": 2748, "start": 27.6, "end": 30.72, "text": " Zamkni\u0119te niedost\u0119pne czarne skrzynki.", "tokens": [50370, 45492, 74, 35938, 975, 32488, 555, 18085, 716, 6472, 289, 716, 1110, 13047, 77, 2984, 13, 50526], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 7, "seek": 2748, "start": 30.92, "end": 33.56, "text": " A koszt ich stworzenia jest astronomiczny.", "tokens": [50536, 316, 19532, 2682, 1893, 342, 28321, 14320, 3492, 26302, 17946, 1634, 13, 50668], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 8, "seek": 2748, "start": 33.76, "end": 37.88, "text": " I w\u0142a\u015bnie w ten kraj obraz wchodzi praca naukowa od Meta AI,", "tokens": [50678, 286, 14234, 261, 2064, 28248, 73, 22798, 89, 261, 34616, 582, 6628, 35616, 74, 5528, 3611, 6377, 64, 7318, 11, 50884], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 9, "seek": 2748, "start": 38.08, "end": 42.32, "text": " kt\u00f3ra mam wra\u017cenie postanowi\u0142a wywa\u017cy\u0107 drzwi do tej fortecy.", "tokens": [50894, 19456, 13524, 7843, 41118, 2183, 282, 24503, 5024, 4628, 4151, 39687, 1224, 89, 6253, 360, 12573, 23235, 1344, 13, 51106], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 10, "seek": 2748, "start": 42.52, "end": 44.72, "text": " Tak. I to jest w\u0142a\u015bnie klucz.", "tokens": [51116, 9118, 13, 286, 281, 3492, 14234, 9671, 1311, 89, 13, 51226], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 11, "seek": 2748, "start": 44.92, "end": 49.44, "text": " Tytu\u0142 to OPT, Open Pretrained Transformer Language Models.", "tokens": [51236, 314, 4328, 84, 1221, 281, 23324, 51, 11, 7238, 9739, 31774, 27938, 260, 24445, 6583, 1625, 13, 51462], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 12, "seek": 2748, "start": 49.64, "end": 54.64, "text": " I im nie chodzi\u0142o tylko o to, \u017ceby pokaza\u0107, hej, my te\u017c potrafimy zbudowa\u0107 wielki model.", "tokens": [51472, 286, 566, 2838, 23998, 5249, 13219, 277, 281, 11, 11316, 13010, 12257, 2162, 11, 415, 73, 11, 452, 9516, 1847, 10437, 13189, 710, 18281, 11445, 20570, 2984, 2316, 13, 51722], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 13, "seek": 2748, "start": 54.84, "end": 57.36, "text": " Chodzi\u0142o o co\u015b znacznie, znacznie g\u0142\u0119bszego.", "tokens": [51732, 761, 14543, 5249, 277, 19241, 15397, 14875, 2766, 11, 15397, 14875, 2766, 18117, 1274, 929, 27725, 13, 51858], "temperature": 0.0, "avg_logprob": -0.15782872582696805, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0596543624997139}, {"id": 14, "seek": 5748, "start": 57.519999999999996, "end": 58.0, "text": " O co?", "tokens": [50366, 422, 598, 30, 50390], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 15, "seek": 5748, "start": 58.199999999999996, "end": 64.16, "text": " Orzucenie wyzwania ca\u0142ej filozofii tych zamkni\u0119tych bada\u0144 i postawienie pytania.", "tokens": [50400, 422, 19390, 1311, 268, 414, 4628, 14406, 5609, 47631, 73, 1387, 15151, 2670, 5597, 15180, 19876, 74, 35938, 874, 339, 272, 1538, 5248, 741, 2183, 1607, 27385, 25878, 5609, 13, 50698], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 16, "seek": 5748, "start": 64.36, "end": 68.16, "text": " Czy nauka naprawd\u0119 mo\u017ce rozwija\u0107 si\u0119 w tajemnice?", "tokens": [50708, 19832, 35616, 2330, 20970, 12034, 9544, 86, 20642, 2162, 3244, 261, 256, 1805, 443, 77, 573, 30, 50898], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 17, "seek": 5748, "start": 68.36, "end": 71.64, "text": " OK, czyli naszym celem jest zajrzenie do \u015brodka.", "tokens": [50908, 2264, 11, 16591, 48094, 1769, 10386, 3492, 33729, 81, 16778, 360, 28580, 2330, 13, 51072], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 18, "seek": 5748, "start": 71.84, "end": 74.47999999999999, "text": " Zobaczymy, czym jest ten model OPT.", "tokens": [51082, 1176, 996, 14691, 2226, 11, 31466, 3492, 2064, 2316, 23324, 51, 13, 51214], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 19, "seek": 5748, "start": 74.67999999999999, "end": 81.24, "text": " Dlaczego jego otwarcie by\u0142o tak wa\u017cne i jak faktycznie wypada w por\u00f3wnaniu z GPT-3?", "tokens": [51224, 413, 75, 39329, 26542, 4337, 6925, 4260, 14811, 991, 46110, 741, 4207, 33647, 45586, 46392, 1538, 261, 1515, 812, 895, 25849, 710, 26039, 51, 12, 18, 30, 51552], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 20, "seek": 5748, "start": 81.44, "end": 83.8, "text": " Ale nie b\u0119dziemy patrze\u0107 tylko na suche wyniki.", "tokens": [51562, 9366, 2838, 31966, 1947, 13503, 2162, 13219, 1667, 1270, 68, 31936, 9850, 13, 51680], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 21, "seek": 5748, "start": 84.0, "end": 87.24, "text": " Przyjrzymy si\u0119 zapiskom z niezwyk\u0142e trudnego treningu.", "tokens": [51690, 39590, 73, 13047, 2226, 3244, 14223, 7797, 298, 710, 33511, 9726, 74, 19827, 32007, 11858, 2192, 773, 84, 13, 51852], "temperature": 0.0, "avg_logprob": -0.15205105301601435, "compression_ratio": 1.3778501628664495, "no_speech_prob": 0.0011395865585654974}, {"id": 22, "seek": 8724, "start": 87.44, "end": 94.91999999999999, "text": " Tym wszystkim zaskakuj\u0105cym zdolno\u015bciom i co wa\u017cne, brutalnie szczerym przyznaniu si\u0119 tw\u00f3rc\u00f3w do jego VAT.", "tokens": [50374, 314, 4199, 30481, 710, 3863, 514, 13263, 1344, 76, 16221, 401, 16438, 298, 741, 598, 46110, 11, 17878, 2766, 22090, 2109, 76, 6501, 22672, 25849, 3244, 683, 15614, 29268, 360, 26542, 691, 2218, 13, 50748], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 23, "seek": 8724, "start": 95.11999999999999, "end": 95.91999999999999, "text": " Dok\u0142adnie.", "tokens": [50758, 29768, 10358, 2766, 13, 50798], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 24, "seek": 8724, "start": 96.11999999999999, "end": 99.03999999999999, "text": " Chcemy zrozumie\u0107, co ta praca naprawd\u0119 zmieni\u0142a.", "tokens": [50808, 761, 384, 2226, 710, 27857, 449, 414, 2162, 11, 598, 1846, 582, 6628, 20970, 17020, 35462, 5024, 13, 50954], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 25, "seek": 8724, "start": 99.24, "end": 103.6, "text": " Bo to nie jest tylko historia o technologii, ale te\u017c o kulturze bada\u0144 w AI.", "tokens": [50964, 3286, 281, 2838, 3492, 13219, 18385, 277, 1537, 1132, 5597, 11, 6775, 9516, 277, 350, 26099, 1381, 272, 1538, 5248, 261, 7318, 13, 51182], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 26, "seek": 8724, "start": 103.8, "end": 106.28, "text": " No dobrze, to zacznijmy od podstaw.", "tokens": [51192, 883, 28335, 11, 281, 710, 14875, 77, 1718, 2226, 3611, 43443, 13, 51316], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 27, "seek": 8724, "start": 106.47999999999999, "end": 113.03999999999999, "text": " Kiedy m\u00f3wimy, \u017ce meta AI chcia\u0142a rzuci\u0107 wyzwanie temu statusowi, co to konkretnie znaczy?", "tokens": [51326, 591, 16446, 13489, 13189, 11, 3561, 19616, 7318, 26497, 5024, 367, 11728, 39162, 4628, 14406, 7155, 33346, 6558, 24503, 11, 598, 281, 36500, 2766, 36584, 30, 51654], "temperature": 0.0, "avg_logprob": -0.14814445262646858, "compression_ratio": 1.3391608391608392, "no_speech_prob": 0.001250831293873489}, {"id": 28, "seek": 11304, "start": 113.24000000000001, "end": 117.84, "text": " Po prostu zbudowali klona GPT-3 i udost\u0119pnili go za darmo.", "tokens": [50374, 6165, 19518, 710, 18281, 305, 5103, 9671, 4037, 26039, 51, 12, 18, 741, 11727, 555, 18085, 77, 2312, 352, 7949, 4072, 3280, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 29, "seek": 11304, "start": 118.04, "end": 121.32000000000001, "text": " No w\u0142a\u015bnie nie do ko\u0144ca, bo wegl\u0105da to tak jakby", "tokens": [50614, 883, 14234, 2838, 360, 26470, 496, 11, 748, 321, 7191, 26398, 281, 991, 28976, 50778], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 30, "seek": 11304, "start": 121.52000000000001, "end": 125.36000000000001, "text": " wydali miliony dolar\u00f3w tylko po to, \u017ceby co\u015b komu\u015b udowodni\u0107.", "tokens": [50788, 25984, 5103, 1962, 46184, 360, 2200, 3901, 13219, 714, 281, 11, 11316, 19241, 5207, 84, 1788, 11727, 305, 378, 3722, 2162, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 31, "seek": 11304, "start": 125.56, "end": 128.64000000000001, "text": " Wiesz, to znacznie wi\u0119cej ni\u017c tylko udowadnianie.", "tokens": [50990, 343, 15347, 11, 281, 15397, 14875, 2766, 26004, 28502, 13219, 11727, 22647, 77, 952, 414, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 32, "seek": 11304, "start": 128.84, "end": 131.36, "text": " To pr\u00f3ba zmiany ca\u0142ego paradygmatu badawczego.", "tokens": [51154, 1407, 8565, 4231, 43591, 88, 35224, 6308, 13480, 18103, 15677, 84, 272, 1538, 86, 3689, 6308, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 33, "seek": 11304, "start": 131.56, "end": 132.72, "text": " Ca\u0142ego paradygmatu?", "tokens": [51290, 7544, 1221, 6308, 13480, 18103, 15677, 84, 30, 51348], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 34, "seek": 11304, "start": 132.92000000000002, "end": 142.64000000000001, "text": " Tak, stworzyli ca\u0142\u0105 rodzin\u0119 modeli od takich malutkich 125 milionowych a\u017c po giganta maj\u0105cego 175 miliard\u00f3w parametr\u00f3w.", "tokens": [51358, 9118, 11, 342, 28321, 1229, 2081, 1335, 15926, 8685, 23584, 1274, 2316, 72, 3611, 29607, 2806, 325, 48349, 25276, 1962, 313, 19605, 48134, 714, 8741, 5983, 26064, 384, 1571, 41165, 1962, 72, 515, 3901, 6220, 27965, 3901, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1417001129744889, "compression_ratio": 1.431438127090301, "no_speech_prob": 0.0682351291179657}, {"id": 35, "seek": 14264, "start": 142.76, "end": 145.0, "text": " Czyli dok\u0142adnie tyle, co GPT-3?", "tokens": [50370, 37099, 45864, 2766, 39293, 11, 598, 26039, 51, 12, 18, 30, 50482], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 36, "seek": 14264, "start": 145.2, "end": 146.07999999999998, "text": " Dok\u0142adnie tak.", "tokens": [50492, 29768, 10358, 2766, 991, 13, 50536], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 37, "seek": 14264, "start": 146.27999999999997, "end": 151.64, "text": " Architektura jest celowo bardzo podobna, ale misj\u0105 nie by\u0142o samo zbudowanie modelu.", "tokens": [50546, 10984, 642, 2320, 2991, 3492, 9277, 19941, 9034, 43024, 629, 11, 6775, 3346, 8555, 2838, 14811, 36422, 710, 18281, 22028, 2316, 84, 13, 50814], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 38, "seek": 14264, "start": 151.83999999999997, "end": 154.64, "text": " Misj\u0105 by\u0142o jego uwolnienie.", "tokens": [50824, 23240, 8555, 14811, 26542, 23147, 14110, 27385, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 39, "seek": 14264, "start": 154.83999999999997, "end": 158.35999999999999, "text": " Uwolnienie, czyli co ka\u017cdy m\u00f3g\u0142 sobie go po prostu pobra\u0107?", "tokens": [50974, 624, 86, 14110, 27385, 11, 16591, 598, 31615, 275, 14047, 1221, 13652, 352, 714, 19518, 714, 6198, 2162, 30, 51150], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 40, "seek": 14264, "start": 158.55999999999997, "end": 159.79999999999998, "text": " Dok\u0142adnie tak.", "tokens": [51160, 29768, 10358, 2766, 991, 13, 51222], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 41, "seek": 14264, "start": 160.0, "end": 164.23999999999998, "text": " Udost\u0119pnili nie tylko sam model, ale przede wszystkim pe\u0142ny dost\u0119p do jego", "tokens": [51232, 624, 67, 555, 18085, 77, 2312, 2838, 13219, 3247, 2316, 11, 6775, 44786, 30481, 43205, 1634, 48209, 360, 26542, 51444], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 42, "seek": 14264, "start": 164.44, "end": 166.67999999999998, "text": " wn\u0119trzno\u015bci, czyli wag.", "tokens": [51454, 45368, 1274, 6903, 89, 16438, 11, 16591, 36854, 13, 51566], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 43, "seek": 14264, "start": 166.88, "end": 169.92, "text": " Wcze\u015bniej, je\u015bli naukowiec chcia\u0142 bada\u0107 GPT-3,", "tokens": [51576, 343, 9680, 37511, 11, 25630, 35616, 74, 13998, 66, 26497, 1221, 272, 1538, 2162, 26039, 51, 12, 18, 11, 51728], "temperature": 0.0, "avg_logprob": -0.15392230213552283, "compression_ratio": 1.474074074074074, "no_speech_prob": 0.007893350906670094}, {"id": 44, "seek": 16992, "start": 170.11999999999998, "end": 173.04, "text": " m\u00f3g\u0142 jedynie korzysta\u0107 z komercyjnego API.", "tokens": [50374, 275, 14047, 1221, 5232, 2534, 414, 14784, 49590, 2162, 710, 5207, 260, 42949, 11858, 9362, 13, 50520], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 45, "seek": 16992, "start": 173.23999999999998, "end": 177.07999999999998, "text": " To troch\u0119 tak, jakby mechanik samochodowy m\u00f3g\u0142 diagnozowa\u0107 silnik.", "tokens": [50530, 1407, 24926, 991, 11, 28976, 4236, 1035, 3247, 8997, 378, 10089, 275, 14047, 1221, 1026, 559, 1771, 89, 11445, 3425, 13123, 13, 50722], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 46, "seek": 16992, "start": 177.28, "end": 179.95999999999998, "text": " S\u0142uchaj\u0105c go tylko przez zamkni\u0119t\u0105 mask\u0119.", "tokens": [50732, 318, 1221, 625, 38757, 352, 13219, 14064, 19876, 74, 35938, 83, 1611, 6094, 1274, 13, 50866], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 47, "seek": 16992, "start": 180.16, "end": 182.48, "text": " Tak, analizuj\u0105c spaliny.", "tokens": [50876, 9118, 11, 2624, 590, 44733, 637, 304, 3519, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 48, "seek": 16992, "start": 182.67999999999998, "end": 189.23999999999998, "text": " M\u00f3g\u0142 zadawa\u0107 pytania, dostawa\u0142 odpowiedzi, ale nie mia\u0142 poj\u0119cia, co dzieje si\u0119 w \u015brodku.", "tokens": [51002, 376, 14047, 1221, 710, 1538, 25234, 25878, 5609, 11, 20568, 10449, 1221, 36574, 3992, 11, 6775, 2838, 27989, 714, 11115, 2755, 11, 598, 17953, 2884, 3244, 261, 28580, 5279, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 49, "seek": 16992, "start": 189.44, "end": 196.23999999999998, "text": " A OPT to tak jakby dali ka\u017cdemu klucze do warsztatu i pozwolili rozkr\u0119ci\u0107 ten silnik na cz\u0119\u015bci pierwsze.", "tokens": [51340, 316, 23324, 51, 281, 991, 28976, 274, 5103, 21912, 10730, 84, 9671, 1311, 1381, 360, 13718, 2682, 20546, 741, 40557, 401, 2312, 9544, 38553, 1274, 39162, 2064, 3425, 13123, 1667, 41314, 45994, 13, 51680], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 50, "seek": 16992, "start": 196.44, "end": 198.6, "text": " To jest idealna analogia.", "tokens": [51690, 1407, 3492, 7157, 629, 16660, 654, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1203928380399137, "compression_ratio": 1.4305084745762713, "no_speech_prob": 0.051655467599630356}, {"id": 51, "seek": 19860, "start": 198.79999999999998, "end": 203.04, "text": " Nagle badacze mogli zobaczy\u0107, jak informacja przep\u0142ywa przez sie\u0107,", "tokens": [50374, 426, 15088, 1578, 326, 1381, 13172, 2081, 37273, 2162, 11, 4207, 1356, 23395, 30829, 6825, 4151, 14064, 2804, 2162, 11, 50586], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 52, "seek": 19860, "start": 203.23999999999998, "end": 207.88, "text": " kt\u00f3re neurony si\u0119 aktywuj\u0105, gdzie kryj\u0105 si\u0119 uprzedzenia.", "tokens": [50596, 8864, 12087, 2526, 3244, 9308, 874, 86, 13263, 11, 18922, 34847, 8555, 3244, 493, 81, 11312, 14320, 13, 50828], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 53, "seek": 19860, "start": 208.07999999999998, "end": 209.79999999999998, "text": " I dlaczego model pope\u0142nia b\u0142\u0119dy?", "tokens": [50838, 286, 37873, 39329, 2316, 42248, 1221, 12679, 272, 46564, 3173, 30, 50924], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 54, "seek": 19860, "start": 210.0, "end": 211.04, "text": " W\u0142a\u015bnie.", "tokens": [50934, 343, 5024, 12221, 13, 50986], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 55, "seek": 19860, "start": 211.24, "end": 212.76, "text": " To zmieni\u0142o wszystko.", "tokens": [50996, 1407, 17020, 35462, 5249, 22607, 13, 51072], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 56, "seek": 19860, "start": 212.95999999999998, "end": 216.68, "text": " Zamiast by\u0107 tylko u\u017cytkownikami, stali si\u0119 badaczami.", "tokens": [51082, 1176, 4526, 525, 15069, 13219, 344, 1427, 4328, 74, 44895, 4526, 11, 342, 5103, 3244, 1578, 14875, 4526, 13, 51268], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 57, "seek": 19860, "start": 216.88, "end": 221.88, "text": " To by\u0142a prawdziwa demokratyzacja bada\u0144 na DI, na wielk\u0105 skal\u0119.", "tokens": [51278, 1407, 23936, 41175, 3992, 4151, 49432, 37433, 23395, 272, 1538, 5248, 1667, 11953, 11, 1667, 20570, 26304, 16890, 1274, 13, 51528], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 58, "seek": 19860, "start": 222.07999999999998, "end": 225.48, "text": " To, co mnie uderzy\u0142o w tej pracy, to co\u015b, czego prawie nigdy nie widzi si\u0119 w", "tokens": [51538, 1407, 11, 598, 17661, 344, 1068, 1229, 5249, 261, 12573, 35591, 11, 281, 19241, 11, 36559, 3206, 8699, 26996, 3173, 2838, 5274, 3992, 3244, 261, 51708], "temperature": 0.0, "avg_logprob": -0.11781155471260665, "compression_ratio": 1.4412811387900355, "no_speech_prob": 0.005467678885906935}, {"id": 59, "seek": 22548, "start": 225.48, "end": 230.16, "text": " publikacjach naukowych. Taka, wiesz, niezwyk\u0142a, niemal bolesna szczero\u015b\u0107.", "tokens": [50364, 11227, 1035, 326, 45059, 35616, 74, 19605, 13, 314, 7849, 11, 261, 15347, 11, 33511, 9726, 74, 5024, 11, 2838, 5579, 272, 7456, 629, 22090, 2032, 7753, 13, 50598], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 60, "seek": 22548, "start": 230.35999999999999, "end": 232.88, "text": " Szczero\u015b\u0107 na temat tego, co posz\u0142o nie tak.", "tokens": [50608, 24699, 3689, 2032, 7753, 1667, 32954, 8627, 11, 598, 1366, 89, 5249, 2838, 991, 13, 50734], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 61, "seek": 22548, "start": 233.07999999999998, "end": 238.72, "text": " Tak, zazwyczaj czytamy histori\u0119 sukcesu, a tutaj dostali\u015bmy szczeg\u00f3\u0142owy dziennik z pola bitwy.", "tokens": [50744, 9118, 11, 710, 921, 9726, 3689, 1805, 6430, 83, 7804, 4058, 5034, 46432, 887, 84, 11, 257, 12749, 20568, 33955, 22090, 1146, 16181, 10089, 9758, 1053, 13123, 710, 1180, 64, 857, 9726, 13, 51026], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 62, "seek": 22548, "start": 238.92, "end": 243.44, "text": " A to jest prawdopodobnie jedna z najcenniejszych cz\u0119\u015bci tej publikacji.", "tokens": [51036, 316, 281, 3492, 41175, 46684, 996, 2766, 5232, 629, 710, 11212, 66, 1857, 7764, 45021, 41314, 12573, 11227, 1035, 13152, 13, 51262], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 63, "seek": 22548, "start": 243.64, "end": 247.0, "text": " Nazwali to logbook, czyli dziennik pok\u0142adowy.", "tokens": [51272, 11870, 40054, 281, 3565, 2939, 11, 16591, 9758, 1053, 13123, 13010, 10358, 10089, 13, 51440], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 64, "seek": 22548, "start": 247.2, "end": 248.44, "text": " A co w nim jest?", "tokens": [51450, 316, 598, 261, 24887, 3492, 30, 51512], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 65, "seek": 22548, "start": 248.64, "end": 253.64, "text": " To bezcenny zapis dla ka\u017cdego, kto pr\u00f3buje trenowa\u0107 modele na tak\u0105 skal\u0119.", "tokens": [51522, 1407, 10782, 13037, 1634, 14223, 271, 12285, 21912, 67, 6308, 11, 23780, 8565, 6021, 2884, 23136, 11445, 4391, 306, 1667, 31069, 16890, 1274, 13, 51772], "temperature": 0.0, "avg_logprob": -0.12491761954726686, "compression_ratio": 1.4633333333333334, "no_speech_prob": 0.18116138875484467}, {"id": 66, "seek": 25364, "start": 253.83999999999997, "end": 260.47999999999996, "text": " Dowiadujemy si\u0119 z niego o brutalnej rzeczywisto\u015bci, np. o awariach sprz\u0119tu.", "tokens": [50374, 20947, 38069, 21767, 3244, 710, 49615, 277, 17878, 11794, 26297, 86, 9334, 6199, 11, 33808, 13, 277, 1714, 3504, 608, 6103, 11052, 9179, 13, 50706], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 67, "seek": 25364, "start": 260.68, "end": 261.28, "text": " A\u017c tak?", "tokens": [50716, 316, 1427, 991, 30, 50746], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 68, "seek": 25364, "start": 261.47999999999996, "end": 263.24, "text": " W ci\u0105gu zaledwie dw\u00f3ch miesi\u0119cy", "tokens": [50756, 343, 42398, 2794, 710, 5573, 8699, 27379, 812, 339, 41543, 47303, 50844], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 69, "seek": 25364, "start": 263.44, "end": 272.84, "text": " treningu tego najwi\u0119kszego modelu OPTI 75B musieli ponad 35 razy r\u0119cznie restartowa\u0107 ca\u0142y proces.", "tokens": [50854, 2192, 773, 84, 8627, 48636, 1694, 27725, 2316, 84, 23324, 5422, 9562, 33, 1038, 23099, 9224, 345, 6976, 9639, 88, 41197, 19923, 21022, 11445, 35226, 17565, 13, 51324], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 70, "seek": 25364, "start": 273.03999999999996, "end": 274.0, "text": " 35 razy?", "tokens": [51334, 6976, 9639, 88, 30, 51382], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 71, "seek": 25364, "start": 274.2, "end": 279.0, "text": " Tak. I wymienili ponad 100 serwer\u00f3w, kt\u00f3re po prostu si\u0119 zepsu\u0142y pod obci\u0105\u017ceniem.", "tokens": [51392, 9118, 13, 286, 29764, 1053, 2312, 9224, 345, 2319, 816, 1554, 3901, 11, 8864, 714, 19518, 3244, 710, 10653, 84, 6825, 2497, 1111, 34381, 24930, 4907, 13, 51632], "temperature": 0.0, "avg_logprob": -0.19739218015928525, "compression_ratio": 1.2943548387096775, "no_speech_prob": 0.021453462541103363}, {"id": 72, "seek": 27900, "start": 279.08, "end": 282.36, "text": " Fila, czyli to nie wygl\u0105da\u0142o tak, \u017ce wcisn\u0119li guzik start,", "tokens": [50368, 479, 7371, 11, 16591, 281, 2838, 32015, 5249, 991, 11, 3561, 261, 26720, 77, 1274, 2081, 695, 89, 1035, 722, 11, 50532], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 73, "seek": 27900, "start": 282.56, "end": 285.32, "text": " poszli na kaw\u0119 i wr\u00f3cili po dw\u00f3ch miesi\u0105cach po gotowy model?", "tokens": [50542, 1366, 89, 2081, 1667, 350, 1607, 1274, 741, 928, 40993, 2312, 714, 27379, 812, 339, 41543, 11404, 66, 608, 714, 658, 10089, 2316, 30, 50680], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 74, "seek": 27900, "start": 285.52, "end": 290.04, "text": " Absolutno nie. To by\u0142a ci\u0105g\u0142a walka z maszyn\u0105, ci\u0105g\u0142e gaszenie po\u017car\u00f3w.", "tokens": [50690, 5813, 2308, 1771, 2838, 13, 1407, 23936, 42398, 70, 5024, 1792, 64, 710, 2300, 1229, 13113, 11, 42398, 70, 19827, 4211, 16778, 714, 1427, 289, 3901, 13, 50916], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 75, "seek": 27900, "start": 290.24, "end": 290.92, "text": " Niesamowite.", "tokens": [50926, 426, 530, 335, 305, 642, 13, 50960], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 76, "seek": 27900, "start": 291.12, "end": 294.92, "text": " A to prowadzi do jeszcze ciekawszego problemu, kt\u00f3re opisali.", "tokens": [50970, 316, 281, 36590, 3992, 360, 14168, 46419, 1607, 15453, 6308, 1154, 84, 11, 8864, 45477, 5103, 13, 51160], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 77, "seek": 27900, "start": 295.12, "end": 297.88, "text": " Tak zwane loss divergences.", "tokens": [51170, 9118, 11873, 1929, 4470, 18558, 1766, 887, 13, 51308], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 78, "seek": 27900, "start": 298.08, "end": 298.8, "text": " Co to takiego?", "tokens": [51318, 3066, 281, 32296, 30, 51354], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 79, "seek": 27900, "start": 299.0, "end": 306.36, "text": " Wyobra\u017amy sobie, \u017ce trening modelu to takie powolne schodzenie w d\u00f3\u0142 do liny, gdzie na dnie jest optymalne rozwi\u0105zanie.", "tokens": [51364, 14458, 24393, 10659, 2226, 13652, 11, 3561, 2192, 773, 2316, 84, 281, 15963, 3388, 401, 716, 956, 378, 16778, 261, 274, 16181, 360, 287, 3519, 11, 18922, 1667, 274, 2766, 3492, 2427, 4199, 304, 716, 9544, 22620, 7155, 13, 51732], "temperature": 0.0, "avg_logprob": -0.15517366223218965, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.0309534203261137}, {"id": 80, "seek": 30636, "start": 306.6, "end": 313.12, "text": " Loss Divergence to sytuacja, w kt\u00f3rej model nagle, bez ostrze\u017cenia, zamiast schodzi\u0107.", "tokens": [50376, 441, 772, 413, 1837, 15260, 281, 28275, 23395, 11, 261, 36023, 2316, 297, 15088, 11, 10782, 44024, 1381, 48830, 11, 710, 4526, 525, 956, 14543, 2162, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 81, "seek": 30636, "start": 313.32, "end": 314.36, "text": " Zaczyna si\u0119 wspina\u0107.", "tokens": [50712, 1176, 14691, 629, 3244, 17757, 1426, 2162, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 82, "seek": 30636, "start": 314.56, "end": 320.96000000000004, "text": " Gorzej. Teleportuje si\u0119 na szczyt pobliskiej g\u00f3ry i zaczyna generowa\u0107 kompletne bzdury.", "tokens": [50774, 26144, 16920, 13, 14889, 2707, 13008, 3244, 1667, 7870, 6522, 83, 30548, 7797, 7764, 290, 812, 627, 741, 43811, 629, 1337, 11445, 5207, 14657, 716, 272, 31278, 2598, 13, 51094], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 83, "seek": 30636, "start": 321.16, "end": 324.96000000000004, "text": " Wanto\u015b\u0107 funkcji strate, kt\u00f3ra powinna male\u0107, po prostu eksplodowa\u0142a.", "tokens": [51104, 343, 5857, 7753, 26476, 19649, 1056, 473, 11, 19456, 27310, 629, 7133, 2162, 11, 714, 19518, 30724, 564, 378, 5528, 5024, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 84, "seek": 30636, "start": 325.16, "end": 327.6, "text": " I co wtedy? Ca\u0142a praca namarny?", "tokens": [51304, 286, 598, 26959, 30, 7544, 5024, 582, 6628, 8835, 1083, 88, 30, 51426], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 85, "seek": 30636, "start": 327.8, "end": 332.76, "text": " Musia\u0142y dzia\u0142a\u0107 r\u0119cznie, zatrzyma\u0107 wszystko, wr\u00f3ci\u0107 do ostatniego zapisanego punktu", "tokens": [51436, 3569, 654, 6825, 37903, 2162, 41197, 19923, 11, 35802, 13047, 1696, 2162, 22607, 11, 928, 812, 39162, 360, 32686, 2766, 1571, 14223, 14804, 6308, 39561, 84, 51684], "temperature": 0.0, "avg_logprob": -0.1529615512792615, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.008138388395309448}, {"id": 86, "seek": 33276, "start": 332.76, "end": 337.36, "text": " kontrolnego, czasem sprzed wielu godzin i spr\u00f3bowa\u0107 ponownie, ale z innymi ustawieniami.", "tokens": [50364, 14373, 6623, 11858, 11, 13190, 443, 6103, 11312, 40437, 3044, 23584, 741, 6103, 14216, 11445, 9224, 648, 414, 11, 6775, 710, 294, 31813, 26189, 1607, 1053, 15568, 13, 50594], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 87, "seek": 33276, "start": 337.56, "end": 338.96, "text": " Jakimi ustawieniami?", "tokens": [50604, 15029, 10121, 26189, 1607, 1053, 15568, 30, 50674], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 88, "seek": 33276, "start": 339.15999999999997, "end": 342.28, "text": " Najcz\u0119\u015bciej zmniejszali tak zwane Learning Rate.", "tokens": [50684, 31576, 41151, 9815, 73, 17020, 10402, 15453, 5103, 991, 11873, 1929, 15205, 49583, 13, 50840], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 89, "seek": 33276, "start": 342.48, "end": 344.64, "text": " OK, a czym jest ten Learning Rate?", "tokens": [50850, 2264, 11, 257, 31466, 3492, 2064, 15205, 49583, 30, 50958], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 90, "seek": 33276, "start": 344.84, "end": 349.68, "text": " To paramet, kt\u00f3ry kontroluje, jak du\u017ce kroki stawia model podczas nauki.", "tokens": [50968, 1407, 6220, 302, 11, 9913, 14373, 340, 2781, 2884, 11, 4207, 1581, 2875, 45909, 2984, 342, 34953, 2316, 2497, 30989, 35616, 2984, 13, 51210], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 91, "seek": 33276, "start": 349.88, "end": 353.88, "text": " Zbyt du\u017cy Learning Rate jest jak pr\u00f3ba zej\u015bcia z g\u00f3ry wielkimi skokami.", "tokens": [51220, 1176, 2322, 83, 1581, 7735, 15205, 49583, 3492, 4207, 8565, 4231, 5277, 73, 1788, 2755, 710, 290, 812, 627, 20570, 74, 10121, 1110, 453, 4526, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 92, "seek": 33276, "start": 354.08, "end": 355.44, "text": " \u0141atwo straci\u0107 r\u00f3wnowag\u0119.", "tokens": [51430, 36901, 267, 6120, 1056, 326, 12757, 11416, 895, 305, 40748, 13, 51498], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 93, "seek": 33276, "start": 355.64, "end": 361.15999999999997, "text": " I spa\u015b\u0107. Musieli wi\u0119c zmniejszy\u0107 d\u0142ugo\u015b\u0107 kroku i kaza\u0107 mu i\u015b\u0107 ostro\u017cniej.", "tokens": [51508, 286, 32543, 7753, 13, 3569, 23099, 16677, 17020, 10402, 7706, 2162, 44042, 20746, 7753, 45909, 5279, 741, 350, 12257, 2162, 2992, 741, 7753, 277, 27616, 1427, 10402, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1099600094120677, "compression_ratio": 1.54, "no_speech_prob": 0.41601866483688354}, {"id": 94, "seek": 36116, "start": 361.36, "end": 366.04, "text": " Ten logbook pokazuje, \u017ce trening wielkiego modelu to nie jest czysta in\u017cynieria.", "tokens": [50374, 9380, 3565, 2939, 13010, 43317, 11, 3561, 2192, 773, 20570, 42349, 2316, 84, 281, 2838, 3492, 6430, 9140, 294, 1427, 2534, 811, 654, 13, 50608], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 95, "seek": 36116, "start": 366.24, "end": 369.12, "text": " To bardziej sztuka i ci\u0105g\u0142a improwizacja.", "tokens": [50618, 1407, 27209, 262, 2682, 13599, 741, 42398, 70, 5024, 704, 1892, 590, 23395, 13, 50762], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 96, "seek": 36116, "start": 369.32000000000005, "end": 374.24, "text": " Czyli to mniej przypomina\u0142o opieczenie ciasta wed\u0142ug idealnego przepisu, a bardziej", "tokens": [50772, 37099, 281, 39513, 41780, 49217, 5249, 999, 414, 39043, 6983, 12468, 6393, 34077, 7157, 11858, 30829, 25871, 11, 257, 27209, 51018], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 97, "seek": 36116, "start": 374.44000000000005, "end": 379.96000000000004, "text": " pr\u00f3b\u0119 utrzymania na ziemi eksperymentalnej rakiety, kt\u00f3ra w ka\u017cdej chwili grozi wybuchem.", "tokens": [51028, 8565, 65, 1274, 2839, 13047, 37268, 1667, 16503, 3057, 30724, 610, 88, 15875, 11794, 35544, 4014, 11, 19456, 261, 21912, 1479, 73, 26237, 2312, 4634, 3992, 4628, 39742, 443, 13, 51304], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 98, "seek": 36116, "start": 380.16, "end": 381.56, "text": " Doskonale powiedziane.", "tokens": [51314, 33474, 18295, 1220, 27617, 21133, 13, 51384], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 99, "seek": 36116, "start": 381.76000000000005, "end": 387.24, "text": " Ka\u017cdy restart, ka\u017cda korekta, to by\u0142 realny problem, stracony czas i pieni\u0105dze.", "tokens": [51394, 10988, 1427, 3173, 21022, 11, 21912, 2675, 350, 418, 74, 1328, 11, 281, 16673, 957, 1634, 1154, 11, 1056, 326, 2526, 13190, 741, 26274, 11404, 67, 1381, 13, 51668], "temperature": 0.0, "avg_logprob": -0.11791823892032399, "compression_ratio": 1.4390243902439024, "no_speech_prob": 0.008151998743414879}, {"id": 100, "seek": 38724, "start": 387.48, "end": 388.48, "text": " Zdecydowanie.", "tokens": [50376, 1176, 1479, 1344, 67, 22028, 13, 50426], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 101, "seek": 38724, "start": 388.68, "end": 392.84000000000003, "text": " I jest jeszcze jeden aspekt tej transparentno\u015bci, o kt\u00f3rym trzeba wspomnie\u0107.", "tokens": [50436, 286, 3492, 14168, 12906, 382, 23533, 12573, 12737, 16438, 11, 277, 30120, 25860, 17757, 298, 2766, 2162, 13, 50644], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 102, "seek": 38724, "start": 393.04, "end": 395.72, "text": " \u015alad w\u0119glowy to gor\u0105cy temat w AI.", "tokens": [50654, 27933, 9290, 261, 1274, 7191, 10089, 281, 24012, 1611, 1344, 32954, 261, 7318, 13, 50788], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 103, "seek": 38724, "start": 395.92, "end": 396.52, "text": " No tak.", "tokens": [50798, 883, 991, 13, 50828], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 104, "seek": 38724, "start": 396.72, "end": 405.28000000000003, "text": " Tw\u00f3rcy OPT oszacowali, \u017ce wytrenowanie ich najwi\u0119kszego modelu poch\u0142on\u0119\u0142o oko\u0142o 75 ton ekwiwalentu CO2.", "tokens": [50838, 2574, 15614, 1344, 23324, 51, 3003, 89, 326, 305, 5103, 11, 3561, 261, 4328, 1095, 22028, 1893, 48636, 1694, 27725, 2316, 84, 714, 339, 1221, 266, 1274, 5249, 45730, 5249, 9562, 2952, 13359, 6253, 29530, 317, 84, 3002, 17, 13, 51266], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 105, "seek": 38724, "start": 405.48, "end": 409.04, "text": " 75 ton, a dla por\u00f3wnania GPT-3.", "tokens": [51276, 9562, 2952, 11, 257, 12285, 1515, 812, 895, 5609, 26039, 51, 12, 18, 13, 51454], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 106, "seek": 38724, "start": 409.24, "end": 415.24, "text": " W tej samej pracy przytaczaj\u0105 szacunki dla GPT-3, kt\u00f3re m\u00f3wi\u0142y o ponad 500 tonach.", "tokens": [51464, 343, 12573, 912, 73, 35591, 6501, 83, 14875, 11133, 7870, 326, 409, 2984, 12285, 26039, 51, 12, 18, 11, 8864, 24592, 6825, 277, 9224, 345, 5923, 2952, 608, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 107, "seek": 38724, "start": 415.44, "end": 416.36, "text": " 500?", "tokens": [51774, 5923, 30, 51820], "temperature": 0.0, "avg_logprob": -0.15050094657474095, "compression_ratio": 1.3345195729537367, "no_speech_prob": 0.03760042414069176}, {"id": 108, "seek": 41636, "start": 416.56, "end": 418.8, "text": " To jest niemal siedmiokrotna r\u00f3\u017cnica.", "tokens": [50374, 1407, 3492, 2838, 5579, 262, 1091, 3057, 453, 10536, 629, 19637, 32687, 13, 50486], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 109, "seek": 41636, "start": 419.0, "end": 419.8, "text": " Ogromna.", "tokens": [50496, 422, 861, 298, 629, 13, 50536], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 110, "seek": 41636, "start": 420.0, "end": 420.88, "text": " Ale chwila.", "tokens": [50546, 9366, 26237, 7371, 13, 50590], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 111, "seek": 41636, "start": 421.08000000000004, "end": 423.44, "text": " Czy te liczwy s\u0105 w og\u00f3le por\u00f3wnywalne?", "tokens": [50600, 19832, 535, 6169, 89, 9726, 9015, 261, 29229, 1515, 812, 895, 27112, 304, 716, 30, 50718], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 112, "seek": 41636, "start": 423.64, "end": 428.52000000000004, "text": " Czy my wiemy, jak OpenAI liczy\u0142o sw\u00f3j \u015blad w\u0119glowy, a jak zrobi\u0142a to meta?", "tokens": [50728, 19832, 452, 3355, 2226, 11, 4207, 7238, 48698, 6169, 1229, 5249, 1693, 18999, 8299, 9290, 261, 1274, 7191, 10089, 11, 257, 4207, 24483, 5024, 281, 19616, 30, 50972], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 113, "seek": 41636, "start": 428.72, "end": 433.28000000000003, "text": " I to jest \u015bwietne pytanie, kt\u00f3re pokazuje, dlaczego otwarto\u015b\u0107 jest tak wa\u017cna.", "tokens": [50982, 286, 281, 3492, 8299, 39083, 716, 36610, 11, 8864, 13010, 43317, 11, 37873, 39329, 4337, 86, 15864, 7753, 3492, 991, 27777, 629, 13, 51210], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 114, "seek": 41636, "start": 433.48, "end": 438.52000000000004, "text": " Szacunki dla GPT-3 s\u0105 w\u0142a\u015bnie tym szacunkami zewn\u0119trznych badaczy.", "tokens": [51220, 24699, 326, 409, 2984, 12285, 26039, 51, 12, 18, 9015, 14234, 8107, 7870, 326, 3197, 4526, 5277, 895, 1274, 6903, 89, 9399, 1578, 14691, 13, 51472], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 115, "seek": 41636, "start": 438.72, "end": 441.88, "text": " Bo OpenAI nigdy nie opublikowa\u0142o oficjalnych danych.", "tokens": [51482, 3286, 7238, 48698, 26996, 3173, 2838, 999, 48620, 5528, 5249, 295, 299, 22600, 9399, 274, 34644, 13, 51640], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 116, "seek": 41636, "start": 442.08000000000004, "end": 442.92, "text": " Dok\u0142adnie.", "tokens": [51650, 29768, 10358, 2766, 13, 51692], "temperature": 0.0, "avg_logprob": -0.11676343282063802, "compression_ratio": 1.3767123287671232, "no_speech_prob": 0.0139010613784194}, {"id": 117, "seek": 44292, "start": 443.08000000000004, "end": 445.8, "text": " Meta Natoniast poda\u0142a swoj\u0105 metodologi\u0119.", "tokens": [50372, 6377, 64, 6821, 17049, 525, 2497, 64, 5024, 49194, 1131, 378, 1132, 5034, 13, 50508], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 118, "seek": 44292, "start": 446.0, "end": 451.48, "text": " U\u017cyli bardziej energooszcz\u0119dnych procesor\u00f3w graficznych, zoptymalizowali proces.", "tokens": [50518, 624, 7735, 2081, 27209, 2043, 1571, 329, 43771, 6298, 9399, 17565, 284, 3901, 1295, 1786, 89, 9399, 11, 710, 404, 874, 5579, 590, 305, 5103, 17565, 13, 50792], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 119, "seek": 44292, "start": 451.68, "end": 454.40000000000003, "text": " Nawet je\u015bli jest tu pewien margines b\u0142\u0119du.", "tokens": [50802, 40315, 302, 25630, 3492, 2604, 25889, 1053, 10270, 279, 272, 46564, 769, 13, 50938], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 120, "seek": 44292, "start": 454.6, "end": 457.20000000000005, "text": " To pokazali, \u017ce da si\u0119 to zrobi\u0107 znacznie wydajniej.", "tokens": [50948, 1407, 13010, 921, 5103, 11, 3561, 1120, 3244, 281, 31785, 15397, 14875, 2766, 25984, 1805, 10402, 13, 51078], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 121, "seek": 44292, "start": 457.40000000000003, "end": 459.88, "text": " I podzielili si\u0119 wiedz\u0105, jak to osi\u0105gn\u0119li.", "tokens": [51088, 286, 2497, 42280, 2312, 3244, 46894, 8925, 11, 4207, 281, 3003, 11404, 4568, 1274, 2081, 13, 51212], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 122, "seek": 44292, "start": 460.08000000000004, "end": 462.32, "text": " Zn\u00f3w. Chodzi o transparentno\u015b\u0107.", "tokens": [51222, 1176, 77, 3901, 13, 761, 14543, 277, 12737, 23293, 13, 51334], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 123, "seek": 44292, "start": 462.52000000000004, "end": 467.8, "text": " OK, mamy wi\u0119c model, kt\u00f3ry powsta\u0142 w bardziej otwarty, transparentny i", "tokens": [51344, 2264, 11, 17335, 16677, 2316, 11, 9913, 3388, 9140, 1221, 261, 27209, 4337, 29587, 88, 11, 12737, 1634, 741, 51608], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 124, "seek": 44292, "start": 468.0, "end": 469.28000000000003, "text": " oszcz\u0119dny spos\u00f3b.", "tokens": [51618, 3003, 43771, 6298, 1634, 22904, 13, 51682], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 125, "seek": 44292, "start": 469.48, "end": 470.84000000000003, "text": " Ale przejd\u017amy do sedna.", "tokens": [51692, 9366, 8325, 37109, 10659, 2226, 360, 9643, 629, 13, 51760], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 126, "seek": 44292, "start": 471.04, "end": 472.36, "text": " Czy jest r\u00f3wnie dobry?", "tokens": [51770, 19832, 3492, 11416, 14215, 35884, 30, 51836], "temperature": 0.0, "avg_logprob": -0.14354668623246486, "compression_ratio": 1.4276729559748427, "no_speech_prob": 0.006131156347692013}, {"id": 127, "seek": 47236, "start": 472.52000000000004, "end": 476.92, "text": " Jak OPT wypada w bezpo\u015brednim starciu z legendarnym GPT-3?", "tokens": [50372, 15029, 23324, 51, 46392, 1538, 261, 10782, 2259, 1788, 986, 39223, 3543, 30795, 710, 9451, 1083, 4199, 26039, 51, 12, 18, 30, 50592], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 128, "seek": 47236, "start": 477.12, "end": 480.48, "text": " No i tu dochodzimy do najbardziej fascynuj\u0105cej cz\u0119\u015bci.", "tokens": [50602, 883, 741, 2604, 9243, 378, 89, 13189, 360, 41857, 30632, 1344, 77, 13263, 20811, 41314, 13, 50770], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 129, "seek": 47236, "start": 480.68, "end": 484.68, "text": " Przetestowali go na szesnastu standardowych benchmark\u00f3w NLP.", "tokens": [50780, 2114, 40399, 377, 305, 5103, 352, 1667, 7870, 279, 77, 525, 84, 3832, 19605, 18927, 3901, 426, 45196, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 130, "seek": 47236, "start": 484.88, "end": 486.28000000000003, "text": " Jakie to by\u0142y testy?", "tokens": [50990, 15029, 414, 281, 26366, 1500, 88, 30, 51060], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 131, "seek": 47236, "start": 486.48, "end": 488.24, "text": " Sprawdzali go w dw\u00f3ch trybach.", "tokens": [51070, 1738, 15889, 89, 5103, 352, 261, 27379, 812, 339, 853, 32096, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 132, "seek": 47236, "start": 488.44, "end": 490.0, "text": " Pierwszy to zero shot.", "tokens": [51168, 16676, 30012, 281, 4018, 3347, 13, 51246], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 133, "seek": 47236, "start": 490.2, "end": 494.32, "text": " Dajesz modelowi zadanie, kt\u00f3rego nigdy wcze\u015bniej nie widzia\u0142 i oczekujesz", "tokens": [51256, 413, 1805, 10430, 2316, 24503, 42788, 7155, 11, 46951, 26996, 3173, 40785, 2838, 27486, 8908, 741, 277, 3689, 916, 4579, 10430, 51462], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 134, "seek": 47236, "start": 494.52000000000004, "end": 496.92, "text": " poprawnej odpowiedzi bez \u017cadnych przyk\u0142ad\u00f3w.", "tokens": [51472, 1665, 5131, 11794, 36574, 3992, 10782, 39628, 9399, 23144, 3901, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 135, "seek": 47236, "start": 497.12, "end": 499.16, "text": " Czyli taki sprawdzian z zaskoczenia.", "tokens": [51602, 37099, 20065, 46192, 89, 952, 710, 710, 3863, 905, 14320, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 136, "seek": 47236, "start": 499.36, "end": 500.32, "text": " A drugi tryb?", "tokens": [51714, 316, 4110, 72, 853, 65, 30, 51762], "temperature": 0.0, "avg_logprob": -0.1355078204784518, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.005001813173294067}, {"id": 137, "seek": 50032, "start": 500.48, "end": 505.92, "text": " Drugi to Fuse Shot, gdzie dajesz mu dos\u0142ownie kilka przyk\u0142ad\u00f3w, \u017ceby go naprowadzi\u0107", "tokens": [50372, 2491, 24780, 281, 479, 438, 28845, 11, 18922, 1120, 73, 10430, 2992, 4491, 1221, 648, 414, 36466, 23144, 3901, 11, 11316, 352, 9296, 1892, 345, 28496, 50644], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 138, "seek": 50032, "start": 506.12, "end": 507.44, "text": " na to, o co ci chodzi.", "tokens": [50654, 1667, 281, 11, 277, 598, 6983, 23998, 13, 50720], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 139, "seek": 50032, "start": 507.64, "end": 509.36, "text": " Rozumiem i jak wysz\u0142o.", "tokens": [50730, 43313, 449, 4907, 741, 4207, 261, 20589, 5249, 13, 50816], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 140, "seek": 50032, "start": 509.56, "end": 513.36, "text": " W obu tych scenariuszach wyniki by\u0142y uderzaj\u0105co podobne.", "tokens": [50826, 343, 1111, 84, 15180, 4191, 27440, 89, 608, 31936, 9850, 26366, 344, 1068, 89, 11133, 1291, 43024, 716, 13, 51016], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 141, "seek": 50032, "start": 513.56, "end": 523.04, "text": " Wykresy w pracy pokazuj\u0105, \u017ce krzywe wydajno\u015bci dla OPT i GPT-3 id\u0105 niemal web w web wraz ze wzrostem skali.", "tokens": [51026, 14458, 74, 495, 88, 261, 35591, 13010, 921, 13263, 11, 3561, 350, 13047, 826, 25984, 1805, 16438, 12285, 23324, 51, 741, 26039, 51, 12, 18, 4496, 1611, 2838, 5579, 3670, 261, 3670, 7843, 89, 5277, 24809, 27494, 443, 1110, 5103, 13, 51500], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 142, "seek": 50032, "start": 523.24, "end": 524.4, "text": " Czyli wniosek jest prosty.", "tokens": [51510, 37099, 261, 3722, 541, 74, 3492, 10293, 88, 13, 51568], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 143, "seek": 50032, "start": 524.6, "end": 529.88, "text": " Tak. W og\u00f3lnym rozrachunku OPT zbudowano za \u0142amek kosztu w\u0119glowego", "tokens": [51578, 9118, 13, 343, 5360, 15741, 12996, 9544, 81, 608, 49910, 23324, 51, 710, 18281, 305, 3730, 7949, 220, 20177, 916, 19532, 2682, 84, 261, 1274, 7191, 26576, 51842], "temperature": 0.0, "avg_logprob": -0.16591524924001386, "compression_ratio": 1.3661016949152542, "no_speech_prob": 0.001348231453448534}, {"id": 144, "seek": 52988, "start": 530.08, "end": 533.2, "text": " dor\u00f3wnuje wydajno\u015bci\u0105 GPT-3.", "tokens": [50374, 26313, 812, 895, 13008, 25984, 1805, 16438, 1611, 26039, 51, 12, 18, 13, 50530], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 145, "seek": 52988, "start": 533.4, "end": 538.72, "text": " A czy by\u0142y jakie\u015b obszary, w kt\u00f3rych OPT szczeg\u00f3lnie zaskoczy\u0142, gdzie pokaza\u0142 co\u015b nieoczekiwanego?", "tokens": [50540, 316, 6430, 26366, 31163, 3181, 89, 822, 11, 261, 30382, 23324, 51, 49624, 2766, 710, 3863, 905, 1229, 1221, 11, 18922, 13010, 12257, 1221, 19241, 2838, 905, 89, 14753, 7916, 6308, 30, 50806], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 146, "seek": 52988, "start": 538.92, "end": 541.68, "text": " By\u0142y dwa takie obszary i to bardzo wymowne.", "tokens": [50816, 3146, 6825, 35045, 15963, 3181, 89, 822, 741, 281, 9034, 29764, 648, 68, 13, 50954], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 147, "seek": 52988, "start": 541.88, "end": 543.6, "text": " Pierwszy to dialog.", "tokens": [50964, 16676, 30012, 281, 19308, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 148, "seek": 52988, "start": 543.8, "end": 548.72, "text": " OPT 175B, kt\u00f3ry by\u0142 trenowany w spos\u00f3b unsupervised.", "tokens": [51060, 23324, 51, 41165, 33, 11, 9913, 16673, 23136, 23341, 261, 22904, 2693, 12879, 24420, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 149, "seek": 52988, "start": 548.92, "end": 551.16, "text": " Fila, co to znaczy unsupervised?", "tokens": [51316, 479, 7371, 11, 598, 281, 36584, 2693, 12879, 24420, 30, 51428], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 150, "seek": 52988, "start": 551.36, "end": 556.04, "text": " To znaczy, \u017ce nikt go nie nadzorowa\u0142, nie uczy\u0142 konkretnych zada\u0144.", "tokens": [51438, 1407, 36584, 11, 3561, 297, 9874, 352, 2838, 12617, 89, 284, 30105, 11, 2838, 344, 6522, 1221, 36500, 9399, 710, 1538, 5248, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1545543074607849, "compression_ratio": 1.3869731800766283, "no_speech_prob": 0.011215083301067352}, {"id": 151, "seek": 55604, "start": 556.1999999999999, "end": 561.8399999999999, "text": " Po prostu karmiono go gigantyczn\u0105 ilo\u015bci\u0105 surowego tekstu z internetu i pozwolono mu", "tokens": [50372, 6165, 19518, 350, 4452, 49020, 352, 8741, 394, 17466, 13113, 1930, 44468, 1611, 1022, 26576, 16624, 372, 84, 710, 4705, 84, 741, 40557, 401, 8957, 2992, 50654], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 152, "seek": 55604, "start": 562.04, "end": 565.16, "text": " samodzielnie odkrywa\u0107 wzorce w j\u0119zyku.", "tokens": [50664, 3247, 378, 42280, 2766, 3611, 43298, 25234, 24809, 284, 384, 261, 49055, 5279, 13, 50820], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 153, "seek": 55604, "start": 565.36, "end": 570.76, "text": " OK. I ten model, nietrenowany do bycia chatbotem, w niekt\u00f3rych testach radzi\u0142 sobie", "tokens": [50830, 2264, 13, 286, 2064, 2316, 11, 6899, 1095, 23341, 360, 538, 2755, 5081, 18870, 443, 11, 261, 2838, 43073, 627, 339, 1500, 608, 2843, 3992, 1221, 13652, 51100], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 154, "seek": 55604, "start": 570.9599999999999, "end": 576.0799999999999, "text": " r\u00f3wnie dobrze, a czasem nawet lepiej, czasem nawet lepiej ni\u017c modele takie jak Blenderbot,", "tokens": [51110, 11416, 14215, 28335, 11, 257, 13190, 443, 22696, 476, 39699, 11, 13190, 443, 22696, 476, 39699, 28502, 4391, 306, 15963, 4207, 2177, 3216, 18870, 11, 51366], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 155, "seek": 55604, "start": 576.28, "end": 581.7199999999999, "text": " kt\u00f3re przesz\u0142y specjalistyczny trening, tak zwany fine tuning, \u017ceby dobrze prowadzi\u0107 konwersacje.", "tokens": [51376, 8864, 6541, 10430, 6825, 46433, 468, 17466, 1634, 2192, 773, 11, 991, 11873, 1325, 2489, 15164, 11, 11316, 28335, 36590, 28496, 5897, 5364, 29293, 13, 51648], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 156, "seek": 55604, "start": 581.92, "end": 585.4, "text": " Czyli zdolno\u015b\u0107 do prowadzenia dialogu po prostu si\u0119 w nim pojawi\u0142a.", "tokens": [51658, 37099, 16221, 401, 23293, 360, 36590, 14320, 19308, 84, 714, 19518, 3244, 261, 24887, 30655, 72, 5024, 13, 51832], "temperature": 0.0, "avg_logprob": -0.16537785370077862, "compression_ratio": 1.5173501577287065, "no_speech_prob": 0.05647583678364754}, {"id": 157, "seek": 58540, "start": 585.52, "end": 589.6, "text": " Dok\u0142adnie. To jest w\u0142a\u015bnie to, co naukowcy nazywaj\u0105 emergent abilities.", "tokens": [50370, 29768, 10358, 2766, 13, 1407, 3492, 14234, 281, 11, 598, 35616, 74, 305, 1344, 20151, 27112, 11133, 4345, 6930, 11582, 13, 50574], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 158, "seek": 58540, "start": 589.8, "end": 594.6, "text": " Wy\u0142aniaj\u0105ce si\u0119 zdolno\u015bci zdolno\u015bci, kt\u00f3rych nikt nie programowa\u0142, a kt\u00f3re pojawiaj\u0105 si\u0119", "tokens": [50584, 14458, 1221, 5609, 8555, 384, 3244, 16221, 401, 16438, 16221, 401, 16438, 11, 30382, 297, 9874, 2838, 1461, 30105, 11, 257, 8864, 30655, 48125, 3244, 50824], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 159, "seek": 58540, "start": 594.8, "end": 598.56, "text": " spontanicznie, gdy model osi\u0105ga odpowiednio du\u017c\u0105 skal\u0119 i z\u0142o\u017cono\u015b\u0107.", "tokens": [50834, 20795, 282, 17946, 2766, 11, 28405, 2316, 3003, 11404, 3680, 36574, 41084, 21783, 1611, 16890, 1274, 741, 710, 5249, 1427, 8957, 7753, 13, 51022], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 160, "seek": 58540, "start": 598.76, "end": 601.1999999999999, "text": " To pokazuje, jak pot\u0119\u017cne s\u0105 te architektury.", "tokens": [51032, 1407, 13010, 43317, 11, 4207, 1847, 1274, 1427, 716, 9015, 535, 3912, 642, 2320, 2598, 13, 51154], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 161, "seek": 58540, "start": 601.4, "end": 605.92, "text": " Niesamowite. A ten drugi zaskakuj\u0105cy obszar wspomnia\u0142a\u015b o dw\u00f3ch.", "tokens": [51164, 426, 530, 335, 305, 642, 13, 316, 2064, 4110, 72, 710, 3863, 514, 13263, 1344, 3181, 26236, 17757, 45438, 5024, 1788, 277, 27379, 812, 339, 13, 51390], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 162, "seek": 58540, "start": 606.12, "end": 610.3199999999999, "text": " Drugi jest jeszcze bardziej fascynuj\u0105cy i dotyczy toksyczno\u015bci,", "tokens": [51400, 2491, 24780, 3492, 14168, 27209, 30632, 1344, 77, 13263, 1344, 741, 5893, 88, 6522, 281, 1694, 17466, 16438, 11, 51610], "temperature": 0.0, "avg_logprob": -0.12797248363494873, "compression_ratio": 1.462837837837838, "no_speech_prob": 0.008262460120022297}, {"id": 163, "seek": 61032, "start": 610.44, "end": 612.48, "text": " a czyli mroczna strona AI.", "tokens": [50370, 257, 16591, 275, 340, 3689, 629, 1056, 4037, 7318, 13, 50472], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 164, "seek": 61032, "start": 612.6800000000001, "end": 615.5200000000001, "text": " I tu mamy do czynienia z prawdziwym paradoksem.", "tokens": [50482, 286, 2604, 17335, 360, 6430, 77, 18811, 710, 41175, 3992, 86, 4199, 13480, 453, 19872, 13, 50624], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 165, "seek": 61032, "start": 615.72, "end": 622.0400000000001, "text": " Zbi\u00f3r danych, na kt\u00f3rym trenowano OPTI, by\u0142 mniej filtrowany ni\u017c ten u\u017cyty dla GP3.", "tokens": [50634, 1176, 5614, 15614, 274, 34644, 11, 1667, 30120, 23136, 305, 3730, 23324, 5422, 11, 16673, 39513, 1387, 6903, 23341, 28502, 2064, 34097, 874, 12285, 26039, 18, 13, 50950], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 166, "seek": 61032, "start": 622.24, "end": 626.2800000000001, "text": " Zawiera\u0142 wi\u0119cej surowych, nieoczyszczonych tre\u015bci z internetu.", "tokens": [50960, 1176, 1607, 10609, 1221, 26004, 1022, 19605, 11, 2838, 905, 89, 20589, 3689, 2526, 339, 2192, 6199, 710, 4705, 84, 13, 51162], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 167, "seek": 61032, "start": 626.48, "end": 627.72, "text": " Na przyk\u0142ad serwisu Reddit.", "tokens": [51172, 6056, 23144, 816, 86, 25871, 32210, 13, 51234], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 168, "seek": 61032, "start": 627.9200000000001, "end": 630.6400000000001, "text": " OK, czyli wi\u0119cej tego, co w internecie najgorszy.", "tokens": [51244, 2264, 11, 16591, 26004, 8627, 11, 598, 261, 728, 716, 4260, 11212, 70, 830, 1229, 13, 51380], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 169, "seek": 61032, "start": 630.84, "end": 632.5200000000001, "text": " Mo\u017cna tak powiedzie\u0107.", "tokens": [51390, 44736, 629, 991, 27886, 13, 51474], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 170, "seek": 61032, "start": 632.72, "end": 633.6400000000001, "text": " I co si\u0119 okaza\u0142o?", "tokens": [51484, 286, 598, 3244, 3133, 12257, 5249, 30, 51530], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 171, "seek": 61032, "start": 633.84, "end": 639.32, "text": " W testach polegaj\u0105cych na wykrywaniu mowy nienawi\u015bci OPTI by\u0142 od GPT3 lepszy.", "tokens": [51540, 343, 1500, 608, 714, 6363, 11133, 31306, 1667, 39287, 47705, 25849, 275, 10089, 297, 1053, 38402, 6199, 23324, 5422, 16673, 3611, 26039, 51, 18, 476, 1878, 1229, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16929507407413166, "compression_ratio": 1.4045307443365695, "no_speech_prob": 0.019055364653468132}, {"id": 172, "seek": 63932, "start": 639.44, "end": 640.44, "text": " Jak to? Mo\u017cliwe.", "tokens": [50370, 15029, 281, 30, 44736, 2081, 826, 13, 50420], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 173, "seek": 63932, "start": 640.6400000000001, "end": 643.96, "text": " Bo po prostu widzia\u0142 wi\u0119cej tego typu tre\u015bci.", "tokens": [50430, 3286, 714, 19518, 27486, 8908, 26004, 8627, 2125, 84, 2192, 6199, 13, 50596], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 174, "seek": 63932, "start": 644.1600000000001, "end": 650.4000000000001, "text": " Nauczy\u0142 si\u0119 rozpoznawa\u0107 toksyczny j\u0119zyk, bo mia\u0142 z nim wi\u0119cej do czynienia podczas treningu.", "tokens": [50606, 6056, 1311, 1229, 1221, 3244, 9544, 2259, 35458, 25234, 281, 1694, 17466, 1634, 49055, 74, 11, 748, 27989, 710, 24887, 26004, 360, 6430, 77, 18811, 2497, 30989, 2192, 773, 84, 13, 50918], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 175, "seek": 63932, "start": 650.6, "end": 656.5600000000001, "text": " To troch\u0119 jak z lekarzem, kt\u00f3ry lepiej diagnozuje rzadk\u0105 chorob\u0119, bo widzia\u0142 w swojej karierze wi\u0119cej jej przypadk\u00f3w.", "tokens": [50928, 1407, 24926, 4207, 710, 476, 12303, 24313, 11, 9913, 476, 39699, 1026, 559, 1771, 11728, 2884, 367, 89, 345, 26304, 14965, 996, 1274, 11, 748, 27486, 8908, 261, 29489, 73, 7917, 811, 1381, 26004, 28924, 33100, 23849, 13, 51226], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 176, "seek": 63932, "start": 656.7600000000001, "end": 657.72, "text": " Dok\u0142adnie tak.", "tokens": [51236, 29768, 10358, 2766, 991, 13, 51284], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 177, "seek": 63932, "start": 657.9200000000001, "end": 661.4000000000001, "text": " To brzmi jak dobra wiadomo\u015b\u0107, ale czuj\u0119, \u017ce jest tu jakie\u015b ale.", "tokens": [51294, 1407, 738, 89, 3057, 4207, 360, 6198, 26393, 40633, 7753, 11, 6775, 6472, 18258, 11, 3561, 3492, 2604, 31163, 6775, 13, 51468], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 178, "seek": 63932, "start": 661.6, "end": 663.12, "text": " A to pot\u0119\u017cne.", "tokens": [51478, 316, 281, 1847, 1274, 1427, 716, 13, 51554], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 179, "seek": 63932, "start": 663.32, "end": 665.12, "text": " Jest te\u017c druga strona medalu.", "tokens": [51564, 24918, 9516, 4110, 64, 1056, 4037, 1205, 4929, 13, 51654], "temperature": 0.0, "avg_logprob": -0.137676123026255, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.02106616087257862}, {"id": 180, "seek": 66512, "start": 665.12, "end": 675.12, "text": " Z tego samego powodu przez te same brudne dane treningowe OPTI jest r\u00f3wnie\u017c bardziej sk\u0142onny do generowania toksycznych tre\u015bci.", "tokens": [50364, 1176, 8627, 912, 1571, 3388, 34873, 14064, 535, 912, 738, 532, 716, 49206, 2192, 773, 6880, 23324, 5422, 3492, 20532, 27209, 1110, 1221, 266, 1634, 360, 1337, 21308, 281, 1694, 17466, 9399, 2192, 6199, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1320108905915291, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.09481827914714813}, {"id": 181, "seek": 66512, "start": 675.32, "end": 678.36, "text": " A, czyli nie tylko je rozpoznaje, ale i tworzy.", "tokens": [50874, 316, 11, 16591, 2838, 13219, 1506, 9544, 2259, 35458, 2884, 11, 6775, 741, 46288, 1229, 13, 51026], "temperature": 0.0, "avg_logprob": -0.1320108905915291, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.09481827914714813}, {"id": 182, "seek": 66512, "start": 678.5600000000001, "end": 679.8, "text": " I po wiele stereotypy.", "tokens": [51036, 286, 714, 33137, 41182, 8200, 13, 51098], "temperature": 0.0, "avg_logprob": -0.1320108905915291, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.09481827914714813}, {"id": 183, "seek": 66512, "start": 680.0, "end": 681.48, "text": " To jest fundamentalny dylemat.", "tokens": [51108, 1407, 3492, 8088, 1634, 274, 2072, 15677, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1320108905915291, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.09481827914714813}, {"id": 184, "seek": 66512, "start": 681.68, "end": 690.84, "text": " Niefiltrowane dane daj\u0105 modelowi g\u0142\u0119bsze, bardziej realistyczne zrozumienie j\u0119zyka, ale jednocze\u015bnie ucz\u0105 go t\u0119 mroczne wzorce na\u015bladowa\u0107.", "tokens": [51192, 12016, 69, 2352, 1892, 1929, 49206, 1120, 8555, 2316, 24503, 18117, 1274, 929, 1381, 11, 27209, 957, 468, 17466, 716, 710, 27857, 449, 27385, 42309, 40940, 11, 6775, 5232, 26694, 1381, 12221, 35403, 1611, 352, 32489, 275, 340, 38491, 24809, 284, 384, 1667, 1788, 9290, 11445, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1320108905915291, "compression_ratio": 1.3956043956043955, "no_speech_prob": 0.09481827914714813}, {"id": 185, "seek": 69084, "start": 691.0400000000001, "end": 696.4, "text": " Mamy wi\u0119c pot\u0119\u017cny, otwarty, ale i potencjalnie niebezpieczny model.", "tokens": [50374, 376, 7804, 16677, 1847, 1274, 1427, 1634, 11, 4337, 29587, 88, 11, 6775, 741, 1847, 22660, 22600, 2766, 2838, 650, 89, 9144, 3689, 1634, 2316, 13, 50642], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 186, "seek": 69084, "start": 696.6, "end": 700.4, "text": " Czy autorzy pr\u00f3buj\u0105 to jako\u015b, no wiesz, zamie\u015b\u0107 pod dywan?", "tokens": [50652, 19832, 19510, 1229, 8565, 65, 13263, 281, 17123, 1788, 11, 572, 261, 15347, 11, 19876, 414, 7753, 2497, 14584, 7916, 30, 50842], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 187, "seek": 69084, "start": 700.6, "end": 704.64, "text": " Wr\u0119cz przeciwnie i to jest kolejny dow\u00f3d na ich odpowiedzialne podej\u015bcie.", "tokens": [50852, 10159, 1274, 3689, 39622, 14215, 741, 281, 3492, 23749, 1634, 9459, 17081, 1667, 1893, 24314, 15338, 831, 716, 7468, 73, 9815, 13, 51054], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 188, "seek": 69084, "start": 704.84, "end": 708.52, "text": " Ca\u0142y rozdzia\u0142 pracy po\u015bwi\u0119cili na um\u00f3wienie znanych im ogranicze\u0144.", "tokens": [51064, 7544, 6825, 9544, 28168, 8908, 35591, 714, 1788, 22423, 66, 2312, 1667, 1105, 3901, 27385, 15397, 34644, 566, 34416, 30732, 49689, 13, 51248], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 189, "seek": 69084, "start": 708.72, "end": 709.6800000000001, "text": " I co tam wymieniaj\u0105?", "tokens": [51258, 286, 598, 7677, 29764, 18811, 8555, 30, 51306], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 190, "seek": 69084, "start": 709.88, "end": 712.24, "text": " Wymieniaj\u0105 je z rozbrajaj\u0105c\u0105 szczero\u015bci\u0105.", "tokens": [51316, 343, 4199, 18811, 8555, 1506, 710, 9544, 6198, 73, 11133, 32557, 22090, 2032, 50227, 13, 51434], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 191, "seek": 69084, "start": 712.44, "end": 716.0, "text": " Po pierwsze model ma problem z wykonywaniem prostych polece\u0144.", "tokens": [51444, 6165, 45994, 2316, 463, 1154, 710, 39287, 2526, 7916, 4907, 10293, 16384, 13208, 384, 5248, 13, 51622], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 192, "seek": 69084, "start": 716.2, "end": 717.1600000000001, "text": " Co to znaczy?", "tokens": [51632, 3066, 281, 36584, 30, 51680], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 193, "seek": 69084, "start": 717.36, "end": 719.12, "text": " Prosisz go o co\u015b, a on odmawia?", "tokens": [51690, 26024, 23848, 352, 277, 19241, 11, 257, 322, 3611, 76, 34953, 30, 51778], "temperature": 0.0, "avg_logprob": -0.11186544244939631, "compression_ratio": 1.4651898734177216, "no_speech_prob": 0.0499856062233448}, {"id": 194, "seek": 71912, "start": 719.24, "end": 724.08, "text": " Gorzej. Zawezd wykona\u0107 instrukcj\u0119, cz\u0119sto zaczyna symurowa\u0107 rozmow\u0119 o tej instrukcji.", "tokens": [50370, 26144, 16920, 13, 1176, 1607, 4371, 67, 39287, 4037, 2162, 1058, 25126, 41960, 11, 34369, 43811, 629, 6697, 374, 11445, 35234, 305, 1274, 277, 12573, 1058, 25126, 19649, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 195, "seek": 71912, "start": 724.28, "end": 725.32, "text": " Dziwne.", "tokens": [50622, 413, 3992, 86, 716, 13, 50674], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 196, "seek": 71912, "start": 725.52, "end": 733.96, "text": " Prosisz go o podsumowanie tekstu, a on generuje dialog, w kt\u00f3rym jedna posta\u0107 prosi drug\u0105 o podsumowanie tego tekstu.", "tokens": [50684, 26024, 23848, 352, 277, 31925, 449, 22028, 16624, 372, 84, 11, 257, 322, 1337, 13008, 19308, 11, 261, 30120, 5232, 629, 2183, 43379, 6267, 72, 4110, 1611, 277, 31925, 449, 22028, 8627, 16624, 372, 84, 13, 51106], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 197, "seek": 71912, "start": 734.16, "end": 735.36, "text": " Niesamowite.", "tokens": [51116, 426, 530, 335, 305, 642, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 198, "seek": 71912, "start": 735.5600000000001, "end": 737.28, "text": " Jakie\u015b inne problemy.", "tokens": [51186, 15029, 414, 1788, 24170, 1154, 88, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 199, "seek": 71912, "start": 737.48, "end": 740.88, "text": " Tak, ma tendencj\u0119 do powtarzania si\u0119, wpadania w p\u0119tl\u0119.", "tokens": [51282, 9118, 11, 463, 3928, 22660, 11115, 360, 3388, 23480, 89, 5609, 3244, 11, 32444, 345, 5609, 261, 280, 46788, 75, 1274, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 200, "seek": 71912, "start": 741.08, "end": 743.76, "text": " Generuje te same frazy w k\u00f3\u0142ko.", "tokens": [51462, 15409, 13008, 535, 912, 6600, 1229, 261, 350, 16181, 4093, 13, 51596], "temperature": 0.0, "avg_logprob": -0.1699830980011911, "compression_ratio": 1.41869918699187, "no_speech_prob": 0.03088564984500408}, {"id": 201, "seek": 74376, "start": 743.92, "end": 749.64, "text": " Oczywi\u015bcie potrafi te\u017c generowa\u0107 kompletnie fa\u0142szywe informacje, co znamy jako halucynacj\u0119.", "tokens": [50372, 42980, 1847, 10437, 72, 9516, 1337, 11445, 5207, 14657, 2766, 2050, 1221, 7706, 826, 1356, 29293, 11, 598, 710, 5378, 88, 17123, 7523, 1311, 2534, 29924, 13, 50658], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 202, "seek": 74376, "start": 749.84, "end": 752.76, "text": " Ale najwa\u017cniejsze jest zdanie, kt\u00f3re wie\u0144czy czytno zdzia\u0142.", "tokens": [50668, 9366, 11212, 27111, 44258, 3492, 16221, 7155, 11, 8864, 3355, 5248, 6522, 6430, 83, 1771, 16221, 43070, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 203, "seek": 74376, "start": 752.96, "end": 753.48, "text": " Jakie?", "tokens": [50824, 15029, 414, 30, 50850], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 204, "seek": 74376, "start": 753.68, "end": 755.76, "text": " Warto je zacytowa\u0107 niemal dos\u0142ownie.", "tokens": [50860, 343, 15864, 1506, 710, 2551, 83, 11445, 2838, 5579, 4491, 1221, 648, 414, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 205, "seek": 74376, "start": 755.96, "end": 759.76, "text": " Autorzy stwierdzaj\u0105, \u017ce w ich ocenie technologia ta jest", "tokens": [50974, 6049, 284, 1229, 342, 40717, 28168, 11133, 11, 3561, 261, 1893, 10409, 268, 414, 1537, 24103, 1846, 3492, 51164], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 206, "seek": 74376, "start": 759.96, "end": 766.16, "text": " przedwczesna do wdro\u017ce\u0144 w produktach komercyjnych z powodu ryzyka zwi\u0105zanego z bezpiecze\u0144stwem.", "tokens": [51174, 18334, 86, 3689, 279, 629, 360, 261, 45869, 2875, 5248, 261, 42816, 608, 5207, 260, 42949, 9399, 710, 3388, 34873, 20791, 40940, 27741, 282, 6308, 710, 47153, 9680, 12229, 86, 443, 13, 51484], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 207, "seek": 74376, "start": 766.36, "end": 768.4, "text": " To jest bardzo mocne o\u015bwiadczenie.", "tokens": [51494, 1407, 3492, 9034, 34962, 716, 277, 37750, 39043, 13, 51596], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 208, "seek": 74376, "start": 768.6, "end": 772.8, "text": " W bran\u017cy, kt\u00f3ra p\u0119dzi, by jak najszybciej monetyzowa\u0107 ka\u017cdy nowy model,", "tokens": [51606, 343, 12029, 7735, 11, 19456, 280, 6298, 3992, 11, 538, 4207, 11212, 7706, 65, 4260, 73, 1108, 2210, 89, 11445, 31615, 586, 88, 2316, 11, 51816], "temperature": 0.0, "avg_logprob": -0.13900541677707579, "compression_ratio": 1.4397590361445782, "no_speech_prob": 0.039929620921611786}, {"id": 209, "seek": 77280, "start": 773.0, "end": 774.1999999999999, "text": " oni m\u00f3wi\u0105 wprost.", "tokens": [50374, 36317, 46591, 261, 1424, 555, 13, 50434], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 210, "seek": 77280, "start": 774.4, "end": 776.7199999999999, "text": " Nasze dzie\u0142o nie jest jeszcze na to gotowe.", "tokens": [50444, 16151, 1381, 17953, 5249, 2838, 3492, 14168, 1667, 281, 658, 6880, 13, 50560], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 211, "seek": 77280, "start": 776.92, "end": 779.8399999999999, "text": " To jest akt niezwyk\u0142ej odpowiedzialno\u015bci.", "tokens": [50570, 1407, 3492, 13680, 33511, 9726, 74, 19827, 73, 24314, 15338, 831, 16438, 13, 50716], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 212, "seek": 77280, "start": 780.04, "end": 787.0, "text": " Zamiast ukrywa\u0107 wady, wystawili je na widok publiczny, daj\u0105c innym badaczom narz\u0119dzie", "tokens": [50726, 1176, 4526, 525, 26769, 627, 25234, 261, 880, 11, 4628, 22580, 2312, 1506, 1667, 5274, 453, 1908, 89, 1634, 11, 1120, 8555, 66, 294, 12996, 1578, 14875, 298, 6714, 89, 42643, 51074], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 213, "seek": 77280, "start": 787.1999999999999, "end": 791.28, "text": " i jednocze\u015bnie ostrzegaj\u0105c ich przed potencjalnymi zagro\u017ceniami.", "tokens": [51084, 741, 5232, 26694, 1381, 12221, 44024, 89, 1146, 38757, 1893, 18334, 1847, 22660, 22600, 31813, 27001, 340, 24930, 15568, 13, 51288], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 214, "seek": 77280, "start": 791.4799999999999, "end": 792.7199999999999, "text": " Podsumujmy wi\u0119c.", "tokens": [51298, 12646, 82, 449, 4579, 2226, 16677, 13, 51360], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 215, "seek": 77280, "start": 792.92, "end": 799.64, "text": " Mamy otwarty, pot\u0119\u017cny, wydajny, ale jednocze\u015bnie niedoskona\u0142y i momentami toksyczny model.", "tokens": [51370, 376, 7804, 4337, 29587, 88, 11, 1847, 1274, 1427, 1634, 11, 25984, 1805, 1634, 11, 6775, 5232, 26694, 1381, 12221, 32488, 329, 74, 4037, 6825, 741, 1623, 4526, 281, 1694, 17466, 1634, 2316, 13, 51706], "temperature": 0.0, "avg_logprob": -0.09994823812580794, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.007421181071549654}, {"id": 216, "seek": 79964, "start": 799.88, "end": 802.48, "text": " Jaki jest wi\u0119c ostateczny wniosek z tej pracy?", "tokens": [50376, 508, 7421, 3492, 16677, 277, 15406, 3689, 1634, 261, 3722, 541, 74, 710, 12573, 35591, 30, 50506], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 217, "seek": 79964, "start": 802.68, "end": 804.76, "text": " Co ona tak naprawd\u0119 zmieni\u0142a?", "tokens": [50516, 3066, 20325, 991, 20970, 17020, 35462, 5024, 30, 50620], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 218, "seek": 79964, "start": 804.96, "end": 806.64, "text": " Zmieni\u0142a rozmow\u0119.", "tokens": [50630, 1176, 76, 35462, 5024, 35234, 305, 1274, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 219, "seek": 79964, "start": 806.84, "end": 812.1999999999999, "text": " Publikacja OLPT to co\u015b znacznie wi\u0119cej ni\u017c prezentacja kolejnego modelu.", "tokens": [50724, 21808, 13462, 23395, 39191, 47, 51, 281, 19241, 15397, 14875, 2766, 26004, 28502, 659, 14185, 23395, 23749, 11858, 2316, 84, 13, 50992], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 220, "seek": 79964, "start": 812.4, "end": 813.92, "text": " To by\u0142 manifest.", "tokens": [51002, 1407, 16673, 10067, 13, 51078], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 221, "seek": 79964, "start": 814.12, "end": 815.52, "text": " Manifest na temat czego?", "tokens": [51088, 2458, 351, 377, 1667, 32954, 36559, 30, 51158], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 222, "seek": 79964, "start": 815.72, "end": 819.68, "text": " Na temat tego, jak powinny wygl\u0105da\u0107 badania nad AI.", "tokens": [51168, 6056, 32954, 8627, 11, 4207, 27310, 1634, 32015, 2162, 1578, 5609, 12617, 7318, 13, 51366], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 223, "seek": 79964, "start": 819.88, "end": 826.3199999999999, "text": " Meta pokaza\u0142a, \u017ce priorytetem nie musi by\u0107 budowanie najwi\u0119kszych, najbardziej zamkni\u0119tych system\u00f3w.", "tokens": [51376, 6377, 64, 13010, 12257, 5024, 11, 3561, 1790, 827, 83, 302, 443, 2838, 37587, 15069, 3265, 22028, 48636, 1694, 28051, 11, 41857, 19876, 74, 35938, 874, 339, 1185, 3901, 13, 51698], "temperature": 0.0, "avg_logprob": -0.12456426166352771, "compression_ratio": 1.4037037037037037, "no_speech_prob": 0.08277665078639984}, {"id": 224, "seek": 82632, "start": 826.48, "end": 827.36, "text": " Zamiast tego?", "tokens": [50372, 1176, 4526, 525, 8627, 30, 50416], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 225, "seek": 82632, "start": 827.5600000000001, "end": 833.5200000000001, "text": " Zamiast tego mo\u017cna skupi\u0107 si\u0119 na tworzeniu narz\u0119dzi, kt\u00f3re pozwol\u0105 ca\u0142ej spo\u0142eczno\u015bci naukowej", "tokens": [50426, 1176, 4526, 525, 8627, 17790, 1110, 1010, 12757, 3244, 1667, 46288, 39651, 6714, 89, 6298, 3992, 11, 8864, 40557, 401, 1611, 47631, 73, 36851, 89, 16438, 35616, 74, 21091, 50724], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 226, "seek": 82632, "start": 833.72, "end": 841.96, "text": " wsp\u00f3lnie zrozumie\u0107, jak te pot\u0119\u017cne technologie dzia\u0142aj\u0105, jakie nios\u0105 ze sob\u0105 ryzyka i jak mo\u017cna je w przysz\u0142o\u015bci ulepszy\u0107.", "tokens": [50734, 47148, 2766, 710, 27857, 449, 414, 2162, 11, 4207, 535, 1847, 1274, 1427, 716, 1537, 20121, 27121, 11133, 11, 22124, 297, 2717, 1611, 5277, 18253, 1611, 20791, 40940, 741, 4207, 17790, 1506, 261, 44018, 35059, 344, 306, 1878, 27150, 13, 51146], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 227, "seek": 82632, "start": 842.1600000000001, "end": 850.4000000000001, "text": " Czyli OLPT nie jest celem samym w sobie, a raczej pot\u0119\u017cnym mikroskopem, kt\u00f3ry zosta\u0142 podarowany ca\u0142ej spo\u0142eczno\u015bci naukowej.", "tokens": [51156, 37099, 39191, 47, 51, 2838, 3492, 1769, 10386, 3247, 4199, 261, 13652, 11, 257, 4129, 16920, 1847, 1274, 1427, 12996, 23959, 2635, 43855, 443, 11, 9913, 23154, 1221, 2497, 289, 23341, 47631, 73, 36851, 89, 16438, 35616, 74, 21091, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 228, "seek": 82632, "start": 850.6, "end": 851.6, "text": " Dok\u0142adnie.", "tokens": [51578, 29768, 10358, 2766, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 229, "seek": 82632, "start": 851.8000000000001, "end": 855.4000000000001, "text": " Mikroskopem do badania fenomenu wielkich modeli j\u0119zykowych.", "tokens": [51638, 16380, 2635, 43855, 443, 360, 1578, 5609, 26830, 4726, 84, 20570, 48349, 2316, 72, 49055, 74, 19605, 13, 51818], "temperature": 0.0, "avg_logprob": -0.1015664545694987, "compression_ratio": 1.528428093645485, "no_speech_prob": 0.02580408938229084}, {"id": 230, "seek": 85540, "start": 855.6, "end": 859.64, "text": " To narz\u0119dzie do wsp\u00f3lnego badania odpowiedzialnej sztucznej inteligencji.", "tokens": [50374, 1407, 6714, 89, 42643, 360, 47148, 11858, 1578, 5609, 24314, 15338, 831, 11794, 262, 2682, 1311, 89, 11794, 24777, 3213, 19649, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 231, "seek": 85540, "start": 859.84, "end": 861.88, "text": " Tak, to \u015bwietne podsumowanie.", "tokens": [50586, 9118, 11, 281, 8299, 39083, 716, 31925, 449, 22028, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 232, "seek": 85540, "start": 862.0799999999999, "end": 865.3199999999999, "text": " Przesun\u0119\u0142o akcent z wy\u015bcigu na wsp\u00f3\u0142prac\u0119.", "tokens": [50698, 2114, 12214, 409, 1274, 5249, 9308, 2207, 710, 4628, 1788, 66, 16397, 1667, 39069, 1424, 326, 1274, 13, 50860], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 233, "seek": 85540, "start": 865.52, "end": 870.3199999999999, "text": " Na koniec chcia\u0142bym podrzuci\u0107 my\u015bl, kt\u00f3ra zosta\u0142a ze mn\u0105 po lekturze tej pracy.", "tokens": [50870, 6056, 5897, 35733, 26497, 43579, 15305, 11728, 39162, 452, 19212, 11, 19456, 23154, 5024, 5277, 275, 13113, 714, 476, 2320, 374, 1381, 12573, 35591, 13, 51110], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 234, "seek": 85540, "start": 870.52, "end": 874.0, "text": " Jasno z niej wynika, \u017ce niefiltrowane, brudne dane z", "tokens": [51120, 34023, 1771, 710, 2838, 73, 31936, 5439, 11, 3561, 2838, 69, 2352, 1892, 1929, 11, 738, 532, 716, 49206, 710, 51294], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 235, "seek": 85540, "start": 874.1999999999999, "end": 882.64, "text": " internetu da\u0142y modelowi jednocze\u015bnie co\u015b dobrego, zdolno\u015b\u0107 do rozpoznawania toksyczno\u015bci i co\u015b z\u0142ego, sk\u0142onno\u015b\u0107 do jej generowania.", "tokens": [51304, 4705, 84, 1120, 6825, 2316, 24503, 5232, 26694, 1381, 12221, 19241, 41959, 1571, 11, 16221, 401, 23293, 360, 9544, 2259, 35458, 86, 5609, 281, 1694, 17466, 16438, 741, 19241, 31614, 6308, 11, 1110, 1221, 266, 23293, 360, 28924, 1337, 21308, 13, 51726], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 236, "seek": 85540, "start": 882.84, "end": 884.0799999999999, "text": " To jest sedno problemu.", "tokens": [51736, 1407, 3492, 9643, 1771, 1154, 84, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1146250550851882, "compression_ratio": 1.4620253164556962, "no_speech_prob": 0.012805210426449776}, {"id": 237, "seek": 88408, "start": 884.2800000000001, "end": 888.1600000000001, "text": " I to prowadzi do fundamentalnego pytania, kt\u00f3re ta praca przed nami stawia.", "tokens": [50374, 286, 281, 36590, 3992, 360, 8088, 11858, 25878, 5609, 11, 8864, 1846, 582, 6628, 18334, 297, 4526, 342, 34953, 13, 50568], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 238, "seek": 88408, "start": 888.36, "end": 893.1600000000001, "text": " Czy w og\u00f3le da si\u0119 stworzy\u0107 model AI, kt\u00f3ry b\u0119dzie w pe\u0142ni rozumia\u0142 ludzki j\u0119zyk z", "tokens": [50578, 19832, 261, 29229, 1120, 3244, 342, 28321, 27150, 2316, 7318, 11, 9913, 10562, 261, 43205, 3722, 48797, 8908, 15946, 89, 2984, 49055, 74, 710, 50818], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 239, "seek": 88408, "start": 893.36, "end": 899.2, "text": " ca\u0142ym jego bogactwem i mrocznymi zakamarkami, ale jednocze\u015bnie nie o dziedziczy naszych najgorszych cech?", "tokens": [50828, 35224, 4199, 26542, 26132, 578, 86, 443, 741, 275, 340, 3689, 31813, 23810, 335, 809, 4526, 11, 6775, 5232, 26694, 1381, 12221, 2838, 277, 9758, 15338, 299, 1229, 45002, 11212, 70, 830, 28051, 1769, 339, 30, 51120], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 240, "seek": 88408, "start": 899.4000000000001, "end": 900.44, "text": " Dobre pytanie.", "tokens": [51130, 29679, 265, 36610, 13, 51182], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 241, "seek": 88408, "start": 900.64, "end": 903.88, "text": " A mo\u017ce jedyna droga do bezpiecznej AI prowadzi", "tokens": [51192, 316, 12034, 5232, 88, 629, 3789, 3680, 360, 47153, 3689, 11794, 7318, 36590, 3992, 51354], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 242, "seek": 88408, "start": 904.08, "end": 910.72, "text": " przez stworzenie sterylnych modeli, trenowanych tylko na wyselekcjonowanych czy z tych danych?", "tokens": [51364, 14064, 342, 28321, 16778, 342, 2109, 75, 9399, 2316, 72, 11, 23136, 23341, 339, 13219, 1667, 4628, 405, 29205, 45677, 23341, 339, 6430, 710, 15180, 274, 34644, 30, 51696], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 243, "seek": 88408, "start": 910.9200000000001, "end": 911.9200000000001, "text": " Ale wtedy?", "tokens": [51706, 9366, 26959, 30, 51756], "temperature": 0.0, "avg_logprob": -0.10811726142620218, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.010141895152628422}, {"id": 244, "seek": 91192, "start": 912.12, "end": 917.24, "text": " By\u0142yby mo\u017ce bezpieczniejsze, ale jednocze\u015bnie odci\u0119te od rzeczywisto\u015bci.", "tokens": [50374, 3146, 6825, 2322, 12034, 47153, 3689, 44258, 11, 6775, 5232, 26694, 1381, 12221, 3611, 537, 1274, 975, 3611, 26297, 86, 9334, 6199, 13, 50630], "temperature": 0.0, "avg_logprob": -0.13347179074830648, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.001892603700980544}, {"id": 245, "seek": 91192, "start": 917.4399999999999, "end": 920.92, "text": " Mniej \u015bwiadome \u015bwiata, w kt\u00f3rym maj\u0105 funkcjonowa\u0107,", "tokens": [50640, 376, 10402, 21485, 345, 423, 21485, 3274, 11, 261, 30120, 26064, 26476, 45677, 11445, 11, 50814], "temperature": 0.0, "avg_logprob": -0.13347179074830648, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.001892603700980544}, {"id": 246, "seek": 91192, "start": 921.12, "end": 924.4, "text": " \u017cy\u0142yby w sztucznej, wyidealizowanej ba\u0144ce.", "tokens": [50824, 16136, 6825, 2322, 261, 262, 2682, 1311, 89, 11794, 11, 4628, 482, 304, 590, 23066, 73, 4773, 5248, 384, 13, 50988], "temperature": 0.0, "avg_logprob": -0.13347179074830648, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.001892603700980544}, {"id": 247, "seek": 91192, "start": 924.5999999999999, "end": 927.16, "text": " I pytanie brzmi, co wtedy tracimy?", "tokens": [50998, 286, 36610, 738, 89, 3057, 11, 598, 26959, 504, 326, 13189, 30, 51126], "temperature": 0.0, "avg_logprob": -0.13347179074830648, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.001892603700980544}], "language": "pl"}