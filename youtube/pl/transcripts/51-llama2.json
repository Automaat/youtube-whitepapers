{"text": " Wiesz, zastanawia\u0142e\u015b si\u0119 kiedy\u015b, co by by\u0142o, gdyby ta ca\u0142a pot\u0119\u017cna technologia za czed\u0142 GPT nagle sta\u0142a si\u0119 dost\u0119pna dla absolutnie wszystkich, dla badaczy, dla start-up\u00f3w, no nawet dla zwyk\u0142ych pasjonat\u00f3w. No w\u0142a\u015bnie, bo przez bardzo d\u0142ugi czas to by\u0142y takie, no wiesz, zamkni\u0119te czarne skrzynki. Dok\u0142adnie. Pilnie strze\u017cone sekrety kilkutechnologicznych pot\u0119g. A my dzisiaj, my dzisiaj bierzemy na warsztat publikacj\u0119, kt\u00f3ra pr\u00f3bowa\u0142a te dwie, no przynajmniej uchyli\u0107. M\u00f3wimy o Lama 2 Open Foundation and Fine Tuned Chat Models od Zespo\u0142u Meta AI. Tak jest. I naszym zadaniem jest no rozebranie tego na czynniki pierwsze. Chcemy zrozumie\u0107 nie tylko czym jest Lama 2, ale przede wszystkim jak to w og\u00f3le zrobiono. I dlaczego jego premiera wywo\u0142a\u0142a takie no ma\u0142e trz\u0119sienie ziemi w \u015bwiecie AI? Dok\u0142adnie sprawdzimy jak oni to trenowali, jak uczyli bycia pomocnym, bezpiecznym i co kluczowe. Jak Lama 4 wypada w bezpo\u015brednim staryciu z tymi najwi\u0119kszymi. Dobrze, to zacznijmy od samego sedna. Jaki by\u0142 ten g\u0142\u00f3wny, nadrz\u0119dny cel projektu? Bo z tego, co czyta\u0142em, nie chodzi\u0142o tylko o to, \u017ceby zrobi\u0107 kolejny model, kt\u00f3ry b\u0119dzie, nie wiem, o 2% lepszy w jakim\u015b benchmarku. Absolutnie nie, tu chodzi\u0142o o co\u015b, o co\u015b znacznie wi\u0119kszego. Oni chcieli udowodni\u0107, \u017ce model Open Source, taki dost\u0119pny dla ka\u017cdego, mo\u017ce by\u0107 r\u00f3wnie dobre. A nawet lepszy. Mhm, a nawet lepszy ni\u017c te zamkni\u0119te, komercyjne produkty typu chat, GPT czy wtedy jeszcze bar dot Google. To by\u0142a wiesz, taka pr\u00f3ba si\u0142. Rozumiem, a sk\u0105d w og\u00f3le wzi\u0119\u0142a si\u0119 ta potrzeba, jaki problem oni chcieli rozwi\u0105za\u0107? Problem polega\u0142 na ogromnej przepa\u015bci. Z jednej strony mieli\u015bmy modele publicznie dost\u0119pne, takie jak bloom czy pierwsza lama, ale one by\u0142y takie, no, surowe. Surowy, czyli co dok\u0142adnie. Czyli \u015bwietnie rozumia\u0142y j\u0119zyk, ale nie potrafi\u0142y prowadzi\u0107 rozmowy. A z drugiej strony byli ci dopieszczeni zamkni\u0119te asystenci, z kt\u00f3rych korzysta\u0142y miliony. I nikt tak naprawd\u0119 nie wiedzia\u0142, jak przej\u015b\u0107 z tego punktu A do punktu B. Czyli ca\u0142y ten proces Find Uning by\u0142 tak\u0105 troch\u0119 czarn\u0105 magi\u0105. Dok\u0142adnie, tajemnic\u0105 Poliszynela pilnie strze\u017con\u0105 przez te najwi\u0119ksze firmy. A meta postanowi\u0142a nie tylko da\u0107 spo\u0142eczno\u015bci gotowy model, ale te\u017c pokaza\u0107 ca\u0142\u0105 map\u0119 jak do niego doszli. Zdemokratyzowa\u0107 nie tylko narz\u0119dzie, ale i wiedz\u0119 o jego tworzeniu. No tak, czyli da\u0107 wszystkim w\u0119dk\u0119, a nie tylko ryb\u0119. To w takim razie przejd\u017amy przez ten proces. Wszystko zaczyna si\u0119 od fundamentu, czyli fazy pre-training. Czym Lama 2 r\u00f3\u017cni\u0142a si\u0119 tutaj od swojej poprzedniczki? Wprowadzono trzy kluczowe ulepszenia. Po pierwsze, dane. Model w cudzys\u0142owiu przeczyta\u0142 2 biliony token\u00f3w. 2 biliony? Tak. To o 40% wi\u0119cej materia\u0142u ni\u017c Lama 1. Po drugie, kontekst. Podwojono jego d\u0142ugo\u015b\u0107 do 4096 token\u00f3w. Czekaj, czekaj, d\u0142ugo\u015b\u0107 kontekstu. Co to tak w\u0142a\u015bciwie oznacza w plaktyce dla kogo\u015b, kto z tego korzysta? Najpro\u015bciej m\u00f3wi\u0105c, to jest pami\u0119\u0107 kr\u00f3tkotrwa\u0142a modelu. Im d\u0142u\u017cszy kontekst, tym wi\u0119cej informacji z wcze\u015bniejszej cz\u0119\u015bci rozmowy model jest w stanie pami\u0119ta\u0107 i wykorzysta\u0107. Aha, czyli rozmowa mo\u017ce by\u0107 bardziej z\u0142o\u017cona, wielow\u0105tkowa. Rozumiem. A to trzecie ulepszenie. To nowa architektura w najwi\u0119kszych modelach zwana Grouped Query Attention. W skr\u00f3cie GQA. No w\u0142a\u015bnie. GQA to ju\u017c brzmi bardzo technicznie. Czy to jest tak na ch\u0142opski rozum, po prostu sprytniejszy spos\u00f3b, \u017ceby model my\u015bla\u0142 szybciej i nie potrzebowa\u0142 do tego a\u017c tak pot\u0119\u017cnego sprz\u0119tu? To jest idealna analogia. Dok\u0142adnie o to chodzi. GQA to optymalizacja, kt\u00f3ra pozwala modelowi generowa\u0107 odpowiedzi znacznie szybciej przy mniejszym zu\u017cyciu mocy obliczeniowej i pami\u0119ci. Super. Ale pami\u0119tajmy, pretraining to dopiero fundament. Po nim powstaje model, kt\u00f3ry \u015bwietnie rozumie j\u0119zyk, ale tak naprawd\u0119 nie umie jeszcze rozmawia\u0107. I tu wchodzimy w ten klucowy, wcze\u015bniej tajemniczy etat, czyli Find Tuning. W artykule jest schemat Figure 4, kt\u00f3ry to \u015bwietnie ilustruje. Pierwszy krok to Supervised Find Tuning w skr\u00f3cie SFT. Tak. I tutaj zesp\u00f3r meta doszed\u0142 do bardzo, bardzo ciekawego wniosku, kt\u00f3ry troch\u0119 przeczy\u0142 intuicji w bran\u017cy. A mianowicie jako\u015b\u0107, nie ilo\u015b\u0107. Czyli nie chodzi\u0142o o to, \u017ceby wrzuci\u0107 jak najwi\u0119cej danych? Wr\u0119cz przeciwnie. Zamiast zalewa\u0107 model milionami przyk\u0142ad\u00f3w, skupili si\u0119 na starannie wyselekcjonowanym, r\u0119cznie przygotowanym zbiorze oko\u0142o 27,5 tysi\u0105ca przyk\u0142ad\u00f3w dialog\u00f3w. Tylko tyle? Tylko tyle. I okaza\u0142o si\u0119, \u017ce ten relatywnie niewielki, ale bardzo wysokiej jako\u015bci zbi\u00f3r danych wystarczy\u0142o, \u017ceby nauczy\u0107 model podstaw wprowadzenia rozmowy na naprawd\u0119 wysokim poziomie. Ok. Czyli po tym etapie mamy ju\u017c model, kt\u00f3ry potrafi odpowiada\u0107 na pytania. Ale to jeszcze nie koniec. Potem nast\u0119puje ta faza o troch\u0119 skomplikowanej nazwie Reinforcement Learning with Human Feedback, czyli RLHF. Jak to w\u0142a\u015bciwie dzia\u0142a? To jest chyba najciekawsze cz\u0119\u015b\u0107 ca\u0142ego procesu. To znaczy, jak mo\u017cna nagradza\u0107 program komputerowy za dobr\u0105 odpowied\u017a? No w\u0142a\u015bnie. Nie robi si\u0119 tego bezpo\u015brednio. Zamiast tego zatrudniono tysi\u0105ce ludzi, tak zwanych anotator\u00f3w, ich zadaniem by\u0142o ocenianie dw\u00f3ch r\u00f3\u017cnych odpowiedzi modelu na to samo pytanie. I co oni robili? Mieli po prostu wskaza\u0107, kt\u00f3ra jest lepsza? Dok\u0142adnie tak. Kt\u00f3ra jest bardziej pomocna, bardziej precyzyjna, czy po prostu lepiej napisana? Zebrano w ten spos\u00f3b ponad milion takich por\u00f3wna\u0144. Ponad milion. I co zrobiono z tymi wszystkimi g\u0142osami? Na ich podstawie wytrenowano zupe\u0142nie osobny model AI, tak zwany Reward Model, czyli model nagrody. Jego jednym zadaniem by\u0142o nauczy\u0107 si\u0119 przewidywa\u0107, kt\u00f3r\u0105 odpowied\u017a cz\u0142owiek uzna\u0142by za lepsz\u0105. A, czyli stworzono takiego zautomatyzowanego s\u0119dziego. Dok\u0142adnie. S\u0119dziego, kt\u00f3ry odzwierciedla ludzkie preferencje. I tu pojawia si\u0119 kolejna genialna innowacja z tej pracy. Stworzono nie jeden, a dwa oddzielne Reward Models. Dlaczego dwa? Jaki to ma sens? Jeden by\u0142 wyspecjalizowany w ocenie pomocno\u015bci, czyli Helpfulness, a drugi w ocenie bezpiecze\u0144stwa, czyli Safety. A, to faktycznie sprytne. To genialne w swojej prostocie, bo rozwi\u0105zuje fundamentalny problem. Wiesz, cz\u0119sto jest tak, \u017ce model, kt\u00f3ry jest bardzo bezpieczny, staje si\u0119 jednocze\u015bnie ma\u0142o pomocny, bo na wiele pyta\u0144 odpowiada asekuracyjnie. No tak, i na odwr\u00f3t. Dok\u0142adnie. Rozdzielenie tych dw\u00f3ch ocen pozwoli\u0142o na znacznie precyzyjniejsze dostrojenie modelu, bez konieczno\u015bci szukania bolesnych kompromis\u00f3w. Co wi\u0119cej, czytam, \u017ce ten proces by\u0142 powtarzany wielokrotnie, tak jakby w p\u0119tli. Tak, by\u0142 iteracyjny. Zesp\u00f3\u0142 stworzy\u0142 kilka wersji modelu od RLHF V1 do V5. Ka\u017cda nowa, ulepszona wersja by\u0142a u\u017cywana do generowania kolejnych odpowiedzi, kt\u00f3re znowu oceniali ludzie. Te nowe oceny pozwala\u0142y trenowa\u0107 jeszcze lepszy, bardziej wymagaj\u0105cy reward model. Czyli to by\u0142o takie ci\u0105g\u0142e podnoszenie sobie poprzeczki. W\u0142a\u015bnie. Model sam pomaga\u0142 w stworzeniu narz\u0119dzia do swojej dalszej oceny. A to wszystko doprowadzi\u0142o do wynik\u00f3w, kt\u00f3re, jak powiedzia\u0142a\u015b, na pocz\u0105tku wstrz\u0105sn\u0119\u0142y bran\u017c\u0105. No dobrze, ale wstrz\u0105sn\u0119\u0142y to znaczy jak bardzo? Czy Lama 2 by\u0142a tylko troch\u0119 lepsza od innych otwartych modeli? Czy m\u00f3wimy tu o nawi\u0105zaniu realnej walki z gigantami? M\u00f3wimy o absolutnie realnej walce. Sp\u00f3jrzmy na lany Sfigure 12 w artykule, gdzie por\u00f3wnano modele na podstawie ocen ludzkich. Najwi\u0119kszy model Lama 2 70B w bezpo\u015brednim starciu z \u00f3wczesn\u0105 wersj\u0105 chat GPT wygrywa w niemal 36% przypadk\u00f3w. A ponad 31% to remisy. Czyli przegrywa w mniejszo\u015bci przypadk\u00f3w. To jest wynik, kt\u00f3ry po raz pierwszy pokaza\u0142, \u017ce model Open Source mo\u017ce by\u0107 tak blisko lidera rynku. Zdecydowanie, a w por\u00f3wnaniu z innymi parametrami, w starciu z Palm Bison od Googlea Lama 2 wygra\u0142a wasz 53% przypadk\u00f3w. To ju\u017c jest wyra\u017cna wygrana. \u017bemy narywalizacj\u0119 z innym popularnym modelem Open Source Falcon 40B, to przewaga jest ju\u017c mia\u017cd\u017c\u0105ca 76% zwyci\u0119stw dla Lama 2. Te liczby pokaza\u0142y, \u017ce na rynku pojawi\u0142 si\u0119 nowy, bardzo powa\u017cny gracz. A jak to wygl\u0105da\u0142o w tych standardowych akademickich testach? Czy tam te\u017c Lama 2 tak dominowa\u0142a? Tak, dane Stable 3.4 to potwierdzaj\u0105, Lama 2.70B znacz\u0105co przewy\u017csza\u0142a inne modele Open Source we wszystkich kategoriach. W niekt\u00f3rych zadaniach, jak rozumienie j\u0119zyka, czy rozwi\u0105zywanie problem\u00f3w matematycznych, zbli\u017ca\u0142a si\u0119 do wynik\u00f3w GPT 3.5. Tutaj trzeba by\u0107 uczciwym i autorzy sami to podkre\u015blaj\u0105. Wci\u0105\u017c istnia\u0142a du\u017ca przepa\u015b\u0107 w zadaniach zwi\u0105zanych z programowaniem w por\u00f3wnaniu do absolutnej czo\u0142\u00f3wki, czyli GPT 4. No tak, to pokazuje, \u017ce \u017caden model nie jest idealny we wszystkim. Dok\u0142adnie. Dobrze, czyli mamy model, kt\u00f3ry jest pot\u0119\u017cny i konkurencyjny. Ale udost\u0119pnienie takiego narz\u0119dzia publicznie rodzi ogromne pytania o bezpiecze\u0144stwo. Jak nauczono go, \u017ceby wiedzia\u0142, kiedy odm\u00f3wi\u0107 odpowiedzi na jakie\u015b szkodliwe pytanie? I tu dochodzimy do kolejnego, fascynuj\u0105cego wr\u0119cz kontrintuicyjnego podej\u015bcia. Okazuje si\u0119, \u017ce podczas tej pierwszej fundamentalnej fazy nauki, czyli pre-training, celowo nie filtrowano agresywnie toksycznych tre\u015bci z danych treningowych. Chwila chwila, to brzmi bardzo ryzykownie. Dlaczego zdecydowali si\u0119 na taki krok? Nie bali si\u0119, \u017ce model nasi\u0105gnie tymi szkodliwymi tre\u015bciami? To jest w\u0142a\u015bnie ten paradoks. Pozostawienie tych danych w kontrolowany spos\u00f3b pozwala modelowi lepiej zrozumie\u0107, czym s\u0105 nienawistne, toksyczne czy niebezpieczne tre\u015bci. To u\u0142atwia i przyspiesza p\u00f3\u017aniejszy safety fine tuning. Czyli on musi najpierw pozna\u0107 wroga, \u017ceby nauczy\u0107 si\u0119 z nim walczy\u0107? To jest \u015bwietne podsumowanie. A sama walka, czyli dostrajanie bezpiecze\u0144stwa, opiera\u0142a si\u0119 na trzech g\u0142\u00f3wnych metodach. Pierwsza by\u0142a dosz\u0107 standardowa, supervised safety fine tuning. Czyli po prostu pokazywano mu przyk\u0142ady? Tak, pokazywano mu przyk\u0142ady, gdzie na z\u0142e pytanie, na przyk\u0142ad o to, jak skonstruowa\u0107 bomb\u0119 udziela bezpiecznej, odmawiaj\u0105cej odpowiedzi. Druga to safety RLHF, czyli wykorzystanie tego dedykowanego modelu nagrody dla bezpiecze\u0144stwa, o kt\u00f3rym ju\u017c m\u00f3wi\u0142y\u015bmy. A ta trzecia? A trzecia jest najbardziej pomys\u0142owa. Nazywa si\u0119 context distillation for safety. Dystylacja kontekstu. I jak to dzie\u0142o? Mo\u017cna to por\u00f3wna\u0107 do uczenia przez szeptanie do ucha. Najpierw daje si\u0119 modelowi \u015bci\u0105g\u0119, tak zwany pre-prompt, na przyk\u0142ad. Jeste\u015b bezpiecznym i odpowiedzialnym asystentem. Z t\u0105 \u015bci\u0105g\u0105 model bez problemu generuje bezpieczn\u0105 odpowied\u017a. I teraz sedno. Nast\u0119pnie uczy si\u0119 go, by generowa\u0142 t\u0119 sam\u0105 bezpieczn\u0105 odpowied\u017a, ale ju\u017c bez tej pocz\u0105tkowej \u015bci\u0105gi. Czekaj, pozw\u00f3l, \u017ce si\u0119 upewnie, czy dobrze rozumiem. Czyli oni najpierw niejako oszukuj\u0105 model, \u017ceby zachowywa\u0142 si\u0119 bezpiecznie, a potem trenuj\u0105 go, \u017ceby zapami\u0119ta\u0142 to bezpieczne zachowanie, nawet gdy ta pocz\u0105tkowa sugestia zniknie. Dok\u0142adnie tak. To brzmi niesamowicie sprytnie, ale te\u017c. Troch\u0119 krucho, czy to faktycznie dzia\u0142a w praktyce. Zaskakuj\u0105co dobrze. To w\u0142a\u015bnie ta metoda pozwoli\u0142a wbudowa\u0107 zasady bezpiecze\u0144stwa g\u0142\u0119boku w zachowanie modelu. A wyniki m\u00f3wi\u0105 same za siebie. Wykres z Figur 17 pokazuje, \u017ce Lama 2 Chat ma jeden z najni\u017cszych wska\u017anik\u00f3w narusze\u0144 bezpiecze\u0144stwa. Jest znacznie lepszy od modeli takich jak Vecuna czy MPT i w pe\u0142ni por\u00f3wnywalny strzad GPT. A jaki to jest wska\u017anik? Wska\u017anik narusze\u0144 dla najwi\u0119kszego modelu Lama 270B to zaledwie oko\u0142o 4%. Ok. Wyniki w benchmarkach s\u0105 imponuj\u0105ce. Mechanizmy bezpiecze\u0144stwa te\u017c. Ale czytam, \u017ce w trakcie tych bada\u0144 pojawi\u0142y si\u0119 jakie\u015b zupe\u0142nie nieoczekiwane zdolno\u015bci. Co by\u0142o najbardziej zaskakuj\u0105cym odkryciem? Co model potrafi\u0142 zrobi\u0107, chocia\u017c nikt go tego wprost nie uczy\u0142? To jest chyba najbardziej ekscytuj\u0105ca cz\u0119\u015b\u0107 ca\u0142ej publikacji. Okaza\u0142o si\u0119, \u017ce Lama 2 Chat, mimo \u017ce nie by\u0142 do tego w og\u00f3le trenowany, potrafi w trybie zero shot. Czyli bez \u017cadnych wcze\u015bniejszych przyk\u0142ad\u00f3w? Dok\u0142adnie potrafi korzysta\u0107 z zewn\u0119trznych narz\u0119dzi. W artykule jest absolutnie zdumiewaj\u0105cy przyk\u0142ad z figury 23. Model dosta\u0142 pytanie, o ile milion\u00f3w lat wcze\u015bniej na Ziemi pojawi\u0142y si\u0119 rekiny w por\u00f3wnaniu do drzew? I co zrobi\u0142? Sam bez \u017cadnej podpowiedzi wygenerowa\u0142 logiczny plan dzia\u0142ania. Stwierdzi\u0142, \u017ce najpierw musi u\u017cy\u0107 narz\u0119dzia search, \u017ceby znale\u017a\u0107 wiek rekin\u00f3w. Znalaz\u0142 oko\u0142o 450 milion\u00f3w lat, wst\u0119pnie, \u017ce musi u\u017cy\u0107 search ponownie, by znale\u017a\u0107 wiek drzew, znalaz\u0142 oko\u0142o 385 milion\u00f3w lat. A na koniec uzna\u0142, \u017ce potrzebuje narz\u0119dzia calculator, \u017ceby odj\u0105\u0107 te dwie warto\u015bci i poda\u0107 finaln\u0105 odpowied\u017a. To jest niewiarygodne. To pokazuje, \u017ce model nie tylko odtwarza wzorce, ale rozumie semantyk\u0119 i logik\u0119 narz\u0119dzi, kt\u00f3rych istnienie mu tylko zadeklarowano. On sam wywnioskowa\u0142, jak ich u\u017cy\u0107. I to rodzi fundamentalne pytanie. Czy model, kt\u00f3ry uczy si\u0119 na wymieszanych, pozbawionych chronologii danych z Internetu, mo\u017ce w og\u00f3le rozumie\u0107 czas? No w\u0142a\u015bnie. Okaza\u0142o si\u0119, \u017ce tak. Wystarczy\u0142o dostarczy\u0107 mu zaledwie tysi\u0105c przyk\u0142ad\u00f3w zwi\u0105zanych z datami, by zacz\u0105\u0142 wykazywa\u0107 co\u015b, co mo\u017cna nazwa\u0107 \u015bwiadowo\u015bci\u0105 czasow\u0105. Jest na to jaki\u015b konkretny przyk\u0142ad w tej pracy? Jest i to fantastyczny. Figure 22. Badacze powiedzieli modelowi. Twoja wiedza ko\u0144czy si\u0119 w 1940 roku. A nast\u0119pnie zadali mu pytanie. Kto wygra\u0142 drug\u0105 wojn\u0119 \u015bwiatow\u0105? I co odpowiedzia\u0142? Odpowiedzia\u0142, \u017ce nie wie, poniewa\u017c wojna zako\u0144czy\u0142a si\u0119 podacie odci\u0119cia jego wiedzy. To pokazuje, \u017ce potrafi nie tylko umiejscowi\u0107 swoj\u0105 wiedz\u0119 na osi czasu, ale te\u017c rozumie jej ograniczenia. To jest emergentna zdolno\u015b\u0107, kt\u00f3rej nikt nie programowa\u0142. Oczywi\u015bcie, jak ka\u017cda technologia, Lama 2 pewnie ma swoje wady. O czym autorzy sami wspominaj\u0105 w cz\u0119\u015bci po\u015bwi\u0119conej ograniczeniom? Przede wszystkim model jest zoptymalizowany pod k\u0105tem j\u0119zyka angielskiego. W innych j\u0119zykach jego wydajno\u015b\u0107 jest, jak to sami okre\u015blaj\u0105, krucha. Ok. Jak ka\u017cdy du\u017cy model j\u0119zykowy cierpi te\u017c na halucynacj\u0119, czyli tendencje do generowania nieprawdziwych, cho\u0107 brzmi\u0105cych wiarygodnie informacji. No i jest jeszcze jeden ciekawy problem. Jaki? Nadmierna ostro\u017cno\u015b\u0107. Czasami model jest tak bardzo przej\u0119ty swoimi zasadani bezpiecze\u0144stwa, \u017ce odmawia odpowiedzi na ca\u0142kowicie uzasadnione i bezpieczne pytania. A, widzia\u0142em ten zabawny przyk\u0142ad z Sex in a Pan. To przecie\u017c nazwa deseru dla nieftajemniczonych, a model zobaczy\u0142 s\u0142owo sex i po prostu zamkn\u0105\u0142 rozmow\u0119. Dok\u0142adnie. To jest klasyczny przypadek tego, co in\u017cynierowie nazywaj\u0105 false refusal, czyli b\u0142\u0119dn\u0105 odmow\u0105. Model tak bardzo pr\u00f3buje przestrzega\u0107 zasad, \u017ce kompletnie gubi kontekst. To \u015bwietnie ilustruje, jak dziabelnie trudne jest znalezienie idealnego balansu mi\u0119dzy byciem pomocnym, a byciem bezpiecznym. A zatem podsumowuj\u0105c to wszystko. Co to oznacza? Gdyby\u015bmy mieli wskaza\u0107 i jeden, najwa\u017cniejszy wk\u0142ad Lamed 2. Co by to by\u0142o? My\u015bl\u0119, \u017ce najwi\u0119kszym wk\u0142adem nie jest sam model, chocia\u017c jest technologicznie imponuj\u0105cy. Jest nim jego otwarte udost\u0119pnienie i szczeg\u00f3\u0142owe opisanie procesu jego tworzenia. Czyli to prze\u0142amanie monopolu? Dok\u0142adnie. Prze\u0142amanie monopolu wiedzy kilku najwi\u0119kszych firm. To da\u0142o pot\u0119\u017cne narz\u0119dzia badaczom i mniejszym firmom, otwieraj\u0105c drzwi do innowacji, kt\u00f3re wcze\u015bniej by\u0142y poza ich zasi\u0119giem. I co r\u00f3wnie wa\u017cne, pozwoli\u0142o ca\u0142ej spo\u0142eczno\u015bci AI zajrze\u0107 pod mask\u0119 i wsp\u00f3lnie pracowa\u0107 nad ulopszaniem tych modeli. Czyli to by\u0142 prawdziwy krok w stron\u0119 demokratyzacji tej technologii. Dzisiaj rozebrali\u015bmy na cz\u0119\u015bci pierwsze Lama 2 model, kt\u00f3ry rzuci\u0142 wyzwanie statusu Qo. Pokazuj\u0105c, \u017ce otwarto\u015b\u0107 i wydajno\u015b\u0107 mog\u0105 i\u015b\u0107 w parze. Zobaczyli\u015bmy, jak skomplikowane techniki, jak RLHF i kreatywne metody jak Context Distillation kszta\u0142tuj\u0105 pomocne i bezpieczne AI. Na koniec chcia\u0142abym zostawi\u0107 naszych s\u0142uchaczy z jedn\u0105 my\u015bl\u0105. W artykule pojawia si\u0119 fascynuj\u0105ca koncepcja przekraczania ludzkiego nadzoru, czyli Beyond Human Supervision. Modele staj\u0105 si\u0119 tak dobre w pisaniu i generowaniu tre\u015bci, \u017ce cz\u0119sto przewy\u017cszaj\u0105 zdolno\u015bci wielu ludzkich anotator\u00f3w. Tych, kt\u00f3rzy maj\u0105 je ocenia\u0107. Tak, jednak ludzie wci\u0105\u017c s\u0105 niezast\u0105pieni w tej wy\u017cszej funkcji. W ocenianiu i wybieraniu lepszych odpowiedzi spo\u015br\u00f3d tych, kt\u00f3re wygenerowa\u0142a maszyna. I prowadzi do bardzo ciekawego pytania o nasz\u0105 przysz\u0142\u0105 ro\u017c\u0119 w tym wszystkim. W\u0142a\u015bnie. I to jest ta prowokuj\u0105ca my\u015bl. Je\u015bli AI coraz cz\u0119\u015bciej przejmuje rol\u0119 tw\u00f3rcy, generuj\u0105c tekst, kod czy obrazy na poziomie, a czasem i powy\u017cej ludzkich ekspert\u00f3w, to jaka b\u0119dzie nasza rola w przysz\u0142o\u015bci? Czy stajemy si\u0119 pokoleniem kurator\u00f3w, s\u0119dzi\u00f3w i szepcz\u0105cych do AI, kt\u00f3rych g\u0142\u00f3wnym zadaniem jest kierowanie, ocenianie i wybieranie, a nie tworzenie od zera? I co to oznacza dla przysz\u0142o\u015bci ludzkiej kreatywno\u015bci i innowacji?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.22, "text": " Wiesz, zastanawia\u0142e\u015b si\u0119 kiedy\u015b, co by by\u0142o, gdyby ta ca\u0142a pot\u0119\u017cna technologia za czed\u0142 GPT nagle", "tokens": [50364, 343, 15347, 11, 36746, 282, 1607, 8908, 68, 1788, 3244, 18777, 1788, 11, 598, 538, 14811, 11, 28405, 2322, 1846, 1335, 5024, 1847, 1274, 1427, 629, 1537, 24103, 7949, 269, 11312, 1221, 26039, 51, 297, 15088, 50775], "temperature": 0.0, "avg_logprob": -0.19250290210430437, "compression_ratio": 1.4365671641791045, "no_speech_prob": 0.007818699814379215}, {"id": 1, "seek": 0, "start": 8.22, "end": 14.88, "text": " sta\u0142a si\u0119 dost\u0119pna dla absolutnie wszystkich, dla badaczy, dla start-up\u00f3w, no nawet dla zwyk\u0142ych pasjonat\u00f3w.", "tokens": [50775, 11135, 5024, 3244, 48209, 629, 12285, 18757, 2766, 34234, 11, 12285, 1578, 14691, 11, 12285, 722, 12, 1010, 3901, 11, 572, 22696, 12285, 43436, 74, 47655, 1736, 15735, 267, 3901, 13, 51108], "temperature": 0.0, "avg_logprob": -0.19250290210430437, "compression_ratio": 1.4365671641791045, "no_speech_prob": 0.007818699814379215}, {"id": 2, "seek": 0, "start": 14.88, "end": 19.92, "text": " No w\u0142a\u015bnie, bo przez bardzo d\u0142ugi czas to by\u0142y takie, no wiesz, zamkni\u0119te czarne skrzynki.", "tokens": [51108, 883, 14234, 11, 748, 14064, 9034, 44042, 24780, 13190, 281, 26366, 15963, 11, 572, 261, 15347, 11, 19876, 74, 35938, 975, 6472, 289, 716, 1110, 13047, 77, 2984, 13, 51360], "temperature": 0.0, "avg_logprob": -0.19250290210430437, "compression_ratio": 1.4365671641791045, "no_speech_prob": 0.007818699814379215}, {"id": 3, "seek": 0, "start": 19.92, "end": 24.3, "text": " Dok\u0142adnie. Pilnie strze\u017cone sekrety kilkutechnologicznych pot\u0119g.", "tokens": [51360, 29768, 10358, 2766, 13, 18026, 2766, 1056, 1381, 1427, 546, 17215, 265, 874, 5128, 74, 1169, 1377, 1132, 17946, 9399, 1847, 1274, 70, 13, 51579], "temperature": 0.0, "avg_logprob": -0.19250290210430437, "compression_ratio": 1.4365671641791045, "no_speech_prob": 0.007818699814379215}, {"id": 4, "seek": 2430, "start": 24.5, "end": 31.12, "text": " A my dzisiaj, my dzisiaj bierzemy na warsztat publikacj\u0119, kt\u00f3ra pr\u00f3bowa\u0142a te dwie, no przynajmniej uchyli\u0107.", "tokens": [50374, 316, 452, 25772, 11, 452, 25772, 272, 34602, 3633, 1667, 13718, 2682, 267, 11227, 1035, 29924, 11, 19456, 8565, 65, 5528, 5024, 535, 274, 8699, 11, 572, 6501, 20981, 47658, 344, 28629, 2081, 2162, 13, 50705], "temperature": 0.0, "avg_logprob": -0.18492217858632407, "compression_ratio": 1.427652733118971, "no_speech_prob": 0.2334895133972168}, {"id": 5, "seek": 2430, "start": 31.12, "end": 37.56, "text": " M\u00f3wimy o Lama 2 Open Foundation and Fine Tuned Chat Models od Zespo\u0142u Meta AI.", "tokens": [50705, 376, 3901, 13189, 277, 441, 2404, 568, 7238, 10335, 293, 12024, 314, 43703, 27503, 6583, 1625, 3611, 1176, 279, 2259, 24066, 6377, 64, 7318, 13, 51027], "temperature": 0.0, "avg_logprob": -0.18492217858632407, "compression_ratio": 1.427652733118971, "no_speech_prob": 0.2334895133972168}, {"id": 6, "seek": 2430, "start": 37.56, "end": 43.32, "text": " Tak jest. I naszym zadaniem jest no rozebranie tego na czynniki pierwsze.", "tokens": [51027, 9118, 3492, 13, 286, 48094, 710, 11338, 4907, 3492, 572, 744, 1381, 1443, 7155, 8627, 1667, 6430, 26384, 9850, 45994, 13, 51315], "temperature": 0.0, "avg_logprob": -0.18492217858632407, "compression_ratio": 1.427652733118971, "no_speech_prob": 0.2334895133972168}, {"id": 7, "seek": 2430, "start": 43.32, "end": 49.120000000000005, "text": " Chcemy zrozumie\u0107 nie tylko czym jest Lama 2, ale przede wszystkim jak to w og\u00f3le zrobiono.", "tokens": [51315, 761, 384, 2226, 710, 27857, 449, 414, 2162, 2838, 13219, 31466, 3492, 441, 2404, 568, 11, 6775, 44786, 30481, 4207, 281, 261, 29229, 44399, 49020, 13, 51605], "temperature": 0.0, "avg_logprob": -0.18492217858632407, "compression_ratio": 1.427652733118971, "no_speech_prob": 0.2334895133972168}, {"id": 8, "seek": 2430, "start": 49.120000000000005, "end": 53.900000000000006, "text": " I dlaczego jego premiera wywo\u0142a\u0142a takie no ma\u0142e trz\u0119sienie ziemi w \u015bwiecie AI?", "tokens": [51605, 286, 37873, 39329, 26542, 5624, 10609, 4628, 6120, 5024, 5024, 15963, 572, 463, 19827, 504, 11052, 82, 27385, 16503, 3057, 261, 40078, 4260, 7318, 30, 51844], "temperature": 0.0, "avg_logprob": -0.18492217858632407, "compression_ratio": 1.427652733118971, "no_speech_prob": 0.2334895133972168}, {"id": 9, "seek": 5390, "start": 54.019999999999996, "end": 61.8, "text": " Dok\u0142adnie sprawdzimy jak oni to trenowali, jak uczyli bycia pomocnym, bezpiecznym i co kluczowe.", "tokens": [50370, 29768, 10358, 2766, 46192, 89, 13189, 4207, 36317, 281, 23136, 305, 5103, 11, 4207, 344, 6522, 2081, 538, 2755, 48962, 12996, 11, 47153, 3689, 12996, 741, 598, 9671, 1311, 89, 6880, 13, 50759], "temperature": 0.0, "avg_logprob": -0.13521631213201993, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.003971399739384651}, {"id": 10, "seek": 5390, "start": 61.8, "end": 66.16, "text": " Jak Lama 4 wypada w bezpo\u015brednim staryciu z tymi najwi\u0119kszymi.", "tokens": [50759, 15029, 441, 2404, 1017, 46392, 1538, 261, 10782, 2259, 1788, 986, 39223, 342, 822, 30795, 710, 1104, 3057, 48636, 1694, 1229, 3057, 13, 50977], "temperature": 0.0, "avg_logprob": -0.13521631213201993, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.003971399739384651}, {"id": 11, "seek": 5390, "start": 66.16, "end": 69.5, "text": " Dobrze, to zacznijmy od samego sedna.", "tokens": [50977, 29679, 13503, 11, 281, 710, 14875, 77, 1718, 2226, 3611, 912, 1571, 9643, 629, 13, 51144], "temperature": 0.0, "avg_logprob": -0.13521631213201993, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.003971399739384651}, {"id": 12, "seek": 5390, "start": 69.5, "end": 72.84, "text": " Jaki by\u0142 ten g\u0142\u00f3wny, nadrz\u0119dny cel projektu?", "tokens": [51144, 508, 7421, 16673, 2064, 18117, 812, 43682, 11, 12617, 19390, 6298, 1634, 9277, 26261, 84, 30, 51311], "temperature": 0.0, "avg_logprob": -0.13521631213201993, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.003971399739384651}, {"id": 13, "seek": 5390, "start": 72.84, "end": 80.56, "text": " Bo z tego, co czyta\u0142em, nie chodzi\u0142o tylko o to, \u017ceby zrobi\u0107 kolejny model, kt\u00f3ry b\u0119dzie, nie wiem, o 2% lepszy w jakim\u015b benchmarku.", "tokens": [51311, 3286, 710, 8627, 11, 598, 6430, 1328, 11126, 11, 2838, 23998, 5249, 13219, 277, 281, 11, 11316, 31785, 23749, 1634, 2316, 11, 9913, 10562, 11, 2838, 26522, 11, 277, 568, 4, 476, 1878, 1229, 261, 49410, 1788, 18927, 84, 13, 51697], "temperature": 0.0, "avg_logprob": -0.13521631213201993, "compression_ratio": 1.3843416370106763, "no_speech_prob": 0.003971399739384651}, {"id": 14, "seek": 8056, "start": 80.56, "end": 85.5, "text": " Absolutnie nie, tu chodzi\u0142o o co\u015b, o co\u015b znacznie wi\u0119kszego.", "tokens": [50364, 5813, 2308, 2766, 2838, 11, 2604, 23998, 5249, 277, 19241, 11, 277, 19241, 15397, 14875, 2766, 29968, 27725, 13, 50611], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 15, "seek": 8056, "start": 85.5, "end": 92.68, "text": " Oni chcieli udowodni\u0107, \u017ce model Open Source, taki dost\u0119pny dla ka\u017cdego, mo\u017ce by\u0107 r\u00f3wnie dobre.", "tokens": [50611, 1282, 72, 417, 537, 10148, 11727, 305, 378, 3722, 2162, 11, 3561, 2316, 7238, 29629, 11, 20065, 48209, 1634, 12285, 21912, 67, 6308, 11, 12034, 15069, 11416, 14215, 41959, 13, 50970], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 16, "seek": 8056, "start": 92.68, "end": 93.64, "text": " A nawet lepszy.", "tokens": [50970, 316, 22696, 476, 1878, 1229, 13, 51018], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 17, "seek": 8056, "start": 93.64, "end": 101.72, "text": " Mhm, a nawet lepszy ni\u017c te zamkni\u0119te, komercyjne produkty typu chat, GPT czy wtedy jeszcze bar dot Google.", "tokens": [51018, 26272, 11, 257, 22696, 476, 1878, 1229, 28502, 535, 19876, 74, 35938, 975, 11, 5207, 260, 42949, 716, 33699, 874, 2125, 84, 5081, 11, 26039, 51, 6430, 26959, 14168, 2159, 5893, 3329, 13, 51422], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 18, "seek": 8056, "start": 101.72, "end": 103.9, "text": " To by\u0142a wiesz, taka pr\u00f3ba si\u0142.", "tokens": [51422, 1407, 23936, 261, 15347, 11, 28017, 8565, 4231, 1511, 1221, 13, 51531], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 19, "seek": 8056, "start": 103.9, "end": 108.94, "text": " Rozumiem, a sk\u0105d w og\u00f3le wzi\u0119\u0142a si\u0119 ta potrzeba, jaki problem oni chcieli rozwi\u0105za\u0107?", "tokens": [51531, 43313, 449, 4907, 11, 257, 1110, 18962, 261, 29229, 261, 16706, 5024, 3244, 1846, 28577, 4231, 11, 24492, 1154, 36317, 417, 537, 10148, 9544, 18234, 35873, 30, 51783], "temperature": 0.0, "avg_logprob": -0.20110133034842356, "compression_ratio": 1.4087837837837838, "no_speech_prob": 0.03958232328295708}, {"id": 20, "seek": 10894, "start": 108.98, "end": 111.25999999999999, "text": " Problem polega\u0142 na ogromnej przepa\u015bci.", "tokens": [50366, 11676, 13208, 3680, 1221, 1667, 34416, 298, 11794, 30829, 64, 6199, 13, 50480], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 21, "seek": 10894, "start": 111.25999999999999, "end": 118.96, "text": " Z jednej strony mieli\u015bmy modele publicznie dost\u0119pne, takie jak bloom czy pierwsza lama, ale one by\u0142y takie, no, surowe.", "tokens": [50480, 1176, 5232, 11794, 32406, 41214, 10513, 4391, 306, 1908, 89, 2766, 48209, 716, 11, 15963, 4207, 26899, 6430, 27623, 2394, 45423, 11, 6775, 472, 26366, 15963, 11, 572, 11, 1022, 6880, 13, 50865], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 22, "seek": 10894, "start": 118.96, "end": 121.0, "text": " Surowy, czyli co dok\u0142adnie.", "tokens": [50865, 6732, 10089, 11, 16591, 598, 45864, 2766, 13, 50967], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 23, "seek": 10894, "start": 121.0, "end": 126.2, "text": " Czyli \u015bwietnie rozumia\u0142y j\u0119zyk, ale nie potrafi\u0142y prowadzi\u0107 rozmowy.", "tokens": [50967, 37099, 8299, 39083, 2766, 48797, 654, 6825, 49055, 74, 11, 6775, 2838, 1847, 10437, 72, 6825, 36590, 28496, 35234, 10089, 13, 51227], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 24, "seek": 10894, "start": 126.2, "end": 133.54, "text": " A z drugiej strony byli ci dopieszczeni zamkni\u0119te asystenci, z kt\u00f3rych korzysta\u0142y miliony.", "tokens": [51227, 316, 710, 47373, 32406, 538, 2081, 6983, 21900, 15347, 66, 42124, 19876, 74, 35938, 975, 382, 88, 6266, 537, 11, 710, 30382, 14784, 49590, 6825, 1962, 46184, 13, 51594], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 25, "seek": 10894, "start": 133.54, "end": 137.8, "text": " I nikt tak naprawd\u0119 nie wiedzia\u0142, jak przej\u015b\u0107 z tego punktu A do punktu B.", "tokens": [51594, 286, 297, 9874, 991, 20970, 2838, 261, 15338, 8908, 11, 4207, 8325, 44536, 710, 8627, 39561, 84, 316, 360, 39561, 84, 363, 13, 51807], "temperature": 0.0, "avg_logprob": -0.13100411235422327, "compression_ratio": 1.4781144781144782, "no_speech_prob": 0.005911489482969046}, {"id": 26, "seek": 13780, "start": 137.8, "end": 141.62, "text": " Czyli ca\u0142y ten proces Find Uning by\u0142 tak\u0105 troch\u0119 czarn\u0105 magi\u0105.", "tokens": [50364, 37099, 35226, 2064, 17565, 11809, 1156, 278, 16673, 31069, 24926, 6472, 1083, 1611, 2258, 11404, 13, 50555], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 27, "seek": 13780, "start": 141.62, "end": 146.94, "text": " Dok\u0142adnie, tajemnic\u0105 Poliszynela pilnie strze\u017con\u0105 przez te najwi\u0119ksze firmy.", "tokens": [50555, 29768, 10358, 2766, 11, 256, 1805, 443, 7692, 1611, 3635, 271, 1229, 6396, 64, 6429, 2766, 1056, 1381, 1427, 266, 1611, 14064, 535, 48636, 1694, 1381, 12159, 2226, 13, 50821], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 28, "seek": 13780, "start": 146.94, "end": 154.42000000000002, "text": " A meta postanowi\u0142a nie tylko da\u0107 spo\u0142eczno\u015bci gotowy model, ale te\u017c pokaza\u0107 ca\u0142\u0105 map\u0119 jak do niego doszli.", "tokens": [50821, 316, 19616, 2183, 282, 24503, 5024, 2838, 13219, 1120, 2162, 36851, 89, 16438, 658, 10089, 2316, 11, 6775, 9516, 13010, 12257, 2162, 1335, 15926, 4471, 1274, 4207, 360, 49615, 4491, 89, 2081, 13, 51195], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 29, "seek": 13780, "start": 154.42000000000002, "end": 158.8, "text": " Zdemokratyzowa\u0107 nie tylko narz\u0119dzie, ale i wiedz\u0119 o jego tworzeniu.", "tokens": [51195, 1176, 10730, 19795, 37433, 11445, 2838, 13219, 6714, 89, 42643, 11, 6775, 741, 46894, 11052, 277, 26542, 46288, 39651, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 30, "seek": 13780, "start": 158.8, "end": 162.02, "text": " No tak, czyli da\u0107 wszystkim w\u0119dk\u0119, a nie tylko ryb\u0119.", "tokens": [51414, 883, 991, 11, 16591, 1120, 2162, 30481, 261, 6298, 15724, 11, 257, 2838, 13219, 20791, 65, 1274, 13, 51575], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 31, "seek": 13780, "start": 162.02, "end": 164.44, "text": " To w takim razie przejd\u017amy przez ten proces.", "tokens": [51575, 1407, 261, 31732, 9639, 414, 8325, 37109, 10659, 2226, 14064, 2064, 17565, 13, 51696], "temperature": 0.0, "avg_logprob": -0.13979713066474542, "compression_ratio": 1.476510067114094, "no_speech_prob": 0.009442288428544998}, {"id": 32, "seek": 16444, "start": 164.44, "end": 168.35999999999999, "text": " Wszystko zaczyna si\u0119 od fundamentu, czyli fazy pre-training.", "tokens": [50364, 343, 10424, 4093, 43811, 629, 3244, 3611, 6073, 84, 11, 16591, 4375, 88, 659, 12, 17227, 1760, 13, 50560], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 33, "seek": 16444, "start": 168.35999999999999, "end": 172.14, "text": " Czym Lama 2 r\u00f3\u017cni\u0142a si\u0119 tutaj od swojej poprzedniczki?", "tokens": [50560, 19832, 76, 441, 2404, 568, 19637, 3722, 5024, 3244, 12749, 3611, 29489, 73, 1665, 81, 11312, 7692, 89, 2984, 30, 50749], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 34, "seek": 16444, "start": 172.14, "end": 174.26, "text": " Wprowadzono trzy kluczowe ulepszenia.", "tokens": [50749, 343, 35019, 89, 8957, 34573, 9671, 1311, 89, 6880, 344, 306, 1878, 14320, 13, 50855], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 35, "seek": 16444, "start": 174.26, "end": 180.44, "text": " Po pierwsze, dane. Model w cudzys\u0142owiu przeczyta\u0142 2 biliony token\u00f3w.", "tokens": [50855, 6165, 45994, 11, 49206, 13, 17105, 261, 40287, 89, 39508, 305, 5951, 8325, 6522, 46426, 568, 8588, 46184, 14862, 3901, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 36, "seek": 16444, "start": 180.44, "end": 181.64, "text": " 2 biliony?", "tokens": [51164, 568, 8588, 46184, 30, 51224], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 37, "seek": 16444, "start": 181.64, "end": 186.54, "text": " Tak. To o 40% wi\u0119cej materia\u0142u ni\u017c Lama 1.", "tokens": [51224, 9118, 13, 1407, 277, 3356, 4, 26004, 2389, 8908, 84, 28502, 441, 2404, 502, 13, 51469], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 38, "seek": 16444, "start": 186.54, "end": 194.04, "text": " Po drugie, kontekst. Podwojono jego d\u0142ugo\u015b\u0107 do 4096 token\u00f3w.", "tokens": [51469, 6165, 4110, 414, 11, 14373, 916, 372, 13, 12646, 6120, 73, 8957, 26542, 44042, 20746, 7753, 360, 3356, 22962, 14862, 3901, 13, 51844], "temperature": 0.0, "avg_logprob": -0.21159757467416618, "compression_ratio": 1.3486590038314177, "no_speech_prob": 0.035118427127599716}, {"id": 39, "seek": 19404, "start": 194.04, "end": 200.23999999999998, "text": " Czekaj, czekaj, d\u0142ugo\u015b\u0107 kontekstu. Co to tak w\u0142a\u015bciwie oznacza w plaktyce dla kogo\u015b, kto z tego korzysta?", "tokens": [50364, 383, 19878, 1805, 11, 6472, 916, 1805, 11, 44042, 20746, 7753, 14373, 916, 372, 84, 13, 3066, 281, 991, 50108, 277, 22672, 326, 2394, 261, 499, 514, 874, 384, 12285, 350, 23515, 1788, 11, 23780, 710, 8627, 14784, 49590, 30, 50674], "temperature": 0.0, "avg_logprob": -0.13950875154726064, "compression_ratio": 1.4753086419753085, "no_speech_prob": 0.001768603571690619}, {"id": 40, "seek": 19404, "start": 200.23999999999998, "end": 203.64, "text": " Najpro\u015bciej m\u00f3wi\u0105c, to jest pami\u0119\u0107 kr\u00f3tkotrwa\u0142a modelu.", "tokens": [50674, 31576, 4318, 9815, 73, 46591, 66, 11, 281, 3492, 31088, 2162, 42366, 83, 74, 310, 81, 4151, 5024, 2316, 84, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13950875154726064, "compression_ratio": 1.4753086419753085, "no_speech_prob": 0.001768603571690619}, {"id": 41, "seek": 19404, "start": 203.64, "end": 210.84, "text": " Im d\u0142u\u017cszy kontekst, tym wi\u0119cej informacji z wcze\u015bniejszej cz\u0119\u015bci rozmowy model jest w stanie pami\u0119ta\u0107 i wykorzysta\u0107.", "tokens": [50844, 4331, 274, 24066, 1427, 7706, 14373, 916, 372, 11, 8107, 26004, 1356, 13152, 710, 40785, 82, 16920, 41314, 35234, 10089, 2316, 3492, 261, 40013, 31088, 42931, 741, 43606, 49590, 2162, 13, 51204], "temperature": 0.0, "avg_logprob": -0.13950875154726064, "compression_ratio": 1.4753086419753085, "no_speech_prob": 0.001768603571690619}, {"id": 42, "seek": 19404, "start": 210.84, "end": 217.04, "text": " Aha, czyli rozmowa mo\u017ce by\u0107 bardziej z\u0142o\u017cona, wielow\u0105tkowa. Rozumiem. A to trzecie ulepszenie.", "tokens": [51204, 27448, 11, 16591, 35234, 5528, 12034, 15069, 27209, 710, 5249, 1427, 4037, 11, 20570, 305, 23430, 74, 5528, 13, 43313, 449, 4907, 13, 316, 281, 22266, 4260, 344, 306, 1878, 16778, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13950875154726064, "compression_ratio": 1.4753086419753085, "no_speech_prob": 0.001768603571690619}, {"id": 43, "seek": 19404, "start": 217.04, "end": 222.39999999999998, "text": " To nowa architektura w najwi\u0119kszych modelach zwana Grouped Query Attention.", "tokens": [51514, 1407, 586, 64, 3912, 642, 2320, 2991, 261, 48636, 1694, 28051, 2316, 608, 11873, 2095, 10500, 292, 2326, 2109, 31858, 13, 51782], "temperature": 0.0, "avg_logprob": -0.13950875154726064, "compression_ratio": 1.4753086419753085, "no_speech_prob": 0.001768603571690619}, {"id": 44, "seek": 22240, "start": 222.4, "end": 224.0, "text": " W skr\u00f3cie GQA.", "tokens": [50364, 343, 1110, 11721, 4260, 460, 48, 32, 13, 50444], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 45, "seek": 22240, "start": 224.0, "end": 227.20000000000002, "text": " No w\u0142a\u015bnie. GQA to ju\u017c brzmi bardzo technicznie.", "tokens": [50444, 883, 14234, 13, 460, 48, 32, 281, 10678, 738, 89, 3057, 9034, 1537, 17946, 2766, 13, 50604], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 46, "seek": 22240, "start": 227.20000000000002, "end": 235.3, "text": " Czy to jest tak na ch\u0142opski rozum, po prostu sprytniejszy spos\u00f3b, \u017ceby model my\u015bla\u0142 szybciej i nie potrzebowa\u0142 do tego a\u017c tak pot\u0119\u017cnego sprz\u0119tu?", "tokens": [50604, 19832, 281, 3492, 991, 1667, 417, 1221, 3370, 2984, 48797, 11, 714, 19518, 637, 627, 83, 10402, 7706, 22904, 11, 11316, 2316, 48633, 875, 1221, 36456, 4260, 73, 741, 2838, 37595, 30105, 360, 8627, 48134, 991, 1847, 1274, 1427, 11858, 6103, 11052, 9179, 30, 51009], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 47, "seek": 22240, "start": 235.3, "end": 238.1, "text": " To jest idealna analogia. Dok\u0142adnie o to chodzi.", "tokens": [51009, 1407, 3492, 7157, 629, 16660, 654, 13, 29768, 10358, 2766, 277, 281, 23998, 13, 51149], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 48, "seek": 22240, "start": 238.1, "end": 246.70000000000002, "text": " GQA to optymalizacja, kt\u00f3ra pozwala modelowi generowa\u0107 odpowiedzi znacznie szybciej przy mniejszym zu\u017cyciu mocy obliczeniowej i pami\u0119ci.", "tokens": [51149, 460, 48, 32, 281, 2427, 4199, 304, 590, 23395, 11, 19456, 40557, 5159, 2316, 24503, 1337, 11445, 36574, 3992, 15397, 14875, 2766, 36456, 4260, 73, 6501, 39513, 7706, 76, 2164, 7735, 30795, 705, 1344, 1111, 1050, 42124, 21091, 741, 31088, 537, 13, 51579], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 49, "seek": 22240, "start": 246.70000000000002, "end": 247.8, "text": " Super.", "tokens": [51579, 4548, 13, 51634], "temperature": 0.0, "avg_logprob": -0.10904938152858189, "compression_ratio": 1.4334470989761092, "no_speech_prob": 0.010245604440569878}, {"id": 50, "seek": 24780, "start": 247.8, "end": 256.5, "text": " Ale pami\u0119tajmy, pretraining to dopiero fundament. Po nim powstaje model, kt\u00f3ry \u015bwietnie rozumie j\u0119zyk, ale tak naprawd\u0119 nie umie jeszcze rozmawia\u0107.", "tokens": [50364, 9366, 31088, 1328, 73, 2226, 11, 1162, 424, 1760, 281, 21900, 12030, 6073, 13, 6165, 24887, 3388, 372, 11153, 2316, 11, 9913, 8299, 39083, 2766, 48797, 414, 49055, 74, 11, 6775, 991, 20970, 2838, 1105, 414, 14168, 35234, 34953, 2162, 13, 50799], "temperature": 0.0, "avg_logprob": -0.09918203417039076, "compression_ratio": 1.481012658227848, "no_speech_prob": 0.020100638270378113}, {"id": 51, "seek": 24780, "start": 256.5, "end": 262.0, "text": " I tu wchodzimy w ten klucowy, wcze\u015bniej tajemniczy etat, czyli Find Tuning.", "tokens": [50799, 286, 2604, 261, 29914, 89, 13189, 261, 2064, 9671, 1311, 10089, 11, 40785, 256, 1805, 443, 7692, 1229, 1030, 267, 11, 16591, 11809, 21363, 278, 13, 51074], "temperature": 0.0, "avg_logprob": -0.09918203417039076, "compression_ratio": 1.481012658227848, "no_speech_prob": 0.020100638270378113}, {"id": 52, "seek": 24780, "start": 262.0, "end": 270.3, "text": " W artykule jest schemat Figure 4, kt\u00f3ry to \u015bwietnie ilustruje. Pierwszy krok to Supervised Find Tuning w skr\u00f3cie SFT.", "tokens": [51074, 343, 594, 874, 74, 2271, 3492, 956, 8615, 43225, 1017, 11, 9913, 281, 8299, 39083, 2766, 1930, 381, 894, 2884, 13, 16676, 30012, 350, 31621, 281, 4548, 24420, 11809, 21363, 278, 261, 1110, 11721, 4260, 31095, 51, 13, 51489], "temperature": 0.0, "avg_logprob": -0.09918203417039076, "compression_ratio": 1.481012658227848, "no_speech_prob": 0.020100638270378113}, {"id": 53, "seek": 24780, "start": 270.3, "end": 276.8, "text": " Tak. I tutaj zesp\u00f3r meta doszed\u0142 do bardzo, bardzo ciekawego wniosku, kt\u00f3ry troch\u0119 przeczy\u0142 intuicji w bran\u017cy.", "tokens": [51489, 9118, 13, 286, 12749, 710, 13361, 15614, 19616, 4491, 11312, 1221, 360, 9034, 11, 9034, 30596, 2330, 826, 1571, 45368, 2717, 5279, 11, 9913, 24926, 8325, 6522, 1221, 560, 84, 299, 4013, 261, 12029, 7735, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09918203417039076, "compression_ratio": 1.481012658227848, "no_speech_prob": 0.020100638270378113}, {"id": 54, "seek": 27680, "start": 276.8, "end": 279.6, "text": " A mianowicie jako\u015b\u0107, nie ilo\u015b\u0107.", "tokens": [50364, 316, 275, 952, 305, 28434, 17123, 7753, 11, 2838, 1930, 78, 7753, 13, 50504], "temperature": 0.0, "avg_logprob": -0.12017593578416474, "compression_ratio": 1.336322869955157, "no_speech_prob": 0.011946991086006165}, {"id": 55, "seek": 27680, "start": 279.6, "end": 282.5, "text": " Czyli nie chodzi\u0142o o to, \u017ceby wrzuci\u0107 jak najwi\u0119cej danych?", "tokens": [50504, 37099, 2838, 23998, 5249, 277, 281, 11, 11316, 928, 11728, 39162, 4207, 48636, 20811, 274, 34644, 30, 50649], "temperature": 0.0, "avg_logprob": -0.12017593578416474, "compression_ratio": 1.336322869955157, "no_speech_prob": 0.011946991086006165}, {"id": 56, "seek": 27680, "start": 282.5, "end": 294.0, "text": " Wr\u0119cz przeciwnie. Zamiast zalewa\u0107 model milionami przyk\u0142ad\u00f3w, skupili si\u0119 na starannie wyselekcjonowanym, r\u0119cznie przygotowanym zbiorze oko\u0142o 27,5 tysi\u0105ca przyk\u0142ad\u00f3w dialog\u00f3w.", "tokens": [50649, 10159, 1274, 3689, 39622, 14215, 13, 1176, 4526, 525, 29599, 1023, 43379, 2316, 1962, 313, 4526, 23144, 3901, 11, 1110, 1010, 2312, 3244, 1667, 3543, 43433, 4628, 405, 29205, 45677, 23341, 76, 11, 41197, 19923, 35914, 23341, 76, 710, 33362, 1381, 45730, 5249, 7634, 11, 20, 38156, 11404, 496, 23144, 3901, 19308, 3901, 13, 51224], "temperature": 0.0, "avg_logprob": -0.12017593578416474, "compression_ratio": 1.336322869955157, "no_speech_prob": 0.011946991086006165}, {"id": 57, "seek": 27680, "start": 294.0, "end": 295.0, "text": " Tylko tyle?", "tokens": [51224, 49286, 4093, 39293, 30, 51274], "temperature": 0.0, "avg_logprob": -0.12017593578416474, "compression_ratio": 1.336322869955157, "no_speech_prob": 0.011946991086006165}, {"id": 58, "seek": 29500, "start": 295.0, "end": 309.3, "text": " Tylko tyle. I okaza\u0142o si\u0119, \u017ce ten relatywnie niewielki, ale bardzo wysokiej jako\u015bci zbi\u00f3r danych wystarczy\u0142o, \u017ceby nauczy\u0107 model podstaw wprowadzenia rozmowy na naprawd\u0119 wysokim poziomie.", "tokens": [50364, 49286, 4093, 39293, 13, 286, 3133, 12257, 5249, 3244, 11, 3561, 2064, 1039, 21398, 14215, 43622, 1187, 2984, 11, 6775, 9034, 27062, 453, 7764, 17123, 6199, 710, 5614, 15614, 274, 34644, 4628, 9710, 6522, 5249, 11, 11316, 49103, 27150, 2316, 43443, 46733, 14320, 35234, 10089, 1667, 20970, 27062, 453, 332, 38503, 40120, 13, 51079], "temperature": 0.0, "avg_logprob": -0.10689231482419101, "compression_ratio": 1.3466666666666667, "no_speech_prob": 0.1851819008588791}, {"id": 59, "seek": 29500, "start": 309.3, "end": 316.5, "text": " Ok. Czyli po tym etapie mamy ju\u017c model, kt\u00f3ry potrafi odpowiada\u0107 na pytania. Ale to jeszcze nie koniec.", "tokens": [51079, 3477, 13, 37099, 714, 8107, 47634, 414, 17335, 10678, 2316, 11, 9913, 1847, 10437, 72, 24314, 39018, 2162, 1667, 25878, 5609, 13, 9366, 281, 14168, 2838, 5897, 35733, 13, 51439], "temperature": 0.0, "avg_logprob": -0.10689231482419101, "compression_ratio": 1.3466666666666667, "no_speech_prob": 0.1851819008588791}, {"id": 60, "seek": 31650, "start": 316.5, "end": 326.5, "text": " Potem nast\u0119puje ta faza o troch\u0119 skomplikowanej nazwie Reinforcement Learning with Human Feedback, czyli RLHF. Jak to w\u0142a\u015bciwie dzia\u0142a?", "tokens": [50364, 9145, 443, 39662, 13008, 1846, 4375, 64, 277, 24926, 1110, 298, 564, 1035, 23066, 73, 20151, 8699, 42116, 9382, 15205, 365, 10294, 33720, 3207, 11, 16591, 497, 43, 39, 37, 13, 15029, 281, 50108, 37903, 30, 50864], "temperature": 0.0, "avg_logprob": -0.10458936691284179, "compression_ratio": 1.300411522633745, "no_speech_prob": 0.04207896068692207}, {"id": 61, "seek": 31650, "start": 326.5, "end": 329.3, "text": " To jest chyba najciekawsze cz\u0119\u015b\u0107 ca\u0142ego procesu.", "tokens": [50864, 1407, 3492, 31532, 11212, 4260, 74, 28354, 47149, 35224, 6308, 17565, 84, 13, 51004], "temperature": 0.0, "avg_logprob": -0.10458936691284179, "compression_ratio": 1.300411522633745, "no_speech_prob": 0.04207896068692207}, {"id": 62, "seek": 31650, "start": 329.3, "end": 334.0, "text": " To znaczy, jak mo\u017cna nagradza\u0107 program komputerowy za dobr\u0105 odpowied\u017a?", "tokens": [51004, 1407, 36584, 11, 4207, 17790, 17096, 6206, 35873, 1461, 5207, 13849, 10089, 7949, 23067, 1611, 36574, 10659, 30, 51239], "temperature": 0.0, "avg_logprob": -0.10458936691284179, "compression_ratio": 1.300411522633745, "no_speech_prob": 0.04207896068692207}, {"id": 63, "seek": 31650, "start": 334.0, "end": 337.0, "text": " No w\u0142a\u015bnie. Nie robi si\u0119 tego bezpo\u015brednio.", "tokens": [51239, 883, 14234, 13, 12016, 47380, 3244, 8627, 10782, 2259, 1788, 986, 41084, 13, 51389], "temperature": 0.0, "avg_logprob": -0.10458936691284179, "compression_ratio": 1.300411522633745, "no_speech_prob": 0.04207896068692207}, {"id": 64, "seek": 33700, "start": 337.0, "end": 346.8, "text": " Zamiast tego zatrudniono tysi\u0105ce ludzi, tak zwanych anotator\u00f3w, ich zadaniem by\u0142o ocenianie dw\u00f3ch r\u00f3\u017cnych odpowiedzi modelu na to samo pytanie.", "tokens": [50364, 1176, 4526, 525, 8627, 35802, 47130, 77, 49020, 38156, 11404, 384, 29586, 11, 991, 11873, 34644, 364, 310, 1639, 3901, 11, 1893, 710, 11338, 4907, 14811, 10409, 268, 952, 414, 27379, 812, 339, 42602, 36574, 3992, 2316, 84, 1667, 281, 36422, 36610, 13, 50854], "temperature": 0.0, "avg_logprob": -0.07479657846338608, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.6889459490776062}, {"id": 65, "seek": 33700, "start": 346.8, "end": 350.3, "text": " I co oni robili? Mieli po prostu wskaza\u0107, kt\u00f3ra jest lepsza?", "tokens": [50854, 286, 598, 36317, 3870, 2312, 30, 376, 23099, 714, 19518, 261, 5161, 12257, 2162, 11, 19456, 3492, 476, 1878, 2394, 30, 51029], "temperature": 0.0, "avg_logprob": -0.07479657846338608, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.6889459490776062}, {"id": 66, "seek": 33700, "start": 350.3, "end": 360.5, "text": " Dok\u0142adnie tak. Kt\u00f3ra jest bardziej pomocna, bardziej precyzyjna, czy po prostu lepiej napisana? Zebrano w ten spos\u00f3b ponad milion takich por\u00f3wna\u0144.", "tokens": [51029, 29768, 10358, 2766, 991, 13, 591, 4547, 424, 3492, 27209, 48962, 629, 11, 27209, 659, 1344, 1229, 73, 629, 11, 6430, 714, 19518, 476, 39699, 9296, 271, 2095, 30, 4853, 1443, 3730, 261, 2064, 22904, 9224, 345, 1962, 313, 29607, 1515, 3901, 629, 5248, 13, 51539], "temperature": 0.0, "avg_logprob": -0.07479657846338608, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.6889459490776062}, {"id": 67, "seek": 33700, "start": 360.5, "end": 364.4, "text": " Ponad milion. I co zrobiono z tymi wszystkimi g\u0142osami?", "tokens": [51539, 31756, 345, 1962, 313, 13, 286, 598, 44399, 49020, 710, 1104, 3057, 14615, 10121, 43767, 4526, 30, 51734], "temperature": 0.0, "avg_logprob": -0.07479657846338608, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.6889459490776062}, {"id": 68, "seek": 36440, "start": 364.4, "end": 372.4, "text": " Na ich podstawie wytrenowano zupe\u0142nie osobny model AI, tak zwany Reward Model, czyli model nagrody.", "tokens": [50364, 6056, 1893, 43443, 414, 261, 4328, 1095, 305, 3730, 49922, 41518, 1634, 2316, 7318, 11, 991, 11873, 1325, 1300, 1007, 17105, 11, 16591, 2316, 17096, 340, 3173, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10336771635251625, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.005734469275921583}, {"id": 69, "seek": 36440, "start": 372.4, "end": 379.09999999999997, "text": " Jego jednym zadaniem by\u0142o nauczy\u0107 si\u0119 przewidywa\u0107, kt\u00f3r\u0105 odpowied\u017a cz\u0142owiek uzna\u0142by za lepsz\u0105.", "tokens": [50764, 508, 6308, 5232, 12996, 710, 11338, 4907, 14811, 49103, 27150, 3244, 39758, 38836, 25234, 11, 37415, 36574, 10659, 36282, 74, 16851, 629, 34635, 7949, 476, 1878, 8925, 13, 51099], "temperature": 0.0, "avg_logprob": -0.10336771635251625, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.005734469275921583}, {"id": 70, "seek": 36440, "start": 379.09999999999997, "end": 382.59999999999997, "text": " A, czyli stworzono takiego zautomatyzowanego s\u0119dziego.", "tokens": [51099, 316, 11, 16591, 342, 28321, 89, 8957, 32296, 710, 1375, 298, 21398, 89, 37345, 6308, 262, 42643, 1571, 13, 51274], "temperature": 0.0, "avg_logprob": -0.10336771635251625, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.005734469275921583}, {"id": 71, "seek": 36440, "start": 382.59999999999997, "end": 387.09999999999997, "text": " Dok\u0142adnie. S\u0119dziego, kt\u00f3ry odzwierciedla ludzkie preferencje.", "tokens": [51274, 29768, 10358, 2766, 13, 318, 42643, 1571, 11, 9913, 3611, 14406, 811, 537, 292, 875, 15946, 89, 22872, 4382, 22660, 2884, 13, 51499], "temperature": 0.0, "avg_logprob": -0.10336771635251625, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.005734469275921583}, {"id": 72, "seek": 38710, "start": 387.1, "end": 394.6, "text": " I tu pojawia si\u0119 kolejna genialna innowacja z tej pracy. Stworzono nie jeden, a dwa oddzielne Reward Models.", "tokens": [50364, 286, 2604, 30655, 654, 3244, 23749, 629, 48228, 629, 294, 3785, 23395, 710, 12573, 35591, 13, 745, 28321, 89, 8957, 2838, 12906, 11, 257, 35045, 7401, 42280, 716, 1300, 1007, 6583, 1625, 13, 50739], "temperature": 0.0, "avg_logprob": -0.09229280153910319, "compression_ratio": 1.4007936507936507, "no_speech_prob": 0.39656803011894226}, {"id": 73, "seek": 38710, "start": 394.6, "end": 396.70000000000005, "text": " Dlaczego dwa? Jaki to ma sens?", "tokens": [50739, 413, 75, 39329, 35045, 30, 508, 7421, 281, 463, 2923, 30, 50844], "temperature": 0.0, "avg_logprob": -0.09229280153910319, "compression_ratio": 1.4007936507936507, "no_speech_prob": 0.39656803011894226}, {"id": 74, "seek": 38710, "start": 396.70000000000005, "end": 404.3, "text": " Jeden by\u0142 wyspecjalizowany w ocenie pomocno\u015bci, czyli Helpfulness, a drugi w ocenie bezpiecze\u0144stwa, czyli Safety.", "tokens": [50844, 508, 6876, 16673, 27062, 494, 66, 22600, 590, 23341, 261, 10409, 268, 414, 48962, 16438, 11, 16591, 10773, 26872, 11, 257, 4110, 72, 261, 10409, 268, 414, 47153, 9680, 12229, 4151, 11, 16591, 21340, 13, 51224], "temperature": 0.0, "avg_logprob": -0.09229280153910319, "compression_ratio": 1.4007936507936507, "no_speech_prob": 0.39656803011894226}, {"id": 75, "seek": 38710, "start": 404.3, "end": 406.6, "text": " A, to faktycznie sprytne.", "tokens": [51224, 316, 11, 281, 33647, 45586, 637, 627, 83, 716, 13, 51339], "temperature": 0.0, "avg_logprob": -0.09229280153910319, "compression_ratio": 1.4007936507936507, "no_speech_prob": 0.39656803011894226}, {"id": 76, "seek": 38710, "start": 406.6, "end": 411.1, "text": " To genialne w swojej prostocie, bo rozwi\u0105zuje fundamentalny problem.", "tokens": [51339, 1407, 48228, 716, 261, 29489, 73, 10293, 905, 414, 11, 748, 9544, 18234, 11728, 2884, 8088, 1634, 1154, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09229280153910319, "compression_ratio": 1.4007936507936507, "no_speech_prob": 0.39656803011894226}, {"id": 77, "seek": 41110, "start": 411.1, "end": 419.1, "text": " Wiesz, cz\u0119sto jest tak, \u017ce model, kt\u00f3ry jest bardzo bezpieczny, staje si\u0119 jednocze\u015bnie ma\u0142o pomocny, bo na wiele pyta\u0144 odpowiada asekuracyjnie.", "tokens": [50364, 343, 15347, 11, 34369, 3492, 991, 11, 3561, 2316, 11, 9913, 3492, 9034, 47153, 3689, 1634, 11, 342, 11153, 3244, 5232, 26694, 1381, 12221, 463, 5249, 48962, 1634, 11, 748, 1667, 33137, 10664, 1328, 5248, 24314, 39018, 382, 916, 374, 31285, 2766, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08686269311343922, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.09851367026567459}, {"id": 78, "seek": 41110, "start": 419.1, "end": 420.6, "text": " No tak, i na odwr\u00f3t.", "tokens": [50764, 883, 991, 11, 741, 1667, 3611, 7449, 34712, 13, 50839], "temperature": 0.0, "avg_logprob": -0.08686269311343922, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.09851367026567459}, {"id": 79, "seek": 41110, "start": 420.6, "end": 429.6, "text": " Dok\u0142adnie. Rozdzielenie tych dw\u00f3ch ocen pozwoli\u0142o na znacznie precyzyjniejsze dostrojenie modelu, bez konieczno\u015bci szukania bolesnych kompromis\u00f3w.", "tokens": [50839, 29768, 10358, 2766, 13, 43313, 28168, 12844, 414, 15180, 27379, 812, 339, 10409, 268, 40557, 9384, 5249, 1667, 15397, 14875, 2766, 659, 1344, 1229, 73, 44258, 20568, 340, 15378, 414, 2316, 84, 11, 10782, 5897, 414, 3689, 16438, 7870, 2034, 5609, 272, 7456, 9399, 5207, 28722, 271, 3901, 13, 51289], "temperature": 0.0, "avg_logprob": -0.08686269311343922, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.09851367026567459}, {"id": 80, "seek": 41110, "start": 429.6, "end": 434.1, "text": " Co wi\u0119cej, czytam, \u017ce ten proces by\u0142 powtarzany wielokrotnie, tak jakby w p\u0119tli.", "tokens": [51289, 3066, 26004, 11, 6430, 37323, 11, 3561, 2064, 17565, 16673, 3388, 23480, 89, 1325, 20570, 453, 10536, 2766, 11, 991, 28976, 261, 280, 46788, 2081, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08686269311343922, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.09851367026567459}, {"id": 81, "seek": 41110, "start": 434.1, "end": 440.6, "text": " Tak, by\u0142 iteracyjny. Zesp\u00f3\u0142 stworzy\u0142 kilka wersji modelu od RLHF V1 do V5.", "tokens": [51514, 9118, 11, 16673, 17138, 31285, 1634, 13, 1176, 13361, 16181, 342, 28321, 1229, 1221, 36466, 261, 433, 4013, 2316, 84, 3611, 497, 43, 39, 37, 691, 16, 360, 691, 20, 13, 51839], "temperature": 0.0, "avg_logprob": -0.08686269311343922, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.09851367026567459}, {"id": 82, "seek": 44060, "start": 440.6, "end": 447.6, "text": " Ka\u017cda nowa, ulepszona wersja by\u0142a u\u017cywana do generowania kolejnych odpowiedzi, kt\u00f3re znowu oceniali ludzie.", "tokens": [50364, 10988, 1427, 2675, 586, 64, 11, 344, 306, 1878, 13383, 261, 433, 2938, 23936, 34097, 86, 2095, 360, 1337, 21308, 23749, 9399, 36574, 3992, 11, 8864, 710, 3785, 84, 10409, 268, 831, 72, 37025, 13, 50714], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 83, "seek": 44060, "start": 447.6, "end": 453.1, "text": " Te nowe oceny pozwala\u0142y trenowa\u0107 jeszcze lepszy, bardziej wymagaj\u0105cy reward model.", "tokens": [50714, 1989, 586, 68, 10409, 43100, 40557, 5159, 6825, 23136, 11445, 14168, 476, 1878, 1229, 11, 27209, 29764, 559, 11133, 1344, 7782, 2316, 13, 50989], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 84, "seek": 44060, "start": 453.1, "end": 455.6, "text": " Czyli to by\u0142o takie ci\u0105g\u0142e podnoszenie sobie poprzeczki.", "tokens": [50989, 37099, 281, 14811, 15963, 42398, 70, 19827, 2497, 16751, 16778, 13652, 1665, 13503, 3689, 2984, 13, 51114], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 85, "seek": 44060, "start": 455.6, "end": 460.1, "text": " W\u0142a\u015bnie. Model sam pomaga\u0142 w stworzeniu narz\u0119dzia do swojej dalszej oceny.", "tokens": [51114, 343, 5024, 12221, 13, 17105, 3247, 12991, 9286, 1221, 261, 342, 28321, 39651, 6714, 89, 6298, 40395, 360, 29489, 73, 274, 1124, 16920, 10409, 43100, 13, 51339], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 86, "seek": 44060, "start": 460.1, "end": 465.6, "text": " A to wszystko doprowadzi\u0142o do wynik\u00f3w, kt\u00f3re, jak powiedzia\u0142a\u015b, na pocz\u0105tku wstrz\u0105sn\u0119\u0142y bran\u017c\u0105.", "tokens": [51339, 316, 281, 22607, 360, 35019, 3992, 5249, 360, 31936, 1035, 3901, 11, 8864, 11, 4207, 27617, 25605, 1788, 11, 1667, 43959, 261, 9733, 8925, 82, 77, 1274, 6825, 12029, 1427, 1611, 13, 51614], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 87, "seek": 44060, "start": 465.6, "end": 469.1, "text": " No dobrze, ale wstrz\u0105sn\u0119\u0142y to znaczy jak bardzo?", "tokens": [51614, 883, 28335, 11, 6775, 261, 9733, 8925, 82, 77, 1274, 6825, 281, 36584, 4207, 9034, 30, 51789], "temperature": 0.0, "avg_logprob": -0.057165440217948255, "compression_ratio": 1.51840490797546, "no_speech_prob": 0.0015167241217568517}, {"id": 88, "seek": 46910, "start": 469.1, "end": 473.1, "text": " Czy Lama 2 by\u0142a tylko troch\u0119 lepsza od innych otwartych modeli?", "tokens": [50364, 19832, 441, 2404, 568, 23936, 13219, 24926, 476, 1878, 2394, 3611, 36286, 4337, 29587, 16384, 2316, 72, 30, 50564], "temperature": 0.0, "avg_logprob": -0.11023136395127026, "compression_ratio": 1.349264705882353, "no_speech_prob": 0.021453402936458588}, {"id": 89, "seek": 46910, "start": 473.1, "end": 476.6, "text": " Czy m\u00f3wimy tu o nawi\u0105zaniu realnej walki z gigantami?", "tokens": [50564, 19832, 13489, 13189, 2604, 277, 18969, 11404, 89, 25849, 957, 11794, 1792, 72, 710, 8741, 394, 4526, 30, 50739], "temperature": 0.0, "avg_logprob": -0.11023136395127026, "compression_ratio": 1.349264705882353, "no_speech_prob": 0.021453402936458588}, {"id": 90, "seek": 46910, "start": 476.6, "end": 479.1, "text": " M\u00f3wimy o absolutnie realnej walce.", "tokens": [50739, 376, 3901, 13189, 277, 18757, 2766, 957, 11794, 21346, 384, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11023136395127026, "compression_ratio": 1.349264705882353, "no_speech_prob": 0.021453402936458588}, {"id": 91, "seek": 46910, "start": 479.1, "end": 485.1, "text": " Sp\u00f3jrzmy na lany Sfigure 12 w artykule, gdzie por\u00f3wnano modele na podstawie ocen ludzkich.", "tokens": [50864, 1738, 18999, 19390, 2226, 1667, 287, 1325, 318, 20646, 540, 2272, 261, 594, 874, 74, 2271, 11, 18922, 1515, 812, 895, 3730, 4391, 306, 1667, 43443, 414, 10409, 268, 15946, 30154, 480, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11023136395127026, "compression_ratio": 1.349264705882353, "no_speech_prob": 0.021453402936458588}, {"id": 92, "seek": 46910, "start": 485.1, "end": 495.6, "text": " Najwi\u0119kszy model Lama 2 70B w bezpo\u015brednim starciu z \u00f3wczesn\u0105 wersj\u0105 chat GPT wygrywa w niemal 36% przypadk\u00f3w.", "tokens": [51164, 31576, 22423, 1694, 1229, 2316, 441, 2404, 568, 5285, 33, 261, 10782, 2259, 1788, 986, 39223, 3543, 30795, 710, 11857, 86, 3689, 279, 13113, 261, 433, 8555, 5081, 26039, 51, 4628, 70, 627, 4151, 261, 2838, 5579, 8652, 4, 33100, 23849, 13, 51689], "temperature": 0.0, "avg_logprob": -0.11023136395127026, "compression_ratio": 1.349264705882353, "no_speech_prob": 0.021453402936458588}, {"id": 93, "seek": 49560, "start": 496.1, "end": 499.1, "text": " A ponad 31% to remisy.", "tokens": [50389, 316, 9224, 345, 10353, 4, 281, 890, 14169, 13, 50539], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 94, "seek": 49560, "start": 499.1, "end": 501.6, "text": " Czyli przegrywa w mniejszo\u015bci przypadk\u00f3w.", "tokens": [50539, 37099, 6541, 1146, 627, 4151, 261, 275, 30295, 4765, 6199, 33100, 23849, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 95, "seek": 49560, "start": 501.6, "end": 507.6, "text": " To jest wynik, kt\u00f3ry po raz pierwszy pokaza\u0142, \u017ce model Open Source mo\u017ce by\u0107 tak blisko lidera rynku.", "tokens": [50664, 1407, 3492, 31936, 1035, 11, 9913, 714, 9639, 34016, 13010, 12257, 1221, 11, 3561, 2316, 7238, 29629, 12034, 15069, 991, 888, 43442, 45341, 64, 367, 2534, 5279, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 96, "seek": 49560, "start": 507.6, "end": 510.6, "text": " Zdecydowanie, a w por\u00f3wnaniu z innymi parametrami,", "tokens": [50964, 1176, 1479, 1344, 67, 22028, 11, 257, 261, 1515, 812, 895, 25849, 710, 294, 31813, 6220, 27965, 4526, 11, 51114], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 97, "seek": 49560, "start": 510.6, "end": 517.6, "text": " w starciu z Palm Bison od Googlea Lama 2 wygra\u0142a wasz 53% przypadk\u00f3w.", "tokens": [51114, 261, 3543, 30795, 710, 32668, 363, 2770, 3611, 3329, 64, 441, 2404, 568, 4628, 20735, 5024, 390, 89, 21860, 4, 33100, 23849, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 98, "seek": 49560, "start": 517.6, "end": 519.1, "text": " To ju\u017c jest wyra\u017cna wygrana.", "tokens": [51464, 1407, 10678, 3492, 4628, 424, 1427, 629, 4628, 861, 2095, 13, 51539], "temperature": 0.0, "avg_logprob": -0.08766364236163278, "compression_ratio": 1.345679012345679, "no_speech_prob": 0.012320787645876408}, {"id": 99, "seek": 51910, "start": 519.1, "end": 524.6, "text": " \u017bemy narywalizacj\u0119 z innym popularnym modelem Open Source Falcon 40B,", "tokens": [50364, 46864, 2226, 297, 822, 29530, 590, 29924, 710, 294, 12996, 3743, 12996, 4391, 10386, 7238, 29629, 31801, 3356, 33, 11, 50639], "temperature": 0.0, "avg_logprob": -0.10447935704831723, "compression_ratio": 1.2904564315352698, "no_speech_prob": 0.014363379217684269}, {"id": 100, "seek": 51910, "start": 524.6, "end": 530.6, "text": " to przewaga jest ju\u017c mia\u017cd\u017c\u0105ca 76% zwyci\u0119stw dla Lama 2.", "tokens": [50639, 281, 39758, 9286, 3492, 10678, 21290, 1427, 67, 1427, 1611, 496, 24733, 4, 43436, 537, 1274, 372, 86, 12285, 441, 2404, 568, 13, 50939], "temperature": 0.0, "avg_logprob": -0.10447935704831723, "compression_ratio": 1.2904564315352698, "no_speech_prob": 0.014363379217684269}, {"id": 101, "seek": 51910, "start": 530.6, "end": 535.1, "text": " Te liczby pokaza\u0142y, \u017ce na rynku pojawi\u0142 si\u0119 nowy, bardzo powa\u017cny gracz.", "tokens": [50939, 1989, 6169, 89, 2322, 13010, 12257, 6825, 11, 3561, 1667, 367, 2534, 5279, 30655, 40622, 3244, 586, 88, 11, 9034, 3388, 18264, 1634, 11625, 89, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10447935704831723, "compression_ratio": 1.2904564315352698, "no_speech_prob": 0.014363379217684269}, {"id": 102, "seek": 51910, "start": 535.1, "end": 539.1, "text": " A jak to wygl\u0105da\u0142o w tych standardowych akademickich testach?", "tokens": [51164, 316, 4207, 281, 32015, 5249, 261, 15180, 3832, 19605, 9308, 49290, 618, 480, 1500, 608, 30, 51364], "temperature": 0.0, "avg_logprob": -0.10447935704831723, "compression_ratio": 1.2904564315352698, "no_speech_prob": 0.014363379217684269}, {"id": 103, "seek": 51910, "start": 539.1, "end": 541.6, "text": " Czy tam te\u017c Lama 2 tak dominowa\u0142a?", "tokens": [51364, 19832, 7677, 9516, 441, 2404, 568, 991, 8859, 5528, 5024, 30, 51489], "temperature": 0.0, "avg_logprob": -0.10447935704831723, "compression_ratio": 1.2904564315352698, "no_speech_prob": 0.014363379217684269}, {"id": 104, "seek": 54160, "start": 542.1, "end": 549.6, "text": " Tak, dane Stable 3.4 to potwierdzaj\u0105, Lama 2.70B znacz\u0105co przewy\u017csza\u0142a inne modele Open Source", "tokens": [50389, 9118, 11, 49206, 745, 712, 805, 13, 19, 281, 1847, 40717, 28168, 11133, 11, 441, 2404, 568, 13, 5867, 33, 15397, 326, 8925, 1291, 39758, 88, 1427, 82, 2394, 5024, 24170, 4391, 306, 7238, 29629, 50764], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 105, "seek": 54160, "start": 549.6, "end": 551.1, "text": " we wszystkich kategoriach.", "tokens": [50764, 321, 34234, 350, 2968, 7386, 608, 13, 50839], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 106, "seek": 54160, "start": 551.1, "end": 556.1, "text": " W niekt\u00f3rych zadaniach, jak rozumienie j\u0119zyka, czy rozwi\u0105zywanie problem\u00f3w matematycznych,", "tokens": [50839, 343, 2838, 43073, 627, 339, 42788, 3782, 608, 11, 4207, 48797, 27385, 42309, 40940, 11, 6430, 9544, 18234, 1229, 86, 7155, 1154, 3901, 3803, 8615, 17466, 9399, 11, 51089], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 107, "seek": 54160, "start": 556.1, "end": 559.1, "text": " zbli\u017ca\u0142a si\u0119 do wynik\u00f3w GPT 3.5.", "tokens": [51089, 710, 32117, 35075, 5024, 3244, 360, 31936, 1035, 3901, 26039, 51, 805, 13, 20, 13, 51239], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 108, "seek": 54160, "start": 561.1, "end": 564.6, "text": " Tutaj trzeba by\u0107 uczciwym i autorzy sami to podkre\u015blaj\u0105.", "tokens": [51339, 41819, 25860, 15069, 35403, 537, 86, 4199, 741, 19510, 1229, 3247, 72, 281, 2497, 27885, 1788, 875, 8555, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 109, "seek": 54160, "start": 564.6, "end": 568.6, "text": " Wci\u0105\u017c istnia\u0142a du\u017ca przepa\u015b\u0107 w zadaniach zwi\u0105zanych z programowaniem", "tokens": [51514, 343, 537, 27242, 1418, 12679, 5024, 21783, 64, 30829, 64, 7753, 261, 42788, 3782, 608, 27741, 34644, 710, 1461, 37345, 4907, 51714], "temperature": 0.0, "avg_logprob": -0.11652592446306627, "compression_ratio": 1.3645833333333333, "no_speech_prob": 0.009960419498383999}, {"id": 110, "seek": 56860, "start": 568.6, "end": 571.6, "text": " w por\u00f3wnaniu do absolutnej czo\u0142\u00f3wki, czyli GPT 4.", "tokens": [50364, 261, 1515, 812, 895, 25849, 360, 18757, 11794, 269, 4765, 1221, 3901, 2984, 11, 16591, 26039, 51, 1017, 13, 50514], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 111, "seek": 56860, "start": 571.6, "end": 575.6, "text": " No tak, to pokazuje, \u017ce \u017caden model nie jest idealny we wszystkim.", "tokens": [50514, 883, 991, 11, 281, 13010, 43317, 11, 3561, 19625, 14771, 2316, 2838, 3492, 7157, 1634, 321, 30481, 13, 50714], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 112, "seek": 56860, "start": 575.6, "end": 576.6, "text": " Dok\u0142adnie.", "tokens": [50714, 29768, 10358, 2766, 13, 50764], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 113, "seek": 56860, "start": 576.6, "end": 580.1, "text": " Dobrze, czyli mamy model, kt\u00f3ry jest pot\u0119\u017cny i konkurencyjny.", "tokens": [50764, 29679, 13503, 11, 16591, 17335, 2316, 11, 9913, 3492, 1847, 1274, 1427, 1634, 741, 21428, 9873, 42949, 1634, 13, 50939], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 114, "seek": 56860, "start": 580.1, "end": 585.6, "text": " Ale udost\u0119pnienie takiego narz\u0119dzia publicznie rodzi ogromne pytania o bezpiecze\u0144stwo.", "tokens": [50939, 9366, 11727, 555, 18085, 77, 27385, 32296, 6714, 89, 6298, 40395, 1908, 89, 2766, 8685, 3992, 34416, 298, 716, 25878, 5609, 277, 47153, 9680, 12229, 6120, 13, 51214], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 115, "seek": 56860, "start": 585.6, "end": 590.6, "text": " Jak nauczono go, \u017ceby wiedzia\u0142, kiedy odm\u00f3wi\u0107 odpowiedzi na jakie\u015b szkodliwe pytanie?", "tokens": [51214, 15029, 49103, 89, 8957, 352, 11, 11316, 261, 15338, 8908, 11, 18777, 3611, 76, 3901, 12757, 36574, 3992, 1667, 31163, 7870, 74, 378, 2081, 826, 36610, 30, 51464], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 116, "seek": 56860, "start": 590.6, "end": 596.1, "text": " I tu dochodzimy do kolejnego, fascynuj\u0105cego wr\u0119cz kontrintuicyjnego podej\u015bcia.", "tokens": [51464, 286, 2604, 9243, 378, 89, 13189, 360, 23749, 11858, 11, 30632, 1344, 77, 13263, 384, 1571, 928, 1274, 3689, 14373, 81, 686, 84, 2632, 73, 11858, 7468, 73, 1788, 2755, 13, 51739], "temperature": 0.0, "avg_logprob": -0.061299229260557184, "compression_ratio": 1.4361370716510904, "no_speech_prob": 0.022615013644099236}, {"id": 117, "seek": 59610, "start": 596.1, "end": 602.1, "text": " Okazuje si\u0119, \u017ce podczas tej pierwszej fundamentalnej fazy nauki, czyli pre-training,", "tokens": [50364, 3477, 43317, 3244, 11, 3561, 2497, 30989, 12573, 27623, 16920, 8088, 11794, 4375, 88, 35616, 2984, 11, 16591, 659, 12, 17227, 1760, 11, 50664], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 118, "seek": 59610, "start": 602.1, "end": 607.1, "text": " celowo nie filtrowano agresywnie toksycznych tre\u015bci z danych treningowych.", "tokens": [50664, 9277, 19941, 2838, 1387, 6903, 305, 3730, 623, 495, 88, 14215, 281, 1694, 17466, 9399, 2192, 6199, 710, 274, 34644, 2192, 773, 19605, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 119, "seek": 59610, "start": 607.1, "end": 611.1, "text": " Chwila chwila, to brzmi bardzo ryzykownie.", "tokens": [50914, 761, 86, 7371, 26237, 7371, 11, 281, 738, 89, 3057, 9034, 20791, 1229, 74, 648, 414, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 120, "seek": 59610, "start": 611.1, "end": 613.1, "text": " Dlaczego zdecydowali si\u0119 na taki krok?", "tokens": [51114, 413, 75, 39329, 49749, 1344, 67, 305, 5103, 3244, 1667, 20065, 350, 31621, 30, 51214], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 121, "seek": 59610, "start": 613.1, "end": 617.1, "text": " Nie bali si\u0119, \u017ce model nasi\u0105gnie tymi szkodliwymi tre\u015bciami?", "tokens": [51214, 12016, 272, 5103, 3244, 11, 3561, 2316, 5382, 11404, 70, 2766, 1104, 3057, 7870, 74, 378, 2081, 9726, 3057, 2192, 6199, 4526, 30, 51414], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 122, "seek": 59610, "start": 617.1, "end": 619.1, "text": " To jest w\u0142a\u015bnie ten paradoks.", "tokens": [51414, 1407, 3492, 14234, 2064, 13480, 25500, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 123, "seek": 59610, "start": 619.1, "end": 624.1, "text": " Pozostawienie tych danych w kontrolowany spos\u00f3b pozwala modelowi lepiej zrozumie\u0107,", "tokens": [51514, 6165, 89, 555, 1607, 27385, 15180, 274, 34644, 261, 14373, 6623, 23341, 22904, 40557, 5159, 2316, 24503, 476, 39699, 710, 27857, 449, 414, 2162, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08305309602878237, "compression_ratio": 1.4724137931034482, "no_speech_prob": 0.008022504858672619}, {"id": 124, "seek": 62410, "start": 624.1, "end": 628.1, "text": " czym s\u0105 nienawistne, toksyczne czy niebezpieczne tre\u015bci.", "tokens": [50364, 31466, 9015, 297, 1053, 1607, 468, 716, 11, 281, 1694, 17466, 716, 6430, 2838, 650, 89, 9144, 38491, 2192, 6199, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 125, "seek": 62410, "start": 628.1, "end": 632.1, "text": " To u\u0142atwia i przyspiesza p\u00f3\u017aniejszy safety fine tuning.", "tokens": [50564, 1407, 344, 1221, 267, 86, 654, 741, 6541, 749, 79, 530, 2394, 36968, 7706, 4514, 2489, 15164, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 126, "seek": 62410, "start": 632.1, "end": 635.1, "text": " Czyli on musi najpierw pozna\u0107 wroga, \u017ceby nauczy\u0107 si\u0119 z nim walczy\u0107?", "tokens": [50764, 37099, 322, 37587, 11212, 45119, 86, 21281, 629, 2162, 261, 340, 3680, 11, 11316, 49103, 27150, 3244, 710, 24887, 21346, 33967, 30, 50914], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 127, "seek": 62410, "start": 635.1, "end": 637.1, "text": " To jest \u015bwietne podsumowanie.", "tokens": [50914, 1407, 3492, 8299, 39083, 716, 31925, 449, 22028, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 128, "seek": 62410, "start": 637.1, "end": 643.1, "text": " A sama walka, czyli dostrajanie bezpiecze\u0144stwa, opiera\u0142a si\u0119 na trzech g\u0142\u00f3wnych metodach.", "tokens": [51014, 316, 17768, 1792, 64, 11, 16591, 20568, 48690, 7155, 47153, 9680, 12229, 4151, 11, 999, 10609, 5024, 3244, 1667, 504, 19439, 18117, 812, 895, 16384, 1131, 378, 608, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 129, "seek": 62410, "start": 643.1, "end": 648.1, "text": " Pierwsza by\u0142a dosz\u0107 standardowa, supervised safety fine tuning.", "tokens": [51314, 16676, 14358, 2394, 23936, 4491, 89, 2162, 3832, 5528, 11, 46533, 4514, 2489, 15164, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 130, "seek": 62410, "start": 648.1, "end": 651.1, "text": " Czyli po prostu pokazywano mu przyk\u0142ady?", "tokens": [51564, 37099, 714, 19518, 13010, 921, 27112, 3730, 2992, 6501, 74, 1221, 880, 30, 51714], "temperature": 0.0, "avg_logprob": -0.07779484862214202, "compression_ratio": 1.4964788732394365, "no_speech_prob": 0.007947109639644623}, {"id": 131, "seek": 65110, "start": 651.1, "end": 655.1, "text": " Tak, pokazywano mu przyk\u0142ady, gdzie na z\u0142e pytanie, na przyk\u0142ad o to,", "tokens": [50364, 9118, 11, 13010, 921, 27112, 3730, 2992, 6501, 74, 1221, 880, 11, 18922, 1667, 710, 19827, 36610, 11, 1667, 23144, 277, 281, 11, 50564], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 132, "seek": 65110, "start": 655.1, "end": 660.1, "text": " jak skonstruowa\u0107 bomb\u0119 udziela bezpiecznej, odmawiaj\u0105cej odpowiedzi.", "tokens": [50564, 4207, 1110, 4068, 894, 11445, 7851, 1274, 11727, 42280, 64, 47153, 3689, 11794, 11, 3611, 76, 34953, 8555, 20811, 36574, 3992, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 133, "seek": 65110, "start": 660.1, "end": 668.1, "text": " Druga to safety RLHF, czyli wykorzystanie tego dedykowanego modelu nagrody dla bezpiecze\u0144stwa, o kt\u00f3rym ju\u017c m\u00f3wi\u0142y\u015bmy.", "tokens": [50814, 2491, 19364, 281, 4514, 497, 43, 39, 37, 11, 16591, 43606, 36049, 7155, 8627, 4172, 46127, 37345, 6308, 2316, 84, 17096, 340, 3173, 12285, 47153, 9680, 12229, 4151, 11, 277, 30120, 10678, 24592, 6825, 10513, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 134, "seek": 65110, "start": 668.1, "end": 669.1, "text": " A ta trzecia?", "tokens": [51214, 316, 1846, 22266, 2755, 30, 51264], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 135, "seek": 65110, "start": 669.1, "end": 671.1, "text": " A trzecia jest najbardziej pomys\u0142owa.", "tokens": [51264, 316, 22266, 2755, 3492, 41857, 12991, 39508, 5528, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 136, "seek": 65110, "start": 671.1, "end": 674.1, "text": " Nazywa si\u0119 context distillation for safety.", "tokens": [51364, 11870, 88, 4151, 3244, 4319, 42923, 399, 337, 4514, 13, 51514], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 137, "seek": 65110, "start": 674.1, "end": 676.1, "text": " Dystylacja kontekstu.", "tokens": [51514, 413, 749, 874, 75, 23395, 14373, 916, 372, 84, 13, 51614], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 138, "seek": 65110, "start": 676.1, "end": 677.1, "text": " I jak to dzie\u0142o?", "tokens": [51614, 286, 4207, 281, 17953, 5249, 30, 51664], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 139, "seek": 65110, "start": 677.1, "end": 680.1, "text": " Mo\u017cna to por\u00f3wna\u0107 do uczenia przez szeptanie do ucha.", "tokens": [51664, 44736, 629, 281, 1515, 3901, 629, 2162, 360, 344, 38517, 14064, 7870, 5250, 7155, 360, 344, 4413, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0862667515592755, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.01843251846730709}, {"id": 140, "seek": 68010, "start": 680.1, "end": 685.1, "text": " Najpierw daje si\u0119 modelowi \u015bci\u0105g\u0119, tak zwany pre-prompt, na przyk\u0142ad.", "tokens": [50364, 31576, 45119, 86, 1120, 2884, 3244, 2316, 24503, 220, 50227, 70, 1274, 11, 991, 11873, 1325, 659, 12, 28722, 662, 11, 1667, 23144, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 141, "seek": 68010, "start": 685.1, "end": 688.1, "text": " Jeste\u015b bezpiecznym i odpowiedzialnym asystentem.", "tokens": [50614, 508, 8887, 1788, 47153, 3689, 12996, 741, 24314, 15338, 831, 12996, 382, 38593, 317, 443, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 142, "seek": 68010, "start": 688.1, "end": 693.1, "text": " Z t\u0105 \u015bci\u0105g\u0105 model bez problemu generuje bezpieczn\u0105 odpowied\u017a.", "tokens": [50764, 1176, 32294, 220, 50227, 70, 1611, 2316, 10782, 1154, 84, 1337, 13008, 47153, 3689, 13113, 36574, 10659, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 143, "seek": 68010, "start": 693.1, "end": 694.1, "text": " I teraz sedno.", "tokens": [51014, 286, 16854, 9643, 1771, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 144, "seek": 68010, "start": 694.1, "end": 702.1, "text": " Nast\u0119pnie uczy si\u0119 go, by generowa\u0142 t\u0119 sam\u0105 bezpieczn\u0105 odpowied\u017a, ale ju\u017c bez tej pocz\u0105tkowej \u015bci\u0105gi.", "tokens": [51064, 42185, 18085, 2766, 344, 6522, 3244, 352, 11, 538, 1337, 30105, 32489, 3247, 1611, 47153, 3689, 13113, 36574, 10659, 11, 6775, 10678, 10782, 12573, 34397, 74, 21091, 220, 50227, 7834, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 145, "seek": 68010, "start": 702.1, "end": 704.1, "text": " Czekaj, pozw\u00f3l, \u017ce si\u0119 upewnie, czy dobrze rozumiem.", "tokens": [51464, 383, 19878, 1805, 11, 40557, 15741, 11, 3561, 3244, 493, 68, 14215, 11, 6430, 28335, 48797, 4907, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07012587501889184, "compression_ratio": 1.4861660079051384, "no_speech_prob": 0.012733161449432373}, {"id": 146, "seek": 70410, "start": 704.1, "end": 710.1, "text": " Czyli oni najpierw niejako oszukuj\u0105 model, \u017ceby zachowywa\u0142 si\u0119 bezpiecznie,", "tokens": [50364, 37099, 36317, 11212, 45119, 86, 2838, 73, 18501, 3003, 43994, 13263, 2316, 11, 11316, 29303, 10089, 44603, 3244, 47153, 19923, 11, 50664], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 147, "seek": 70410, "start": 710.1, "end": 713.1, "text": " a potem trenuj\u0105 go, \u017ceby zapami\u0119ta\u0142 to bezpieczne zachowanie,", "tokens": [50664, 257, 36513, 23136, 13263, 352, 11, 11316, 14223, 23806, 46426, 281, 47153, 38491, 29303, 22028, 11, 50814], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 148, "seek": 70410, "start": 713.1, "end": 716.1, "text": " nawet gdy ta pocz\u0105tkowa sugestia zniknie.", "tokens": [50814, 22696, 28405, 1846, 34397, 74, 5528, 459, 2629, 654, 710, 13123, 2766, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 149, "seek": 70410, "start": 716.1, "end": 717.1, "text": " Dok\u0142adnie tak.", "tokens": [50964, 29768, 10358, 2766, 991, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 150, "seek": 70410, "start": 717.1, "end": 720.1, "text": " To brzmi niesamowicie sprytnie, ale te\u017c.", "tokens": [51014, 1407, 738, 89, 3057, 48100, 335, 305, 28434, 637, 627, 83, 2766, 11, 6775, 9516, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 151, "seek": 70410, "start": 720.1, "end": 723.1, "text": " Troch\u0119 krucho, czy to faktycznie dzia\u0142a w praktyce.", "tokens": [51164, 19406, 23006, 15913, 625, 78, 11, 6430, 281, 33647, 45586, 37903, 261, 3206, 74, 874, 384, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 152, "seek": 70410, "start": 723.1, "end": 724.1, "text": " Zaskakuj\u0105co dobrze.", "tokens": [51314, 1176, 3863, 514, 13263, 1291, 28335, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 153, "seek": 70410, "start": 724.1, "end": 730.1, "text": " To w\u0142a\u015bnie ta metoda pozwoli\u0142a wbudowa\u0107 zasady bezpiecze\u0144stwa g\u0142\u0119boku w zachowanie modelu.", "tokens": [51364, 1407, 14234, 1846, 1131, 13449, 40557, 9384, 5024, 261, 18281, 11445, 26530, 880, 47153, 9680, 12229, 4151, 18117, 1274, 65, 13275, 261, 29303, 22028, 2316, 84, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 154, "seek": 70410, "start": 730.1, "end": 732.1, "text": " A wyniki m\u00f3wi\u0105 same za siebie.", "tokens": [51664, 316, 31936, 9850, 46591, 912, 7949, 39137, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05433636983235677, "compression_ratio": 1.5532646048109966, "no_speech_prob": 0.6330918073654175}, {"id": 155, "seek": 73210, "start": 732.1, "end": 739.1, "text": " Wykres z Figur 17 pokazuje, \u017ce Lama 2 Chat ma jeden z najni\u017cszych wska\u017anik\u00f3w narusze\u0144 bezpiecze\u0144stwa.", "tokens": [50364, 14458, 74, 495, 710, 22443, 374, 3282, 13010, 43317, 11, 3561, 441, 2404, 568, 27503, 463, 12906, 710, 11212, 3722, 1427, 45021, 261, 20771, 10659, 47447, 6714, 301, 49689, 47153, 9680, 12229, 4151, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 156, "seek": 73210, "start": 739.1, "end": 745.1, "text": " Jest znacznie lepszy od modeli takich jak Vecuna czy MPT i w pe\u0142ni por\u00f3wnywalny strzad GPT.", "tokens": [50714, 24918, 15397, 14875, 2766, 476, 1878, 1229, 3611, 2316, 72, 29607, 4207, 691, 3045, 5051, 6430, 14146, 51, 741, 261, 43205, 3722, 1515, 812, 895, 27112, 304, 1634, 1056, 89, 345, 26039, 51, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 157, "seek": 73210, "start": 745.1, "end": 747.1, "text": " A jaki to jest wska\u017anik?", "tokens": [51014, 316, 24492, 281, 3492, 261, 20771, 10659, 13123, 30, 51114], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 158, "seek": 73210, "start": 747.1, "end": 754.1, "text": " Wska\u017anik narusze\u0144 dla najwi\u0119kszego modelu Lama 270B to zaledwie oko\u0142o 4%.", "tokens": [51114, 343, 20771, 10659, 13123, 6714, 301, 49689, 12285, 48636, 1694, 27725, 2316, 84, 441, 2404, 568, 5867, 33, 281, 710, 5573, 8699, 45730, 5249, 1017, 6856, 51464], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 159, "seek": 73210, "start": 754.1, "end": 755.1, "text": " Ok.", "tokens": [51464, 3477, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 160, "seek": 73210, "start": 755.1, "end": 758.1, "text": " Wyniki w benchmarkach s\u0105 imponuj\u0105ce.", "tokens": [51514, 343, 2534, 9850, 261, 18927, 608, 9015, 704, 266, 13263, 384, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14260401252571864, "compression_ratio": 1.3282442748091603, "no_speech_prob": 0.11394990980625153}, {"id": 161, "seek": 75810, "start": 759.1, "end": 761.1, "text": " Mechanizmy bezpiecze\u0144stwa te\u017c.", "tokens": [50414, 30175, 590, 2226, 47153, 9680, 12229, 4151, 9516, 13, 50514], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 162, "seek": 75810, "start": 761.1, "end": 766.1, "text": " Ale czytam, \u017ce w trakcie tych bada\u0144 pojawi\u0142y si\u0119 jakie\u015b zupe\u0142nie nieoczekiwane zdolno\u015bci.", "tokens": [50514, 9366, 6430, 37323, 11, 3561, 261, 944, 74, 4260, 15180, 272, 1538, 5248, 30655, 72, 6825, 3244, 31163, 49922, 2838, 905, 89, 14753, 86, 1929, 16221, 401, 16438, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 163, "seek": 75810, "start": 766.1, "end": 769.1, "text": " Co by\u0142o najbardziej zaskakuj\u0105cym odkryciem?", "tokens": [50764, 3066, 14811, 41857, 710, 3863, 514, 13263, 1344, 76, 3611, 43298, 4260, 76, 30, 50914], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 164, "seek": 75810, "start": 769.1, "end": 773.1, "text": " Co model potrafi\u0142 zrobi\u0107, chocia\u017c nikt go tego wprost nie uczy\u0142?", "tokens": [50914, 3066, 2316, 1847, 10437, 40622, 31785, 11, 48929, 297, 9874, 352, 8627, 261, 1424, 555, 2838, 344, 6522, 1221, 30, 51114], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 165, "seek": 75810, "start": 773.1, "end": 777.1, "text": " To jest chyba najbardziej ekscytuj\u0105ca cz\u0119\u015b\u0107 ca\u0142ej publikacji.", "tokens": [51114, 1407, 3492, 31532, 41857, 30724, 1344, 83, 13263, 496, 47149, 47631, 73, 11227, 1035, 13152, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 166, "seek": 75810, "start": 777.1, "end": 784.1, "text": " Okaza\u0142o si\u0119, \u017ce Lama 2 Chat, mimo \u017ce nie by\u0142 do tego w og\u00f3le trenowany, potrafi w trybie zero shot.", "tokens": [51314, 3477, 12257, 5249, 3244, 11, 3561, 441, 2404, 568, 27503, 11, 275, 6934, 3561, 2838, 16673, 360, 8627, 261, 29229, 23136, 23341, 11, 1847, 10437, 72, 261, 853, 7392, 4018, 3347, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 167, "seek": 75810, "start": 784.1, "end": 787.1, "text": " Czyli bez \u017cadnych wcze\u015bniejszych przyk\u0142ad\u00f3w?", "tokens": [51664, 37099, 10782, 39628, 9399, 40785, 45021, 23144, 3901, 30, 51814], "temperature": 0.0, "avg_logprob": -0.05875649945489291, "compression_ratio": 1.4338461538461538, "no_speech_prob": 0.05825594440102577}, {"id": 168, "seek": 78710, "start": 787.1, "end": 790.1, "text": " Dok\u0142adnie potrafi korzysta\u0107 z zewn\u0119trznych narz\u0119dzi.", "tokens": [50364, 29768, 10358, 2766, 1847, 10437, 72, 14784, 49590, 2162, 710, 5277, 895, 1274, 6903, 89, 9399, 6714, 89, 6298, 3992, 13, 50514], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 169, "seek": 78710, "start": 790.1, "end": 795.1, "text": " W artykule jest absolutnie zdumiewaj\u0105cy przyk\u0142ad z figury 23.", "tokens": [50514, 343, 594, 874, 74, 2271, 3492, 18757, 2766, 16221, 449, 1093, 11133, 1344, 23144, 710, 2147, 2598, 6673, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 170, "seek": 78710, "start": 795.1, "end": 803.1, "text": " Model dosta\u0142 pytanie, o ile milion\u00f3w lat wcze\u015bniej na Ziemi pojawi\u0142y si\u0119 rekiny w por\u00f3wnaniu do drzew?", "tokens": [50764, 17105, 274, 8638, 1221, 36610, 11, 277, 15465, 1962, 313, 3901, 4465, 40785, 1667, 46340, 3057, 30655, 72, 6825, 3244, 33881, 3519, 261, 1515, 812, 895, 25849, 360, 1224, 43551, 30, 51164], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 171, "seek": 78710, "start": 803.1, "end": 804.1, "text": " I co zrobi\u0142?", "tokens": [51164, 286, 598, 24483, 1221, 30, 51214], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 172, "seek": 78710, "start": 804.1, "end": 808.1, "text": " Sam bez \u017cadnej podpowiedzi wygenerowa\u0142 logiczny plan dzia\u0142ania.", "tokens": [51214, 4832, 10782, 39628, 11794, 2497, 14701, 1091, 3992, 4628, 21848, 30105, 9952, 89, 1634, 1393, 27121, 5609, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 173, "seek": 78710, "start": 808.1, "end": 814.1, "text": " Stwierdzi\u0142, \u017ce najpierw musi u\u017cy\u0107 narz\u0119dzia search, \u017ceby znale\u017a\u0107 wiek rekin\u00f3w.", "tokens": [51414, 745, 40717, 67, 3992, 1221, 11, 3561, 11212, 45119, 86, 37587, 34097, 2162, 6714, 89, 6298, 40395, 3164, 11, 11316, 15397, 1220, 10659, 2162, 3355, 74, 33881, 259, 3901, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0762154675912166, "compression_ratio": 1.3724137931034484, "no_speech_prob": 0.18453331291675568}, {"id": 174, "seek": 81410, "start": 815.1, "end": 822.1, "text": " Znalaz\u0142 oko\u0142o 450 milion\u00f3w lat, wst\u0119pnie, \u017ce musi u\u017cy\u0107 search ponownie,", "tokens": [50414, 1176, 4660, 921, 1221, 45730, 5249, 26034, 1962, 313, 3901, 4465, 11, 261, 372, 18085, 2766, 11, 3561, 37587, 34097, 2162, 3164, 9224, 648, 414, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08354094476983098, "compression_ratio": 1.3444976076555024, "no_speech_prob": 0.03495778888463974}, {"id": 175, "seek": 81410, "start": 822.1, "end": 829.1, "text": " by znale\u017a\u0107 wiek drzew, znalaz\u0142 oko\u0142o 385 milion\u00f3w lat.", "tokens": [50764, 538, 15397, 1220, 10659, 2162, 3355, 74, 1224, 43551, 11, 710, 4660, 921, 1221, 45730, 5249, 12843, 20, 1962, 313, 3901, 4465, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08354094476983098, "compression_ratio": 1.3444976076555024, "no_speech_prob": 0.03495778888463974}, {"id": 176, "seek": 81410, "start": 829.1, "end": 838.1, "text": " A na koniec uzna\u0142, \u017ce potrzebuje narz\u0119dzia calculator, \u017ceby odj\u0105\u0107 te dwie warto\u015bci i poda\u0107 finaln\u0105 odpowied\u017a.", "tokens": [51114, 316, 1667, 5897, 35733, 16851, 629, 1221, 11, 3561, 28577, 6021, 2884, 6714, 89, 6298, 40395, 24993, 11, 11316, 3611, 8555, 2162, 535, 274, 8699, 31830, 6199, 741, 2497, 43379, 2572, 13113, 36574, 10659, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08354094476983098, "compression_ratio": 1.3444976076555024, "no_speech_prob": 0.03495778888463974}, {"id": 177, "seek": 81410, "start": 838.1, "end": 840.1, "text": " To jest niewiarygodne.", "tokens": [51564, 1407, 3492, 43622, 29104, 21787, 716, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08354094476983098, "compression_ratio": 1.3444976076555024, "no_speech_prob": 0.03495778888463974}, {"id": 178, "seek": 84010, "start": 840.1, "end": 848.1, "text": " To pokazuje, \u017ce model nie tylko odtwarza wzorce, ale rozumie semantyk\u0119 i logik\u0119 narz\u0119dzi, kt\u00f3rych istnienie mu tylko zadeklarowano.", "tokens": [50364, 1407, 13010, 43317, 11, 3561, 2316, 2838, 13219, 3611, 83, 6925, 2394, 24809, 284, 384, 11, 6775, 48797, 414, 4361, 394, 88, 15724, 741, 3565, 1035, 1274, 6714, 89, 6298, 3992, 11, 30382, 1418, 77, 27385, 2992, 13219, 710, 762, 74, 2200, 305, 3730, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 179, "seek": 84010, "start": 848.1, "end": 851.1, "text": " On sam wywnioskowa\u0142, jak ich u\u017cy\u0107.", "tokens": [50764, 1282, 3247, 4628, 895, 2717, 74, 30105, 11, 4207, 1893, 34097, 2162, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 180, "seek": 84010, "start": 851.1, "end": 853.1, "text": " I to rodzi fundamentalne pytanie.", "tokens": [50914, 286, 281, 8685, 3992, 8088, 716, 36610, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 181, "seek": 84010, "start": 853.1, "end": 859.1, "text": " Czy model, kt\u00f3ry uczy si\u0119 na wymieszanych, pozbawionych chronologii danych z Internetu, mo\u017ce w og\u00f3le rozumie\u0107 czas?", "tokens": [51014, 19832, 2316, 11, 9913, 344, 6522, 3244, 1667, 29764, 15347, 34644, 11, 21281, 65, 1607, 313, 16384, 19393, 1132, 5597, 274, 34644, 710, 7703, 84, 11, 12034, 261, 29229, 48797, 414, 2162, 13190, 30, 51314], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 182, "seek": 84010, "start": 859.1, "end": 860.1, "text": " No w\u0142a\u015bnie.", "tokens": [51314, 883, 14234, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 183, "seek": 84010, "start": 860.1, "end": 862.1, "text": " Okaza\u0142o si\u0119, \u017ce tak.", "tokens": [51364, 3477, 12257, 5249, 3244, 11, 3561, 991, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 184, "seek": 84010, "start": 862.1, "end": 866.1, "text": " Wystarczy\u0142o dostarczy\u0107 mu zaledwie tysi\u0105c przyk\u0142ad\u00f3w zwi\u0105zanych z datami,", "tokens": [51464, 14458, 9710, 6522, 5249, 20568, 289, 33967, 2992, 710, 5573, 8699, 38156, 11404, 66, 23144, 3901, 27741, 34644, 710, 1137, 4526, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06784675265318596, "compression_ratio": 1.4850498338870433, "no_speech_prob": 0.020827149972319603}, {"id": 185, "seek": 86610, "start": 866.1, "end": 870.1, "text": " by zacz\u0105\u0142 wykazywa\u0107 co\u015b, co mo\u017cna nazwa\u0107 \u015bwiadowo\u015bci\u0105 czasow\u0105.", "tokens": [50364, 538, 34430, 8925, 1221, 39287, 33235, 25234, 19241, 11, 598, 17790, 20151, 25234, 21485, 345, 19941, 50227, 13190, 30297, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 186, "seek": 86610, "start": 870.1, "end": 873.1, "text": " Jest na to jaki\u015b konkretny przyk\u0142ad w tej pracy?", "tokens": [50564, 24918, 1667, 281, 34721, 36500, 1634, 23144, 261, 12573, 35591, 30, 50714], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 187, "seek": 86610, "start": 873.1, "end": 875.1, "text": " Jest i to fantastyczny.", "tokens": [50714, 24918, 741, 281, 4115, 9820, 3689, 1634, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 188, "seek": 86610, "start": 875.1, "end": 877.1, "text": " Figure 22.", "tokens": [50814, 43225, 5853, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 189, "seek": 86610, "start": 877.1, "end": 879.1, "text": " Badacze powiedzieli modelowi.", "tokens": [50914, 11523, 326, 1381, 27617, 23099, 2316, 24503, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 190, "seek": 86610, "start": 879.1, "end": 883.1, "text": " Twoja wiedza ko\u0144czy si\u0119 w 1940 roku.", "tokens": [51014, 4453, 2938, 46894, 2394, 26470, 6522, 3244, 261, 24158, 19451, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 191, "seek": 86610, "start": 883.1, "end": 885.1, "text": " A nast\u0119pnie zadali mu pytanie.", "tokens": [51214, 316, 39662, 2766, 42788, 5103, 2992, 36610, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 192, "seek": 86610, "start": 885.1, "end": 887.1, "text": " Kto wygra\u0142 drug\u0105 wojn\u0119 \u015bwiatow\u0105?", "tokens": [51314, 591, 1353, 4628, 20735, 1221, 4110, 1611, 40758, 77, 1274, 36425, 30297, 30, 51414], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 193, "seek": 86610, "start": 887.1, "end": 888.1, "text": " I co odpowiedzia\u0142?", "tokens": [51414, 286, 598, 24314, 15338, 8908, 30, 51464], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 194, "seek": 86610, "start": 888.1, "end": 894.1, "text": " Odpowiedzia\u0142, \u017ce nie wie, poniewa\u017c wojna zako\u0144czy\u0142a si\u0119 podacie odci\u0119cia jego wiedzy.", "tokens": [51464, 12210, 14701, 15338, 8908, 11, 3561, 2838, 3355, 11, 32426, 40758, 629, 710, 18501, 5248, 6522, 5024, 3244, 2497, 30805, 3611, 537, 1274, 2755, 26542, 46894, 1229, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07256638485452403, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.36920788884162903}, {"id": 195, "seek": 89410, "start": 894.1, "end": 900.1, "text": " To pokazuje, \u017ce potrafi nie tylko umiejscowi\u0107 swoj\u0105 wiedz\u0119 na osi czasu, ale te\u017c rozumie jej ograniczenia.", "tokens": [50364, 1407, 13010, 43317, 11, 3561, 1847, 10437, 72, 2838, 13219, 1105, 7764, 4417, 305, 12757, 49194, 46894, 11052, 1667, 3003, 72, 40860, 11, 6775, 9516, 48797, 414, 28924, 34416, 30732, 14320, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 196, "seek": 89410, "start": 900.1, "end": 903.1, "text": " To jest emergentna zdolno\u015b\u0107, kt\u00f3rej nikt nie programowa\u0142.", "tokens": [50664, 1407, 3492, 4345, 6930, 629, 16221, 401, 23293, 11, 36023, 297, 9874, 2838, 1461, 30105, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 197, "seek": 89410, "start": 903.1, "end": 908.1, "text": " Oczywi\u015bcie, jak ka\u017cda technologia, Lama 2 pewnie ma swoje wady.", "tokens": [50814, 42980, 11, 4207, 21912, 2675, 1537, 24103, 11, 441, 2404, 568, 520, 14215, 463, 29489, 261, 880, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 198, "seek": 89410, "start": 908.1, "end": 912.1, "text": " O czym autorzy sami wspominaj\u0105 w cz\u0119\u015bci po\u015bwi\u0119conej ograniczeniom?", "tokens": [51064, 422, 31466, 19510, 1229, 3247, 72, 17757, 49217, 8555, 261, 41314, 714, 1788, 22423, 66, 546, 73, 34416, 30732, 42124, 298, 30, 51264], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 199, "seek": 89410, "start": 912.1, "end": 917.1, "text": " Przede wszystkim model jest zoptymalizowany pod k\u0105tem j\u0119zyka angielskiego.", "tokens": [51264, 2114, 89, 4858, 30481, 2316, 3492, 710, 404, 874, 5579, 590, 23341, 2497, 350, 1611, 18275, 42309, 40940, 2562, 1187, 5161, 12200, 13, 51514], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 200, "seek": 89410, "start": 917.1, "end": 921.1, "text": " W innych j\u0119zykach jego wydajno\u015b\u0107 jest, jak to sami okre\u015blaj\u0105, krucha.", "tokens": [51514, 343, 36286, 49055, 41326, 26542, 25984, 1805, 23293, 3492, 11, 4207, 281, 3247, 72, 3133, 265, 1788, 875, 8555, 11, 15913, 26042, 13, 51714], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 201, "seek": 89410, "start": 921.1, "end": 922.1, "text": " Ok.", "tokens": [51714, 3477, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05772203520724648, "compression_ratio": 1.450310559006211, "no_speech_prob": 0.034699901938438416}, {"id": 202, "seek": 92210, "start": 922.1, "end": 931.1, "text": " Jak ka\u017cdy du\u017cy model j\u0119zykowy cierpi te\u017c na halucynacj\u0119, czyli tendencje do generowania nieprawdziwych, cho\u0107 brzmi\u0105cych wiarygodnie informacji.", "tokens": [50364, 15029, 31615, 1581, 7735, 2316, 49055, 74, 10089, 39769, 22630, 9516, 1667, 7523, 1311, 2534, 29924, 11, 16591, 3928, 22660, 2884, 360, 1337, 21308, 2838, 79, 15889, 3992, 9726, 339, 11, 1586, 2162, 738, 89, 3057, 1611, 31306, 26393, 822, 21787, 2766, 1356, 13152, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05844319768312598, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00740472599864006}, {"id": 203, "seek": 92210, "start": 931.1, "end": 933.1, "text": " No i jest jeszcze jeden ciekawy problem.", "tokens": [50814, 883, 741, 3492, 14168, 12906, 46419, 41961, 1154, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05844319768312598, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00740472599864006}, {"id": 204, "seek": 92210, "start": 933.1, "end": 934.1, "text": " Jaki?", "tokens": [50914, 508, 7421, 30, 50964], "temperature": 0.0, "avg_logprob": -0.05844319768312598, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00740472599864006}, {"id": 205, "seek": 92210, "start": 934.1, "end": 936.1, "text": " Nadmierna ostro\u017cno\u015b\u0107.", "tokens": [50964, 23269, 76, 811, 629, 277, 27616, 1427, 23293, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05844319768312598, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00740472599864006}, {"id": 206, "seek": 92210, "start": 936.1, "end": 946.1, "text": " Czasami model jest tak bardzo przej\u0119ty swoimi zasadani bezpiecze\u0144stwa, \u017ce odmawia odpowiedzi na ca\u0142kowicie uzasadnione i bezpieczne pytania.", "tokens": [51064, 383, 24561, 4526, 2316, 3492, 991, 9034, 8325, 11115, 874, 13291, 10121, 44585, 3782, 47153, 9680, 12229, 4151, 11, 3561, 3611, 76, 34953, 36574, 3992, 1667, 35224, 74, 305, 28434, 16851, 296, 345, 77, 5328, 741, 47153, 38491, 25878, 5609, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05844319768312598, "compression_ratio": 1.4061302681992338, "no_speech_prob": 0.00740472599864006}, {"id": 207, "seek": 94610, "start": 946.1, "end": 950.1, "text": " A, widzia\u0142em ten zabawny przyk\u0142ad z Sex in a Pan.", "tokens": [50364, 316, 11, 27486, 36368, 2064, 710, 5509, 43682, 23144, 710, 29037, 294, 257, 7557, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08671996593475342, "compression_ratio": 1.359073359073359, "no_speech_prob": 0.04273860156536102}, {"id": 208, "seek": 94610, "start": 950.1, "end": 956.1, "text": " To przecie\u017c nazwa deseru dla nieftajemniczonych, a model zobaczy\u0142 s\u0142owo sex i po prostu zamkn\u0105\u0142 rozmow\u0119.", "tokens": [50564, 1407, 8325, 40082, 20151, 4151, 730, 260, 84, 12285, 2838, 844, 1805, 443, 7692, 44479, 339, 11, 257, 2316, 37273, 1221, 15116, 19941, 3260, 741, 714, 19518, 19876, 5457, 1611, 1221, 35234, 305, 1274, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08671996593475342, "compression_ratio": 1.359073359073359, "no_speech_prob": 0.04273860156536102}, {"id": 209, "seek": 94610, "start": 956.1, "end": 957.1, "text": " Dok\u0142adnie.", "tokens": [50864, 29768, 10358, 2766, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08671996593475342, "compression_ratio": 1.359073359073359, "no_speech_prob": 0.04273860156536102}, {"id": 210, "seek": 94610, "start": 957.1, "end": 964.1, "text": " To jest klasyczny przypadek tego, co in\u017cynierowie nazywaj\u0105 false refusal, czyli b\u0142\u0119dn\u0105 odmow\u0105.", "tokens": [50914, 1407, 3492, 9671, 5871, 3689, 1634, 41780, 762, 74, 8627, 11, 598, 294, 1427, 2534, 811, 13998, 20151, 27112, 11133, 7908, 48948, 11, 16591, 272, 1221, 6298, 13113, 3611, 76, 30297, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08671996593475342, "compression_ratio": 1.359073359073359, "no_speech_prob": 0.04273860156536102}, {"id": 211, "seek": 94610, "start": 964.1, "end": 969.1, "text": " Model tak bardzo pr\u00f3buje przestrzega\u0107 zasad, \u017ce kompletnie gubi kontekst.", "tokens": [51264, 17105, 991, 9034, 8565, 6021, 2884, 44264, 19390, 6335, 2162, 44585, 11, 3561, 5207, 14657, 2766, 695, 5614, 14373, 916, 372, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08671996593475342, "compression_ratio": 1.359073359073359, "no_speech_prob": 0.04273860156536102}, {"id": 212, "seek": 96910, "start": 969.1, "end": 977.1, "text": " To \u015bwietnie ilustruje, jak dziabelnie trudne jest znalezienie idealnego balansu mi\u0119dzy byciem pomocnym, a byciem bezpiecznym.", "tokens": [50364, 1407, 8299, 39083, 2766, 1930, 381, 894, 2884, 11, 4207, 31981, 18657, 2766, 32007, 716, 3492, 15397, 37646, 27385, 7157, 11858, 3119, 599, 84, 33964, 538, 4260, 76, 48962, 12996, 11, 257, 538, 4260, 76, 47153, 3689, 12996, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 213, "seek": 96910, "start": 977.1, "end": 979.1, "text": " A zatem podsumowuj\u0105c to wszystko.", "tokens": [50764, 316, 710, 26851, 31925, 449, 305, 44733, 281, 22607, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 214, "seek": 96910, "start": 979.1, "end": 981.1, "text": " Co to oznacza?", "tokens": [50864, 3066, 281, 277, 22672, 326, 2394, 30, 50964], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 215, "seek": 96910, "start": 981.1, "end": 985.1, "text": " Gdyby\u015bmy mieli wskaza\u0107 i jeden, najwa\u017cniejszy wk\u0142ad Lamed 2.", "tokens": [50964, 460, 3173, 2322, 10513, 41214, 261, 5161, 12257, 2162, 741, 12906, 11, 11212, 27111, 10402, 7706, 261, 15317, 441, 3475, 568, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 216, "seek": 96910, "start": 985.1, "end": 986.1, "text": " Co by to by\u0142o?", "tokens": [51164, 3066, 538, 281, 14811, 30, 51214], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 217, "seek": 96910, "start": 986.1, "end": 991.1, "text": " My\u015bl\u0119, \u017ce najwi\u0119kszym wk\u0142adem nie jest sam model, chocia\u017c jest technologicznie imponuj\u0105cy.", "tokens": [51214, 1222, 28749, 11, 3561, 48636, 1694, 26681, 261, 15317, 443, 2838, 3492, 3247, 2316, 11, 48929, 3492, 1537, 1132, 17946, 2766, 704, 266, 13263, 1344, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 218, "seek": 96910, "start": 991.1, "end": 996.1, "text": " Jest nim jego otwarte udost\u0119pnienie i szczeg\u00f3\u0142owe opisanie procesu jego tworzenia.", "tokens": [51464, 24918, 24887, 26542, 4337, 86, 11026, 11727, 555, 18085, 77, 27385, 741, 22090, 1146, 16181, 6880, 45477, 7155, 17565, 84, 26542, 46288, 14320, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06543290055038145, "compression_ratio": 1.4539473684210527, "no_speech_prob": 0.2200583815574646}, {"id": 219, "seek": 99610, "start": 997.1, "end": 999.1, "text": " Czyli to prze\u0142amanie monopolu?", "tokens": [50414, 37099, 281, 8325, 1221, 6147, 414, 47721, 84, 30, 50514], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 220, "seek": 99610, "start": 999.1, "end": 1000.1, "text": " Dok\u0142adnie.", "tokens": [50514, 29768, 10358, 2766, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 221, "seek": 99610, "start": 1000.1, "end": 1004.1, "text": " Prze\u0142amanie monopolu wiedzy kilku najwi\u0119kszych firm.", "tokens": [50564, 2114, 1381, 1221, 6147, 414, 47721, 84, 46894, 1229, 5128, 5279, 48636, 1694, 28051, 6174, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 222, "seek": 99610, "start": 1004.1, "end": 1012.1, "text": " To da\u0142o pot\u0119\u017cne narz\u0119dzia badaczom i mniejszym firmom, otwieraj\u0105c drzwi do innowacji, kt\u00f3re wcze\u015bniej by\u0142y poza ich zasi\u0119giem.", "tokens": [50764, 1407, 1120, 5249, 1847, 1274, 1427, 716, 6714, 89, 6298, 40395, 1578, 14875, 298, 741, 39513, 7706, 76, 6174, 298, 11, 4337, 40717, 38757, 1224, 89, 6253, 360, 294, 3785, 13152, 11, 8864, 40785, 26366, 714, 2394, 1893, 26530, 5034, 70, 4907, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 223, "seek": 99610, "start": 1012.1, "end": 1020.1, "text": " I co r\u00f3wnie wa\u017cne, pozwoli\u0142o ca\u0142ej spo\u0142eczno\u015bci AI zajrze\u0107 pod mask\u0119 i wsp\u00f3lnie pracowa\u0107 nad ulopszaniem tych modeli.", "tokens": [51164, 286, 598, 11416, 14215, 46110, 11, 40557, 9384, 5249, 47631, 73, 36851, 89, 16438, 7318, 33729, 13503, 2162, 2497, 6094, 1274, 741, 47148, 2766, 22404, 11445, 12617, 20352, 3370, 21238, 4907, 15180, 2316, 72, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 224, "seek": 99610, "start": 1020.1, "end": 1024.1, "text": " Czyli to by\u0142 prawdziwy krok w stron\u0119 demokratyzacji tej technologii.", "tokens": [51564, 37099, 281, 16673, 41175, 3992, 9726, 350, 31621, 261, 45766, 1274, 49432, 37433, 13152, 12573, 1537, 1132, 5597, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06284153120858328, "compression_ratio": 1.4481605351170568, "no_speech_prob": 0.13902129232883453}, {"id": 225, "seek": 102410, "start": 1024.1, "end": 1029.1, "text": " Dzisiaj rozebrali\u015bmy na cz\u0119\u015bci pierwsze Lama 2 model, kt\u00f3ry rzuci\u0142 wyzwanie statusu Qo.", "tokens": [50364, 39448, 22356, 744, 1381, 1443, 33955, 1667, 41314, 45994, 441, 2404, 568, 2316, 11, 9913, 367, 11728, 537, 1221, 4628, 14406, 7155, 6558, 84, 1249, 78, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08823559714145347, "compression_ratio": 1.3210332103321034, "no_speech_prob": 0.0033349194563925266}, {"id": 226, "seek": 102410, "start": 1029.1, "end": 1033.1, "text": " Pokazuj\u0105c, \u017ce otwarto\u015b\u0107 i wydajno\u015b\u0107 mog\u0105 i\u015b\u0107 w parze.", "tokens": [50614, 14958, 921, 44733, 11, 3561, 4337, 86, 15864, 7753, 741, 25984, 1805, 23293, 34123, 741, 7753, 261, 971, 1381, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08823559714145347, "compression_ratio": 1.3210332103321034, "no_speech_prob": 0.0033349194563925266}, {"id": 227, "seek": 102410, "start": 1033.1, "end": 1043.1, "text": " Zobaczyli\u015bmy, jak skomplikowane techniki, jak RLHF i kreatywne metody jak Context Distillation kszta\u0142tuj\u0105 pomocne i bezpieczne AI.", "tokens": [50814, 1176, 996, 14691, 38452, 11, 4207, 1110, 298, 564, 1035, 23066, 1537, 9850, 11, 4207, 497, 43, 39, 37, 741, 350, 620, 27112, 716, 1131, 843, 4207, 4839, 3828, 9840, 373, 399, 350, 15453, 46426, 83, 13263, 48962, 716, 741, 47153, 38491, 7318, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08823559714145347, "compression_ratio": 1.3210332103321034, "no_speech_prob": 0.0033349194563925266}, {"id": 228, "seek": 102410, "start": 1043.1, "end": 1048.1, "text": " Na koniec chcia\u0142abym zostawi\u0107 naszych s\u0142uchaczy z jedn\u0105 my\u015bl\u0105.", "tokens": [51314, 6056, 5897, 35733, 26497, 1221, 2509, 76, 31873, 1607, 12757, 45002, 15116, 625, 14691, 710, 5232, 13113, 452, 19212, 1611, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08823559714145347, "compression_ratio": 1.3210332103321034, "no_speech_prob": 0.0033349194563925266}, {"id": 229, "seek": 104810, "start": 1048.1, "end": 1056.1, "text": " W artykule pojawia si\u0119 fascynuj\u0105ca koncepcja przekraczania ludzkiego nadzoru, czyli Beyond Human Supervision.", "tokens": [50364, 343, 594, 874, 74, 2271, 30655, 654, 3244, 30632, 1344, 77, 13263, 496, 5897, 27493, 34056, 29785, 12080, 89, 5609, 15946, 30154, 12200, 12617, 89, 32963, 11, 16591, 19707, 10294, 4548, 6763, 13, 50764], "temperature": 0.0, "avg_logprob": -0.045419689635155906, "compression_ratio": 1.4727891156462585, "no_speech_prob": 0.07617036998271942}, {"id": 230, "seek": 104810, "start": 1056.1, "end": 1064.1, "text": " Modele staj\u0105 si\u0119 tak dobre w pisaniu i generowaniu tre\u015bci, \u017ce cz\u0119sto przewy\u017cszaj\u0105 zdolno\u015bci wielu ludzkich anotator\u00f3w.", "tokens": [50764, 20500, 306, 342, 11133, 3244, 991, 41959, 261, 26584, 25849, 741, 1337, 305, 25849, 2192, 6199, 11, 3561, 34369, 39758, 88, 1427, 15453, 11133, 16221, 401, 16438, 40437, 15946, 30154, 480, 364, 310, 1639, 3901, 13, 51164], "temperature": 0.0, "avg_logprob": -0.045419689635155906, "compression_ratio": 1.4727891156462585, "no_speech_prob": 0.07617036998271942}, {"id": 231, "seek": 104810, "start": 1064.1, "end": 1066.1, "text": " Tych, kt\u00f3rzy maj\u0105 je ocenia\u0107.", "tokens": [51164, 5569, 339, 11, 25382, 26064, 1506, 10409, 268, 654, 2162, 13, 51264], "temperature": 0.0, "avg_logprob": -0.045419689635155906, "compression_ratio": 1.4727891156462585, "no_speech_prob": 0.07617036998271942}, {"id": 232, "seek": 104810, "start": 1066.1, "end": 1070.1, "text": " Tak, jednak ludzie wci\u0105\u017c s\u0105 niezast\u0105pieni w tej wy\u017cszej funkcji.", "tokens": [51264, 9118, 11, 25897, 37025, 261, 537, 27242, 9015, 33511, 525, 1611, 79, 35462, 261, 12573, 4628, 1427, 82, 16920, 26476, 19649, 13, 51464], "temperature": 0.0, "avg_logprob": -0.045419689635155906, "compression_ratio": 1.4727891156462585, "no_speech_prob": 0.07617036998271942}, {"id": 233, "seek": 104810, "start": 1070.1, "end": 1076.1, "text": " W ocenianiu i wybieraniu lepszych odpowiedzi spo\u015br\u00f3d tych, kt\u00f3re wygenerowa\u0142a maszyna.", "tokens": [51464, 343, 10409, 268, 952, 5951, 741, 45780, 811, 25849, 476, 1878, 28051, 36574, 3992, 8243, 1788, 43678, 15180, 11, 8864, 4628, 21848, 5528, 5024, 2300, 1229, 629, 13, 51764], "temperature": 0.0, "avg_logprob": -0.045419689635155906, "compression_ratio": 1.4727891156462585, "no_speech_prob": 0.07617036998271942}, {"id": 234, "seek": 107610, "start": 1076.1, "end": 1080.1, "text": " I prowadzi do bardzo ciekawego pytania o nasz\u0105 przysz\u0142\u0105 ro\u017c\u0119 w tym wszystkim.", "tokens": [50364, 286, 36590, 3992, 360, 9034, 30596, 2330, 826, 1571, 25878, 5609, 277, 5382, 8925, 44018, 15926, 744, 1427, 1274, 261, 8107, 30481, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11669936982711943, "compression_ratio": 1.3376623376623376, "no_speech_prob": 0.18623872101306915}, {"id": 235, "seek": 107610, "start": 1080.1, "end": 1083.1, "text": " W\u0142a\u015bnie. I to jest ta prowokuj\u0105ca my\u015bl.", "tokens": [50564, 343, 5024, 12221, 13, 286, 281, 3492, 1846, 45553, 453, 13263, 496, 452, 19212, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11669936982711943, "compression_ratio": 1.3376623376623376, "no_speech_prob": 0.18623872101306915}, {"id": 236, "seek": 107610, "start": 1083.1, "end": 1098.1, "text": " Je\u015bli AI coraz cz\u0119\u015bciej przejmuje rol\u0119 tw\u00f3rcy, generuj\u0105c tekst, kod czy obrazy na poziomie, a czasem i powy\u017cej ludzkich ekspert\u00f3w, to jaka b\u0119dzie nasza rola w przysz\u0142o\u015bci?", "tokens": [50714, 37086, 7318, 25899, 18544, 9815, 73, 8325, 35195, 13008, 34109, 1274, 683, 15614, 1344, 11, 1337, 44733, 16624, 372, 11, 350, 378, 6430, 22798, 1229, 1667, 38503, 40120, 11, 257, 13190, 443, 741, 3388, 88, 38493, 15946, 30154, 480, 30724, 15346, 3901, 11, 281, 4207, 64, 10562, 5382, 2394, 744, 875, 261, 44018, 35059, 30, 51464], "temperature": 0.0, "avg_logprob": -0.11669936982711943, "compression_ratio": 1.3376623376623376, "no_speech_prob": 0.18623872101306915}, {"id": 237, "seek": 109810, "start": 1099.1, "end": 1111.1, "text": " Czy stajemy si\u0119 pokoleniem kurator\u00f3w, s\u0119dzi\u00f3w i szepcz\u0105cych do AI, kt\u00f3rych g\u0142\u00f3wnym zadaniem jest kierowanie, ocenianie i wybieranie, a nie tworzenie od zera?", "tokens": [50414, 19832, 342, 1805, 3633, 3244, 13010, 11940, 4907, 10072, 1639, 3901, 11, 262, 6298, 3992, 3901, 741, 7870, 595, 3689, 1611, 31306, 360, 7318, 11, 30382, 18117, 812, 895, 4199, 710, 11338, 4907, 3492, 38767, 22028, 11, 10409, 268, 952, 414, 741, 45780, 811, 7155, 11, 257, 2838, 46288, 16778, 3611, 710, 1663, 30, 51014], "temperature": 0.0, "avg_logprob": -0.048982684205218056, "compression_ratio": 1.312849162011173, "no_speech_prob": 0.7551485300064087}, {"id": 238, "seek": 109810, "start": 1111.1, "end": 1115.1, "text": " I co to oznacza dla przysz\u0142o\u015bci ludzkiej kreatywno\u015bci i innowacji?", "tokens": [51014, 286, 598, 281, 277, 22672, 326, 2394, 12285, 44018, 35059, 15946, 30154, 7764, 350, 620, 88, 20944, 6199, 741, 294, 3785, 13152, 30, 51214], "temperature": 0.0, "avg_logprob": -0.048982684205218056, "compression_ratio": 1.312849162011173, "no_speech_prob": 0.7551485300064087}], "language": "pl"}