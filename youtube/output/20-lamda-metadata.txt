TYTUÅ:
LaMDA: Jak Google Uczy AI MÃ³wiÄ‡ PrawdÄ™ i ByÄ‡ BezpiecznÄ… | Deep Dive

OPIS:
ğŸ™ï¸ GÅ‚Ä™boka analiza przeÅ‚omowej pracy badawczej Google - LaMDA (Language Models for Dialogue Applications). Omawiamy dlaczego samo powiÄ™kszanie modeli jÄ™zykowych nie rozwiÄ…zuje problemu halucynacji i jak dwuÅ›cieÅ¼kowe dostrajanie (fine-tuning) zmienia zasady gry.

W tym odcinku omawiamy:
â€¢ Dlaczego wiÄ™ksze modele nie sÄ… automatycznie mÄ…drzejsze - puÅ‚apka pÅ‚ynnoÅ›ci vs prawdomÃ³wnoÅ›ci
â€¢ Metryki SSI (Sensibleness, Specificity, Interestingness) - jak nauczyÄ‡ AI "dobrej" konwersacji
â€¢ Mechanizm wewnÄ™trznego krytyka - model ktÃ³ry sam ocenia i filtruje swoje odpowiedzi
â€¢ Toolset - jak LaMDA nauczyÅ‚a siÄ™ siÄ™gaÄ‡ po zewnÄ™trzne ÅºrÃ³dÅ‚a wiedzy zamiast zmyÅ›laÄ‡
â€¢ PrzykÅ‚ady z artykuÅ‚u: Rosalia Gascon, WieÅ¼a Eiffla, Mount Everest
â€¢ Wyniki: gigantyczny postÄ™p w jakoÅ›ci, ale wciÄ…Å¼ luka do ludzkiego poziomu w bezpieczeÅ„stwie
â€¢ Etyczne implikacje AI tak dobrej w konwersacji, Å¼e zapominamy Å¼e to maszyna

ğŸ“„ Oryginalny artykuÅ‚: https://arxiv.org/abs/2201.08239

Autorzy: Romal Thoppilan, Daniel De Freitas, Jamie Hall et al. (Google Research)

TAGI:
#AI #MachineLearning #DeepLearning #LaMDA #Google #NLP #Chatbot #LLM #FineTuning #Safety #FactualGrounding #Halucynacje #SztucznaInteligencja
