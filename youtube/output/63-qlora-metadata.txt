TYTUÅ:
QLoRA: Dostrajanie Gigantycznych Modeli na Jednej Karcie GPU | Deep Dive

OPIS:
ğŸ™ï¸ W tym odcinku badamy przeÅ‚omowÄ… technikÄ™ QLoRA, ktÃ³ra umoÅ¼liwia dostrajanie modeli o 65 miliardach parametrÃ³w na pojedynczej karcie GPU z 48GB pamiÄ™ci - zamiast wymaganych 780GB! Autorzy Å‚Ä…czÄ… kwantyzacjÄ™ 4-bitowÄ… z adapterami LoRA, wprowadzajÄ…c kluczowe innowacje: NF4 (4-bitowy typ danych zoptymalizowany pod rozkÅ‚ad normalny), podwÃ³jnÄ… kwantyzacjÄ™ oraz stronicowane optymalizatory.

W tym odcinku omawiamy:
â€¢ Problem: Dostrajanie modeli jÄ™zykowych poza zasiÄ™giem wiÄ™kszoÅ›ci zespoÅ‚Ã³w (wymagania pamiÄ™ciowe >780GB)
â€¢ Kwantyzacja: Redukcja precyzji wag z 16-bit do 4-bit przy zachowaniu jakoÅ›ci
â€¢ LoRA (Low-Rank Adapters): Dostrajanie tylko niewielkiej czÄ™Å›ci parametrÃ³w zamiast caÅ‚ego modelu
â€¢ PrzeÅ‚om QLoRA: PoÅ‚Ä…czenie 4-bitowego modelu bazowego z trenowalnymi adapterami
â€¢ NF4: Teoretycznie optymalny typ danych dla wag o rozkÅ‚adzie normalnym
â€¢ PodwÃ³jna kwantyzacja: Kompresowanie metadanych o kompresji
â€¢ Stronicowane optymalizatory: Ochrona przed skokami zuÅ¼ycia pamiÄ™ci GPU
â€¢ Wyniki: Guanaco 65B osiÄ…ga 99.3% wydajnoÅ›ci ChatGPT na benchmarku Vicuna
â€¢ Wnioski: JakoÅ›Ä‡ danych waÅ¼niejsza niÅ¼ ich iloÅ›Ä‡
â€¢ WpÅ‚yw: Demokratyzacja dostÄ™pu do najnowoczeÅ›niejszych modeli jÄ™zykowych
â€¢ Ograniczenia: SÅ‚aboÅ›ci w matematyce i podatnoÅ›Ä‡ na prompt injection

ğŸ“„ Oryginalny artykuÅ‚: https://arxiv.org/abs/2305.14314

Autorzy: Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer (University of Washington)

ğŸ’¡ Masz propozycjÄ™ artykuÅ‚u? ZgÅ‚oÅ›: https://github.com/Automaat/youtube-whitepapers/issues

TAGI:
#AI #MachineLearning #DeepLearning #QLoRA #LoRA #Kwantyzacja #FineTuning #LLM #DuÅ¼eModeleJÄ™zykowe #Guanaco #Optymalizacja #NF4 #GÅ‚Ä™bokiOdczyt #Podcast
