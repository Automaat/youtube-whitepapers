TYTUÅ:
T0: Wielozadaniowy Trening z Promptami dla Generalizacji Zero-Shot | Deep Dive

OPIS:
ğŸ™ï¸ PrzeÅ‚omowa praca pokazujÄ…ca, jak mniejszy model (11B) moÅ¼e pokonaÄ‡ gigantÃ³w (175B) dziÄ™ki inteligentnemu treningowi wielozadaniowemu zamiast brutalnej siÅ‚y skalowania.

W tym odcinku omawiamy:
â€¢ Paradygmat "Finezja ponad siÅ‚Ä…" - jak T0 rzuca wyzwanie dogmatowi "wiÄ™kszy = lepszy"
â€¢ Zero-Shot Generalization - zdolnoÅ›Ä‡ do wykonywania zadaÅ„ bez wczeÅ›niejszego treningu
â€¢ Metodologia Multitask Prompted Training - jawny trening na zrÃ³Å¼nicowanych promptach
â€¢ PromptSource i P3 - otwarty projekt 36 autorÃ³w z 24 instytucji w 8 krajach
â€¢ Rewelacyjne wyniki - T0 (11B) pokonuje GPT-3 (175B) na 9 z 11 zadaÅ„ testowych
â€¢ OdpornoÅ›Ä‡ na prompty - gÅ‚Ä™bia wariantÃ³w waÅ¼niejsza niÅ¼ szerokoÅ›Ä‡ zadaÅ„
â€¢ PorÃ³wnanie z FLAN - przewaga ludzkiej kreatywnoÅ›ci w tworzeniu promptÃ³w
â€¢ Implikacje dla przyszÅ‚oÅ›ci AI - bardziej zrÃ³wnowaÅ¼ony i demokratyczny rozwÃ³j

ğŸ“„ Oryginalny artykuÅ‚: https://arxiv.org/abs/2110.08207

Autorzy: Victor Sanh i zespÃ³Å‚ BigScience (36 autorÃ³w z 24 instytucji w 8 krajach)

TAGI:
#AI #MachineLearning #DeepLearning #NLP #T0 #ZeroShot #BigScience #PromptEngineering #Transformers #HuggingFace #LLM #LanguageModels #MultitaskLearning #AIResearch
