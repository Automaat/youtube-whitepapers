TYTUÅ:
Minerva: UczÄ…c Maszyny JÄ™zyka Matematyki | Deep Dive

OPIS:
ğŸ™ï¸ W tym odcinku omawiamy przeÅ‚omowy model Minerva od Google Research, ktÃ³ry osiÄ…ga zaawansowane rozumowanie matematyczne i naukowe. Analizujemy jak duÅ¼e modele jÄ™zykowe mogÄ… nauczyÄ‡ siÄ™ "jÄ™zyka matematyki" dziÄ™ki specjalistycznym danym treningowym.

W tym odcinku omawiamy:
â€¢ Dlaczego rozumowanie iloÅ›ciowe (quantitative reasoning) jest tak trudne dla LLM-Ã³w
â€¢ Anatomia wyzwania: 4 kluczowe umiejÄ™tnoÅ›ci potrzebne do rozwiÄ…zywania zadaÅ„ matematycznych
â€¢ Specjalna "dieta treningowa" Minervy: 38,5 miliarda tokenÃ³w danych technicznych
â€¢ Technika gÅ‚osowania wiÄ™kszoÅ›ciowego (Majority Voting) jako sposÃ³b na zwiÄ™kszenie dokÅ‚adnoÅ›ci
â€¢ Wyniki: od 6,9% do 50,3% na benchmarku MATH (poziom olimpiad matematycznych)
â€¢ Czy Minerva to myÅ›liciel czy plagiator? 3 testy weryfikujÄ…ce
â€¢ Ograniczenia: brak formalnej weryfikacji, narzÄ™dzi zewnÄ™trznych i przejrzystoÅ›ci
â€¢ Wizja przyszÅ‚oÅ›ci: hybrydowe systemy Å‚Ä…czÄ…ce rozumowanie z precyzjÄ… narzÄ™dzi

ğŸ“„ Oryginalny artykuÅ‚: https://arxiv.org/abs/2206.14858

Autorzy: Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, et al. (Google Research)

TAGI:
#AI #MachineLearning #DeepLearning #Minerva #GoogleResearch #MathematicalReasoning #LLM #QuantitativeReasoning #STEM #LanguageModels #SztucznaInteligencja #Matematyka
