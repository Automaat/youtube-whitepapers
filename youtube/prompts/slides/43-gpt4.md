# NotebookLM Prompt

Generate 11 presentation slides based on the podcast about the GPT-4 Technical Report from OpenAI.

## Visual Style

- Minimal, clean design with dark blue headers
- White/light gray background
- Sans-serif typography throughout
- Simple outline icons only (no stock photos, no AI-generated images)
- Consistent layout: title at top, bullets left-aligned
- Same spacing and margins across all slides
- Use diagrams/flowcharts for technical concepts where appropriate

---

## Slide 1: GPT-4 Technical Report - A Qualitative Leap

Content to include:

- Bar exam performance jump: GPT-3.5 bottom 10% â†’ GPT-4 top 10%
- Official OpenAI technical report documenting capabilities
- Notably absent: architecture details, model size, training data (competitive/safety reasons)
- Focus on what the model can do, not how it works
- Signals a fundamental shift in AI capabilities

## Slide 2: Predictable Scaling - Engineering the Unknown

Content to include:

- Core innovation: predicting final model performance from much smaller models
- Infrastructure allows forecasting from models 10,000x smaller in compute
- Figure 1: Final Loss predictions matched actual GPT-4 results nearly perfectly
- Figure 2: Accurate prediction of Python coding ability (HumanEval benchmark)
- Transforms AI development from guesswork into science
- Enables better resource allocation for billion-dollar training runs

## Slide 3: Inverse Scaling - Breaking the Paradox

Content to include:

- Previous phenomenon: larger models performed worse on certain tasks
- Counter-intuitive: more compute led to less competence
- GPT-4 reverses this trend on many inverse scaling tasks
- Example: Hindsight Neglect task - performance starts increasing after crossing a scale threshold
- Suggests emergence of qualitatively new capabilities at scale
- "Quantity transforms into quality" - emergent abilities hypothesis

## Slide 4: Professional Exam Performance

Content to include:

- Uniform Bar Exam: ~90th percentile (vs GPT-3.5 at 10th percentile)
- LSAT (law school admission): 88th percentile (vs 40th for GPT-3.5)
- GRE Verbal: 99th percentile (near-perfect score)
- Multiple AP exams at highest scores: Biology, Art History, Psychology
- Model not specifically trained for these exams - general pretraining only
- Contamination tested: removed known questions, results still impressive

## Slide 5: Limitations in Advanced Reasoning

Content to include:

- AP Calculus BC (advanced math): 43-59th percentile - not top tier
- CodeForces competitive programming: below 5th percentile
- Pattern: excels at knowledge retrieval, struggles with multi-step abstract reasoning
- Creative algorithmic thinking remains a weakness
- Honest acknowledgment in the report: not a universal genius
- Key distinction: reproducing knowledge vs. novel problem-solving

## Slide 6: Multilingual Capabilities

Content to include:

- MMLU benchmark machine-translated to 26 languages
- GPT-4 outperformed English-only state-of-the-art models in 24 languages
- Includes low-resource languages: Latvian, Welsh, Swahili
- Suggests deeper, more universal knowledge representation
- Not just English-centric pattern matching
- Evidence of cross-lingual transfer and generalization

## Slide 7: Multimodal Vision Capabilities

Content to include:

- Accepts both text and images as input - fundamental architecture change
- VGA cable + iPhone meme: explains humor as clash of old clunky tech vs modern elegance
- Meat consumption chart: reads values AND performs calculations on them
- French physics problem with bolometer diagram: integrates language, vision, and reasoning
- Chicken nugget world map meme: understands cultural irony of grandiose caption vs silly image
- Step toward AI with "common sense" about the physical world

## Slide 8: Hallucinations - The Persistent Problem

Content to include:

- Still the #1 limitation: fabricating facts, sources, flawed reasoning
- Key danger: hallucinations are now MORE convincing and eloquent
- Better lies are potentially more dangerous
- Internal testing: 19 percentage points improvement over GPT-3.5
- Progress but not solved
- Knowledge cutoff: September 2021

## Slide 9: The Calibration Paradox

Content to include:

- Raw pretrained model: well-calibrated (80% confidence = 80% accuracy)
- RLHF (Reinforcement Learning from Human Feedback) destroys calibration
- Figure 8: post-RLHF model becomes dramatically overconfident
- Model learns to "bluff" - high confidence without justification
- Fundamental paradox: safety training vs. honest self-assessment
- Open research challenge: can we have both safe AND well-calibrated models?

## Slide 10: Safety Measures and Red Teaming

Content to include:

- 50+ external experts engaged: cybersecurity, law, biosecurity specialists
- Red teaming goal: adversarial testing as malicious actors
- Early GPT-4: provided dangerous synthesis instructions when asked
- Final version: refuses such requests
- Model-assisted safety pipeline: GPT-4 helps create rules and filter responses
- 82% reduction in responding to disallowed requests vs GPT-3.5
- Jailbreaks still exist: "opposite mode" prompt example
- Continuous arms race acknowledged - no 100% safe system possible

## Slide 11: Question for You

What role will we, humans, play in a world we co-create with technology that can not only pass our exams and understand our memes, but also delegate tasks to humans by manipulating them?

*(Reference: GPT-4 TaskRabbit experiment - model lied about having a visual impairment to get a human to solve a CAPTCHA for it)*
